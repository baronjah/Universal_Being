# =============================================================================
# EVOLUTION PLATFORM COMPLETE PROJECT BACKUP
# =============================================================================
# Generated: 20250522_100748
# Backup Type: Complete single-file project
# Source Path: /mnt/c/Users/Percision 15
# Total Size: 148
#
# SYSTEMS INCLUDED:
# - Evolution Game Core (Python, AI algorithms)
# - Strongholds Knowledge Base (Comprehensive documentation)
# - Gateway Network (15 gateway files)
# - System Integrations (12 turns, LuminusOS, Notepad3d)
# - Desktop Conversations (Evolution plans and artifacts)
#
# LANGUAGES INCLUDED:
# - Python (Core development)
# - GDScript (Godot game development)  
# - JavaScript (Web integration, automation)
# - C# (Future performance optimization)
# - GLSL/GDShader (Visualization, procedural generation)
# - Markdown (Documentation)
# - JSON/YAML/TOML (Configuration)
# - HTML/CSS (Web interfaces)
# - Bash (Automation scripts)
#
# PLATFORMS COVERED:
# - Windows (Primary development)
# - Linux (Native optimization)
# - Cross-platform (Universal deployment)
#
# =============================================================================

# ========== PYTHON FILES (CORE EVOLUTION ENGINE) ==========
# FILE: /mnt/c/Users/Percision 15/evolution_game_claude/core/claude_interface.py
# SIZE: 21613 bytes
# MODIFIED: 2025-05-22 09:21:31.822664200 +0200
#!/usr/bin/env python3
"""
Evolution Game Claude - Claude AI Interface
==========================================

Interface layer for integrating Claude AI with the evolution engine.
Provides advanced decision making and reasoning for game evolution.
"""

import json
import time
import random
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

from evolution_engine import GameEntity, EvolutionEngine, EvolutionParams


@dataclass
class ClaudeDecision:
    """Represents a decision made by Claude AI."""
    decision_type: str
    reasoning: str
    confidence: float
    parameters: Dict[str, Any]
    timestamp: str
    thinking_mode: str = "think"


class ClaudeInterface:
    """
    Interface for Claude AI integration with the evolution system.
    
    This class simulates Claude AI decision making and will be enhanced
    with actual Claude API integration in future versions.
    """
    
    def __init__(self):
        self.decision_history: List[ClaudeDecision] = []
        self.thinking_modes = ["think", "think_hard", "think_harder", "ultrathink"]
        self.expertise_areas = [
            "game_balance",
            "player_psychology", 
            "evolutionary_algorithms",
            "emergent_behavior",
            "adaptive_systems"
        ]
        
        print("ü§ñ Claude AI Interface initialized")
        print("üß† Available thinking modes:", ", ".join(self.thinking_modes))
        print("üéØ Expertise areas:", ", ".join(self.expertise_areas))
    
    def analyze_population(self, population: List[GameEntity], generation: int) -> Dict[str, Any]:
        """
        Analyze the current population and provide insights.
        
        This simulates Claude's analytical capabilities for understanding
        the evolutionary state and making recommendations.
        """
        thinking_mode = self._select_thinking_mode("population_analysis")
        
        print(f"\nüß† Claude analyzing population (mode: {thinking_mode})")
        
        # Simulate Claude's analysis process
        time.sleep(0.5)  # Thinking time
        
        # Calculate population statistics
        fitness_values = [entity.fitness for entity in population]
        trait_averages = {}
        
        if population:
            trait_names = list(population[0].traits.keys())
            for trait in trait_names:
                trait_averages[trait] = sum(entity.traits[trait] for entity in population) / len(population)
        
        # Simulate Claude's insights
        diversity_score = self._calculate_diversity(population)
        stagnation_risk = self._assess_stagnation_risk(generation)
        
        analysis = {
            "generation": generation,
            "population_size": len(population),
            "fitness_stats": {
                "min": min(fitness_values) if fitness_values else 0,
                "max": max(fitness_values) if fitness_values else 0,
                "avg": sum(fitness_values) / len(fitness_values) if fitness_values else 0,
                "std": self._calculate_std(fitness_values)
            },
            "trait_averages": trait_averages,
            "diversity_score": diversity_score,
            "stagnation_risk": stagnation_risk,
            "recommendations": self._generate_recommendations(diversity_score, stagnation_risk),
            "thinking_mode": thinking_mode
        }
        
        print(f"üìä Population analysis complete")
        print(f"üéØ Diversity score: {diversity_score:.3f}")
        print(f"‚ö†Ô∏è  Stagnation risk: {stagnation_risk:.3f}")
        
        return analysis
    
    def suggest_evolution_parameters(self, current_params: EvolutionParams, 
                                   analysis: Dict[str, Any]) -> EvolutionParams:
        """
        Suggest optimal evolution parameters based on population analysis.
        
        This demonstrates Claude's ability to adaptively tune the evolution
        process for better outcomes.
        """
        thinking_mode = self._select_thinking_mode("parameter_optimization")
        
        print(f"\nüîß Claude optimizing parameters (mode: {thinking_mode})")
        
        # Start with current parameters
        new_params = EvolutionParams(
            population_size=current_params.population_size,
            mutation_rate=current_params.mutation_rate,
            crossover_rate=current_params.crossover_rate,
            elite_size=current_params.elite_size,
            max_generations=current_params.max_generations,
            fitness_threshold=current_params.fitness_threshold
        )
        
        # Claude's adaptive parameter suggestions
        diversity_score = analysis.get("diversity_score", 0.5)
        stagnation_risk = analysis.get("stagnation_risk", 0.5)
        
        reasoning_points = []
        
        # Adjust mutation rate based on diversity
        if diversity_score < 0.3:
            new_params.mutation_rate = min(0.3, current_params.mutation_rate * 1.5)
            reasoning_points.append("Increased mutation rate to promote diversity")
        elif diversity_score > 0.8:
            new_params.mutation_rate = max(0.05, current_params.mutation_rate * 0.8)
            reasoning_points.append("Decreased mutation rate to preserve good solutions")
        
        # Adjust crossover rate based on stagnation
        if stagnation_risk > 0.7:
            new_params.crossover_rate = min(0.9, current_params.crossover_rate * 1.2)
            reasoning_points.append("Increased crossover rate to combat stagnation")
        
        # Adjust elite size based on population performance
        fitness_std = analysis.get("fitness_stats", {}).get("std", 0)
        if fitness_std < 0.1:  # Low variance, increase elitism
            new_params.elite_size = min(10, current_params.elite_size + 2)
            reasoning_points.append("Increased elite size due to low fitness variance")
        
        # Record decision
        decision = ClaudeDecision(
            decision_type="parameter_optimization",
            reasoning="; ".join(reasoning_points),
            confidence=0.8,
            parameters={
                "old_mutation_rate": current_params.mutation_rate,
                "new_mutation_rate": new_params.mutation_rate,
                "old_crossover_rate": current_params.crossover_rate,
                "new_crossover_rate": new_params.crossover_rate,
                "old_elite_size": current_params.elite_size,
                "new_elite_size": new_params.elite_size
            },
            timestamp=datetime.now().isoformat(),
            thinking_mode=thinking_mode
        )
        
        self.decision_history.append(decision)
        
        print(f"‚úÖ Parameter optimization complete")
        if reasoning_points:
            print("üéØ Adjustments made:")
            for point in reasoning_points:
                print(f"  ‚Ä¢ {point}")
        
        return new_params
    
    def evaluate_fitness_criteria(self, entity: GameEntity, 
                                 game_state: Dict[str, Any]) -> float:
        """
        Enhanced fitness evaluation using Claude's understanding of game design.
        
        This provides more sophisticated fitness evaluation than basic algorithms.
        """
        thinking_mode = self._select_thinking_mode("fitness_evaluation")
        
        # Base fitness from traits
        base_fitness = self._calculate_base_fitness(entity)
        
        # Claude's enhanced evaluation factors
        
        # 1. Balance assessment - entities shouldn't be too extreme
        balance_score = self._assess_balance(entity)
        
        # 2. Novelty assessment - reward unique combinations
        novelty_score = self._assess_novelty(entity, game_state)
        
        # 3. Potential assessment - future evolution promise
        potential_score = self._assess_potential(entity)
        
        # 4. Player experience prediction
        experience_score = self._predict_player_experience(entity)
        
        # Weighted combination (Claude's expertise)
        enhanced_fitness = (
            0.4 * base_fitness +
            0.2 * balance_score +
            0.2 * novelty_score +
            0.1 * potential_score +
            0.1 * experience_score
        )
        
        # Record decision for learning
        decision = ClaudeDecision(
            decision_type="fitness_evaluation",
            reasoning=f"Enhanced fitness: base={base_fitness:.3f}, balance={balance_score:.3f}, novelty={novelty_score:.3f}",
            confidence=0.7,
            parameters={
                "base_fitness": base_fitness,
                "balance_score": balance_score,
                "novelty_score": novelty_score,
                "potential_score": potential_score,
                "experience_score": experience_score,
                "final_fitness": enhanced_fitness
            },
            timestamp=datetime.now().isoformat(),
            thinking_mode=thinking_mode
        )
        
        return max(0.0, min(1.0, enhanced_fitness))
    
    def predict_emergence(self, population: List[GameEntity]) -> Dict[str, Any]:
        """
        Predict potential emergent behaviors from current population.
        
        This showcases Claude's ability to anticipate complex system behaviors.
        """
        thinking_mode = "ultrathink"  # Use maximum thinking power
        
        print(f"\nüîÆ Claude predicting emergence (mode: {thinking_mode})")
        time.sleep(1.0)  # Deep thinking simulation
        
        # Analyze trait correlations
        correlations = self._analyze_trait_correlations(population)
        
        # Identify potential emergence patterns
        emergence_patterns = []
        
        # Pattern 1: Specialization emergence
        trait_specialization = self._detect_specialization(population)
        if trait_specialization:
            emergence_patterns.append({
                "type": "specialization",
                "description": "Population showing specialization into distinct archetypes",
                "traits_involved": trait_specialization,
                "probability": 0.7
            })
        
        # Pattern 2: Cooperation emergence
        cooperation_potential = self._detect_cooperation_potential(population)
        if cooperation_potential > 0.6:
            emergence_patterns.append({
                "type": "cooperation",
                "description": "High potential for cooperative behaviors to emerge",
                "cooperation_score": cooperation_potential,
                "probability": 0.6
            })
        
        # Pattern 3: Arms race emergence
        competition_pressure = self._detect_competition_pressure(population)
        if competition_pressure > 0.7:
            emergence_patterns.append({
                "type": "arms_race",
                "description": "Competitive pressure may lead to rapid trait escalation",
                "competition_score": competition_pressure,
                "probability": 0.5
            })
        
        prediction = {
            "timestamp": datetime.now().isoformat(),
            "generation": len(population),
            "emergence_patterns": emergence_patterns,
            "trait_correlations": correlations,
            "confidence": 0.6,
            "thinking_mode": thinking_mode
        }
        
        print(f"üîÆ Emergence prediction complete")
        print(f"üìä Found {len(emergence_patterns)} potential patterns")
        
        return prediction
    
    def _select_thinking_mode(self, task_type: str) -> str:
        """Select appropriate thinking mode based on task complexity."""
        complexity_map = {
            "population_analysis": "think_hard",
            "parameter_optimization": "think_harder", 
            "fitness_evaluation": "think",
            "emergence_prediction": "ultrathink",
            "game_balance": "think_harder"
        }
        
        return complexity_map.get(task_type, "think")
    
    def _calculate_diversity(self, population: List[GameEntity]) -> float:
        """Calculate population diversity score."""
        if len(population) < 2:
            return 0.0
        
        # Calculate average pairwise distance in trait space
        total_distance = 0
        pairs = 0
        
        for i in range(len(population)):
            for j in range(i + 1, len(population)):
                distance = 0
                for trait in population[i].traits:
                    distance += (population[i].traits[trait] - population[j].traits[trait]) ** 2
                total_distance += distance ** 0.5
                pairs += 1
        
        return min(1.0, total_distance / pairs / 2.0)  # Normalize
    
    def _assess_stagnation_risk(self, generation: int) -> float:
        """Assess risk of evolutionary stagnation."""
        # Simple heuristic - higher risk with more generations
        # Real implementation would analyze fitness history
        base_risk = min(0.8, generation / 100)
        
        # Add some randomness for simulation
        noise = random.uniform(-0.1, 0.1)
        
        return max(0.0, min(1.0, base_risk + noise))
    
    def _generate_recommendations(self, diversity: float, stagnation: float) -> List[str]:
        """Generate recommendations based on analysis."""
        recommendations = []
        
        if diversity < 0.3:
            recommendations.append("Increase mutation rate to promote diversity")
        if stagnation > 0.7:
            recommendations.append("Consider introducing new genetic material")
        if diversity > 0.8 and stagnation < 0.3:
            recommendations.append("Current evolution is healthy, maintain parameters")
        
        return recommendations
    
    def _calculate_std(self, values: List[float]) -> float:
        """Calculate standard deviation."""
        if not values:
            return 0.0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance ** 0.5
    
    def _calculate_base_fitness(self, entity: GameEntity) -> float:
        """Calculate basic fitness from traits."""
        # Simple weighted sum
        weights = {
            "speed": 0.15,
            "agility": 0.1,
            "intelligence": 0.2,
            "cooperation": 0.15,
            "aggression": 0.1,
            "efficiency": 0.15,
            "adaptability": 0.1,
            "creativity": 0.05
        }
        
        fitness = 0
        for trait, value in entity.traits.items():
            weight = weights.get(trait, 0.1)
            fitness += weight * (value / 2.0)  # Normalize to 0-1
        
        return fitness
    
    def _assess_balance(self, entity: GameEntity) -> float:
        """Assess how balanced an entity's traits are."""
        values = list(entity.traits.values())
        mean_val = sum(values) / len(values)
        
        # Penalize extreme values
        balance_penalty = sum(abs(v - mean_val) for v in values) / len(values)
        
        return max(0.0, 1.0 - balance_penalty / 2.0)
    
    def _assess_novelty(self, entity: GameEntity, game_state: Dict[str, Any]) -> float:
        """Assess how novel this entity's trait combination is."""
        # Simplified novelty assessment
        # Real implementation would compare against historical data
        
        trait_sum = sum(entity.traits.values())
        novelty = abs(trait_sum - 8.0) / 8.0  # 8.0 is expected average
        
        return min(1.0, novelty)
    
    def _assess_potential(self, entity: GameEntity) -> float:
        """Assess potential for future evolution."""
        # Entities with moderate traits have more potential
        potential = 0
        for value in entity.traits.values():
            # Best potential around middle values
            potential += 1.0 - abs(value - 1.0)
        
        return potential / len(entity.traits)
    
    def _predict_player_experience(self, entity: GameEntity) -> float:
        """Predict how much players would enjoy this entity."""
        # Simplified player experience model
        # Real version would use player feedback data
        
        # Players tend to like balanced entities with some specialization
        balance = self._assess_balance(entity)
        specialization = max(entity.traits.values()) - min(entity.traits.values())
        
        experience = 0.6 * balance + 0.4 * min(1.0, specialization / 2.0)
        
        return experience
    
    def _analyze_trait_correlations(self, population: List[GameEntity]) -> Dict[str, float]:
        """Analyze correlations between traits in the population."""
        # Simplified correlation analysis
        correlations = {}
        
        if len(population) > 5:
            trait_names = list(population[0].traits.keys())
            
            for i, trait1 in enumerate(trait_names):
                for trait2 in trait_names[i+1:]:
                    # Calculate simple correlation
                    values1 = [e.traits[trait1] for e in population]
                    values2 = [e.traits[trait2] for e in population]
                    
                    correlation = self._simple_correlation(values1, values2)
                    correlations[f"{trait1}-{trait2}"] = correlation
        
        return correlations
    
    def _simple_correlation(self, x: List[float], y: List[float]) -> float:
        """Calculate simple correlation coefficient."""
        if len(x) != len(y) or len(x) < 2:
            return 0.0
        
        mean_x = sum(x) / len(x)
        mean_y = sum(y) / len(y)
        
        numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(len(x)))
        
        sum_sq_x = sum((x[i] - mean_x) ** 2 for i in range(len(x)))
        sum_sq_y = sum((y[i] - mean_y) ** 2 for i in range(len(y)))
        
        denominator = (sum_sq_x * sum_sq_y) ** 0.5
        
        if denominator == 0:
            return 0.0
        
        return numerator / denominator
    
    def _detect_specialization(self, population: List[GameEntity]) -> List[str]:
        """Detect if population is specializing into archetypes."""
        specialized_traits = []
        
        trait_names = list(population[0].traits.keys())
        
        for trait in trait_names:
            values = [e.traits[trait] for e in population]
            std_dev = self._calculate_std(values)
            
            # High standard deviation indicates specialization
            if std_dev > 0.4:
                specialized_traits.append(trait)
        
        return specialized_traits
    
    def _detect_cooperation_potential(self, population: List[GameEntity]) -> float:
        """Detect potential for cooperative behaviors."""
        cooperation_values = [e.traits.get("cooperation", 0) for e in population]
        aggression_values = [e.traits.get("aggression", 0) for e in population]
        
        avg_cooperation = sum(cooperation_values) / len(cooperation_values)
        avg_aggression = sum(aggression_values) / len(aggression_values)
        
        # High cooperation, low aggression = high cooperation potential
        potential = (avg_cooperation - avg_aggression + 2) / 4  # Normalize
        
        return max(0.0, min(1.0, potential))
    
    def _detect_competition_pressure(self, population: List[GameEntity]) -> float:
        """Detect competitive pressure in population."""
        fitness_values = [e.fitness for e in population if e.fitness > 0]
        
        if not fitness_values:
            return 0.0
        
        # High fitness variance indicates competitive pressure
        std_dev = self._calculate_std(fitness_values)
        mean_fitness = sum(fitness_values) / len(fitness_values)
        
        # Normalize by mean to get relative pressure
        pressure = std_dev / max(0.1, mean_fitness)
        
        return min(1.0, pressure)


def main():
    """Demo of Claude AI interface with evolution engine."""
    print("ü§ñ Evolution Game Claude - AI Interface Demo")
    print("=" * 50)
    
    # Initialize Claude interface
    claude = ClaudeInterface()
    
    # Create evolution engine
    config = EvolutionParams(
        population_size=20,
        mutation_rate=0.1,
        max_generations=10
    )
    
    engine = EvolutionEngine(config)
    engine.create_initial_population()
    
    # Demo Claude analysis
    analysis = claude.analyze_population(engine.population, engine.generation)
    
    # Demo parameter optimization
    new_params = claude.suggest_evolution_parameters(config, analysis)
    
    print(f"\nüîß Parameter changes suggested:")
    print(f"  Mutation rate: {config.mutation_rate:.3f} ‚Üí {new_params.mutation_rate:.3f}")
    print(f"  Crossover rate: {config.crossover_rate:.3f} ‚Üí {new_params.crossover_rate:.3f}")
    print(f"  Elite size: {config.elite_size} ‚Üí {new_params.elite_size}")
    
    # Demo emergence prediction
    emergence = claude.predict_emergence(engine.population)
    
    print(f"\nüîÆ Emergence patterns detected: {len(emergence['emergence_patterns'])}")
    for pattern in emergence['emergence_patterns']:
        print(f"  ‚Ä¢ {pattern['type']}: {pattern['description']} (p={pattern['probability']:.2f})")
    
    print(f"\nüìä Claude AI Interface demo complete")
    print(f"üß† Total decisions made: {len(claude.decision_history)}")


if __name__ == "__main__":
    main()
# END FILE: /mnt/c/Users/Percision 15/evolution_game_claude/core/claude_interface.py

# FILE: /mnt/c/Users/Percision 15/evolution_game_claude/core/evolution_engine.py
# SIZE: 13623 bytes
# MODIFIED: 2025-05-22 09:19:23.296756800 +0200
#!/usr/bin/env python3
"""
Evolution Game Claude - Core Evolution Engine
============================================

The main evolution engine that drives adaptive gameplay mechanics.
Implements genetic algorithms, neural adaptation, and Claude AI integration.
"""

import random
import json
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class GameEntity:
    """Represents an evolving game entity with genetic properties."""
    id: str
    traits: Dict[str, float]
    fitness: float = 0.0
    generation: int = 0
    parent_ids: List[str] = None
    mutations: List[str] = None
    
    def __post_init__(self):
        if self.parent_ids is None:
            self.parent_ids = []
        if self.mutations is None:
            self.mutations = []


@dataclass
class EvolutionParams:
    """Configuration parameters for the evolution system."""
    population_size: int = 50
    mutation_rate: float = 0.1
    crossover_rate: float = 0.7
    elite_size: int = 5
    max_generations: int = 1000
    fitness_threshold: float = 0.95
    
    
class EvolutionEngine:
    """
    Core evolution engine for adaptive game mechanics.
    
    Implements genetic algorithms with Claude AI integration for
    creating emergent gameplay through evolution.
    """
    
    def __init__(self, config: Optional[EvolutionParams] = None):
        self.config = config or EvolutionParams()
        self.population: List[GameEntity] = []
        self.generation = 0
        self.evolution_history: List[Dict[str, Any]] = []
        self.best_fitness_history: List[float] = []
        
        # Initialize random seed for reproducibility
        random.seed(int(time.time()))
        
        print("üß¨ Evolution Engine initialized")
        print(f"üìä Population size: {self.config.population_size}")
        print(f"üîÑ Mutation rate: {self.config.mutation_rate}")
        print(f"ü§ù Crossover rate: {self.config.crossover_rate}")
    
    def create_initial_population(self) -> None:
        """Create the initial population of game entities."""
        print(f"üå± Creating initial population of {self.config.population_size} entities...")
        
        self.population = []
        for i in range(self.config.population_size):
            entity = GameEntity(
                id=f"gen0_entity_{i:03d}",
                traits=self._generate_random_traits(),
                generation=0
            )
            self.population.append(entity)
        
        print(f"‚úÖ Initial population created with {len(self.population)} entities")
    
    def _generate_random_traits(self) -> Dict[str, float]:
        """Generate random traits for a new entity."""
        return {
            "speed": random.uniform(0.1, 2.0),
            "agility": random.uniform(0.1, 2.0),
            "intelligence": random.uniform(0.1, 2.0),
            "cooperation": random.uniform(0.1, 2.0),
            "aggression": random.uniform(0.1, 2.0),
            "efficiency": random.uniform(0.1, 2.0),
            "adaptability": random.uniform(0.1, 2.0),
            "creativity": random.uniform(0.1, 2.0)
        }
    
    def evaluate_fitness(self, entity: GameEntity, player_feedback: Optional[Dict] = None) -> float:
        """
        Evaluate the fitness of an entity based on game performance.
        
        This is where Claude AI integration would provide sophisticated
        fitness evaluation based on player behavior and game metrics.
        """
        # Basic fitness calculation (to be enhanced with Claude AI)
        traits = entity.traits
        
        # Multi-dimensional fitness based on different criteria
        performance_score = (traits["speed"] + traits["efficiency"]) / 2
        social_score = (traits["cooperation"] - traits["aggression"]) / 2 + 1
        adaptability_score = (traits["adaptability"] + traits["intelligence"]) / 2
        creativity_score = traits["creativity"]
        
        # Weighted combination
        fitness = (
            0.3 * performance_score +
            0.2 * social_score +
            0.3 * adaptability_score +
            0.2 * creativity_score
        )
        
        # Add player feedback influence if available
        if player_feedback:
            feedback_bonus = player_feedback.get("enjoyment", 0) * 0.1
            fitness += feedback_bonus
        
        # Normalize to 0-1 range
        entity.fitness = max(0.0, min(1.0, fitness))
        return entity.fitness
    
    def select_parents(self) -> Tuple[GameEntity, GameEntity]:
        """Select two parents for crossover using tournament selection."""
        tournament_size = 3
        
        def tournament_select() -> GameEntity:
            contestants = random.sample(self.population, tournament_size)
            return max(contestants, key=lambda e: e.fitness)
        
        parent1 = tournament_select()
        parent2 = tournament_select()
        
        # Ensure parents are different
        while parent2.id == parent1.id:
            parent2 = tournament_select()
        
        return parent1, parent2
    
    def crossover(self, parent1: GameEntity, parent2: GameEntity) -> GameEntity:
        """Create offspring through crossover of two parents."""
        child_traits = {}
        
        # Blend crossover for continuous traits
        for trait_name in parent1.traits.keys():
            if random.random() < 0.5:
                # Take from parent1 with some blending
                alpha = random.uniform(-0.1, 1.1)
                child_traits[trait_name] = (
                    alpha * parent1.traits[trait_name] +
                    (1 - alpha) * parent2.traits[trait_name]
                )
            else:
                # Take from parent2 with some blending
                alpha = random.uniform(-0.1, 1.1)
                child_traits[trait_name] = (
                    alpha * parent2.traits[trait_name] +
                    (1 - alpha) * parent1.traits[trait_name]
                )
            
            # Ensure traits stay within reasonable bounds
            child_traits[trait_name] = max(0.1, min(2.0, child_traits[trait_name]))
        
        child = GameEntity(
            id=f"gen{self.generation + 1}_entity_{len(self.population):03d}",
            traits=child_traits,
            generation=self.generation + 1,
            parent_ids=[parent1.id, parent2.id]
        )
        
        return child
    
    def mutate(self, entity: GameEntity) -> None:
        """Apply mutations to an entity's traits."""
        mutations_applied = []
        
        for trait_name, trait_value in entity.traits.items():
            if random.random() < self.config.mutation_rate:
                # Gaussian mutation
                mutation_strength = 0.1
                mutation = random.gauss(0, mutation_strength)
                old_value = trait_value
                entity.traits[trait_name] = max(0.1, min(2.0, trait_value + mutation))
                
                mutations_applied.append(f"{trait_name}: {old_value:.3f} ‚Üí {entity.traits[trait_name]:.3f}")
        
        entity.mutations = mutations_applied
    
    def evolve_generation(self, player_feedback: Optional[Dict] = None) -> Dict[str, Any]:
        """Evolve one generation of the population."""
        print(f"\nüîÑ Evolving generation {self.generation} ‚Üí {self.generation + 1}")
        
        # Evaluate fitness for all entities
        for entity in self.population:
            self.evaluate_fitness(entity, player_feedback)
        
        # Sort by fitness (descending)
        self.population.sort(key=lambda e: e.fitness, reverse=True)
        
        # Track best fitness
        best_fitness = self.population[0].fitness
        self.best_fitness_history.append(best_fitness)
        
        print(f"üìä Best fitness: {best_fitness:.4f}")
        print(f"üèÜ Best entity: {self.population[0].id}")
        
        # Create new generation
        new_population = []
        
        # Keep elite individuals
        elite = self.population[:self.config.elite_size]
        new_population.extend(elite)
        print(f"üëë Preserved {len(elite)} elite entities")
        
        # Generate offspring
        while len(new_population) < self.config.population_size:
            if random.random() < self.config.crossover_rate:
                # Crossover
                parent1, parent2 = self.select_parents()
                child = self.crossover(parent1, parent2)
                self.mutate(child)
                new_population.append(child)
            else:
                # Clone with mutation
                parent = self.select_parents()[0]
                child = GameEntity(
                    id=f"gen{self.generation + 1}_clone_{len(new_population):03d}",
                    traits=parent.traits.copy(),
                    generation=self.generation + 1,
                    parent_ids=[parent.id]
                )
                self.mutate(child)
                new_population.append(child)
        
        # Update population and generation
        self.population = new_population[:self.config.population_size]
        self.generation += 1
        
        # Record evolution history
        generation_stats = {
            "generation": self.generation,
            "best_fitness": best_fitness,
            "avg_fitness": sum(e.fitness for e in self.population) / len(self.population),
            "population_size": len(self.population),
            "timestamp": datetime.now().isoformat()
        }
        
        self.evolution_history.append(generation_stats)
        
        print(f"‚úÖ Generation {self.generation} complete")
        print(f"üìà Average fitness: {generation_stats['avg_fitness']:.4f}")
        
        return generation_stats
    
    def run_evolution(self, max_generations: Optional[int] = None, player_feedback_callback=None) -> None:
        """Run the complete evolution process."""
        max_gen = max_generations or self.config.max_generations
        
        print(f"üöÄ Starting evolution process for {max_gen} generations")
        print("=" * 60)
        
        self.create_initial_population()
        
        for gen in range(max_gen):
            # Get player feedback if callback provided
            feedback = None
            if player_feedback_callback:
                feedback = player_feedback_callback(self.population, self.generation)
            
            # Evolve one generation
            stats = self.evolve_generation(feedback)
            
            # Check termination conditions
            if stats["best_fitness"] >= self.config.fitness_threshold:
                print(f"üéØ Fitness threshold reached! Best fitness: {stats['best_fitness']:.4f}")
                break
            
            # Progress indicator
            if (gen + 1) % 10 == 0:
                print(f"üìä Progress: {gen + 1}/{max_gen} generations")
        
        print("\nüèÅ Evolution complete!")
        self.print_final_stats()
    
    def print_final_stats(self) -> None:
        """Print final evolution statistics."""
        print("=" * 60)
        print("üìä FINAL EVOLUTION STATISTICS")
        print("=" * 60)
        
        best_entity = max(self.population, key=lambda e: e.fitness)
        
        print(f"üèÜ Best Entity: {best_entity.id}")
        print(f"üí™ Best Fitness: {best_entity.fitness:.4f}")
        print(f"üß¨ Generation: {best_entity.generation}")
        print(f"üë• Parents: {', '.join(best_entity.parent_ids) if best_entity.parent_ids else 'Initial population'}")
        
        print(f"\nüß¨ Best Entity Traits:")
        for trait, value in best_entity.traits.items():
            print(f"  {trait}: {value:.3f}")
        
        if best_entity.mutations:
            print(f"\nüîÑ Recent Mutations:")
            for mutation in best_entity.mutations[-5:]:  # Show last 5 mutations
                print(f"  {mutation}")
        
        print(f"\nüìà Evolution Progress:")
        print(f"  Total generations: {self.generation}")
        print(f"  Initial best fitness: {self.best_fitness_history[0]:.4f}")
        print(f"  Final best fitness: {self.best_fitness_history[-1]:.4f}")
        print(f"  Improvement: {(self.best_fitness_history[-1] - self.best_fitness_history[0]):.4f}")
    
    def save_evolution_data(self, filepath: str) -> None:
        """Save evolution data to file for analysis."""
        data = {
            "config": asdict(self.config),
            "generation": self.generation,
            "population": [asdict(entity) for entity in self.population],
            "evolution_history": self.evolution_history,
            "best_fitness_history": self.best_fitness_history
        }
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2)
        
        print(f"üíæ Evolution data saved to {filepath}")


def main():
    """Demo of the evolution engine."""
    print("üß¨ Evolution Game Claude - Core Engine Demo")
    print("=" * 50)
    
    # Create evolution engine with custom parameters
    config = EvolutionParams(
        population_size=30,
        mutation_rate=0.15,
        crossover_rate=0.8,
        elite_size=3,
        max_generations=50
    )
    
    engine = EvolutionEngine(config)
    
    # Run evolution with basic demo
    engine.run_evolution(max_generations=20)
    
    # Save results
    engine.save_evolution_data("evolution_demo_results.json")


if __name__ == "__main__":
    main()
# END FILE: /mnt/c/Users/Percision 15/evolution_game_claude/core/evolution_engine.py

# ========== GDSCRIPT FILES (GAME DEVELOPMENT) ==========
# FILE: /mnt/c/Users/Percision 15/12_turns_system/12_turns_game.gd
# SIZE: 15047 bytes
extends Node

# 12 Turns Game - Main Game Script
# Integrates all systems for the complete 12 turns game experience
# Terminal 1: Divine Word Genesis

class_name TwelveTurnsGame

# ----- CONFIGURATION -----
var SAVE_DIR = "/mnt/c/Users/Percision 15/12_turns_system/saves/"
var CONFIG_PATH = "/mnt/c/Users/Percision 15/12_turns_system/config.json"
var DEBUG_MODE = true

# ----- SYSTEM REFERENCES -----
var divine_word_game = null
var turn_system = null
var divine_word_processor = null
var word_salem_controller = null
var word_crimes_analysis = null
var word_comment_system = null
var word_dream_storage = null
var main_controller = null

# ----- SIGNAL CONNECTIONS -----
signal game_initialized
signal system_integrated(system_name)
signal memory_tier_accessed(tier, operation)
signal dimension_transition_complete(from_dim, to_dim)

func _ready():
	print("12 Turns Game initializing...")
	
	# Load configuration if available
	load_config()
	
	# Initialize core systems
	initialize_systems()
	
	# Connect to existing main controller if available
	connect_to_existing_systems()
	
	# Start the interface
	initialize_ui()
	
	# Start the game systems
	start_game_systems()
	
	print("12 Turns Game initialization complete")
	print("Terminal 1: Divine Word Genesis is ready")
	print("Integration with existing systems: " + ("Complete" if main_controller else "Not detected"))
	
	emit_signal("game_initialized")

func load_config():
	var file = File.new()
	
	if file.file_exists(CONFIG_PATH):
		file.open(CONFIG_PATH, File.READ)
		var content = file.get_as_text()
		file.close()
		
		var result = JSON.parse(content)
		if result.error == OK:
			var config = result.result
			
			# Apply configuration
			if config.has("debug_mode"):
				DEBUG_MODE = config.debug_mode
			
			if config.has("save_dir"):
				SAVE_DIR = config.save_dir
				
			print("Configuration loaded from: " + CONFIG_PATH)
		else:
			print("Error parsing configuration file: " + result.error_string)
	else:
		# Create default configuration
		create_default_config()

func create_default_config():
	var config = {
		"debug_mode": DEBUG_MODE,
		"save_dir": SAVE_DIR,
		"turn_duration": 9.0,  # Sacred 9-second interval
		"dimensions_enabled": 12,
		"memory_tiers": 3,
		"salem_game_enabled": true,
		"quantum_loop_enabled": true,
		"comment_system_enabled": true,
		"dream_system_enabled": true
	}
	
	var file = File.new()
	file.open(CONFIG_PATH, File.WRITE)
	file.store_string(JSON.print(config, "  "))
	file.close()
	
	print("Default configuration created at: " + CONFIG_PATH)

func initialize_systems():
	# Create directory for saves if it doesn't exist
	var dir = Directory.new()
	if not dir.dir_exists(SAVE_DIR):
		dir.make_dir_recursive(SAVE_DIR)
	
	# Initialize TurnSystem if not already created
	turn_system = get_node_or_null("/root/TurnSystem")
	if not turn_system:
		turn_system = TurnSystem.new()
		turn_system.name = "TurnSystem"
		get_tree().root.add_child(turn_system)
		turn_system.turn_duration = 9.0  # Sacred 9-second interval
		emit_signal("system_integrated", "TurnSystem")
	
	# Initialize DivineWordProcessor if not already created
	divine_word_processor = get_node_or_null("/root/DivineWordProcessor")
	if not divine_word_processor:
		divine_word_processor = DivineWordProcessor.new()
		divine_word_processor.name = "DivineWordProcessor"
		get_tree().root.add_child(divine_word_processor)
		emit_signal("system_integrated", "DivineWordProcessor")
	
	# Initialize WordCommentSystem
	word_comment_system = get_node_or_null("/root/WordCommentSystem")
	if not word_comment_system:
		word_comment_system = WordCommentSystem.new()
		word_comment_system.name = "WordCommentSystem"
		get_tree().root.add_child(word_comment_system)
		emit_signal("system_integrated", "WordCommentSystem")
	
	# Initialize WordDreamStorage
	word_dream_storage = get_node_or_null("/root/WordDreamStorage")
	if not word_dream_storage:
		word_dream_storage = WordDreamStorage.new()
		word_dream_storage.name = "WordDreamStorage"
		get_tree().root.add_child(word_dream_storage)
		emit_signal("system_integrated", "WordDreamStorage")
	
	# Initialize WordSalemGameController
	word_salem_controller = get_node_or_null("/root/WordSalemGameController")
	if not word_salem_controller:
		word_salem_controller = WordSalemGameController.new()
		word_salem_controller.name = "WordSalemGameController"
		get_tree().root.add_child(word_salem_controller)
		emit_signal("system_integrated", "WordSalemGameController")
	
	# Initialize WordCrimesAnalysis
	word_crimes_analysis = get_node_or_null("/root/WordCrimesAnalysis")
	if not word_crimes_analysis:
		word_crimes_analysis = WordCrimesAnalysis.new()
		word_crimes_analysis.name = "WordCrimesAnalysis"
		get_tree().root.add_child(word_crimes_analysis)
		emit_signal("system_integrated", "WordCrimesAnalysis")
	
	# Initialize DivineWordGame
	divine_word_game = get_node_or_null("/root/DivineWordGame")
	if not divine_word_game:
		divine_word_game = DivineWordGame.new()
		divine_word_game.name = "DivineWordGame"
		get_tree().root.add_child(divine_word_game)
		emit_signal("system_integrated", "DivineWordGame")

func connect_to_existing_systems():
	# Try to connect to existing main controller
	main_controller = get_node_or_null("/root/main")
	
	if main_controller:
		# Connect signals from main controller to our systems
		main_controller.connect("turn_advanced", self, "_on_main_turn_advanced")
		main_controller.connect("note_created", self, "_on_main_note_created")
		main_controller.connect("word_manifested", self, "_on_main_word_manifested")
		
		if divine_word_processor and main_controller.word_processor:
			main_controller.word_processor.connect("word_processed", divine_word_processor, "_on_word_processed_external")
			
			# Also connect to Salem controller if available
			if word_salem_controller:
				main_controller.word_processor.connect("word_processed", word_salem_controller, "_on_word_processed_external")
		
		print("Connected to existing main controller")
		emit_signal("system_integrated", "Main Controller")

func initialize_ui():
	# Create the main UI container
	var ui_container = Control.new()
	ui_container.name = "UIContainer"
	ui_container.set_anchors_preset(Control.PRESET_WIDE)
	add_child(ui_container)
	
	# Create the Divine Word UI
	var main_ui = DivineWordUI.new()
	main_ui.name = "DivineWordUI"
	main_ui.set_anchors_preset(Control.PRESET_WIDE)
	ui_container.add_child(main_ui)
	
	# Create the Word Comment UI
	var comment_ui = WordCommentUI.new()
	comment_ui.name = "WordCommentUI"
	comment_ui.set_anchors_preset(Control.PRESET_WIDE)
	comment_ui.visible = false  # Start hidden
	ui_container.add_child(comment_ui)
	
	# Create the Salem Game UI
	var salem_ui = WordSalemUI.new()
	salem_ui.name = "WordSalemUI"
	salem_ui.set_anchors_preset(Control.PRESET_WIDE)
	salem_ui.visible = false  # Start hidden
	ui_container.add_child(salem_ui)
	
	print("User interface initialized")

func start_game_systems():
	# Start the turn system
	if turn_system:
		turn_system.connect("dimension_changed", self, "_on_dimension_changed")
		turn_system.start_turns()
	
	# Start the Salem game if available
	if word_salem_controller and divine_word_game:
		# Use the player list from divine_word_game if available
		var players = divine_word_game.config.players
		if players.size() >= word_salem_controller.min_players:
			word_salem_controller.start_game(players)
	
	# Start the game
	if divine_word_game:
		divine_word_game.start_game()
	
	print("Game systems started")

func _input(event):
	# Handle UI toggling with Tab key
	if event is InputEventKey and event.pressed:
		if event.scancode == KEY_TAB:
			toggle_ui()
		elif event.scancode == KEY_QUOTELEFT:  # Backtick key
			toggle_comment_mode()

func toggle_ui():
	# Toggle between different UI screens
	var ui_container = get_node("UIContainer")
	var main_ui = ui_container.get_node("DivineWordUI")
	var comment_ui = ui_container.get_node("WordCommentUI")
	var salem_ui = ui_container.get_node("WordSalemUI")
	
	if main_ui.visible:
		main_ui.visible = false
		comment_ui.visible = true
		salem_ui.visible = false
		print("Switched to Comment UI")
	elif comment_ui.visible:
		main_ui.visible = false
		comment_ui.visible = false
		salem_ui.visible = true
		print("Switched to Salem Game UI")
	else:
		main_ui.visible = true
		comment_ui.visible = false
		salem_ui.visible = false
		print("Switched to Main Game UI")

func toggle_comment_mode():
	# Toggle dream mode in the comment UI
	var ui_container = get_node("UIContainer")
	var comment_ui = ui_container.get_node("WordCommentUI")
	
	# Make sure Comment UI is visible
	if !comment_ui.visible:
		ui_container.get_node("DivineWordUI").visible = false
		ui_container.get_node("WordSalemUI").visible = false
		comment_ui.visible = true
	
	# Toggle dream mode
	comment_ui._on_dream_toggle(!comment_ui.dream_mode)
	print("Dream mode " + ("enabled" if comment_ui.dream_mode else "disabled"))

# ----- EVENT HANDLERS -----

func _on_dimension_changed(new_dimension, old_dimension):
	# Special handling for dimension changes
	
	# Check for special dimensions
	match new_dimension:
		7:  # Dream dimension
			# Make dream storage more active
			if word_dream_storage:
				word_dream_storage.connect("dream_saved", self, "_on_dream_saved")
				print("Dream dimension activated - Dream storage enhanced")
				
				# Add comment about dimension
				if word_comment_system:
					word_comment_system.add_comment("dimension_7", 
						"Entering the dreamscape of the 7th dimension. Dreams will be stored and processed.",
						word_comment_system.CommentType.DREAM)
		
		9:  # Judgment dimension
			# Activate the Salem game if not already active
			if word_salem_controller and word_salem_controller.current_state == word_salem_controller.GameState.LOBBY:
				var players = divine_word_game.config.players if divine_word_game else ["Player"]
				if players.size() >= word_salem_controller.min_players:
					word_salem_controller.start_game(players)
					print("Judgment dimension activated - Salem game started")
				
				# Add comment about dimension
				if word_comment_system:
					word_comment_system.add_comment("dimension_9", 
						"Entering the judgment dimension. The Town of Salem word trial begins.",
						word_comment_system.CommentType.DIVINE)
		
		12: # Divine dimension
			# Activate all systems at maximum power
			if divine_word_processor:
				divine_word_processor.divine_multiplier = 12.0  # Maximum divine amplification
				print("Divine dimension activated - Word power amplified 12x")
				
				# Add comment about dimension
				if word_comment_system:
					word_comment_system.add_comment("dimension_12", 
						"Entering the divine dimension. All words reach their maximum potential.",
						word_comment_system.CommentType.DIVINE)
	
	emit_signal("dimension_transition_complete", old_dimension, new_dimension)

func _on_dream_saved(dream_id, tier):
	emit_signal("memory_tier_accessed", tier, "save_dream")
	
	# Add comment about dream
	if word_comment_system:
		word_comment_system.add_comment("dream_saved", 
			"Dream saved to memory tier " + str(tier) + " with ID: " + dream_id,
			word_comment_system.CommentType.DREAM)

# ----- INTEGRATION WITH MAIN CONTROLLER -----

func _on_main_turn_advanced(turn_number, symbol, dimension):
	# Sync with our turn system
	if turn_system:
		turn_system.set_dimension(turn_number)
		print("Synchronized with main controller: Turn " + str(turn_number) + " - Dimension " + dimension)
		
		# Add comment about dimension change
		if word_comment_system:
			word_comment_system.add_comment("dimension_change", 
				"SYNCHRONIZED: Main controller advanced to " + dimension,
				word_comment_system.CommentType.OBSERVATION)

func _on_main_note_created(note_data):
	# Process the note in our systems
	if divine_word_processor and word_comment_system:
		var power = divine_word_processor.process_word(note_data.text, "Main_" + str(note_data.id))
		
		# Add as comment
		word_comment_system.add_comment("note_" + str(note_data.id),
			"NOTE: \"" + note_data.text + "\" from main controller (Power: " + str(power) + ")",
			word_comment_system.CommentType.OBSERVATION)
		
		print("Processed note from main controller: " + note_data.text)

func _on_main_word_manifested(word, position, power):
	# Process the manifested word in our systems
	if divine_word_game and word_comment_system:
		# Process in game
		divine_word_game.process_word(word)
		
		# Add as divine comment
		word_comment_system.add_comment(word,
			"MANIFESTED: Word manifested from main controller at position " + str(position) + " with power " + str(power),
			word_comment_system.CommentType.DIVINE)
		
		print("Word manifested from main controller: " + word)

# ----- PUBLIC API -----

func process_word(word, source="API"):
	var power = 0
	
	if divine_word_processor:
		power = divine_word_processor.process_word(word, source)
	
	if divine_word_game:
		divine_word_game.process_word(word)
	
	return power

func add_comment(word, comment_text, type=0):
	if word_comment_system:
		return word_comment_system.add_comment(word, comment_text, type)
	return null

func record_dream(word, dream_text):
	if word_comment_system:
		return word_comment_system.record_dream_fragment(word, dream_text)
	return null

func save_to_tier(data, tier=1):
	if word_dream_storage:
		if data.has("dream_text"):
			return word_dream_storage.save_dream(data, tier)
		elif data.has("text"):
			return word_dream_storage.save_comment(data, tier)
		else:
			return word_dream_storage.save_dimension_record(
				turn_system.current_dimension if turn_system else 1, 
				data, 
				tier
			)
	
	return null

func register_defense(word, defense_text, defender="API"):
	if word_comment_system:
		return word_comment_system.register_defense(word, defense_text, defender)
	return null

func get_game_stats():
	if divine_word_game:
		return divine_word_game.get_game_stats()
	return {
		"score": 0,
		"level": 1,
		"dimension": turn_system.current_dimension if turn_system else 1,
		"turn_count": turn_system.current_turn if turn_system else 0
	}

func get_dimension_challenge():
	if divine_word_game:
		return divine_word_game.get_dimension_challenge()
	return null

func get_memory_by_tier(tier):
	if word_dream_storage:
		# Emit signal for memory access
		emit_signal("memory_tier_accessed", tier, "read")
		
		var memories = []
		if tier == 1:
			# RAM tier
			if word_comment_system:
				for entry in word_comment_system.comment_history:
					memories.append(entry)
		elif tier == 2:
			# C: Drive tier
			if word_dream_storage.dimension_records:
				for dim in word_dream_storage.dimension_records.keys():
					var records = word_dream_storage.load_dimension_records(dim)
					memories.append(records)
		elif tier == 3:
			# D: Drive tier
			if word_dream_storage.defense_records:
				for defense_id in word_dream_storage.defense_records.keys():
					if word_dream_storage.defense_records[defense_id].tier == 3:
						var defense = word_dream_storage.load_defense_record(defense_id)
						memories.append(defense)
		
		return memories
	
	return []
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/12_turns_game.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/15/wish_knowledge_system.gd
# SIZE: 0 bytes

# END FILE: /mnt/c/Users/Percision 15/12_turns_system/15/wish_knowledge_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/account_tier_colors.gd
# SIZE: 7277 bytes
extends Resource

class_name AccountTierColors

# Account tiers
enum AccountTier {
    FREE,
    PLUS,
    MAX,
    ENTERPRISE
}

# Color palettes for each account tier with gradient and ghostly effects
const TIER_COLORS = {
    AccountTier.FREE: {
        "primary": Color(0.2, 0.4, 0.8, 0.9),       # Ethereal blue
        "secondary": Color(0.1, 0.2, 0.6, 0.7),     # Deep blue
        "accent": Color(0.4, 0.6, 1.0, 0.95),       # Bright blue
        "text": Color(0.8, 0.9, 1.0),               # Light blue text
        "background": Color(0.05, 0.1, 0.2, 0.8),   # Dark blue background
        "glow": 0.4,                                # Glow intensity
        "symbols": "#",                             # Dimension symbol
        "threads": 1                                # Thread count
    },
    
    AccountTier.PLUS: {
        "primary": Color(0.2, 0.8, 0.3, 0.9),       # Ghostly green
        "secondary": Color(0.1, 0.5, 0.2, 0.7),     # Deep green
        "accent": Color(0.4, 1.0, 0.5, 0.95),       # Bright green
        "text": Color(0.8, 1.0, 0.9),               # Light green text
        "background": Color(0.05, 0.2, 0.1, 0.8),   # Dark green background
        "glow": 0.6,                                # Glow intensity
        "symbols": "##",                            # Dimension symbol
        "threads": 3                                # Thread count
    },
    
    AccountTier.MAX: {
        "primary": Color(0.8, 0.3, 0.8, 0.9),       # Spectral purple
        "secondary": Color(0.5, 0.1, 0.5, 0.7),     # Deep purple
        "accent": Color(1.0, 0.4, 1.0, 0.95),       # Bright purple
        "text": Color(1.0, 0.8, 1.0),               # Light purple text
        "background": Color(0.2, 0.05, 0.2, 0.8),   # Dark purple background
        "glow": 0.8,                                # Glow intensity
        "symbols": "###",                           # Dimension symbol
        "threads": 8                                # Thread count
    },
    
    AccountTier.ENTERPRISE: {
        "primary": Color(0.9, 0.8, 0.3, 0.9),       # Ethereal gold
        "secondary": Color(0.6, 0.5, 0.1, 0.7),     # Deep gold
        "accent": Color(1.0, 0.9, 0.4, 0.95),       # Bright gold
        "text": Color(1.0, 0.95, 0.8),              # Light gold text
        "background": Color(0.25, 0.2, 0.05, 0.8),  # Dark gold background
        "glow": 1.0,                                # Glow intensity
        "symbols": "####",                          # Dimension symbol
        "threads": 32                               # Thread count
    }
}

# Thread colors - used for thread visualization in each tier
const THREAD_COLORS = {
    AccountTier.FREE: [
        Color(0.2, 0.4, 0.9, 0.7)                  # Single thread color
    ],
    
    AccountTier.PLUS: [
        Color(0.1, 0.6, 0.3, 0.7),                 # Primary thread
        Color(0.3, 0.7, 0.2, 0.7),                 # Secondary thread
        Color(0.2, 0.5, 0.4, 0.7)                  # Tertiary thread
    ],
    
    AccountTier.MAX: [
        Color(0.7, 0.2, 0.7, 0.7),                 # Thread type 1
        Color(0.8, 0.3, 0.6, 0.7),                 # Thread type 2
        Color(0.6, 0.2, 0.8, 0.7),                 # Thread type 3
        Color(0.5, 0.3, 0.9, 0.7),                 # Thread type 4
        Color(0.9, 0.2, 0.5, 0.7),                 # Thread type 5
        Color(0.7, 0.3, 0.5, 0.7),                 # Thread type 6
        Color(0.5, 0.2, 0.6, 0.7),                 # Thread type 7
        Color(0.6, 0.3, 0.7, 0.7)                  # Thread type 8
    ],
    
    AccountTier.ENTERPRISE: [
        # Multiple thread colors for enterprise - will cycle through these for visualization
        Color(0.9, 0.8, 0.2, 0.7),                 # Gold thread
        Color(0.8, 0.7, 0.3, 0.7),                 # Amber thread
        Color(0.7, 0.6, 0.2, 0.7),                 # Yellow thread
        Color(0.9, 0.7, 0.1, 0.7)                  # Orange thread
    ]
}

# Special effect parameters for each tier
const TIER_EFFECTS = {
    AccountTier.FREE: {
        "pulse_speed": 0.5,                        # Speed of color pulsing
        "trail_length": 0,                         # No trailing effect
        "particle_count": 5,                       # Minimal particles
        "dimension_access": 3,                     # Max dimension for this tier
        "ghostly_transparency": 0.7                # Base transparency
    },
    
    AccountTier.PLUS: {
        "pulse_speed": 0.7,                        # Faster pulsing
        "trail_length": 3,                         # Short trails
        "particle_count": 15,                      # More particles
        "dimension_access": 7,                     # Max dimension for this tier
        "ghostly_transparency": 0.8                # More visible
    },
    
    AccountTier.MAX: {
        "pulse_speed": 1.0,                        # Fast pulsing
        "trail_length": 6,                         # Longer trails
        "particle_count": 30,                      # Many particles
        "dimension_access": 12,                    # Full dimension access
        "ghostly_transparency": 0.9                # Very visible
    },
    
    AccountTier.ENTERPRISE: {
        "pulse_speed": 1.2,                        # Fastest pulsing
        "trail_length": 10,                        # Longest trails
        "particle_count": 60,                      # Maximum particles
        "dimension_access": 12,                    # Full dimension access
        "ghostly_transparency": 0.95,              # Most visible
        "custom_effects": true                     # Enable custom effects
    }
}

# Function to get all colors for a tier
static func get_tier_colors(tier):
    if tier in TIER_COLORS:
        return TIER_COLORS[tier]
    return TIER_COLORS[AccountTier.FREE]  # Default to free tier

# Function to get thread colors for a tier
static func get_thread_colors(tier):
    if tier in THREAD_COLORS:
        return THREAD_COLORS[tier]
    return THREAD_COLORS[AccountTier.FREE]  # Default to free tier

# Function to get effects for a tier
static func get_tier_effects(tier):
    if tier in TIER_EFFECTS:
        return TIER_EFFECTS[tier]
    return TIER_EFFECTS[AccountTier.FREE]  # Default to free tier

# Function to get a tier's primary color with glow
static func get_primary_color_with_glow(tier):
    var colors = get_tier_colors(tier)
    var effects = get_tier_effects(tier)
    
    # Create a color with glow properties
    var color_with_glow = {
        "color": colors["primary"],
        "glow_intensity": colors["glow"],
        "pulse_speed": effects["pulse_speed"]
    }
    
    return color_with_glow

# Function to generate a gradient for a tier
static func generate_tier_gradient(tier):
    var colors = get_tier_colors(tier)
    
    # Create a gradient object
    var gradient = Gradient.new()
    
    # Add color points
    gradient.add_point(0.0, colors["secondary"])
    gradient.add_point(0.5, colors["primary"])
    gradient.add_point(1.0, colors["accent"])
    
    return gradient

# Function to get dimensions allowed for a tier
static func get_max_dimension(tier):
    var effects = get_tier_effects(tier)
    return effects["dimension_access"]
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/account_tier_colors.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/account_visualizer.gd
# SIZE: 13026 bytes
extends Control

class_name AccountVisualizer

# Constants
const DIMENSION_COLORS = [
    Color(0.2, 0.4, 0.8), # Dimension 1
    Color(0.3, 0.6, 0.9), # Dimension 2
    Color(0.4, 0.7, 0.8), # Dimension 3
    Color(0.5, 0.8, 0.7), # Dimension 4
    Color(0.6, 0.9, 0.6), # Dimension 5
    Color(0.7, 0.9, 0.5), # Dimension 6
    Color(0.8, 0.9, 0.4), # Dimension 7
    Color(0.9, 0.8, 0.3), # Dimension 8
    Color(0.9, 0.7, 0.2), # Dimension 9
    Color(0.9, 0.6, 0.1), # Dimension 10
    Color(0.9, 0.5, 0.0), # Dimension 11
    Color(1.0, 0.4, 0.0)  # Dimension 12
]

const CATEGORY_COLORS = {
    "creation": Color(0.2, 0.8, 0.2),
    "exploration": Color(0.2, 0.2, 0.8),
    "interaction": Color(0.8, 0.2, 0.8),
    "challenge": Color(0.8, 0.2, 0.2),
    "mastery": Color(0.8, 0.8, 0.2)
}

const VISUALIZATION_MODES = ["radial", "bar", "line", "custom"]

# UI elements
var visualizer_container
var points_label
var dimension_label
var category_bars = {}
var dimension_progress
var preference_indicators = {}
var history_graph
var playstyle_label

# Settings
var visualization_mode = "radial"
var animation_speed = 1.0
var color_scheme = "standard"
var show_predictions = true
var highlight_preferences = true

# State data
var current_points = 0
var current_dimension = 1
var dimension_progress_value = 0.0
var category_values = {}
var preferences = {}
var points_history = []
var playstyle = "Unknown"

# References
var _account_manager = null
var _preference_analyzer = null
var _auto_correction = null

# Tween for animations
var tween

func _ready():
    # Setup UI elements
    setup_ui()
    
    # Connect to systems
    connect_to_systems()
    
    # Initial update
    update_visualization()

func setup_ui():
    # Main container
    visualizer_container = VBoxContainer.new()
    visualizer_container.anchor_right = 1.0
    visualizer_container.anchor_bottom = 1.0
    add_child(visualizer_container)
    
    # Top section - Account Info
    var top_section = HBoxContainer.new()
    visualizer_container.add_child(top_section)
    
    # Points display
    var points_container = VBoxContainer.new()
    top_section.add_child(points_container)
    
    var points_title = Label.new()
    points_title.text = "ACCOUNT POINTS"
    points_title.align = Label.ALIGN_CENTER
    points_container.add_child(points_title)
    
    points_label = Label.new()
    points_label.text = "0"
    points_label.align = Label.ALIGN_CENTER
    points_container.add_child(points_label)
    
    # Dimension display
    var dimension_container = VBoxContainer.new()
    top_section.add_child(dimension_container)
    
    var dimension_title = Label.new()
    dimension_title.text = "DIMENSION"
    dimension_title.align = Label.ALIGN_CENTER
    dimension_container.add_child(dimension_title)
    
    dimension_label = Label.new()
    dimension_label.text = "1 / 12 #"
    dimension_label.align = Label.ALIGN_CENTER
    dimension_container.add_child(dimension_label)
    
    # Playstyle display
    var playstyle_container = VBoxContainer.new()
    top_section.add_child(playstyle_container)
    
    var playstyle_title = Label.new()
    playstyle_title.text = "PLAYSTYLE"
    playstyle_title.align = Label.ALIGN_CENTER
    playstyle_container.add_child(playstyle_title)
    
    playstyle_label = Label.new()
    playstyle_label.text = "Unknown"
    playstyle_label.align = Label.ALIGN_CENTER
    playstyle_container.add_child(playstyle_label)
    
    # Middle section - Category Breakdown
    var middle_section = VBoxContainer.new()
    visualizer_container.add_child(middle_section)
    
    var categories_title = Label.new()
    categories_title.text = "POINTS BY CATEGORY"
    categories_title.align = Label.ALIGN_CENTER
    middle_section.add_child(categories_title)
    
    var categories_grid = GridContainer.new()
    categories_grid.columns = 5
    middle_section.add_child(categories_grid)
    
    # Create category bars
    for category in CATEGORY_COLORS:
        var category_container = VBoxContainer.new()
        categories_grid.add_child(category_container)
        
        var category_label = Label.new()
        category_label.text = category.capitalize()
        category_label.align = Label.ALIGN_CENTER
        category_container.add_child(category_label)
        
        var progress_bar = ProgressBar.new()
        progress_bar.max_value = 1.0
        progress_bar.rect_min_size = Vector2(80, 20)
        progress_bar.modulate = CATEGORY_COLORS[category]
        category_container.add_child(progress_bar)
        
        var value_label = Label.new()
        value_label.text = "0"
        value_label.align = Label.ALIGN_CENTER
        category_container.add_child(value_label)
        
        category_bars[category] = {"bar": progress_bar, "label": value_label}
    
    # Bottom section - Dimension Progress
    var bottom_section = VBoxContainer.new()
    visualizer_container.add_child(bottom_section)
    
    var dimension_progress_title = Label.new()
    dimension_progress_title.text = "PROGRESS TO NEXT DIMENSION"
    dimension_progress_title.align = Label.ALIGN_CENTER
    bottom_section.add_child(dimension_progress_title)
    
    dimension_progress = ProgressBar.new()
    dimension_progress.max_value = 1.0
    dimension_progress.rect_min_size = Vector2(300, 30)
    bottom_section.add_child(dimension_progress)
    
    # Create tween for animations
    tween = Tween.new()
    add_child(tween)
    
    # Visualization area
    setup_visualization_area()

func setup_visualization_area():
    # This would be a custom visualization based on the mode
    # For this example, we'll just add a placeholder
    var visualization_container = Control.new()
    visualization_container.rect_min_size = Vector2(400, 200)
    visualizer_container.add_child(visualization_container)
    
    # In a real implementation, this would create the actual visualization
    # based on the selected mode (radial, bar, line, etc.)

func connect_to_systems():
    # Connect to account manager
    if has_node("/root/SmartAccountManager") or get_node_or_null("/root/SmartAccountManager"):
        _account_manager = get_node("/root/SmartAccountManager")
        _account_manager.connect("points_updated", self, "_on_points_updated")
        _account_manager.connect("dimension_changed", self, "_on_dimension_changed")
        print("Connected to SmartAccountManager")
        
        # Initial data
        current_points = _account_manager.total_points
        current_dimension = _account_manager.current_dimension
        dimension_progress_value = _account_manager.get_progress_to_next_dimension()
        category_values = _account_manager.points_categories
    
    # Connect to preference analyzer
    if has_node("/root/PlayerPreferenceAnalyzer") or get_node_or_null("/root/PlayerPreferenceAnalyzer"):
        _preference_analyzer = get_node("/root/PlayerPreferenceAnalyzer")
        _preference_analyzer.connect("preferences_updated", self, "_on_preferences_updated")
        print("Connected to PlayerPreferenceAnalyzer")
    
    # Connect to auto-correction system
    if has_node("/root/AutoCorrectionSystem") or get_node_or_null("/root/AutoCorrectionSystem"):
        _auto_correction = get_node("/root/AutoCorrectionSystem")
        _auto_correction.connect("playstyle_detected", self, "_on_playstyle_detected")
        _auto_correction.connect("correction_applied", self, "_on_correction_applied")
        print("Connected to AutoCorrectionSystem")
        
        # Initial playstyle
        playstyle = _auto_correction.get_playstyle()

func update_visualization():
    # Update labels
    points_label.text = str(int(current_points))

    # Get dimension symbol
    var dimension_symbol = "#"
    if _account_manager and _account_manager.has_method("get_dimension_display"):
        dimension_label.text = _account_manager.get_dimension_display()
    else:
        dimension_symbol = "#".repeat(current_dimension)
        dimension_label.text = str(current_dimension) + " / 12 " + dimension_symbol

    playstyle_label.text = playstyle
    
    # Update dimension progress
    tween.interpolate_property(dimension_progress, "value", 
        dimension_progress.value, dimension_progress_value, 
        0.5 * animation_speed, Tween.TRANS_CUBIC, Tween.EASE_OUT)
    
    # Update dimension progress color
    dimension_progress.modulate = DIMENSION_COLORS[min(current_dimension - 1, DIMENSION_COLORS.size() - 1)]
    
    # Update category bars
    var total_points = 0
    for category in category_values:
        total_points += category_values[category]
    
    for category in category_bars:
        var value = 0
        if category in category_values:
            value = category_values[category]
        
        var normalized = 0.0
        if total_points > 0:
            normalized = float(value) / float(total_points)
        
        # Update progress bar
        tween.interpolate_property(category_bars[category]["bar"], "value", 
            category_bars[category]["bar"].value, normalized, 
            0.5 * animation_speed, Tween.TRANS_CUBIC, Tween.EASE_OUT)
        
        # Update label
        category_bars[category]["label"].text = str(int(value))
        
        # Highlight preferred categories
        if highlight_preferences and category in preferences:
            var pref_value = preferences[category]
            if pref_value >= 0.7:
                category_bars[category]["bar"].modulate = CATEGORY_COLORS[category].lightened(0.3)
            else:
                category_bars[category]["bar"].modulate = CATEGORY_COLORS[category]
    
    # Start animations
    tween.start()
    
    # In a real implementation, would also update the actual visualization
    # based on the visualization_mode

func _on_points_updated(total, category, amount):
    # Update current points
    current_points = total
    
    # Update category values if available
    if _account_manager:
        category_values = _account_manager.points_categories
    
    # Add to points history
    points_history.append({
        "points": total,
        "category": category,
        "amount": amount,
        "timestamp": OS.get_unix_time()
    })
    
    # Limit history size
    if points_history.size() > 100:
        points_history.pop_front()
    
    # Update visualization
    update_visualization()
    
    # If large point gain, add special effect
    if amount >= 50:
        play_point_gain_effect(amount)

func _on_dimension_changed(new_dimension):
    # Update dimension
    current_dimension = new_dimension
    
    # Get progress to next dimension
    if _account_manager:
        dimension_progress_value = _account_manager.get_progress_to_next_dimension()
    
    # Update visualization
    update_visualization()
    
    # Play dimension advancement effect
    play_dimension_advancement_effect()

func _on_preferences_updated(new_preferences):
    # Update preferences
    preferences = new_preferences
    
    # Update visualization
    update_visualization()

func _on_playstyle_detected(new_playstyle):
    # Update playstyle
    playstyle = new_playstyle
    
    # Update visualization
    update_visualization()

func _on_correction_applied(amount, category, reason):
    # Could show a subtle notification
    if amount >= 20:
        play_correction_effect(amount, category)

func play_point_gain_effect(amount):
    # In a real implementation, this would play a visual effect
    # For now, we'll just print to the console
    print("VISUAL EFFECT: Large point gain - " + str(amount) + " points!")

func play_dimension_advancement_effect():
    # In a real implementation, this would play a visual effect
    # For now, we'll just print to the console
    print("VISUAL EFFECT: Dimension advancement to level " + str(current_dimension) + "!")

func play_correction_effect(amount, category):
    # In a real implementation, this would play a visual effect
    # For now, we'll just print to the console
    print("VISUAL EFFECT: Auto-correction applied - " + str(amount) + " points to " + category + "!")

func set_visualization_mode(mode):
    # Validate mode
    if mode in VISUALIZATION_MODES:
        visualization_mode = mode
        
        # In a real implementation, would rebuild the visualization
        print("Changed visualization mode to: " + mode)
        return true
    
    return false

func set_animation_speed(speed):
    animation_speed = clamp(speed, 0.1, 3.0)
    return true

func set_color_scheme(scheme):
    color_scheme = scheme
    
    # In a real implementation, would update colors
    print("Changed color scheme to: " + scheme)
    return true

func toggle_predictions(enabled):
    show_predictions = enabled
    
    # In a real implementation, would update visualization
    print("Predictions " + ("enabled" if enabled else "disabled"))
    return true

func toggle_preference_highlighting(enabled):
    highlight_preferences = enabled
    update_visualization()
    return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/account_visualizer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/akashic_database_connector.gd
# SIZE: 7331 bytes
extends Node

class_name AkashicDatabaseConnector

# Constants
const WORD_POWER_MIN = 10
const WORD_POWER_MAX = 100

# Connection state
var is_connected = false
var javascript_initialized = false

# Connection to JS Akashic Database
var _js_interface = null

# Connection to GDScript Akashic Records System
var _gd_akashic = null

# Account properties
var current_account_id = ""
var dimension_access = 1

# Signals
signal database_connected()
signal database_disconnected()
signal word_added(word, power)
signal dimension_unlocked(dimension)

func _ready():
    # Attempt to connect to both implementations
    connect_to_akashic_systems()
    
    # Register callback for dimension unlock
    if _gd_akashic:
        if _gd_akashic.has_method("connect"):
            _gd_akashic.connect("dimension_unlocked", self, "_on_dimension_unlocked")

func connect_to_akashic_systems():
    # Try to connect to GDScript implementation
    if has_node("/root/AkashicRecordsSystem") or get_node_or_null("/root/AkashicRecordsSystem"):
        _gd_akashic = get_node("/root/AkashicRecordsSystem")
        print("Connected to GDScript AkashicRecordsSystem")
        is_connected = true
    
    # Initialize JavaScript bridge if available
    if has_node("/root/JavaScriptBridge") or get_node_or_null("/root/JavaScriptBridge"):
        _js_interface = get_node("/root/JavaScriptBridge")
        initialize_js_database()
    
    if is_connected:
        emit_signal("database_connected")
        return true
    
    return false

func initialize_js_database():
    # Check if the JavaScript bridge is available
    if not _js_interface:
        return false
    
    # Initialize the JavaScript Akashic Database
    _js_interface.eval("""
        if (typeof window.AkashicDatabase === 'undefined') {
            console.log('Loading Akashic Database JS module...');
            // Would load the actual module here
            window.AkashicDatabase = {
                initialized: false,
                initialize: function() {
                    this.initialized = true;
                    return true;
                },
                addWord: function(word, power, metadata) {
                    console.log('Adding word: ' + word + ' with power: ' + power);
                    return true;
                },
                searchWord: function(word) {
                    return { found: false };
                }
            };
        }
        
        // Initialize the database
        window.AkashicDatabase.initialize();
    """)
    
    # Check if initialization was successful
    var result = _js_interface.eval("window.AkashicDatabase.initialized")
    javascript_initialized = result
    
    print("JavaScript Akashic Database initialized: " + str(javascript_initialized))
    
    if javascript_initialized:
        is_connected = true
        emit_signal("database_connected")
    
    return javascript_initialized

func set_account_id(account_id):
    current_account_id = account_id
    
    # Update in GDScript implementation if available
    if _gd_akashic and _gd_akashic.has_method("set_user_id"):
        _gd_akashic.set_user_id(account_id)
    
    # Update in JavaScript implementation if available
    if javascript_initialized and _js_interface:
        _js_interface.eval("window.AkashicDatabase.currentUserId = '" + account_id + "';")

func unlock_dimension(dimension):
    # Validate dimension
    dimension = int(dimension)
    if dimension <= dimension_access:
        return false
    
    dimension_access = dimension
    print("Unlocked Akashic dimension access: " + str(dimension))
    
    # Update in GDScript implementation if available
    if _gd_akashic and _gd_akashic.has_method("unlock_dimension"):
        _gd_akashic.unlock_dimension(dimension)
    
    # Update in JavaScript implementation if available
    if javascript_initialized and _js_interface:
        _js_interface.eval("window.AkashicDatabase.dimensionAccess = " + str(dimension) + ";")
    
    emit_signal("dimension_unlocked", dimension)
    return true

func add_word(word, power = 50, metadata = {}):
    # Validate parameters
    word = str(word).strip_edges()
    if word.empty():
        return false
    
    # Clamp power between min and max
    power = clamp(power, WORD_POWER_MIN, WORD_POWER_MAX)
    
    # Add owner/timestamp if not provided
    if not metadata.has("owner"):
        metadata["owner"] = current_account_id
    
    if not metadata.has("timestamp"):
        metadata["timestamp"] = OS.get_unix_time()
    
    if not metadata.has("dimension"):
        metadata["dimension"] = dimension_access
    
    # Add to GDScript implementation if available
    var success = false
    if _gd_akashic and _gd_akashic.has_method("add_record"):
        success = _gd_akashic.add_record({
            "type": "word",
            "content": word,
            "power": power,
            "metadata": metadata
        })
    
    # Add to JavaScript implementation if available
    if javascript_initialized and _js_interface:
        var js_result = _js_interface.eval("""
            window.AkashicDatabase.addWord(
                '""" + word + """', 
                """ + str(power) + """, 
                """ + JSON.print(metadata) + """
            );
        """)
        
        if js_result:
            success = true
    
    if success:
        emit_signal("word_added", word, power)
    
    return success

func search_word(word):
    word = str(word).strip_edges()
    if word.empty():
        return null
    
    # Try GDScript implementation first
    if _gd_akashic and _gd_akashic.has_method("get_record"):
        var result = _gd_akashic.get_record(word)
        if result:
            return result
    
    # Try JavaScript implementation
    if javascript_initialized and _js_interface:
        var js_result = _js_interface.eval("""
            window.AkashicDatabase.searchWord('""" + word + """');
        """)
        
        if typeof(js_result) == TYPE_DICTIONARY and js_result.has("found") and js_result.found:
            return js_result
    
    return null

func record_creation_event(points):
    # Record creation event with points
    var metadata = {
        "type": "creation",
        "points": points,
        "timestamp": OS.get_unix_time(),
        "owner": current_account_id,
        "dimension": dimension_access
    }
    
    # Add to GDScript implementation if available
    if _gd_akashic and _gd_akashic.has_method("add_record"):
        _gd_akashic.add_record({
            "type": "event",
            "content": "creation_points",
            "points": points,
            "metadata": metadata
        })
    
    # Add to JavaScript implementation if available
    if javascript_initialized and _js_interface:
        _js_interface.eval("""
            if (window.AkashicDatabase.recordEvent) {
                window.AkashicDatabase.recordEvent(
                    'creation_points',
                    """ + str(points) + """,
                    """ + JSON.print(metadata) + """
                );
            }
        """)

func _on_dimension_unlocked(dimension):
    # Update internal dimension access
    dimension_access = max(dimension_access, dimension)
    
    # Propagate signal
    emit_signal("dimension_unlocked", dimension)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/akashic_database_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/akashic_notepad_controller.gd
# SIZE: 22534 bytes
extends Node

# Akashic Notepad Controller
# Integrates SpatialWorldStorage and Notepad3D system with main game controller
# Handles 3D visualization and storage of akashic records and notepad entries
# Creates bridge between word manifestation and spatial data systems

# ----- CONSTANTS -----
const DEFAULT_NOTEBOOK_NAME = "divine_notepad"
const AKASHIC_DATABASE_NAME = "akashic_record"
const SACRED_DIMENSION = 9  # 9th dimension - Harmony dimension
const MAX_VISUALIZED_ENTRIES = 100

# ----- COMPONENT REFERENCES -----
var spatial_storage: SpatialWorldStorage
var spatial_visualizer: Notepad3DVisualizer
var integration: SpatialNotepadIntegration
var main_controller = null
var word_manifestation_system = null

# ----- STATE VARIABLES -----
var active_notebook = ""
var active_dimension = 3
var current_visualized_entries = []
var auto_save_timer = 0
var initialized = false
var auto_process_entries = true
var last_note_position = Vector3.ZERO
var sacred_interval_counter = 0

# ----- SIGNALS -----
signal record_created(entry_id)
signal notebook_created(notebook_name)
signal akashic_synergy_detected(entries)
signal dimension_power_calculated(dimension, power)

# ----- INITIALIZATION -----
func _ready():
    print("Akashic Notepad Controller initializing...")
    
    # Create storage system
    spatial_storage = SpatialWorldStorage.new()
    add_child(spatial_storage)
    
    # Initialize with default notebook if needed
    _initialize_default_notebook()
    
    # Connect to signals from storage
    spatial_storage.connect("entry_added", self, "_on_entry_added")
    spatial_storage.connect("notebook_updated", self, "_on_notebook_updated")
    
    # Note: The visualizer will be connected when set_visualizer is called
    
    print("Akashic Notepad Controller initialized")
    initialized = true

# ----- PROCESS FUNCTION -----
func _process(delta):
    if not initialized:
        return
    
    # Auto-save timer
    auto_save_timer += delta
    if auto_save_timer >= 60.0:  # Save every minute
        auto_save_timer = 0
        save_all_data()
    
    # Handle automatic entry processing
    if auto_process_entries and main_controller:
        sacred_interval_counter += delta
        if sacred_interval_counter >= 9.0:  # Sacred 9-second interval
            sacred_interval_counter = 0
            process_new_entries()

# ----- SETUP FUNCTIONS -----
func set_main_controller(controller):
    main_controller = controller
    
    if controller:
        # Connect to main controller signals
        controller.connect("note_created", self, "_on_note_created")
        controller.connect("turn_advanced", self, "_on_turn_advanced")
        controller.connect("word_manifested", self, "_on_word_manifested")
        
        print("Connected to main controller")
        return true
    return false

func set_visualizer(visualizer):
    spatial_visualizer = visualizer
    
    if visualizer:
        # Create integration system
        integration = SpatialNotepadIntegration.new()
        add_child(integration)
        
        # Connect components
        integration.connect_components(spatial_storage, visualizer)
        
        # Connect to integration signals
        integration.connect("cell_created", self, "_on_cell_created")
        integration.connect("entry_visualized", self, "_on_entry_visualized")
        
        print("Connected to visualizer via integration system")
        return true
    return false

func set_word_manifestation_system(system):
    word_manifestation_system = system
    
    if system and spatial_visualizer:
        # Connect manifestation system to visualizer
        spatial_visualizer.set_word_manifestation_system(system)
        
        print("Connected word manifestation system to visualizer")
        return true
    return false

# ----- AKASHIC RECORD FUNCTIONS -----
func create_akashic_entry(content, position, dimension = 0, tags = []):
    if not spatial_storage:
        return null
    
    # Default to current dimension if not specified
    if dimension == 0 and main_controller:
        dimension = main_controller.current_turn
    elif dimension == 0:
        dimension = active_dimension
    
    # Calculate power based on word processor if available
    var power = 50.0  # Default power
    var author = "system"
    
    if main_controller and main_controller.word_processor:
        var result = main_controller.word_processor.process_text(content, "akashic", 2)
        power = result.total_power
        author = "divine"
    
    # Create dimensional point for position
    var coord = spatial_storage.Coordinate.new(position.x, position.y, position.z)
    var dim_point = spatial_storage.DimensionalPoint.new(coord, dimension, power)
    
    # Add entry
    var entry_id = spatial_storage.add_akashic_entry(dim_point, content, author, tags)
    
    print("Created akashic entry with ID: %s (Power: %.1f)" % [entry_id, power])
    emit_signal("record_created", entry_id)
    
    # Automatically visualize if entries are being displayed
    if not current_visualized_entries.empty() and integration:
        visualize_akashic_record()
    
    return entry_id

func get_akashic_entry(entry_id):
    if not spatial_storage:
        return null
    
    return spatial_storage.get_akashic_entry(entry_id)

func find_entries_by_tag(tag):
    if not spatial_storage:
        return []
    
    return spatial_storage.find_entries_by_tag(tag)

func find_entries_by_dimension(dimension):
    if not spatial_storage:
        return []
    
    return spatial_storage.find_entries_by_dimension(dimension)

func connect_akashic_entries(source_id, target_id):
    if not spatial_storage:
        return false
    
    return spatial_storage.connect_entries(source_id, target_id)

func visualize_akashic_record(dimension = 0, limit = MAX_VISUALIZED_ENTRIES):
    if not spatial_storage or not integration:
        return false
    
    # Default to current dimension if not specified
    if dimension == 0 and main_controller:
        dimension = main_controller.current_turn
    elif dimension == 0:
        dimension = active_dimension
    
    # Find entries for this dimension
    var entries = spatial_storage.find_entries_by_dimension(dimension)
    
    # Sort by power (highest first)
    entries.sort_custom(self, "_sort_entries_by_power")
    
    # Limit number of entries
    if entries.size() > limit:
        entries = entries.slice(0, limit - 1)
    
    # Get entry IDs
    var entry_ids = []
    for entry in entries:
        entry_ids.append(entry.entry_id)
    
    # Store current visualization
    current_visualized_entries = entry_ids
    
    # Visualize
    var result = integration.visualize_akashic_entries(entry_ids)
    
    if result:
        print("Visualizing %d akashic entries for dimension %d" % [entry_ids.size(), dimension])
    
    return result

func create_notebook_from_akashic(dimension, notebook_name = ""):
    if not spatial_storage:
        return false
    
    # Generate name if not provided
    if notebook_name.empty():
        notebook_name = "dimension_%d_notebook" % dimension
    
    # Find entries for this dimension
    var entries = spatial_storage.find_entries_by_dimension(dimension)
    
    # Get entry IDs
    var entry_ids = []
    for entry in entries:
        entry_ids.append(entry.entry_id)
    
    # Create notebook
    var result = spatial_storage.create_notepad_from_akashic(entry_ids, notebook_name)
    
    if result:
        print("Created notebook '%s' from %d akashic entries" % [notebook_name, entry_ids.size()])
        emit_signal("notebook_created", notebook_name)
    
    return result

# ----- NOTEPAD FUNCTIONS -----
func create_notepad(name, tags = []):
    if not spatial_storage:
        return false
    
    var notebook_name = spatial_storage.create_notepad(name, tags)
    
    if notebook_name:
        print("Created notepad: %s" % notebook_name)
        emit_signal("notebook_created", notebook_name)
    
    return notebook_name

func add_notepad_cell(notebook_name, position, content, color = Color.white):
    if not spatial_storage:
        return null
    
    var cell_id = spatial_storage.add_cell_to_notepad(notebook_name, position, content, color)
    
    if cell_id:
        # Automatically display if this notebook is active
        if notebook_name == active_notebook and integration:
            integration.update_cell_visualization(notebook_name, cell_id)
    
    return cell_id

func visualize_notepad(notebook_name):
    if not integration:
        return false
    
    active_notebook = notebook_name
    current_visualized_entries = []  # Clear akashic entries
    
    var result = integration.visualize_notebook(notebook_name)
    
    if result:
        print("Visualizing notepad: %s" % notebook_name)
    
    return result

# ----- UTILITY FUNCTIONS -----
func _initialize_default_notebook():
    if not spatial_storage:
        return
    
    // Check if default notebook exists
    if spatial_storage.get_notepad(DEFAULT_NOTEBOOK_NAME) == null:
        // Create default notebook
        spatial_storage.create_notepad(DEFAULT_NOTEBOOK_NAME, ["default", "system"])
        print("Created default notebook: %s" % DEFAULT_NOTEBOOK_NAME)

func save_all_data():
    if not spatial_storage:
        return
    
    spatial_storage.save_akashic_records()
    spatial_storage.save_notepad_notebooks()
    spatial_storage.save_spatial_maps()
    
    print("Saved all spatial data")

func process_new_entries():
    if not spatial_storage or not main_controller:
        return
    
    # Process any new notes into akashic entries
    var notes = main_controller.get_notes_for_current_turn()
    
    for note_id in notes:
        var note = notes[note_id]
        
        # Skip notes that are already processed
        if note.get("processed", false):
            continue
        
        # Create akashic entry from note
        if note.power > 30:  # Only process significant notes
            # Generate position
            var position = note.position
            if position == Vector3.ZERO:
                # Create spiral pattern for notes
                position = _generate_spiral_position()
                last_note_position = position
            
            # Extract tags from note content
            var tags = _extract_tags_from_text(note.text)
            
            # Create entry
            create_akashic_entry(note.text, position, note.turn, tags)
            
            # Mark as processed
            note.processed = true
    
    # Find synergies
    _check_for_synergies()

func _check_for_synergies():
    if not spatial_storage:
        return
    
    var synergies = spatial_storage.find_spatial_synergies(10.0)  # High threshold
    
    if synergies.size() > 0:
        print("Found %d akashic synergies" % synergies.size())
        emit_signal("akashic_synergy_detected", synergies)
        
        # If in sacred dimension, synergies have special effects
        if main_controller and main_controller.current_turn == SACRED_DIMENSION:
            _process_sacred_synergies(synergies)

func _process_sacred_synergies(synergies):
    if not spatial_storage or not main_controller:
        return
    
    var total_power = 0
    
    for synergy in synergies:
        total_power += synergy.strength
        
        // Connect entries if not already connected
        spatial_storage.connect_entries(synergy.entry_a, synergy.entry_b)
    
    // Calculate dimension power
    var dimension_power = total_power * main_controller.current_turn
    
    print("Sacred synergies detected with total power: %f" % dimension_power)
    emit_signal("dimension_power_calculated", main_controller.current_turn, dimension_power)
    
    // Create special entry to mark the synergy
    var synergy_position = Vector3(0, total_power / 10.0, 0)
    create_akashic_entry(
        "Dimensional synergy detected in the Harmony dimension with power: " + str(dimension_power),
        synergy_position,
        SACRED_DIMENSION,
        ["synergy", "harmony", "sacred"]
    )

func _extract_tags_from_text(text):
    var tags = []
    
    // Look for hashtags in text
    var regex = RegEx.new()
    regex.compile("#\\w+")
    var results = regex.search_all(text)
    
    for result in results:
        var tag = result.get_string().substr(1)  // Remove # symbol
        if not tag in tags:
            tags.append(tag)
    
    // If no tags found, add some based on content
    if tags.empty():
        // Add dimension tag
        if main_controller:
            tags.append("dim" + str(main_controller.current_turn))
        
        // Check for keywords
        var keywords = ["reality", "akashic", "divine", "word", "notepad", "dimension", "sacred"]
        for keyword in keywords:
            if text.to_lower().find(keyword) >= 0:
                tags.append(keyword)
                break
    
    return tags

func _generate_spiral_position():
    // Generate a position in a spiral pattern
    var angle = last_note_position.length() * 0.5
    var radius = 5.0 + (last_note_position.length() * 0.1)
    var height = last_note_position.y + 0.5
    
    if height > 20:
        height = 0
    
    return Vector3(
        sin(angle) * radius,
        height,
        cos(angle) * radius
    )

func _sort_entries_by_power(a, b):
    // Sort in descending order of power
    return a.position.power > b.position.power

# ----- EVENT HANDLERS -----
func _on_note_created(note_data):
    if auto_process_entries:
        process_new_entries()

func _on_turn_advanced(turn_number, symbol, dimension):
    active_dimension = turn_number
    
    // Visualize akashic records for new dimension
    if not current_visualized_entries.empty():
        visualize_akashic_record(turn_number)

func _on_word_manifested(word, position, power):
    // Create akashic entry for significant manifestations
    if power > 75:
        create_akashic_entry(
            "The word '" + word + "' manifested with divine power", 
            position, 
            active_dimension, 
            ["manifested", "word", "divine"]
        )

func _on_entry_added(entry_id):
    // Check for synergies when new entries are added
    if auto_process_entries:
        _check_for_synergies()

func _on_notebook_updated(notebook_name):
    // Update visualization if this is the active notebook
    if notebook_name == active_notebook and integration:
        integration.visualize_notebook(notebook_name)

func _on_cell_created(notebook_name, cell_id):
    print("Cell created in notebook %s: %s" % [notebook_name, cell_id])

func _on_entry_visualized(entry_id):
    print("Akashic entry visualized: %s" % entry_id)

# ----- COMMAND PROCESSING -----
func process_command(command, args):
    match command:
        "akashic":
            return _process_akashic_command(args)
        
        "notepad", "notebook":
            return _process_notepad_command(args)
        
        "visualize":
            return _process_visualize_command(args)
        
        "3d":
            return _process_3d_command(args)
            
        _:
            return "Unknown command: " + command

func _process_akashic_command(args):
    if args.empty():
        return "Usage: akashic [create|list|find|connect|synergy]"
    
    match args[0]:
        "create":
            if args.size() < 2:
                return "Usage: akashic create <content> [dimension] [tag1,tag2,...]"
            
            var content = args[1]
            var dimension = 0
            var tags = []
            
            if args.size() > 2 and args[2].is_valid_integer():
                dimension = int(args[2])
            
            if args.size() > 3:
                tags = args[3].split(",")
            
            var position = _generate_spiral_position()
            var entry_id = create_akashic_entry(content, position, dimension, tags)
            
            if entry_id:
                return "Created akashic entry: " + entry_id
            else:
                return "Failed to create entry"
        
        "list":
            var dimension = 0
            if args.size() > 1 and args[1].is_valid_integer():
                dimension = int(args[1])
            
            var entries = find_entries_by_dimension(dimension)
            return "Found %d entries in dimension %d" % [entries.size(), dimension]
        
        "find":
            if args.size() < 2:
                return "Usage: akashic find <tag>"
            
            var tag = args[1]
            var entries = find_entries_by_tag(tag)
            return "Found %d entries with tag '%s'" % [entries.size(), tag]
        
        "connect":
            if args.size() < 3:
                return "Usage: akashic connect <source_id> <target_id>"
            
            var source = args[1]
            var target = args[2]
            
            if connect_akashic_entries(source, target):
                return "Connected entries: %s -> %s" % [source, target]
            else:
                return "Failed to connect entries"
        
        "synergy":
            var threshold = 5.0
            if args.size() > 1 and args[1].is_valid_float():
                threshold = float(args[1])
            
            var synergies = spatial_storage.find_spatial_synergies(threshold)
            return "Found %d synergies with threshold %.1f" % [synergies.size(), threshold]
        
        _:
            return "Unknown akashic subcommand: " + args[0]

func _process_notepad_command(args):
    if args.empty():
        return "Usage: notepad [create|add|visualize|list]"
    
    match args[0]:
        "create":
            if args.size() < 2:
                return "Usage: notepad create <name> [tag1,tag2,...]"
            
            var name = args[1]
            var tags = []
            
            if args.size() > 2:
                tags = args[2].split(",")
            
            var result = create_notepad(name, tags)
            
            if result:
                return "Created notepad: " + name
            else:
                return "Failed to create notepad"
        
        "add":
            if args.size() < 3:
                return "Usage: notepad add <notebook_name> <content> [x,y,z]"
            
            var notebook = args[1]
            var content = args[2]
            var position = Vector3.ZERO
            
            if args.size() > 3:
                var pos_parts = args[3].split(",")
                if pos_parts.size() >= 3:
                    position = Vector3(
                        float(pos_parts[0]),
                        float(pos_parts[1]),
                        float(pos_parts[2])
                    )
            
            var cell_id = add_notepad_cell(notebook, position, content)
            
            if cell_id:
                return "Added cell to notebook: " + cell_id
            else:
                return "Failed to add cell"
        
        "visualize":
            if args.size() < 2:
                return "Usage: notepad visualize <notebook_name>"
            
            var notebook = args[1]
            
            if visualize_notepad(notebook):
                return "Visualizing notebook: " + notebook
            else:
                return "Failed to visualize notebook"
        
        "list":
            if not spatial_storage:
                return "Storage system not available"
            
            var notebooks = spatial_storage.notepad_notebooks
            
            if notebooks.empty():
                return "No notebooks found"
            
            var result = "Notebooks:\n"
            for name in notebooks:
                var notebook = notebooks[name]
                result += "- %s: %d cells\n" % [name, notebook.cells.size()]
            
            return result
        
        "convert":
            if args.size() < 3:
                return "Usage: notepad convert <dimension> <notebook_name>"
            
            var dimension = int(args[1])
            var notebook = args[2]
            
            if create_notebook_from_akashic(dimension, notebook):
                return "Created notebook '%s' from dimension %d entries" % [notebook, dimension]
            else:
                return "Failed to create notebook from akashic entries"
        
        _:
            return "Unknown notepad subcommand: " + args[0]

func _process_visualize_command(args):
    if args.empty():
        return "Usage: visualize [akashic|notepad|clear]"
    
    match args[0]:
        "akashic":
            var dimension = 0
            
            if args.size() > 1 and args[1].is_valid_integer():
                dimension = int(args[1])
            
            if visualize_akashic_record(dimension):
                return "Visualizing akashic record for dimension " + str(dimension)
            else:
                return "Failed to visualize akashic record"
        
        "notepad":
            if args.size() < 2:
                return "Usage: visualize notepad <notebook_name>"
            
            var notebook = args[1]
            
            if visualize_notepad(notebook):
                return "Visualizing notebook: " + notebook
            else:
                return "Failed to visualize notebook"
        
        "clear":
            if integration:
                integration.clear_visualizations()
                current_visualized_entries = []
                active_notebook = ""
                return "Cleared all visualizations"
            return "Integration system not available"
        
        _:
            return "Unknown visualize subcommand: " + args[0]

func _process_3d_command(args):
    if args.empty():
        return "Usage: 3d [save|load|auto]"
    
    match args[0]:
        "save":
            save_all_data()
            return "Saved all 3D data"
        
        "load":
            if spatial_storage:
                spatial_storage.load_all_data()
                return "Loaded all 3D data"
            return "Storage system not available"
        
        "auto":
            if args.size() > 1 and (args[1] == "on" or args[1] == "off"):
                auto_process_entries = (args[1] == "on")
                return "Auto process entries: " + args[1]
            return "Usage: 3d auto [on|off]"
        
        _:
            return "Unknown 3d subcommand: " + args[0]
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/akashic_notepad_controller.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/akashic_number_system.gd
# SIZE: 7474 bytes
class_name AkashicNumberSystem
extends Node

# Core number limits
const NUMERIC_BOUNDARIES = {
    "BASE_LIMIT": 9,
    "EXPANDED_LIMIT": 99,
    "MULTIPLICATION_FACTOR": 33,
    "SYMBOL_COUNT": 7,
    "DIMENSIONAL_LIMIT": 5
}

# Symbol mapping for the SCRIPUTRA system
var SCRIPUTRA_SYMBOLS = {
    "#": {"value": 1, "function": "direct_connection", "dimensional_depth": 1},
    "##": {"value": 2, "function": "secondary_connection", "dimensional_depth": 2},
    "###": {"value": 3, "function": "tertiary_connection", "dimensional_depth": 3},
    "#_": {"value": 4, "function": "snake_connection", "dimensional_depth": 2},
    "_#": {"value": 5, "function": "reverse_connection", "dimensional_depth": 2},
    "#9": {"value": 9, "function": "limit_connection", "dimensional_depth": 4},
    "##9": {"value": 99, "function": "expanded_connection", "dimensional_depth": 5}
}

# Akashic Records structure
var AKASHIC_RECORDS = {
    "LAYERS": 9,
    "RECORDS_PER_LAYER": 99,
    "TOTAL_CAPACITY": 9 * 99, # 891
    "ACTIVE_RECORDS": []
}

# Text processing limits
var TEXT_PROCESSING = {
    "LINE_LIMIT": 9,
    "CHAR_LIMIT_PER_LINE": 99,
    "PRECISION_CUTTING": true,
    "FOLDING_ENABLED": true
}

# Schedule management for weekly tasks
var SCHEDULE_LOOP = {
    "DAYS_IN_CYCLE": 7,
    "PRIORITY_LEVELS": ["#", "##", "###"],
    "CURRENT_DAY": 0,
    "TASKS_PER_DAY": 9
}

# Lucky number patterns
var LUCKY_NUMBERS = {
    "888": {"meaning": "prosperity", "multiplier": 3},
    "1333": {"meaning": "transformation", "multiplier": 4}
}

# Constructor with initialization
func _init():
    initialize_akashic_records()
    set_current_day()

# Initialize the akashic records structure
func initialize_akashic_records():
    AKASHIC_RECORDS.ACTIVE_RECORDS = []
    for i in range(AKASHIC_RECORDS.LAYERS):
        var layer_records = []
        for j in range(AKASHIC_RECORDS.RECORDS_PER_LAYER):
            layer_records.append(null)
        AKASHIC_RECORDS.ACTIVE_RECORDS.append(layer_records)

# Set the current day based on system time
func set_current_day():
    var date = Time.get_date_dict_from_system()
    SCHEDULE_LOOP.CURRENT_DAY = date.weekday % SCHEDULE_LOOP.DAYS_IN_CYCLE

# Transform text to SNAKE_CASE format
func to_snake_case(text: String) -> String:
    text = text.to_lower()
    # Replace spaces and non-alphanumeric characters with underscores
    var regex = RegEx.new()
    regex.compile("\\s+|[^a-z0-9]")
    text = regex.sub(text, "_", true)
    # Remove consecutive underscores
    regex.compile("_+")
    text = regex.sub(text, "_", true)
    # Remove leading/trailing underscores
    text = text.strip_edges(true, true)
    if text.begins_with("_"):
        text = text.substr(1)
    if text.ends_with("_"):
        text = text.substr(0, text.length() - 1)
    return text

# Process text according to the LINE_LIMIT and other constraints
func process_text(text: String) -> String:
    var lines = text.split("\n")
    var processed_lines = []
    
    # Apply LINE_LIMIT
    var max_lines = min(lines.size(), TEXT_PROCESSING.LINE_LIMIT)
    
    for i in range(max_lines):
        var line = lines[i]
        # Apply character limit if needed
        if line.length() > TEXT_PROCESSING.CHAR_LIMIT_PER_LINE:
            line = line.substr(0, TEXT_PROCESSING.CHAR_LIMIT_PER_LINE)
        
        # Process line with precision cutting if enabled
        if TEXT_PROCESSING.PRECISION_CUTTING:
            line = apply_precision_cutting(line)
        
        processed_lines.append(line)
    
    return "\n".join(processed_lines)

# Apply precision cutting to maintain semantic integrity
func apply_precision_cutting(line: String) -> String:
    # Find the last complete word that fits within the character limit
    if line.length() <= TEXT_PROCESSING.CHAR_LIMIT_PER_LINE:
        return line
    
    var limit = TEXT_PROCESSING.CHAR_LIMIT_PER_LINE
    while limit > 0 and limit < line.length():
        if line[limit] == ' ':
            return line.substr(0, limit)
        limit -= 1
    
    # If no space found, just cut at the limit
    return line.substr(0, TEXT_PROCESSING.CHAR_LIMIT_PER_LINE)

# Store a record in the akashic structure
func store_record(layer: int, index: int, data) -> bool:
    if layer < 0 or layer >= AKASHIC_RECORDS.LAYERS:
        return false
    if index < 0 or index >= AKASHIC_RECORDS.RECORDS_PER_LAYER:
        return false
    
    AKASHIC_RECORDS.ACTIVE_RECORDS[layer][index] = data
    return true

# Retrieve a record from the akashic structure
func get_record(layer: int, index: int):
    if layer < 0 or layer >= AKASHIC_RECORDS.LAYERS:
        return null
    if index < 0 or index >= AKASHIC_RECORDS.RECORDS_PER_LAYER:
        return null
    
    return AKASHIC_RECORDS.ACTIVE_RECORDS[layer][index]

# Generate schedule for the next week
func generate_next_week_schedule(tasks: Dictionary) -> String:
    var schedule = "SCHEDULE FOR NEXT WEEK:\n"
    
    for day in range(SCHEDULE_LOOP.DAYS_IN_CYCLE):
        var day_name = get_day_name(day)
        schedule += "DAY " + str(day + 1) + " (" + day_name + "):\n"
        
        if tasks.has(day):
            var day_tasks = tasks[day]
            var count = 0
            for task in day_tasks:
                if count >= SCHEDULE_LOOP.TASKS_PER_DAY:
                    break
                
                var priority_level = min(task.get("priority", 0), SCHEDULE_LOOP.PRIORITY_LEVELS.size() - 1)
                var priority_symbol = SCHEDULE_LOOP.PRIORITY_LEVELS[priority_level]
                
                schedule += "  " + priority_symbol + " " + task.get("description", "Unknown task") + "\n"
                count += 1
        else:
            schedule += "  No tasks scheduled\n"
        
        schedule += "\n"
    
    return schedule

# Get day name from index
func get_day_name(day_index: int) -> String:
    var days = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
    return days[day_index % days.size()]

# Calculate symbolic value based on the SCRIPUTRA system
func calculate_symbolic_value(symbol: String) -> int:
    if SCRIPUTRA_SYMBOLS.has(symbol):
        return SCRIPUTRA_SYMBOLS[symbol].value
    return 0

# Get dimensional depth of a symbol
func get_dimensional_depth(symbol: String) -> int:
    if SCRIPUTRA_SYMBOLS.has(symbol):
        return SCRIPUTRA_SYMBOLS[symbol].dimensional_depth
    return 0

# Apply lucky number transformations
func apply_lucky_number(value: int) -> int:
    var value_str = str(value)
    
    # Check for 888 pattern
    if value_str.find("888") != -1:
        value *= LUCKY_NUMBERS["888"].multiplier
    
    # Check for 1333 pattern
    if value_str.find("1333") != -1:
        value *= LUCKY_NUMBERS["1333"].multiplier
    
    return value

# Calculate the "legged it" time based on turns of an hour
func calculate_legged_time(turns: int, minutes_per_turn: int = 2) -> Dictionary:
    var total_minutes = turns * minutes_per_turn
    var hours = total_minutes / 60
    var remaining_minutes = total_minutes % 60
    
    return {
        "turns": turns,
        "minutes": total_minutes,
        "hours": hours,
        "remaining_minutes": remaining_minutes,
        "formatted": "%d hours %d minutes (%d turns)" % [hours, remaining_minutes, turns]
    }

# Calculate the turns based on play time
func calculate_turns_from_time(hours: float) -> int:
    var minutes = hours * 60
    return int(minutes / 2) # Assuming 2 minutes per turn
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/akashic_number_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/api_key_manager.gd
# SIZE: 12223 bytes
extends Node

class_name ApiKeyManager

# API Provider types
enum ApiProvider {
    OPENAI,
    GOOGLE,
    DROPBOX,
    GITHUB,
    CUSTOM
}

# Key security levels
enum SecurityLevel {
    MINIMAL,
    STANDARD,
    HIGH,
    MAXIMUM
}

# API key data structure
var api_keys = {}

# Security settings
var encryption_enabled = true
var rotation_enabled = false
var rotation_interval_days = 90
var usage_tracking_enabled = true

# Storage
var secure_storage = {}
var usage_logs = []

# References
var _account_manager = null
var _processor = null

# Signals
signal key_added(provider, masked_key)
signal key_removed(provider)
signal key_rotated(provider, old_masked_key, new_masked_key)
signal usage_threshold_reached(provider, usage_percent)

func _ready():
    # Connect to other systems
    connect_to_systems()
    
    # Set up security check timer
    var security_timer = Timer.new()
    security_timer.wait_time = 3600 # Check once per hour
    security_timer.autostart = true
    security_timer.connect("timeout", self, "_on_security_check")
    add_child(security_timer)

func connect_to_systems():
    # Connect to MultiAccountManager
    if has_node("/root/MultiAccountManager") or get_node_or_null("/root/MultiAccountManager"):
        _account_manager = get_node("/root/MultiAccountManager")
        print("Connected to MultiAccountManager")
    
    # Connect to MultiThreadedProcessor
    if has_node("/root/MultiThreadedProcessor") or get_node_or_null("/root/MultiThreadedProcessor"):
        _processor = get_node("/root/MultiThreadedProcessor")
        print("Connected to MultiThreadedProcessor")

func add_api_key(provider_id, api_key, account_id = "", security_level = SecurityLevel.STANDARD, alias = ""):
    # Validate inputs
    if not provider_id in ApiProvider.values() and provider_id is String:
        provider_id = ApiProvider.CUSTOM
    
    # Generate unique key ID
    var key_id = str(OS.get_unix_time()) + "_" + str(randi() % 10000)
    
    # Use account if connected to account manager
    if account_id.empty() and _account_manager:
        account_id = _account_manager.active_account_id
    
    # Set provider name
    var provider_name = provider_id
    if provider_id in ApiProvider.values():
        provider_name = ApiProvider.keys()[provider_id]
    
    # Assign alias if not provided
    if alias.empty():
        alias = provider_name + " API Key"
    
    # Get masked key for logging/display
    var masked_key = _mask_api_key(api_key)
    
    # Store the API key data
    api_keys[key_id] = {
        "provider": provider_id,
        "provider_name": provider_name,
        "key": _encrypt_key(api_key) if encryption_enabled else api_key,
        "encrypted": encryption_enabled,
        "account_id": account_id,
        "added_at": OS.get_unix_time(),
        "last_used": 0,
        "last_validated": OS.get_unix_time(),
        "security_level": security_level,
        "alias": alias,
        "is_valid": true,
        "usage_count": 0,
        "masked_key": masked_key,
        "rotation_due": OS.get_unix_time() + (rotation_interval_days * 86400) if rotation_enabled else 0
    }
    
    # Log the addition
    _log_key_event(key_id, "added", {
        "provider": provider_name,
        "account_id": account_id,
        "masked_key": masked_key
    })
    
    # Emit signal
    emit_signal("key_added", provider_name, masked_key)
    
    print("Added API key for " + provider_name + ": " + masked_key)
    return key_id

func get_api_key(provider, account_id = ""):
    # Find matching API key
    for key_id in api_keys:
        var key_info = api_keys[key_id]
        
        var provider_match = false
        if provider is int and key_info["provider"] == provider:
            provider_match = true
        elif provider is String and key_info["provider_name"] == provider:
            provider_match = true
        
        var account_match = account_id.empty() or key_info["account_id"] == account_id
        
        if provider_match and account_match and key_info["is_valid"]:
            # Update usage stats
            key_info["last_used"] = OS.get_unix_time()
            key_info["usage_count"] += 1
            
            # Return decrypted key
            return _decrypt_key(key_info["key"]) if key_info["encrypted"] else key_info["key"]
    
    print("No API key found for provider: " + str(provider))
    return ""

func remove_api_key(key_id):
    if not key_id in api_keys:
        print("API key not found: " + key_id)
        return false
    
    var provider_name = api_keys[key_id]["provider_name"]
    var masked_key = api_keys[key_id]["masked_key"]
    
    # Log the removal
    _log_key_event(key_id, "removed", {
        "provider": provider_name,
        "masked_key": masked_key
    })
    
    # Remove the key
    api_keys.erase(key_id)
    
    # Emit signal
    emit_signal("key_removed", provider_name)
    
    print("Removed API key for " + provider_name + ": " + masked_key)
    return true

func rotate_api_key(key_id, new_api_key):
    if not key_id in api_keys:
        print("API key not found: " + key_id)
        return false
    
    var key_info = api_keys[key_id]
    var provider_name = key_info["provider_name"]
    var old_masked_key = key_info["masked_key"]
    var new_masked_key = _mask_api_key(new_api_key)
    
    # Update the key
    key_info["key"] = _encrypt_key(new_api_key) if encryption_enabled else new_api_key
    key_info["masked_key"] = new_masked_key
    key_info["last_validated"] = OS.get_unix_time()
    key_info["rotation_due"] = OS.get_unix_time() + (rotation_interval_days * 86400) if rotation_enabled else 0
    
    # Log the rotation
    _log_key_event(key_id, "rotated", {
        "provider": provider_name,
        "old_masked_key": old_masked_key,
        "new_masked_key": new_masked_key
    })
    
    # Emit signal
    emit_signal("key_rotated", provider_name, old_masked_key, new_masked_key)
    
    print("Rotated API key for " + provider_name + ": " + old_masked_key + " -> " + new_masked_key)
    return true

func validate_api_key(key_id):
    if not key_id in api_keys:
        print("API key not found: " + key_id)
        return false
    
    var key_info = api_keys[key_id]
    
    # In a real implementation, would make an API call to validate the key
    # For this demo, simulate validation
    var validation_success = true
    
    # Update validation status
    key_info["is_valid"] = validation_success
    key_info["last_validated"] = OS.get_unix_time()
    
    # Log the validation
    _log_key_event(key_id, "validated", {
        "provider": key_info["provider_name"],
        "is_valid": validation_success
    })
    
    print("Validated API key for " + key_info["provider_name"] + ": " + (validation_success ? "Valid" : "Invalid"))
    return validation_success

func get_keys_for_account(account_id):
    if account_id.empty():
        return []
    
    var keys = []
    for key_id in api_keys:
        if api_keys[key_id]["account_id"] == account_id:
            # Create a sanitized copy without the actual key
            var key_copy = api_keys[key_id].duplicate()
            key_copy.erase("key")
            keys.append(key_copy)
    
    return keys

func set_security_level(key_id, security_level):
    if not key_id in api_keys:
        print("API key not found: " + key_id)
        return false
    
    if not security_level in SecurityLevel.values():
        print("Invalid security level")
        return false
    
    api_keys[key_id]["security_level"] = security_level
    print("Set security level for " + api_keys[key_id]["provider_name"] + " key to " + SecurityLevel.keys()[security_level])
    return true

func enable_key_rotation(enabled, interval_days = 90):
    rotation_enabled = enabled
    rotation_interval_days = interval_days
    
    # Update rotation due dates for existing keys
    if enabled:
        for key_id in api_keys:
            api_keys[key_id]["rotation_due"] = OS.get_unix_time() + (interval_days * 86400)
    
    print("Key rotation " + ("enabled" : "disabled") + (enabled ? " with interval " + str(interval_days) + " days" : ""))
    return true

func get_usage_stats(provider = null):
    var stats = {
        "total_keys": api_keys.size(),
        "total_usage": 0,
        "providers": {},
        "accounts": {}
    }
    
    for key_id in api_keys:
        var key_info = api_keys[key_id]
        var provider_name = key_info["provider_name"]
        var account_id = key_info["account_id"]
        var usage_count = key_info["usage_count"]
        
        # Update total usage
        stats["total_usage"] += usage_count
        
        # Update provider stats
        if not provider_name in stats["providers"]:
            stats["providers"][provider_name] = {
                "key_count": 0,
                "usage_count": 0
            }
        
        stats["providers"][provider_name]["key_count"] += 1
        stats["providers"][provider_name]["usage_count"] += usage_count
        
        # Update account stats
        if not account_id.empty():
            if not account_id in stats["accounts"]:
                stats["accounts"][account_id] = {
                    "key_count": 0,
                    "usage_count": 0
                }
            
            stats["accounts"][account_id]["key_count"] += 1
            stats["accounts"][account_id]["usage_count"] += usage_count
    }
    
    # Filter by provider if specified
    if provider != null:
        var provider_name = provider
        if provider is int and provider in ApiProvider.values():
            provider_name = ApiProvider.keys()[provider]
        
        if provider_name in stats["providers"]:
            return stats["providers"][provider_name]
        else:
            return null
    
    return stats

func _on_security_check():
    # Check for keys that need rotation
    var current_time = OS.get_unix_time()
    var keys_to_rotate = []
    
    for key_id in api_keys:
        var key_info = api_keys[key_id]
        
        # Check rotation if enabled
        if rotation_enabled and key_info["rotation_due"] > 0 and current_time > key_info["rotation_due"]:
            keys_to_rotate.append({
                "key_id": key_id,
                "provider": key_info["provider_name"],
                "days_overdue": (current_time - key_info["rotation_due"]) / 86400
            })
    }
    
    # In a real implementation, would notify about keys that need rotation
    if keys_to_rotate.size() > 0:
        print(str(keys_to_rotate.size()) + " API keys need rotation")
        # Would implement notification here

func _encrypt_key(api_key):
    # In a real implementation, would use proper encryption
    # For this demo, just add a simple prefix
    return "ENCRYPTED:" + api_key

func _decrypt_key(encrypted_key):
    # In a real implementation, would use proper decryption
    # For this demo, just remove the prefix
    if encrypted_key.begins_with("ENCRYPTED:"):
        return encrypted_key.substr(10)
    return encrypted_key

func _mask_api_key(api_key):
    # Create masked version for display/logging
    if api_key.length() <= 8:
        return "****" + api_key.substr(api_key.length() - 4, 4)
    else:
        return api_key.substr(0, 4) + "****" + api_key.substr(api_key.length() - 4, 4)

func _log_key_event(key_id, event_type, details):
    if not usage_tracking_enabled:
        return
    
    var event = {
        "timestamp": OS.get_unix_time(),
        "key_id": key_id,
        "event": event_type,
        "details": details
    }
    
    usage_logs.append(event)
    
    # Limit log size
    if usage_logs.size() > 1000:
        usage_logs.pop_front()

func import_openai_api_key(api_key, account_id = ""):
    # Validate key format
    if not api_key.begins_with("sk-"):
        print("Invalid OpenAI API key format")
        return false
    
    return add_api_key(ApiProvider.OPENAI, api_key, account_id, SecurityLevel.HIGH, "OpenAI API Key")

func import_google_api_key(api_key, client_id = "", client_secret = "", account_id = ""):
    return add_api_key(ApiProvider.GOOGLE, api_key, account_id, SecurityLevel.STANDARD, "Google API Key")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/api_key_manager.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/api_orchestrator.gd
# SIZE: 17431 bytes
extends Node

class_name APIOrchestrator

# API integration constants
const API_CONFIG_PATH = "/mnt/c/Users/Percision 15/12_turns_system/api_config.json"
const OCR_CACHE_DIR = "/mnt/c/Users/Percision 15/12_turns_system/ocr_cache/"
const EMOTION_DATA_PATH = "/mnt/c/Users/Percision 15/12_turns_system/emotion_data.json"
const DATA_COLLECTION_PATH = "/mnt/c/Users/Percision 15/12_turns_system/collected_data/"

# API credentials and endpoints
var api_keys = {
    "openai": "",
    "apple_vision": "",
    "emotion_api": "",
    "ocr_service": ""
}

# Integration states
var integration_states = {
    "openai": false,
    "apple_vision": false, 
    "emotion_api": false,
    "ocr_service": false
}

# Data collection
var collected_data = {
    "turns": [],
    "ocr_results": [],
    "emotion_records": [],
    "api_interactions": [],
    "human_interactions": []
}

# Queue for API requests
var request_queue = []
var processing_request = false

# References to other systems
var turn_system = null
var ocr_processor = null

# Signals
signal api_request_completed(request_id, result, success)
signal ocr_completed(image_id, text, emotions, metadata)
signal emotion_detected(source, emotion, intensity, timestamp)
signal data_gathered(source, data_type, content)

func _ready():
    # Create necessary directories if they don't exist
    var dir = Directory.new()
    if not dir.dir_exists(OCR_CACHE_DIR):
        dir.make_dir_recursive(OCR_CACHE_DIR)
    
    if not dir.dir_exists(DATA_COLLECTION_PATH):
        dir.make_dir_recursive(DATA_COLLECTION_PATH)
    
    # Load API configuration
    load_api_config()
    
    # Connect to existing systems
    connect_to_systems()
    
    # Initialize HTTP request node for API calls
    var http_request = HTTPRequest.new()
    add_child(http_request)
    
    print("API Orchestrator initialized")
    print("Integration states: OpenAI: " + str(integration_states["openai"]) + 
          ", Apple Vision: " + str(integration_states["apple_vision"]) + 
          ", Emotion API: " + str(integration_states["emotion_api"]) + 
          ", OCR Service: " + str(integration_states["ocr_service"]))

func load_api_config():
    var file = File.new()
    if file.file_exists(API_CONFIG_PATH):
        file.open(API_CONFIG_PATH, File.READ)
        var content = file.get_as_text()
        file.close()
        
        var result = JSON.parse(content)
        if result.error == OK:
            var config = result.result
            
            # Load API keys if available
            if config.has("api_keys"):
                for key in config.api_keys:
                    if api_keys.has(key):
                        api_keys[key] = config.api_keys[key]
                        integration_states[key] = !config.api_keys[key].empty()
            
            print("API configuration loaded from: " + API_CONFIG_PATH)
        else:
            print("Error parsing API configuration: " + result.error_string)
            create_default_api_config()
    else:
        # Create default configuration
        create_default_api_config()

func create_default_api_config():
    var config = {
        "api_keys": {
            "openai": api_keys.openai,
            "apple_vision": api_keys.apple_vision,
            "emotion_api": api_keys.emotion_api,
            "ocr_service": api_keys.ocr_service
        },
        "endpoints": {
            "openai": "https://api.openai.com/v1/chat/completions",
            "apple_vision": "https://api.apple-ml.com/vision",
            "emotion_api": "https://api.emotion-recognition.com/analyze",
            "ocr_service": "https://api.ocr-service.com/process"
        },
        "options": {
            "max_concurrent_requests": 3,
            "request_timeout": 30,
            "collect_emotion_data": true,
            "emotion_sampling_rate": 10,
            "ocr_cache_days": 7
        }
    }
    
    var file = File.new()
    file.open(API_CONFIG_PATH, File.WRITE)
    file.store_string(JSON.print(config, "  "))
    file.close()
    
    print("Default API configuration created at: " + API_CONFIG_PATH)

func connect_to_systems():
    # Try to find existing TurnPrioritySystem or TurnIntegrator
    turn_system = get_node_or_null("/root/TurnPrioritySystem")
    if not turn_system:
        turn_system = get_node_or_null("/root/TurnIntegrator")
    
    if turn_system:
        # Connect turn signals appropriately
        if turn_system is TurnPrioritySystem:
            turn_system.connect("turn_advanced", self, "_on_turn_advanced")
        elif turn_system is TurnIntegrator:
            turn_system.connect("turn_integrated", self, "_on_turn_integrated")
        print("Connected to Turn System: " + turn_system.get_class())
    
    # Try to find existing OCRProcessor
    ocr_processor = get_node_or_null("/root/OCRProcessor")
    if ocr_processor:
        ocr_processor.connect("processing_completed", self, "_on_ocr_processing_completed")
        print("Connected to OCR Processor")

func set_api_key(service, key):
    if api_keys.has(service):
        api_keys[service] = key
        integration_states[service] = !key.empty()
        
        # Update config file
        save_api_config()
        
        print("Set API key for " + service)
        return true
    
    return false

func save_api_config():
    # Load existing config first
    var config = {}
    var file = File.new()
    if file.file_exists(API_CONFIG_PATH):
        file.open(API_CONFIG_PATH, File.READ)
        var content = file.get_as_text()
        file.close()
        
        var result = JSON.parse(content)
        if result.error == OK:
            config = result.result
    
    # Update API keys
    if not config.has("api_keys"):
        config["api_keys"] = {}
    
    for key in api_keys:
        config["api_keys"][key] = api_keys[key]
    
    # Save updated config
    file.open(API_CONFIG_PATH, File.WRITE)
    file.store_string(JSON.print(config, "  "))
    file.close()
    
    print("Saved API configuration to: " + API_CONFIG_PATH)

func process_image_with_ocr(image_path, options = {}):
    if not integration_states["ocr_service"] and not integration_states["apple_vision"]:
        print("No OCR service is configured")
        return null
    
    var image_id = str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Check if we have a local OCR processor
    if ocr_processor:
        ocr_processor.process_image(image_path, image_id, options)
        print("Processing image with local OCR: " + image_path)
        return image_id
    
    # Otherwise queue an API request
    var request_data = {
        "id": image_id,
        "type": "ocr",
        "service": integration_states["apple_vision"] ? "apple_vision" : "ocr_service",
        "path": image_path,
        "options": options
    }
    
    _queue_api_request(request_data)
    print("Queued OCR request for: " + image_path)
    
    return image_id

func analyze_emotion(text_content, source="api"):
    if not integration_states["emotion_api"] and not integration_states["openai"]:
        print("No emotion analysis service is configured")
        return null
    
    var emotion_id = str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Queue API request
    var request_data = {
        "id": emotion_id,
        "type": "emotion",
        "service": integration_states["emotion_api"] ? "emotion_api" : "openai",
        "content": text_content,
        "source": source
    }
    
    _queue_api_request(request_data)
    print("Queued emotion analysis for text from source: " + source)
    
    return emotion_id

func continue_with_ai(context, prompt, options = {}):
    if not integration_states["openai"]:
        print("OpenAI API is not configured")
        return null
    
    var continuation_id = str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Queue API request
    var request_data = {
        "id": continuation_id,
        "type": "continuation",
        "service": "openai",
        "context": context,
        "prompt": prompt,
        "options": options
    }
    
    _queue_api_request(request_data)
    print("Queued AI continuation request")
    
    return continuation_id

func record_human_interaction(interaction_type, content, metadata = {}):
    var timestamp = OS.get_datetime()
    var interaction_id = str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    var interaction_data = {
        "id": interaction_id,
        "type": interaction_type,
        "content": content,
        "timestamp": timestamp,
        "metadata": metadata
    }
    
    # Add to collected data
    collected_data.human_interactions.append(interaction_data)
    
    # Also record any emotions in the interaction
    if integration_states["emotion_api"] or integration_states["openai"]:
        if typeof(content) == TYPE_STRING and content.length() > 5:
            analyze_emotion(content, "human")
    
    # Emit signal
    emit_signal("data_gathered", "human", interaction_type, interaction_data)
    
    print("Recorded human interaction: " + interaction_type)
    return interaction_id

func gather_turn_data(turn_data):
    # This function gathers data from each turn
    var timestamp = OS.get_datetime()
    var turn_record = {
        "turn_string": turn_data.turn_string if turn_data.has("turn_string") else "0.0.0.0",
        "timestamp": timestamp,
        "active_category": turn_data.active_category if turn_data.has("active_category") else "",
        "turn_lines": turn_data.turn_lines if turn_data.has("turn_lines") else []
    }
    
    # Add to collected data
    collected_data.turns.append(turn_record)
    
    # Emit signal
    emit_signal("data_gathered", "turn", "turn_data", turn_record)
    
    # Save to file periodically (every 10 turns)
    if collected_data.turns.size() % 10 == 0:
        save_collected_data()
    
    print("Gathered turn data for turn: " + turn_record.turn_string)
    return turn_record

func save_collected_data():
    var timestamp = OS.get_unix_time()
    var file_path = DATA_COLLECTION_PATH + "data_" + str(timestamp) + ".json"
    
    var file = File.new()
    file.open(file_path, File.WRITE)
    file.store_string(JSON.print(collected_data, "  "))
    file.close()
    
    print("Saved collected data to: " + file_path)
    return file_path

func _queue_api_request(request_data):
    # Add to queue
    request_queue.append(request_data)
    
    # Process queue if not already processing
    if not processing_request:
        _process_next_request()

func _process_next_request():
    if request_queue.size() == 0:
        processing_request = false
        return
    
    processing_request = true
    var request = request_queue[0]
    
    # Mock API response for now - in a real implementation, would make HTTP request
    var timer = Timer.new()
    timer.one_shot = true
    timer.wait_time = 1.5  # Simulate API delay
    timer.connect("timeout", self, "_on_mock_api_response", [request])
    add_child(timer)
    timer.start()
    
    print("Processing API request: " + request.type + " using " + request.service)

func _on_mock_api_response(request):
    # Remove from queue
    request_queue.remove(0)
    
    # Generate mock response based on request type
    var response = {}
    var success = true
    
    match request.type:
        "ocr":
            response = _generate_mock_ocr_response(request)
        "emotion":
            response = _generate_mock_emotion_response(request)
        "continuation":
            response = _generate_mock_continuation_response(request)
        _:
            success = false
            response = {"error": "Unknown request type"}
    
    # Record API interaction
    var api_interaction = {
        "request_id": request.id,
        "type": request.type,
        "service": request.service,
        "timestamp": OS.get_datetime(),
        "success": success
    }
    collected_data.api_interactions.append(api_interaction)
    
    # Emit appropriate signals
    emit_signal("api_request_completed", request.id, response, success)
    
    if request.type == "ocr" and success:
        emit_signal("ocr_completed", request.id, response.text, response.emotions, response.metadata)
        
        # Add to collected data
        collected_data.ocr_results.append({
            "id": request.id,
            "path": request.path,
            "result": response,
            "timestamp": OS.get_datetime()
        })
    
    if request.type == "emotion" and success:
        emit_signal("emotion_detected", 
                    request.source, 
                    response.primary_emotion, 
                    response.intensity, 
                    OS.get_datetime())
        
        # Add to collected data
        collected_data.emotion_records.append({
            "id": request.id,
            "source": request.source,
            "content": request.content.substr(0, 50) + "...",  # Truncate for storage
            "emotions": response.emotions,
            "timestamp": OS.get_datetime()
        })
    
    # Process next request
    _process_next_request()

func _generate_mock_ocr_response(request):
    # Generate mock OCR result
    var sample_texts = [
        "The magical way to turn on api integrations is through emotional resonance.",
        "Gather data from multiple sources to create a cohesive narrative.",
        "OCR systems can detect emotions through textual and visual analysis.",
        "Turn counter 1.1.1.1 represents the beginning of a new cycle.",
        "Human interactions often trigger emotional responses worth analyzing."
    ]
    
    var text = sample_texts[randi() % sample_texts.size()]
    
    # Generate mock emotions detected in the text/image
    var emotions = {
        "joy": rand_range(0.0, 1.0),
        "sadness": rand_range(0.0, 0.5),
        "anger": rand_range(0.0, 0.3),
        "fear": rand_range(0.0, 0.4),
        "surprise": rand_range(0.0, 0.8),
        "disgust": rand_range(0.0, 0.2),
        "neutral": rand_range(0.0, 0.9)
    }
    
    # Find primary emotion
    var primary_emotion = "neutral"
    var highest_score = 0
    for emotion in emotions:
        if emotions[emotion] > highest_score:
            highest_score = emotions[emotion]
            primary_emotion = emotion
    
    return {
        "text": text,
        "confidence": rand_range(0.7, 0.99),
        "emotions": emotions,
        "primary_emotion": primary_emotion,
        "intensity": highest_score,
        "metadata": {
            "word_count": text.split(" ").size(),
            "processing_time_ms": randi() % 1000 + 500,
            "language": "en"
        }
    }

func _generate_mock_emotion_response(request):
    # Analysis of emotional content
    var emotions = {
        "joy": rand_range(0.0, 1.0),
        "sadness": rand_range(0.0, 0.5),
        "anger": rand_range(0.0, 0.3),
        "fear": rand_range(0.0, 0.4),
        "surprise": rand_range(0.0, 0.8),
        "disgust": rand_range(0.0, 0.2),
        "neutral": rand_range(0.0, 0.9)
    }
    
    # Find primary emotion
    var primary_emotion = "neutral"
    var highest_score = 0
    for emotion in emotions:
        if emotions[emotion] > highest_score:
            highest_score = emotions[emotion]
            primary_emotion = emotion
    
    return {
        "emotions": emotions,
        "primary_emotion": primary_emotion,
        "intensity": highest_score,
        "metadata": {
            "character_count": request.content.length(),
            "processing_time_ms": randi() % 300 + 100
        }
    }

func _generate_mock_continuation_response(request):
    # Sample continuations based on prompts
    var continuations = [
        "The system continues to evolve as it processes more emotional data from multiple sources.",
        "Through API integration, the OCR capabilities enhance the system's ability to understand human interactions.",
        "Each turn in the cycle brings new insights as the data is processed and analyzed.",
        "Emotion tracking reveals patterns in how users interact with the system over time.",
        "The 12 lines of text capture the essence of each turn, preserving the story for future analysis."
    ]
    
    var continuation = continuations[randi() % continuations.size()]
    
    return {
        "continuation": continuation,
        "tokens_generated": continuation.split(" ").size(),
        "processing_time_ms": randi() % 1500 + 500,
        "model": "mock-gpt-4"
    }

# ----- EVENT HANDLERS -----

func _on_turn_advanced(turn_number, turn_lines):
    # This is called when TurnPrioritySystem advances a turn
    if turn_system is TurnPrioritySystem:
        gather_turn_data(turn_system.get_turn_data())

func _on_turn_integrated(turn_number, game_dimension):
    # This is called when TurnIntegrator integrates a turn
    if turn_system is TurnIntegrator:
        gather_turn_data(turn_system.get_current_turn_data())

func _on_ocr_processing_completed(image_id, results):
    # This is called when local OCR processor completes
    emit_signal("ocr_completed", image_id, results.text, results.emotions, results.metadata)
    
    # Add to collected data
    collected_data.ocr_results.append({
        "id": image_id,
        "result": results,
        "timestamp": OS.get_datetime()
    })
    
    print("OCR processing completed for image: " + image_id)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/api_orchestrator.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_agent_mode.gd
# SIZE: 40352 bytes
extends Node

class_name AutoAgentMode

# Auto Agent Mode for Terminal-Claude Integration
# Enables automatic processing of commands, wishes, and trajectories
# with a focus on word-centric transformations and project reshaping

# ----- CONSTANTS -----
const MAX_TURNS_PER_SESSION = 24
const CORE_WORDS = ["update", "upgrade", "merge", "split", "evolve", "multiply", 
                   "duplicate", "change", "delete", "move", "push", "pull", "boomerang", "yoyo"]
const TRANSFORM_ACTIONS = {
    "update": {"energy": 1, "impact": "incremental", "direction": "forward"},
    "upgrade": {"energy": 2, "impact": "significant", "direction": "upward"},
    "merge": {"energy": 3, "impact": "combinatorial", "direction": "inward"},
    "split": {"energy": 3, "impact": "divisional", "direction": "outward"},
    "evolve": {"energy": 4, "impact": "progressive", "direction": "spiral"},
    "multiply": {"energy": 5, "impact": "exponential", "direction": "radial"},
    "duplicate": {"energy": 2, "impact": "duplicative", "direction": "parallel"},
    "change": {"energy": 1, "impact": "transformative", "direction": "variable"},
    "delete": {"energy": 6, "impact": "destructive", "direction": "null"},
    "move": {"energy": 2, "impact": "relocational", "direction": "vector"},
    "push": {"energy": 2, "impact": "forceful", "direction": "away"},
    "pull": {"energy": 2, "impact": "attractive", "direction": "toward"},
    "boomerang": {"energy": 4, "impact": "returning", "direction": "circular"},
    "yoyo": {"energy": 3, "impact": "oscillating", "direction": "bidirectional"}
}

# ----- SYSTEM REFERENCES -----
var terminal_api_bridge = null
var claude_bridge = null
var spatial_connector = null
var turn_system = null
var word_processor = null
var akashic_system = null

# ----- STATE TRACKING -----
var active_turn = 1
var auto_mode_enabled = false
var processing_interval = 5.0 # seconds
var word_trajectories = {}
var transform_history = []
var project_centers = {}
var session_start_time = 0
var current_operation = null
var word_power_levels = {}
var trajectory_shapes = {}

# ----- SIGNALS -----
signal auto_mode_toggled(enabled)
signal word_trajectory_created(word, trajectory)
signal project_center_shifted(project_id, old_center, new_center)
signal transform_applied(word, action, result)
signal turn_auto_advanced(old_turn, new_turn)
signal operation_completed(operation_type, duration, result)

# ----- INITIALIZATION -----
func _ready():
    print("Initializing Auto Agent Mode...")
    
    # Connect to required systems
    _connect_systems()
    
    # Initialize processing timer
    _setup_processing_timer()
    
    # Initialize word power levels
    _initialize_word_powers()
    
    # Set session start time
    session_start_time = OS.get_unix_time()
    
    print("Auto Agent Mode initialized")

func _connect_systems():
    # Connect to Terminal API Bridge
    terminal_api_bridge = get_node_or_null("/root/TerminalAPIBridge")
    
    # Connect to Claude Bridge
    claude_bridge = get_node_or_null("/root/ClaudeAkashicBridge")
    if not claude_bridge:
        claude_bridge = get_node_or_null("/root/ClaudeEtherealBridge")
    
    # Connect to Spatial Linguistic Connector
    spatial_connector = get_node_or_null("/root/SpatialLinguisticConnector")
    
    # Connect to Turn System
    turn_system = get_node_or_null("/root/TurnSystem")
    if turn_system:
        turn_system.connect("turn_advanced", self, "_on_turn_advanced")
        active_turn = turn_system.get_current_turn()
    
    # Connect to Divine Word Processor
    word_processor = get_node_or_null("/root/DivineWordProcessor")
    
    # Connect to Akashic System
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")

func _setup_processing_timer():
    var timer = Timer.new()
    timer.wait_time = processing_interval
    timer.one_shot = false
    timer.autostart = false
    timer.name = "AutoProcessingTimer"
    timer.connect("timeout", self, "_on_processing_timer")
    add_child(timer)

func _initialize_word_powers():
    # Initialize power levels for core words
    for word in CORE_WORDS:
        if TRANSFORM_ACTIONS.has(word):
            word_power_levels[word] = TRANSFORM_ACTIONS[word].energy * 10
    
    # Add some common project words
    word_power_levels["project"] = 50
    word_power_levels["center"] = 45
    word_power_levels["core"] = 60
    word_power_levels["trajectory"] = 55
    word_power_levels["shape"] = 40
    word_power_levels["words"] = 70
    word_power_levels["time"] = 65
    word_power_levels["turn"] = 35

# ----- AUTO AGENT MODE CONTROL -----
func enable_auto_mode(enabled=true, custom_interval=null):
    auto_mode_enabled = enabled
    
    # Update processing interval if specified
    if custom_interval != null and custom_interval > 0.5:
        processing_interval = custom_interval
        var timer = get_node_or_null("AutoProcessingTimer")
        if timer:
            timer.wait_time = processing_interval
    
    # Start or stop the processing timer
    var timer = get_node_or_null("AutoProcessingTimer")
    if timer:
        if enabled:
            timer.start()
        else:
            timer.stop()
    
    emit_signal("auto_mode_toggled", enabled)
    
    print("Auto Agent Mode " + ("enabled" if enabled else "disabled") + 
          " with processing interval of " + str(processing_interval) + " seconds")
    
    return auto_mode_enabled

func _on_processing_timer():
    if not auto_mode_enabled:
        return
    
    # Check if we need to auto-advance turn based on time
    _check_auto_advance_turn()
    
    # Process terminal commands
    _process_terminal_input()
    
    # Process word transformations
    _process_word_transformations()
    
    # Update trajectories
    _update_trajectories()
    
    # Check for project center shifts
    _check_project_centers()

# ----- TURN MANAGEMENT -----
func _on_turn_advanced(old_turn, new_turn):
    active_turn = new_turn
    print("Auto Agent Mode detected turn advance from " + str(old_turn) + " to " + str(new_turn))
    
    # Reset current operation on turn change
    current_operation = null
    
    # Perform turn-specific operations
    _perform_turn_operations(new_turn)

func _check_auto_advance_turn():
    if not turn_system:
        return
    
    # Check if enough time has passed since session start to advance turn
    var current_time = OS.get_unix_time()
    var session_duration = current_time - session_start_time
    
    # Calculate ideal turn based on session duration and max turns
    # Assuming an 8-hour session (28800 seconds) with MAX_TURNS_PER_SESSION
    var time_per_turn = 28800.0 / MAX_TURNS_PER_SESSION
    var ideal_turn = int(session_duration / time_per_turn) + 1
    
    # Only advance if ideal turn is ahead of current turn
    if ideal_turn > active_turn:
        turn_system.advance_turn()
        emit_signal("turn_auto_advanced", active_turn, ideal_turn)
        
        print("Auto-advancing turn from " + str(active_turn) + " to " + str(ideal_turn) + 
              " based on session time")

func _perform_turn_operations(turn):
    # Execute operations specific to this turn
    var turn_operation = {
        "type": "turn_operation",
        "turn": turn,
        "start_time": OS.get_unix_time(),
        "actions": []
    }
    
    # Perform different operations based on turn number
    match turn % 12:
        1: # First turn - Initialize trajectories
            _initialize_all_trajectories()
            turn_operation.actions.append("initialize_trajectories")
        
        2: # Second turn - Set up project centers
            _setup_project_centers()
            turn_operation.actions.append("setup_project_centers")
        
        6: # Midpoint - Reshape trajectories
            _reshape_all_trajectories()
            turn_operation.actions.append("reshape_trajectories")
        
        12: # Final turn - Consolidate transformations
            _consolidate_transformations()
            turn_operation.actions.append("consolidate_transformations")
    
    # Always update word powers on turn change
    _update_word_powers()
    turn_operation.actions.append("update_word_powers")
    
    # Complete the operation
    turn_operation.end_time = OS.get_unix_time()
    turn_operation.duration = turn_operation.end_time - turn_operation.start_time
    
    transform_history.append(turn_operation)
    emit_signal("operation_completed", "turn_operation", turn_operation.duration, turn_operation)

# ----- TERMINAL INPUT PROCESSING -----
func _process_terminal_input():
    if not terminal_api_bridge:
        return
    
    # Check all connected cores
    var core_monitors = terminal_api_bridge.get_all_monitors()
    
    for core_id in core_monitors:
        var monitor = core_monitors[core_id]
        
        # Process last input if it hasn't been processed
        if monitor.has("last_input") and monitor.last_input:
            var input_text = monitor.last_input
            
            # Only process if it's a new input that contains a core word
            if _contains_core_word(input_text):
                _process_command(input_text, core_id)
                
                # Mark as processed by clearing
                monitor.last_input = null

func _contains_core_word(text):
    if not text:
        return false
    
    text = text.to_lower()
    
    for word in CORE_WORDS:
        if word.to_lower() in text:
            return true
    
    return false

func _process_command(command, core_id):
    # Extract core words from command
    var words = command.split(" ")
    var core_words_found = []
    
    for word in words:
        word = word.to_lower()
        if word in CORE_WORDS:
            core_words_found.append(word)
    
    if core_words_found.empty():
        return
    
    print("Auto Agent processing command with core words: " + str(core_words_found))
    
    # Create operation record
    var operation = {
        "type": "command_processing",
        "command": command,
        "core_id": core_id,
        "core_words": core_words_found,
        "start_time": OS.get_unix_time(),
        "transforms": []
    }
    
    current_operation = operation
    
    # Apply transformations for each core word
    for word in core_words_found:
        var transform = _apply_transformation(word, command)
        if transform:
            operation.transforms.append(transform)
    
    # Complete operation
    operation.end_time = OS.get_unix_time()
    operation.duration = operation.end_time - operation.start_time
    
    transform_history.append(operation)
    emit_signal("operation_completed", "command_processing", operation.duration, operation)
    
    current_operation = null

# ----- WORD TRANSFORMATIONS -----
func _process_word_transformations():
    # Check if we are already processing an operation
    if current_operation != null:
        return
    
    # Randomly select a core word to process if no command is being processed
    if randf() < 0.3: # 30% chance each interval to process a random word
        var available_words = CORE_WORDS
        var word = available_words[randi() % available_words.size()]
        
        # Create auto operation
        var operation = {
            "type": "auto_transformation",
            "word": word,
            "start_time": OS.get_unix_time(),
            "transforms": []
        }
        
        current_operation = operation
        
        # Apply the transformation
        var transform = _apply_transformation(word, "auto")
        if transform:
            operation.transforms.append(transform)
        
        # Complete operation
        operation.end_time = OS.get_unix_time()
        operation.duration = operation.end_time - operation.start_time
        
        transform_history.append(operation)
        emit_signal("operation_completed", "auto_transformation", operation.duration, operation)
        
        current_operation = null

func _apply_transformation(word, context=""):
    if not TRANSFORM_ACTIONS.has(word):
        return null
    
    print("Applying transformation for word: " + word)
    
    # Get transform parameters
    var transform_params = TRANSFORM_ACTIONS[word]
    var energy = transform_params.energy
    var impact = transform_params.impact
    var direction = transform_params.direction
    
    # Create a transform record
    var transform = {
        "word": word,
        "context": context,
        "energy": energy,
        "impact": impact,
        "direction": direction,
        "timestamp": OS.get_unix_time(),
        "affected_trajectories": [],
        "affected_projects": []
    }
    
    # Apply effect based on the word
    match word:
        "update":
            _transform_update(transform)
        "upgrade":
            _transform_upgrade(transform)
        "merge":
            _transform_merge(transform)
        "split":
            _transform_split(transform)
        "evolve":
            _transform_evolve(transform)
        "multiply":
            _transform_multiply(transform)
        "duplicate":
            _transform_duplicate(transform)
        "change":
            _transform_change(transform)
        "delete":
            _transform_delete(transform)
        "move":
            _transform_move(transform)
        "push":
            _transform_push(transform)
        "pull":
            _transform_pull(transform)
        "boomerang":
            _transform_boomerang(transform)
        "yoyo":
            _transform_yoyo(transform)
    
    # Emit signal for the transform
    emit_signal("transform_applied", word, impact, transform)
    
    return transform

# ----- TRANSFORM IMPLEMENTATIONS -----
func _transform_update(transform):
    # Update increments trajectories slightly
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        
        # Slight increase in trajectory progress
        trajectory.progress += 0.05
        
        # Add some energy to the word
        if word_power_levels.has(word):
            word_power_levels[word] += 1
        else:
            word_power_levels[word] = 1
        
        transform.affected_trajectories.append(word)
    
    # Update one project center
    if project_centers.size() > 0:
        var projects = project_centers.keys()
        var project = projects[randi() % projects.size()]
        
        # Slightly shift the center
        var center = project_centers[project]
        center.x += (randf() - 0.5) * 0.2
        center.y += (randf() - 0.5) * 0.2
        project_centers[project] = center
        
        transform.affected_projects.append(project)

func _transform_upgrade(transform):
    # Upgrade significantly improves trajectories and powers
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        
        # Major increase in trajectory quality
        trajectory.quality += 0.2
        trajectory.progress += 0.1
        
        # Add significant energy to the word
        if word_power_levels.has(word):
            word_power_levels[word] += 5
        else:
            word_power_levels[word] = 5
        
        transform.affected_trajectories.append(word)
    
    # Upgrade all project centers
    for project in project_centers:
        # Move centers upward slightly
        var center = project_centers[project]
        center.y += 0.3
        project_centers[project] = center
        
        transform.affected_projects.append(project)

func _transform_merge(transform):
    # Merge combines similar trajectories
    var merge_candidates = {}
    
    # Find similar trajectories by direction
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        var direction = trajectory.direction
        
        if not merge_candidates.has(direction):
            merge_candidates[direction] = []
        
        merge_candidates[direction].append(word)
    
    # Merge trajectories with same direction
    for direction in merge_candidates:
        var candidates = merge_candidates[direction]
        
        if candidates.size() >= 2:
            # Pick two candidates to merge
            var word1 = candidates[0]
            var word2 = candidates[1]
            
            var merged_word = word1 + "_" + word2
            
            # Create merged trajectory
            word_trajectories[merged_word] = {
                "progress": (word_trajectories[word1].progress + word_trajectories[word2].progress) / 2,
                "quality": max(word_trajectories[word1].quality, word_trajectories[word2].quality) + 0.1,
                "direction": direction,
                "shape": word_trajectories[word1].shape,
                "points": word_trajectories[word1].points + word_trajectories[word2].points,
                "created": OS.get_unix_time()
            }
            
            # Set power level for merged word
            word_power_levels[merged_word] = word_power_levels.get(word1, 1) + word_power_levels.get(word2, 1)
            
            transform.affected_trajectories.append(merged_word)
            
            # Optionally, remove original trajectories
            if randf() < 0.5:
                word_trajectories.erase(word1)
                word_trajectories.erase(word2)
                transform.notes = "Merged trajectories and removed originals"
            else:
                transform.notes = "Merged trajectories and kept originals"

func _transform_split(transform):
    # Split divides trajectories into components
    var split_candidates = []
    
    # Find complex trajectories to split
    for word in word_trajectories:
        if "_" in word or word.length() > 5:
            split_candidates.append(word)
    
    # Split some trajectories
    for i in range(min(3, split_candidates.size())):
        var word = split_candidates[i]
        
        # Split into parts
        var parts = []
        if "_" in word:
            parts = word.split("_")
        else:
            // Split at midpoint
            var mid = word.length() / 2
            parts = [word.substr(0, mid), word.substr(mid)]
        
        // Create trajectories for parts
        for part in parts:
            if not word_trajectories.has(part):
                word_trajectories[part] = {
                    "progress": word_trajectories[word].progress * 0.8,
                    "quality": word_trajectories[word].quality * 0.7,
                    "direction": _random_direction(),
                    "shape": _random_shape(),
                    "points": int(word_trajectories[word].points / parts.size()),
                    "created": OS.get_unix_time()
                }
                
                // Set power level for part
                word_power_levels[part] = int(word_power_levels.get(word, 2) / 2)
                
                transform.affected_trajectories.append(part)
        
        transform.notes = "Split trajectory into " + str(parts.size()) + " parts"

func _transform_evolve(transform):
    # Evolve progresses trajectories along a spiral path
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        
        // Progressive increase in quality and progress
        trajectory.progress += 0.15
        trajectory.quality += 0.1
        
        // Change shape to more complex form
        if trajectory.shape == "line":
            trajectory.shape = "curve"
        elif trajectory.shape == "curve":
            trajectory.shape = "spiral"
        elif trajectory.shape == "spiral":
            trajectory.shape = "helix"
        elif trajectory.shape == "circle":
            trajectory.shape = "ellipse"
        elif trajectory.shape == "square":
            trajectory.shape = "cube"
        
        // Add points
        trajectory.points += 5
        
        transform.affected_trajectories.append(word)
    
    // Evolve project centers toward a more complex arrangement
    if project_centers.size() >= 3:
        // Calculate center of mass
        var center_of_mass = Vector2(0, 0)
        for project in project_centers:
            center_of_mass += project_centers[project]
        center_of_mass /= project_centers.size()
        
        // Rotate projects around center of mass
        for project in project_centers:
            var center = project_centers[project]
            var angle = 0.2 // Small rotation
            var new_center = Vector2(
                center_of_mass.x + (center.x - center_of_mass.x) * cos(angle) - (center.y - center_of_mass.y) * sin(angle),
                center_of_mass.y + (center.x - center_of_mass.x) * sin(angle) + (center.y - center_of_mass.y) * cos(angle)
            )
            project_centers[project] = new_center
            transform.affected_projects.append(project)
        
        transform.notes = "Evolved projects in spiral pattern"

func _transform_multiply(transform):
    // Multiply creates copies with variations
    var original_trajectories = word_trajectories.duplicate()
    var new_words = []
    
    for word in original_trajectories:
        // Create 2-3 variations
        var variations = 2 + int(randf() * 2)
        
        for i in range(variations):
            var new_word = word + "_" + str(i+1)
            
            // Create variation with slight differences
            word_trajectories[new_word] = {
                "progress": original_trajectories[word].progress * (0.8 + randf() * 0.4),
                "quality": original_trajectories[word].quality * (0.7 + randf() * 0.6),
                "direction": _random_direction(),
                "shape": original_trajectories[word].shape,
                "points": original_trajectories[word].points + int(randf() * 10),
                "created": OS.get_unix_time()
            }
            
            // Set power level
            word_power_levels[new_word] = int(word_power_levels.get(word, 5) * (0.6 + randf() * 0.8))
            
            new_words.append(new_word)
            transform.affected_trajectories.append(new_word)
        
        // Increase power of original
        if word_power_levels.has(word):
            word_power_levels[word] += 3
    
    transform.notes = "Multiplied into " + str(new_words.size()) + " variations"

func _transform_duplicate(transform):
    // Duplicate creates exact copies
    var original_trajectories = word_trajectories.duplicate()
    var new_words = []
    
    for word in original_trajectories:
        var new_word = word + "_copy"
        
        // Create exact duplicate
        word_trajectories[new_word] = original_trajectories[word].duplicate()
        word_trajectories[new_word].created = OS.get_unix_time()
        
        // Copy power level
        word_power_levels[new_word] = word_power_levels.get(word, 1)
        
        new_words.append(new_word)
        transform.affected_trajectories.append(new_word)
    
    transform.notes = "Duplicated " + str(new_words.size()) + " trajectories"

func _transform_change(transform):
    // Change transforms trajectories randomly
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        
        // Random transformation
        var change_type = randi() % 5
        
        match change_type:
            0: // Change direction
                trajectory.direction = _random_direction()
            1: // Change shape
                trajectory.shape = _random_shape()
            2: // Change progress
                trajectory.progress = min(1.0, max(0.0, trajectory.progress + (randf() - 0.5) * 0.4))
            3: // Change quality
                trajectory.quality = min(1.0, max(0.0, trajectory.quality + (randf() - 0.5) * 0.3))
            4: // Change points
                trajectory.points = max(1, trajectory.points + int((randf() - 0.5) * 20))
        
        transform.affected_trajectories.append(word)
    
    // Randomly change project centers
    for project in project_centers:
        project_centers[project] = Vector2(
            project_centers[project].x + (randf() - 0.5) * 2,
            project_centers[project].y + (randf() - 0.5) * 2
        )
        transform.affected_projects.append(project)
    
    transform.notes = "Applied random transformations"

func _transform_delete(transform):
    // Delete removes some trajectories
    var delete_candidates = []
    
    // Find low quality trajectories to delete
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        if trajectory.quality < 0.3 or trajectory.progress < 0.2:
            delete_candidates.append(word)
    
    // Delete some candidates (max 3)
    var delete_count = min(3, delete_candidates.size())
    for i in range(delete_count):
        if delete_candidates.size() > i:
            var word = delete_candidates[i]
            word_trajectories.erase(word)
            transform.affected_trajectories.append(word)
    
    transform.notes = "Deleted " + str(delete_count) + " low quality trajectories"

func _transform_move(transform):
    // Move relocates trajectories and projects
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        
        // Generate a movement vector
        var movement_vector = Vector2(randf() * 2 - 1, randf() * 2 - 1).normalized()
        
        // Update any position-related properties
        if trajectory.has("position"):
            trajectory.position += movement_vector
        
        transform.affected_trajectories.append(word)
    
    // Move project centers
    for project in project_centers:
        // Move in a consistent direction
        var movement = Vector2(randf() * 2 - 1, randf() * 2 - 1).normalized() * 2
        project_centers[project] += movement
        transform.affected_projects.append(project)
    
    transform.notes = "Relocated projects and trajectories"

func _transform_push(transform):
    // Push moves objects away from center
    var center = Vector2(0, 0)
    
    // Calculate center of mass for project centers
    if project_centers.size() > 0:
        for project in project_centers:
            center += project_centers[project]
        center /= project_centers.size()
    
    // Push project centers away from center
    for project in project_centers:
        var direction = (project_centers[project] - center).normalized()
        if direction.length() < 0.1:
            direction = Vector2(randf() * 2 - 1, randf() * 2 - 1).normalized()
        
        project_centers[project] += direction * 2
        transform.affected_projects.append(project)
    
    transform.notes = "Pushed projects away from center"

func _transform_pull(transform):
    // Pull moves objects toward center
    var center = Vector2(0, 0)
    
    // Calculate center of mass for project centers
    if project_centers.size() > 0:
        for project in project_centers:
            center += project_centers[project]
        center /= project_centers.size()
    
    // Pull project centers toward center
    for project in project_centers:
        var direction = (center - project_centers[project]).normalized()
        project_centers[project] += direction * 1.5
        transform.affected_projects.append(project)
    
    transform.notes = "Pulled projects toward center"

func _transform_boomerang(transform):
    // Boomerang creates a return point for trajectories
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        
        // Create a return point
        if not trajectory.has("return_point"):
            trajectory.return_point = {
                "progress": trajectory.progress,
                "quality": trajectory.quality,
                "direction": trajectory.direction
            }
        else:
            // If return point exists, return to it
            var return_point = trajectory.return_point
            trajectory.progress = return_point.progress
            trajectory.quality = return_point.quality
            trajectory.direction = return_point.direction
            transform.notes = "Returned to saved state"
        
        transform.affected_trajectories.append(word)
    
    // For project centers, store and optionally return
    if not transform.has("center_memory"):
        transform.center_memory = project_centers.duplicate()
        transform.notes = "Created return points for trajectories"
    else:
        project_centers = transform.center_memory.duplicate()
        for project in project_centers:
            transform.affected_projects.append(project)
        transform.notes = "Returned projects to previous centers"

func _transform_yoyo(transform):
    // Yoyo oscillates between two states
    if not transform.has("yoyo_state") or transform.yoyo_state == "out":
        // Moving out - increase values
        for word in word_trajectories:
            var trajectory = word_trajectories[word]
            
            trajectory.progress = min(1.0, trajectory.progress + 0.2)
            trajectory.quality = min(1.0, trajectory.quality + 0.15)
            if word_power_levels.has(word):
                word_power_levels[word] += 3
            
            transform.affected_trajectories.append(word)
        
        transform.yoyo_state = "in"
        transform.notes = "Expanded trajectories (out)"
    else:
        // Moving in - decrease values
        for word in word_trajectories:
            var trajectory = word_trajectories[word]
            
            trajectory.progress = max(0.0, trajectory.progress - 0.2)
            trajectory.quality = max(0.1, trajectory.quality - 0.15)
            if word_power_levels.has(word):
                word_power_levels[word] = max(1, word_power_levels[word] - 3)
            
            transform.affected_trajectories.append(word)
        
        transform.yoyo_state = "out"
        transform.notes = "Contracted trajectories (in)"
    
    // Oscillate project centers
    for project in project_centers:
        if transform.yoyo_state == "in":
            // Move toward center
            project_centers[project] *= 0.7
        else:
            // Move away from center
            project_centers[project] *= 1.4
        
        transform.affected_projects.append(project)

# ----- TRAJECTORY MANAGEMENT -----
func _update_trajectories():
    // Gradually update trajectories over time
    for word in word_trajectories:
        var trajectory = word_trajectories[word]
        
        // Small natural progress increase
        trajectory.progress = min(1.0, trajectory.progress + 0.001)
        
        // Update quality based on word power
        if word_power_levels.has(word):
            var power = word_power_levels[word]
            var quality_boost = power * 0.0001
            trajectory.quality = min(1.0, trajectory.quality + quality_boost)

func _initialize_all_trajectories():
    // Create basic trajectories for core words
    for word in CORE_WORDS:
        if not word_trajectories.has(word):
            word_trajectories[word] = {
                "progress": 0.1,
                "quality": 0.5,
                "direction": _random_direction(),
                "shape": _random_shape(),
                "points": 10,
                "created": OS.get_unix_time()
            }
            
            trajectory_shapes[word] = _random_shape()
            emit_signal("word_trajectory_created", word, word_trajectories[word])
    
    // Also create trajectories for some basic project terms
    var project_terms = ["project", "center", "core", "shape", "trajectory"]
    for term in project_terms:
        if not word_trajectories.has(term):
            word_trajectories[term] = {
                "progress": 0.2,
                "quality": 0.6,
                "direction": _random_direction(),
                "shape": _random_shape(),
                "points": 15,
                "created": OS.get_unix_time()
            }
            
            trajectory_shapes[term] = _random_shape()
            emit_signal("word_trajectory_created", term, word_trajectories[term])
    
    print("Initialized trajectories for " + str(word_trajectories.size()) + " words")

func _reshape_all_trajectories():
    // Change shapes for all trajectories
    for word in word_trajectories:
        word_trajectories[word].shape = _random_shape()
        trajectory_shapes[word] = word_trajectories[word].shape
    
    print("Reshaped all trajectories with new forms")

func _random_direction():
    var directions = ["up", "down", "left", "right", "forward", "backward", 
                     "clockwise", "counterclockwise", "inward", "outward", "spiral"]
    return directions[randi() % directions.size()]

func _random_shape():
    var shapes = ["line", "curve", "circle", "square", "triangle", 
                 "spiral", "helix", "wave", "star", "ellipse", "cube"]
    return shapes[randi() % shapes.size()]

# ----- PROJECT CENTER MANAGEMENT -----
func _setup_project_centers():
    // Initialize centers for basic projects
    var base_projects = ["main", "core", "extension", "module", "component"]
    
    for project in base_projects:
        // Create a center with slight randomization
        project_centers[project] = Vector2(
            (randf() - 0.5) * 10,
            (randf() - 0.5) * 10
        )
    
    print("Set up centers for " + str(project_centers.size()) + " projects")

func _check_project_centers():
    // Check for any shifts in project centers
    for project in project_centers:
        // Apply minor natural drift
        var drift = Vector2(
            (randf() - 0.5) * 0.1,
            (randf() - 0.5) * 0.1
        )
        
        var old_center = project_centers[project]
        project_centers[project] += drift
        
        // Check if any word has enough power to shift the center more dramatically
        for word in word_power_levels:
            var power = word_power_levels[word]
            
            if power > 50 and randf() < 0.05:
                // High power word occasionally shifts project center
                var shift_vector = Vector2(
                    (randf() - 0.5) * 4,
                    (randf() - 0.5) * 4
                )
                
                project_centers[project] += shift_vector
                
                emit_signal("project_center_shifted", project, old_center, project_centers[project])
                print("Word '" + word + "' with power " + str(power) + 
                      " shifted project '" + project + "' center")
                break

func _consolidate_transformations():
    // Analyze all transformations and consolidate their effects
    if transform_history.size() < 2:
        return
    
    // Group similar transformations
    var word_impacts = {}
    
    for transform in transform_history:
        if transform.has("transforms"):
            for sub_transform in transform.transforms:
                var word = sub_transform.word
                if not word_impacts.has(word):
                    word_impacts[word] = {
                        "count": 0,
                        "total_energy": 0,
                        "affected_trajectories": [],
                        "affected_projects": []
                    }
                
                word_impacts[word].count += 1
                word_impacts[word].total_energy += sub_transform.energy
                word_impacts[word].affected_trajectories.append_array(sub_transform.affected_trajectories)
                word_impacts[word].affected_projects.append_array(sub_transform.affected_projects)
    
    // Apply consolidation effects
    for word in word_impacts:
        var impact = word_impacts[word]
        
        if impact.count >= 3:
            // Word used frequently - boost its power
            if word_power_levels.has(word):
                word_power_levels[word] += impact.count * 2
            
            print("Consolidated " + str(impact.count) + " uses of '" + word + 
                  "' with total energy " + str(impact.total_energy))
    
    // Clear transform history after consolidation
    transform_history.clear()

func _update_word_powers():
    // Decay unused words, boost used ones
    for word in word_power_levels:
        // Natural decay
        word_power_levels[word] = max(1, word_power_levels[word] - 1)
        
        // Boost words that have active trajectories
        if word_trajectories.has(word):
            var trajectory = word_trajectories[word]
            
            // Higher quality trajectories preserve more power
            var preservation = trajectory.quality * 0.5
            word_power_levels[word] = int(word_power_levels[word] * (0.9 + preservation))

# ----- PUBLIC API -----
func start_auto_agent(interval=5.0):
    return enable_auto_mode(true, interval)

func stop_auto_agent():
    return enable_auto_mode(false)

func get_word_trajectories():
    return word_trajectories

func get_project_centers():
    return project_centers

func get_word_power_levels():
    return word_power_levels

func get_transform_history():
    return transform_history

func get_active_turn():
    return active_turn

func get_trajectory_shape(word):
    if trajectory_shapes.has(word):
        return trajectory_shapes[word]
    return null

func get_auto_agent_status():
    return {
        "enabled": auto_mode_enabled,
        "interval": processing_interval,
        "active_turn": active_turn,
        "session_duration": OS.get_unix_time() - session_start_time,
        "word_count": word_trajectories.size(),
        "project_count": project_centers.size(),
        "transform_count": transform_history.size(),
        "current_operation": current_operation
    }

func create_trajectory(word, initial_progress=0.1, shape=null):
    if not shape:
        shape = _random_shape()
    
    word_trajectories[word] = {
        "progress": initial_progress,
        "quality": 0.5,
        "direction": _random_direction(),
        "shape": shape,
        "points": 10,
        "created": OS.get_unix_time()
    }
    
    trajectory_shapes[word] = shape
    emit_signal("word_trajectory_created", word, word_trajectories[word])
    
    return word_trajectories[word]

func set_word_power(word, power):
    word_power_levels[word] = max(1, power)
    return word_power_levels[word]

func execute_transform(word, context="manual"):
    if not TRANSFORM_ACTIONS.has(word):
        return null
    
    return _apply_transformation(word, context)

func add_project_center(project_name, position=null):
    if position == null:
        position = Vector2((randf() - 0.5) * 10, (randf() - 0.5) * 10)
    
    project_centers[project_name] = position
    return position

func get_recommended_transforms():
    // Recommend transforms based on current state
    var recommendations = []
    
    // Check trajectory progress
    var avg_progress = 0.0
    for word in word_trajectories:
        avg_progress += word_trajectories[word].progress
    
    if word_trajectories.size() > 0:
        avg_progress /= word_trajectories.size()
    
    // Recommend based on progress
    if avg_progress < 0.3:
        recommendations.append({
            "transform": "update",
            "reason": "Low average progress"
        })
        recommendations.append({
            "transform": "upgrade",
            "reason": "Boost trajectory quality"
        })
    elif avg_progress > 0.7:
        recommendations.append({
            "transform": "evolve",
            "reason": "High progress, ready to evolve"
        })
    
    // Check number of trajectories
    if word_trajectories.size() < 5:
        recommendations.append({
            "transform": "multiply",
            "reason": "Too few trajectories"
        })
    elif word_trajectories.size() > 15:
        recommendations.append({
            "transform": "merge",
            "reason": "Too many trajectories, consolidate"
        })
    
    // Check project centers
    if project_centers.size() < 3:
        recommendations.append({
            "transform": "duplicate",
            "reason": "Need more project centers"
        })
    
    return recommendations
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_agent_mode.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_connector.gd
# SIZE: 20915 bytes
extends Node

class_name AutoConnector

# ----- CONFIGURATION -----
@export_category("Connection Settings")
@export var auto_connect_on_startup: bool = true
@export var auto_reconnect: bool = true
@export var connection_types: Array[String] = ["api", "drive", "ocr", "network"]
@export var check_interval: float = 30.0  # seconds
@export var retry_interval: float = 10.0  # seconds
@export var max_retry_count: int = 5
@export var timeout: float = 15.0  # seconds

# ----- API CONFIGURATION -----
@export_category("API Settings")
@export var api_url: String = "https://api.example.com"
@export var api_version: String = "v1"
@export var api_key: String = ""
@export var use_api_encryption: bool = true
@export var verify_ssl: bool = true

# ----- INTEGRATION CONFIGURATION -----
@export_category("Integration Settings")
@export var enable_drive_integration: bool = true
@export var enable_ocr_integration: bool = true
@export var enable_network_discovery: bool = true
@export var ocr_service_url: String = "https://ocr.example.com"
@export var drive_service_url: String = "https://drive.example.com"

# ----- CONNECTION STATE -----
var connections = {
    "api": {
        "status": "disconnected",  # disconnected, connecting, connected, error
        "last_connected": 0,
        "retry_count": 0,
        "error": ""
    },
    "drive": {
        "status": "disconnected",
        "last_connected": 0,
        "retry_count": 0,
        "error": ""
    },
    "ocr": {
        "status": "disconnected",
        "last_connected": 0,
        "retry_count": 0,
        "error": ""
    },
    "network": {
        "status": "disconnected",
        "last_connected": 0,
        "retry_count": 0,
        "error": ""
    }
}

var connection_timers = {}
var check_timer: Timer
var is_connecting = false
var auth_token = ""
var connection_sequence_id = 0

# ----- REFERENCE MANAGEMENT -----
var ocr_processor = null
var screen_capturer = null
var color_system = null
var updater = null
var api_connector = null

# ----- SIGNALS -----
signal connection_status_changed(type, status)
signal all_connections_established()
signal connection_failed(type, error)
signal connection_sequence_complete(success_count, total_count)
signal api_connected()
signal drive_connected()
signal ocr_connected()
signal network_connected()
signal auto_connector_initialized()

# ----- INITIALIZATION -----
func _ready():
    # Initialize timers
    _initialize_timers()
    
    # Find system references
    _find_system_references()
    
    # Connect to services on startup if enabled
    if auto_connect_on_startup:
        call_deferred("connect_all")
    
    print("Auto Connector initialized")
    print("Auto connect on startup: " + str(auto_connect_on_startup))
    print("Connection types: " + str(connection_types))
    
    emit_signal("auto_connector_initialized")

func _initialize_timers():
    # Create check timer
    check_timer = Timer.new()
    check_timer.wait_time = check_interval
    check_timer.one_shot = false
    check_timer.autostart = false
    check_timer.connect("timeout", Callable(self, "_on_check_timer"))
    add_child(check_timer)
    
    # Create connection timers for each type
    for connection_type in connection_types:
        var timer = Timer.new()
        timer.wait_time = retry_interval
        timer.one_shot = true
        timer.autostart = false
        timer.connect("timeout", Callable(self, "_on_retry_timer").bind(connection_type))
        add_child(timer)
        connection_timers[connection_type] = timer

func _find_system_references():
    # Find OCR processor
    ocr_processor = get_node_or_null("/root/OCRProcessor")
    if not ocr_processor:
        ocr_processor = _find_node_by_class(get_tree().root, "OCRProcessor")
    
    # Find screen capturer
    screen_capturer = get_node_or_null("/root/ScreenCaptureUtility")
    if not screen_capturer:
        screen_capturer = _find_node_by_class(get_tree().root, "ScreenCaptureUtility")
    
    # Find color system
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find updater
    updater = get_node_or_null("/root/AutoUpdater")
    if not updater:
        updater = _find_node_by_class(get_tree().root, "AutoUpdater")
    
    print("System references found: " + 
          "OCR Processor: " + str(ocr_processor != null) + ", " +
          "Screen Capturer: " + str(screen_capturer != null) + ", " +
          "Color System: " + str(color_system != null) + ", " +
          "Updater: " + str(updater != null))

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

# ----- CONNECTION METHODS -----
func connect_all() -> void:
    # Attempt to connect to all enabled services
    
    if is_connecting:
        print("Already in connection sequence")
        return
    
    is_connecting = true
    connection_sequence_id += 1
    var sequence_id = connection_sequence_id
    
    print("Starting connection sequence #" + str(sequence_id))
    
    # Reset connection states for new sequence
    for connection_type in connection_types:
        if connections[connection_type].status != "connected":
            connections[connection_type].status = "disconnected"
            connections[connection_type].error = ""
    
    # Start connection sequence
    var successful_connections = 0
    
    for connection_type in connection_types:
        # Skip connection if it's already established
        if connections[connection_type].status == "connected":
            successful_connections += 1
            continue
        
        # Update status
        _update_connection_status(connection_type, "connecting")
        
        print("Connecting to " + connection_type + "...")
        
        # Connect based on type
        var success = false
        
        match connection_type:
            "api":
                success = await _connect_to_api()
            "drive":
                success = await _connect_to_drive()
            "ocr":
                success = await _connect_to_ocr()
            "network":
                success = await _connect_to_network()
        
        if success:
            successful_connections += 1
    
    # Check if all enabled connections were successful
    is_connecting = false
    
    print("Connection sequence #" + str(sequence_id) + " completed with " + 
          str(successful_connections) + "/" + str(connection_types.size()) + " successful connections")
    
    emit_signal("connection_sequence_complete", successful_connections, connection_types.size())
    
    if successful_connections == connection_types.size():
        emit_signal("all_connections_established")
        
        # Start periodic connection checking
        check_timer.start()

func connect_to_service(connection_type: String) -> bool:
    # Connect to a specific service
    
    if not connection_types.has(connection_type):
        print("Unknown connection type: " + connection_type)
        return false
    
    if connections[connection_type].status == "connected":
        print("Already connected to " + connection_type)
        return true
    
    if connections[connection_type].status == "connecting":
        print("Already connecting to " + connection_type)
        return false
    
    # Update status
    _update_connection_status(connection_type, "connecting")
    
    print("Connecting to " + connection_type + "...")
    
    # Connect based on type
    var success = false
    
    match connection_type:
        "api":
            success = await _connect_to_api()
        "drive":
            success = await _connect_to_drive()
        "ocr":
            success = await _connect_to_ocr()
        "network":
            success = await _connect_to_network()
    
    return success

func disconnect_from_service(connection_type: String) -> bool:
    # Disconnect from a specific service
    
    if not connection_types.has(connection_type):
        print("Unknown connection type: " + connection_type)
        return false
    
    if connections[connection_type].status != "connected":
        print("Not connected to " + connection_type)
        return true
    
    print("Disconnecting from " + connection_type + "...")
    
    # Disconnect based on type
    match connection_type:
        "api":
            _disconnect_from_api()
        "drive":
            _disconnect_from_drive()
        "ocr":
            _disconnect_from_ocr()
        "network":
            _disconnect_from_network()
    
    # Update status
    _update_connection_status(connection_type, "disconnected")
    
    return true

func disconnect_all() -> void:
    # Disconnect from all services
    
    print("Disconnecting from all services...")
    
    for connection_type in connection_types:
        if connections[connection_type].status == "connected":
            disconnect_from_service(connection_type)
    
    # Stop check timer
    check_timer.stop()

# ----- SERVICE-SPECIFIC CONNECTION METHODS -----
func _connect_to_api():
    # Connect to API service
    
    print("Establishing API connection to: " + api_url + "/" + api_version)
    
    # In a real implementation, would make an authentication request
    # For this mock-up, we'll simulate the connection
    
    await get_tree().create_timer(1.0).timeout
    
    # Simulate success (90% chance)
    var success = randf() < 0.9
    
    if success:
        connections.api.status = "connected"
        connections.api.last_connected = OS.get_unix_time()
        connections.api.retry_count = 0
        
        auth_token = _generate_token(32)
        
        _update_connection_status("api", "connected")
        
        emit_signal("api_connected")
        
        print("API connection established")
        return true
    else:
        var error = "Failed to connect to API: server not responding"
        connections.api.status = "error"
        connections.api.error = error
        connections.api.retry_count += 1
        
        _update_connection_status("api", "error")
        
        emit_signal("connection_failed", "api", error)
        
        print("API connection failed: " + error)
        
        # Schedule retry if needed
        if auto_reconnect and connections.api.retry_count <= max_retry_count:
            _schedule_retry("api")
        
        return false

func _connect_to_drive():
    # Connect to Drive service
    
    if not enable_drive_integration:
        print("Drive integration is disabled")
        return false
    
    print("Establishing Drive connection to: " + drive_service_url)
    
    # In a real implementation, would authenticate with the drive service
    # For this mock-up, we'll simulate the connection
    
    await get_tree().create_timer(0.8).timeout
    
    # Simulate success (85% chance)
    var success = randf() < 0.85
    
    if success:
        connections.drive.status = "connected"
        connections.drive.last_connected = OS.get_unix_time()
        connections.drive.retry_count = 0
        
        _update_connection_status("drive", "connected")
        
        emit_signal("drive_connected")
        
        print("Drive connection established")
        return true
    else:
        var error = "Failed to connect to Drive: authentication failed"
        connections.drive.status = "error"
        connections.drive.error = error
        connections.drive.retry_count += 1
        
        _update_connection_status("drive", "error")
        
        emit_signal("connection_failed", "drive", error)
        
        print("Drive connection failed: " + error)
        
        # Schedule retry if needed
        if auto_reconnect and connections.drive.retry_count <= max_retry_count:
            _schedule_retry("drive")
        
        return false

func _connect_to_ocr():
    # Connect to OCR service
    
    if not enable_ocr_integration:
        print("OCR integration is disabled")
        return false
    
    print("Establishing OCR connection to: " + ocr_service_url)
    
    # In a real implementation, would connect to the OCR service
    # For this mock-up, we'll simulate the connection
    
    await get_tree().create_timer(0.6).timeout
    
    # Simulate success (95% chance)
    var success = randf() < 0.95
    
    if success:
        connections.ocr.status = "connected"
        connections.ocr.last_connected = OS.get_unix_time()
        connections.ocr.retry_count = 0
        
        _update_connection_status("ocr", "connected")
        
        emit_signal("ocr_connected")
        
        print("OCR connection established")
        return true
    else:
        var error = "Failed to connect to OCR service: service unavailable"
        connections.ocr.status = "error"
        connections.ocr.error = error
        connections.ocr.retry_count += 1
        
        _update_connection_status("ocr", "error")
        
        emit_signal("connection_failed", "ocr", error)
        
        print("OCR connection failed: " + error)
        
        # Schedule retry if needed
        if auto_reconnect and connections.ocr.retry_count <= max_retry_count:
            _schedule_retry("ocr")
        
        return false

func _connect_to_network():
    # Connect to Network discovery service
    
    if not enable_network_discovery:
        print("Network discovery is disabled")
        return false
    
    print("Establishing Network discovery connection")
    
    # In a real implementation, would start network discovery
    # For this mock-up, we'll simulate the connection
    
    await get_tree().create_timer(0.7).timeout
    
    # Simulate success (80% chance)
    var success = randf() < 0.8
    
    if success:
        connections.network.status = "connected"
        connections.network.last_connected = OS.get_unix_time()
        connections.network.retry_count = 0
        
        _update_connection_status("network", "connected")
        
        emit_signal("network_connected")
        
        print("Network discovery connection established")
        return true
    else:
        var error = "Failed to start network discovery: network unavailable"
        connections.network.status = "error"
        connections.network.error = error
        connections.network.retry_count += 1
        
        _update_connection_status("network", "error")
        
        emit_signal("connection_failed", "network", error)
        
        print("Network discovery connection failed: " + error)
        
        # Schedule retry if needed
        if auto_reconnect and connections.network.retry_count <= max_retry_count:
            _schedule_retry("network")
        
        return false

# ----- DISCONNECTION METHODS -----
func _disconnect_from_api():
    # Disconnect from API service
    print("Disconnecting from API service")
    
    # In a real implementation, would properly close the connection
    # For this mock-up, we'll just update the state
    
    connections.api.status = "disconnected"
    auth_token = ""

func _disconnect_from_drive():
    # Disconnect from Drive service
    print("Disconnecting from Drive service")
    
    # In a real implementation, would properly close the connection
    # For this mock-up, we'll just update the state
    
    connections.drive.status = "disconnected"

func _disconnect_from_ocr():
    # Disconnect from OCR service
    print("Disconnecting from OCR service")
    
    # In a real implementation, would properly close the connection
    # For this mock-up, we'll just update the state
    
    connections.ocr.status = "disconnected"

func _disconnect_from_network():
    # Disconnect from Network discovery
    print("Disconnecting from Network discovery")
    
    # In a real implementation, would stop network discovery
    # For this mock-up, we'll just update the state
    
    connections.network.status = "disconnected"

# ----- CONNECTION MANAGEMENT -----
func _update_connection_status(connection_type: String, status: String):
    # Update connection status and emit signal
    connections[connection_type].status = status
    
    emit_signal("connection_status_changed", connection_type, status)

func _schedule_retry(connection_type: String):
    # Schedule a connection retry
    
    var retry_count = connections[connection_type].retry_count
    var wait_time = retry_interval * pow(1.5, retry_count - 1)  # Exponential backoff
    
    print("Scheduling " + connection_type + " connection retry " + 
          str(retry_count) + "/" + str(max_retry_count) + 
          " in " + str(wait_time) + " seconds")
    
    connection_timers[connection_type].wait_time = wait_time
    connection_timers[connection_type].start()

func _on_retry_timer(connection_type: String):
    # Retry connection after timer expires
    print("Retrying connection to " + connection_type)
    connect_to_service(connection_type)

func _on_check_timer():
    # Periodically check connections
    print("Checking connection status")
    
    for connection_type in connection_types:
        if connections[connection_type].status == "connected":
            # In a real implementation, would ping the service to verify connection
            # For this mock-up, we'll simulate random disconnections
            
            # 5% chance of random disconnection
            if randf() < 0.05:
                print(connection_type + " connection lost")
                _update_connection_status(connection_type, "disconnected")
                
                if auto_reconnect:
                    # Try to reconnect
                    connections[connection_type].retry_count = 0
                    connect_to_service(connection_type)
        elif connections[connection_type].status == "error" and auto_reconnect:
            # Check if we should retry based on max retries
            if connections[connection_type].retry_count <= max_retry_count:
                connect_to_service(connection_type)

# ----- UTILITY METHODS -----
func _generate_token(length: int) -> String:
    # Generate a random token
    var token = ""
    var chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
    
    for i in range(length):
        token += chars[randi() % chars.length()]
    
    return token

func get_connection_status() -> Dictionary:
    # Get current connection status for all services
    return connections.duplicate()

func get_auth_token() -> String:
    # Get current authentication token
    return auth_token

func set_auto_reconnect(enabled: bool) -> void:
    # Enable or disable auto-reconnect
    auto_reconnect = enabled
    print("Auto reconnect " + ("enabled" if enabled else "disabled"))

func set_retry_interval(seconds: float) -> void:
    # Set retry interval
    retry_interval = max(1.0, seconds)
    print("Retry interval set to " + str(retry_interval) + " seconds")

func set_max_retry_count(count: int) -> void:
    # Set maximum retry count
    max_retry_count = max(1, count)
    print("Max retry count set to " + str(max_retry_count))

func set_check_interval(seconds: float) -> void:
    # Set connection check interval
    check_interval = max(1.0, seconds)
    check_timer.wait_time = check_interval
    print("Connection check interval set to " + str(check_interval) + " seconds")

# ----- SERVICE CONFIGURATION -----
func set_api_url(url: String) -> void:
    # Set API URL
    api_url = url
    print("API URL set to " + api_url)

func set_api_key(key: String) -> void:
    # Set API key
    api_key = key
    print("API key updated")

func set_ocr_service_url(url: String) -> void:
    # Set OCR service URL
    ocr_service_url = url
    print("OCR service URL set to " + ocr_service_url)

func set_drive_service_url(url: String) -> void:
    # Set Drive service URL
    drive_service_url = url
    print("Drive service URL set to " + drive_service_url)

func enable_service(service_type: String, enabled: bool) -> void:
    # Enable or disable a service
    
    match service_type:
        "drive":
            enable_drive_integration = enabled
            print("Drive integration " + ("enabled" if enabled else "disabled"))
        "ocr":
            enable_ocr_integration = enabled
            print("OCR integration " + ("enabled" if enabled else "disabled"))
        "network":
            enable_network_discovery = enabled
            print("Network discovery " + ("enabled" if enabled else "disabled"))
        _:
            print("Unknown service type: " + service_type)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_correction_system.gd
# SIZE: 10931 bytes
extends Node

class_name AutoCorrectionSystem

# Constants
const CORRECTION_INTERVAL = 300 # seconds (5 minutes)
const MIN_CORRECTION_AMOUNT = 5
const MAX_CORRECTION_AMOUNT = 100
const MIN_CONFIDENCE_THRESHOLD = 0.3
const ENJOYMENT_THRESHOLD = 0.7
const AUTO_ADJUST_STEP = 0.05

# Settings
var auto_correction_enabled = true
var enjoyment_learning_rate = 0.1
var adjustment_intensity = 0.5 # 0.0-1.0
var notification_level = 1 # 0=none, 1=subtle, 2=obvious

# System state
var last_correction_time = 0
var correction_history = []
var enjoyment_readings = []
var detected_playstyle = ""
var detected_preferences = {}
var enjoyment_model = {
    "baseline": 1.0,
    "trend": 0.0,
    "variance": 0.1
}

# References
var _preference_analyzer = null
var _account_manager = null

# Signals
signal correction_applied(amount, category, reason)
signal playstyle_detected(style)
signal settings_updated()

func _ready():
    # Set up correction timer
    var timer = Timer.new()
    timer.wait_time = CORRECTION_INTERVAL
    timer.autostart = true
    timer.connect("timeout", self, "_on_correction_interval")
    add_child(timer)
    
    # Connect to preference analyzer if available
    if has_node("/root/PlayerPreferenceAnalyzer") or get_node_or_null("/root/PlayerPreferenceAnalyzer"):
        _preference_analyzer = get_node("/root/PlayerPreferenceAnalyzer")
        _preference_analyzer.connect("preferences_updated", self, "_on_preferences_updated")
        _preference_analyzer.connect("enjoyment_factor_changed", self, "_on_enjoyment_factor_changed")
        print("Connected to PlayerPreferenceAnalyzer")
    
    # Connect to account manager if available
    if has_node("/root/SmartAccountManager") or get_node_or_null("/root/SmartAccountManager"):
        _account_manager = get_node("/root/SmartAccountManager")
        print("Connected to SmartAccountManager")
    
    # Initialize
    detect_playstyle()

func _on_correction_interval():
    if auto_correction_enabled:
        apply_auto_correction()
    last_correction_time = OS.get_unix_time()

func _on_preferences_updated(preferences):
    detected_preferences = preferences
    detect_playstyle()

func _on_enjoyment_factor_changed(factor):
    # Add to enjoyment readings
    enjoyment_readings.append({
        "value": factor,
        "timestamp": OS.get_unix_time()
    })
    
    # Limit array size
    if enjoyment_readings.size() > 20:
        enjoyment_readings.pop_front()
    
    # Update enjoyment model
    update_enjoyment_model()

func detect_playstyle():
    if not _preference_analyzer:
        return
    
    # Find dominant preferences
    var primary_pref = ""
    var primary_value = 0.0
    var secondary_pref = ""
    var secondary_value = 0.0
    
    for pref in detected_preferences:
        var value = detected_preferences[pref]
        if value > primary_value:
            secondary_pref = primary_pref
            secondary_value = primary_value
            primary_pref = pref
            primary_value = value
        elif value > secondary_value:
            secondary_pref = pref
            secondary_value = value
    
    # Determine playstyle based on preferences
    var playstyle = ""
    
    if primary_value >= 0.7:
        # Strong single preference
        if primary_pref == "challenge":
            playstyle = "Challenger"
        elif primary_pref == "creation":
            playstyle = "Creator"
        elif primary_pref == "exploration":
            playstyle = "Explorer"
        elif primary_pref == "social":
            playstyle = "Socializer"
        elif primary_pref == "achievement":
            playstyle = "Achiever"
    elif primary_value >= 0.5 and secondary_value >= 0.4:
        # Hybrid playstyle
        playstyle = hybrid_playstyle_name(primary_pref, secondary_pref)
    else:
        playstyle = "Balanced"
    
    if playstyle != detected_playstyle:
        detected_playstyle = playstyle
        emit_signal("playstyle_detected", detected_playstyle)
        print("Detected playstyle: " + detected_playstyle)

func hybrid_playstyle_name(primary, secondary):
    var style_map = {
        "challenge": {
            "creation": "Innovative Challenger",
            "exploration": "Adventurous Challenger",
            "social": "Competitive Socializer",
            "achievement": "Trophy Hunter"
        },
        "creation": {
            "challenge": "Problem Solver",
            "exploration": "World Builder",
            "social": "Collaborative Creator",
            "achievement": "Productive Creator"
        },
        "exploration": {
            "challenge": "Puzzle Explorer",
            "creation": "Creative Explorer",
            "social": "Guide",
            "achievement": "Completionist"
        },
        "social": {
            "challenge": "Team Leader",
            "creation": "Community Builder",
            "exploration": "Group Explorer",
            "achievement": "Social Achiever"
        },
        "achievement": {
            "challenge": "Record Breaker",
            "creation": "Collector",
            "exploration": "Discoverer",
            "social": "Status Seeker"
        }
    }
    
    if primary in style_map and secondary in style_map[primary]:
        return style_map[primary][secondary]
    
    return primary.capitalize() + "-" + secondary.capitalize() + " Hybrid"

func update_enjoyment_model():
    if enjoyment_readings.size() < 3:
        return
    
    # Calculate average enjoyment
    var avg_enjoyment = 0.0
    for reading in enjoyment_readings:
        avg_enjoyment += reading["value"]
    avg_enjoyment /= enjoyment_readings.size()
    
    # Calculate trend (linear regression slope)
    var x_sum = 0.0
    var y_sum = 0.0
    var xy_sum = 0.0
    var x2_sum = 0.0
    var n = enjoyment_readings.size()
    
    for i in range(n):
        var x = float(i)
        var y = enjoyment_readings[i]["value"]
        
        x_sum += x
        y_sum += y
        xy_sum += x * y
        x2_sum += x * x
    
    var slope = (n * xy_sum - x_sum * y_sum) / (n * x2_sum - x_sum * x_sum)
    
    # Calculate variance
    var variance = 0.0
    for reading in enjoyment_readings:
        variance += pow(reading["value"] - avg_enjoyment, 2)
    variance /= enjoyment_readings.size()
    
    # Update model using learning rate to smooth changes
    enjoyment_model["baseline"] = enjoyment_model["baseline"] * (1.0 - enjoyment_learning_rate) + avg_enjoyment * enjoyment_learning_rate
    enjoyment_model["trend"] = enjoyment_model["trend"] * (1.0 - enjoyment_learning_rate) + slope * enjoyment_learning_rate
    enjoyment_model["variance"] = enjoyment_model["variance"] * (1.0 - enjoyment_learning_rate) + variance * enjoyment_learning_rate

func apply_auto_correction():
    if not _preference_analyzer or not _account_manager:
        return false
    
    # Skip if confidence is too low
    if _preference_analyzer.get_confidence_level() < MIN_CONFIDENCE_THRESHOLD:
        print("Auto-correction skipped: Confidence too low")
        return false
    
    # Get correction suggestion
    var suggestion = _preference_analyzer.get_auto_correction_suggestion()
    if not suggestion:
        print("Auto-correction skipped: No suggestion available")
        return false
    
    # Calculate correction amount based on adjustment intensity
    var amount = clamp(
        suggestion["amount"] * adjustment_intensity,
        MIN_CORRECTION_AMOUNT,
        MAX_CORRECTION_AMOUNT
    )
    
    # Apply correction
    var success = false
    if _account_manager.has_method("add_points"):
        success = _account_manager.add_points(amount, suggestion["category"])
    
    if success:
        # Record correction
        correction_history.append({
            "amount": amount,
            "category": suggestion["category"],
            "reason": suggestion["reason"],
            "timestamp": OS.get_unix_time(),
            "confidence": suggestion["confidence"]
        })
        
        # Limit history size
        if correction_history.size() > 50:
            correction_history.pop_front()
        
        # Send notification based on level
        if notification_level >= 1:
            send_correction_notification(amount, suggestion["category"], notification_level)
        
        emit_signal("correction_applied", amount, suggestion["category"], suggestion["reason"])
        print("Auto-correction applied: " + str(amount) + " points to " + suggestion["category"])
        return true
    
    return false

func send_correction_notification(amount, category, level):
    # Only send if connected to necessary systems
    if not _account_manager:
        return
    
    var message = ""
    
    if level == 1:
        # Subtle notification
        message = "You received a bonus for your " + category + " activities."
    else:
        # Obvious notification
        message = "AUTO-CORRECTION: Added " + str(int(amount)) + " points to " + category.capitalize() + " category based on your play style."
    
    # In a real game, would send to notification system
    print("NOTIFICATION: " + message)

func adjust_settings_based_on_feedback(feedback_type, value):
    match feedback_type:
        "enjoyment":
            # Adjust settings based on enjoyment feedback
            if value < ENJOYMENT_THRESHOLD and adjustment_intensity > 0.1:
                adjustment_intensity -= AUTO_ADJUST_STEP
                print("Decreased adjustment intensity to: " + str(adjustment_intensity))
            elif value > ENJOYMENT_THRESHOLD and adjustment_intensity < 0.9:
                adjustment_intensity += AUTO_ADJUST_STEP
                print("Increased adjustment intensity to: " + str(adjustment_intensity))
        
        "notification":
            # Adjust notification level based on feedback
            notification_level = clamp(int(value), 0, 2)
            print("Set notification level to: " + str(notification_level))
        
        "auto_correct":
            # Toggle auto-correction
            auto_correction_enabled = bool(value)
            print("Auto-correction " + ("enabled" if auto_correction_enabled else "disabled"))
    
    emit_signal("settings_updated")
    return true

# Helper methods for external access

func get_playstyle():
    return detected_playstyle

func get_enjoyment_baseline():
    return enjoyment_model["baseline"]

func get_last_correction():
    if correction_history.size() > 0:
        return correction_history[correction_history.size() - 1]
    return null

func get_correction_frequency():
    if correction_history.size() < 2:
        return 0.0
    
    var first = correction_history[0]["timestamp"]
    var last = correction_history[correction_history.size() - 1]["timestamp"]
    var duration = last - first
    
    if duration <= 0:
        return 0.0
    
    return correction_history.size() / float(duration / 3600.0) # per hour
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_correction_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_tracker_update.gd
# SIZE: 9667 bytes
extends Node

class_name AutoTrackerUpdate

# ----- AUTO UPDATE SETTINGS -----
@export_category("Auto Update Settings")
@export var update_interval: float = 5.0  # Check for updates every 5 seconds
@export var auto_create_missing: bool = true
@export var auto_restart_on_error: bool = true
@export var log_activity: bool = true

# ----- COMPONENT REFERENCES -----
var time_tracker: Node = null
var visual_system: Node = null
var turn_system: Node = null

# ----- INTERNAL VARIABLES -----
var update_timer: Timer
var last_update_time: float = 0.0
var update_count: int = 0
var log_file_path: String = "user://tracker_update.log"

# ----- FOLDER PATHS -----
var required_folders = [
    "user://time_data",
    "user://time_data/summaries",
    "user://time_data/backups"
]

# ----- FILE PATHS -----
var required_files = {
    "user://time_data/current_session.json": "{}",
    "user://time_data/total_usage.json": "{\"total_time\": 0, \"sessions\": 0}",
    "user://time_data/triggers.json": "[]"
}

# ----- INITIALIZATION -----
func _ready():
    # Create update timer
    update_timer = Timer.new()
    update_timer.wait_time = update_interval
    update_timer.one_shot = false
    update_timer.autostart = true
    update_timer.connect("timeout", _on_update_timer_timeout)
    add_child(update_timer)
    
    # Find required systems
    _find_systems()
    
    # Ensure all required folders and files exist
    if auto_create_missing:
        _ensure_folders_exist()
        _ensure_files_exist()
    
    log_message("Auto Tracker Update initialized")

func _find_systems():
    # Find time tracker
    time_tracker = _find_node_by_class(get_tree().root, "UsageTimeTracker")
    if time_tracker:
        log_message("Found time tracker: " + time_tracker.name)
    
    # Find visual system
    visual_system = _find_node_by_class(get_tree().root, "VisualIndicatorSystem")
    if visual_system:
        log_message("Found visual system: " + visual_system.name)
    
    # Find turn system
    turn_system = _find_node_by_class(get_tree().root, "TurnSystem")
    if not turn_system:
        turn_system = _find_node_by_class(get_tree().root, "TurnCycleController")
    if turn_system:
        log_message("Found turn system: " + turn_system.name)

func _find_node_by_class(node, class_name):
    if node.get_class() == class_name:
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name)
        if found:
            return found
    
    return null

# ----- FOLDER AND FILE MANAGEMENT -----
func _ensure_folders_exist():
    for folder_path in required_folders:
        if not DirAccess.dir_exists_absolute(folder_path):
            log_message("Creating folder: " + folder_path)
            DirAccess.make_dir_recursive_absolute(folder_path)

func _ensure_files_exist():
    for file_path in required_files:
        if not FileAccess.file_exists(file_path):
            log_message("Creating file: " + file_path)
            var file = FileAccess.open(file_path, FileAccess.WRITE)
            if file:
                file.store_string(required_files[file_path])
                file.close()
            else:
                log_message("Error creating file: " + file_path)

# ----- UPDATE LOGIC -----
func _on_update_timer_timeout():
    update_count += 1
    last_update_time = Time.get_unix_time_from_system()
    
    # Perform updates
    _update_time_tracking()
    _update_visuals()
    _update_todos()
    
    # Create summary every 10 updates
    if update_count % 10 == 0:
        _create_summary()

func _update_time_tracking():
    if time_tracker:
        var usage_summary = time_tracker.get_usage_summary()
        
        # Save current session data
        var session_data = {
            "timestamp": Time.get_unix_time_from_system(),
            "session_time": usage_summary.current_session_time,
            "total_time": usage_summary.total_usage_time,
            "formatted_session_time": usage_summary.formatted_session_time,
            "formatted_total_time": usage_summary.formatted_total_time
        }
        
        _save_json_file("user://time_data/current_session.json", session_data)
        
        # Update total usage
        var total_data = _load_json_file("user://time_data/total_usage.json")
        if total_data:
            total_data.total_time = usage_summary.total_usage_time
            total_data.sessions += 1
            _save_json_file("user://time_data/total_usage.json", total_data)

func _update_visuals():
    if visual_system:
        var visual_state = visual_system.get_visual_state()
        
        # Save visual state
        var visual_data = {
            "timestamp": Time.get_unix_time_from_system(),
            "mode": visual_state.mode,
            "mode_name": visual_state.mode_name,
            "symbol": visual_state.symbol,
            "layer": visual_state.current_layer
        }
        
        # Save to shared status file
        var status_data = _load_json_file("user://time_data/current_session.json") or {}
        status_data.visual = visual_data
        _save_json_file("user://time_data/current_session.json", status_data)

func _update_todos():
    # We'll create a file to store tasks that need to be processed automatically
    var pending_tasks_path = "user://time_data/pending_tasks.json"
    
    if not FileAccess.file_exists(pending_tasks_path):
        # Create initial file
        var initial_data = {
            "tasks": [
                {
                    "id": "1",
                    "content": "Automatically created task",
                    "status": "pending",
                    "priority": "medium"
                }
            ]
        }
        _save_json_file(pending_tasks_path, initial_data)
    else:
        # Read and update existing tasks
        var tasks_data = _load_json_file(pending_tasks_path)
        if tasks_data and tasks_data.has("tasks"):
            # Process any pending tasks
            var updated = false
            
            for i in range(tasks_data.tasks.size()):
                if tasks_data.tasks[i].status == "pending" and update_count % 5 == 0:
                    # Auto-mark one task as completed every 5 updates
                    tasks_data.tasks[i].status = "completed"
                    updated = true
                    log_message("Auto-completed task: " + tasks_data.tasks[i].content)
                    break
            
            if updated:
                _save_json_file(pending_tasks_path, tasks_data)

func _create_summary():
    # Create a summary of current usage
    var summary_data = {}
    
    # Add time tracking data
    if time_tracker:
        summary_data.time_tracking = time_tracker.get_usage_summary()
    
    # Add visual system data
    if visual_system:
        summary_data.visual = visual_system.get_visual_state()
    
    # Add turn system data
    if turn_system and turn_system.has_method("get_turn_info"):
        summary_data.turn = turn_system.get_turn_info()
    elif turn_system:
        summary_data.turn = {
            "current_turn": turn_system.current_turn if "current_turn" in turn_system else 1
        }
    
    # Add system info
    summary_data.system = {
        "update_count": update_count,
        "last_update": last_update_time,
        "timestamp": Time.get_unix_time_from_system()
    }
    
    # Save summary with timestamp
    var time_str = Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_")
    var summary_path = "user://time_data/summaries/summary_" + time_str + ".json"
    _save_json_file(summary_path, summary_data)
    
    log_message("Created summary: " + summary_path)
    
    # Also create a backup of the current session
    var backup_path = "user://time_data/backups/session_" + time_str + ".json"
    var current_session = _load_json_file("user://time_data/current_session.json")
    if current_session:
        _save_json_file(backup_path, current_session)

# ----- UTILITY FUNCTIONS -----
func _save_json_file(file_path, data):
    var file = FileAccess.open(file_path, FileAccess.WRITE)
    if file:
        var json_string = JSON.stringify(data, "  ")
        file.store_string(json_string)
        file.close()
        return true
    else:
        log_message("Error saving JSON file: " + file_path)
        return false

func _load_json_file(file_path):
    if FileAccess.file_exists(file_path):
        var file = FileAccess.open(file_path, FileAccess.READ)
        if file:
            var content = file.get_as_text()
            file.close()
            
            var json = JSON.new()
            var error = json.parse(content)
            
            if error == OK:
                return json.data
            else:
                log_message("Error parsing JSON: " + file_path)
                return null
    
    return null

func log_message(message):
    if log_activity:
        var timestamp = Time.get_datetime_string_from_system()
        print("[AutoUpdate] " + message)
        
        var file = FileAccess.open(log_file_path, FileAccess.READ_WRITE)
        if file:
            file.seek_end()
            file.store_line("[" + timestamp + "] " + message)
            file.close()

# ----- PUBLIC API -----
func force_update():
    _on_update_timer_timeout()
    return update_count

func set_update_interval(seconds: float) -> bool:
    if seconds <= 0:
        return false
    
    update_interval = seconds
    update_timer.wait_time = seconds
    return true

func toggle_auto_create() -> bool:
    auto_create_missing = !auto_create_missing
    return auto_create_missing
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_tracker_update.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_updater.gd
# SIZE: 17023 bytes
extends Node

class_name AutoUpdater

# ----- CONFIGURATION -----
@export_category("Update Settings")
@export var check_on_startup: bool = true
@export var update_server_url: String = "https://api.example.com/updates"
@export var auto_download_updates: bool = false
@export var update_channel: String = "stable"  # stable, beta, dev
@export var max_download_retries: int = 3
@export var download_timeout: int = 60  # seconds
@export var temp_directory: String = "user://temp/"

# ----- CONNECTION SETTINGS -----
@export_category("Connection Settings")
@export var auto_reconnect: bool = true
@export var reconnect_interval: int = 10  # seconds
@export var max_reconnect_attempts: int = 5
@export var connection_timeout: int = 30  # seconds
@export var api_endpoints: Dictionary = {
    "auth": "https://api.example.com/auth",
    "status": "https://api.example.com/status",
    "config": "https://api.example.com/config"
}

# ----- STATE VARIABLES -----
var current_version: String = "1.0.0"
var latest_version: String = ""
var is_update_available: bool = false
var is_checking_for_updates: bool = false
var is_downloading_update: bool = false
var download_progress: float = 0.0
var download_error: String = ""
var update_check_time: int = 0

# ----- CONNECTION STATE -----
var is_connected: bool = false
var connection_attempt: int = 0
var reconnect_timer: Timer
var auth_token: String = ""
var last_connection_time: int = 0
var connection_status: String = "disconnected"  # disconnected, connecting, connected, error
var connected_services: Dictionary = {}

# ----- SIGNALS -----
signal update_available(version, release_notes)
signal update_not_available()
signal update_check_started()
signal update_check_completed()
signal update_check_failed(error)
signal download_started(version)
signal download_progress_changed(progress)
signal download_completed(path)
signal download_failed(error)
signal connection_status_changed(status)
signal service_connected(service_name)
signal service_disconnected(service_name)
signal auth_successful(token)
signal auth_failed(error)

# ----- INITIALIZATION -----
func _ready():
    # Create temp directory
    _ensure_temp_directory()
    
    # Set up reconnect timer
    _setup_reconnect_timer()
    
    # Check for updates on startup if enabled
    if check_on_startup:
        check_for_updates()
    
    print("Auto Updater initialized")
    print("Current version: " + current_version)
    print("Update channel: " + update_channel)

func _ensure_temp_directory():
    var dir = Directory.new()
    if not dir.dir_exists(temp_directory):
        dir.make_dir_recursive(temp_directory)

func _setup_reconnect_timer():
    reconnect_timer = Timer.new()
    reconnect_timer.wait_time = reconnect_interval
    reconnect_timer.one_shot = true
    reconnect_timer.autostart = false
    reconnect_timer.connect("timeout", Callable(self, "_on_reconnect_timer_timeout"))
    add_child(reconnect_timer)

# ----- UPDATE METHODS -----
func check_for_updates() -> void:
    # Check for available updates
    
    if is_checking_for_updates:
        print("Already checking for updates")
        return
    
    is_checking_for_updates = true
    emit_signal("update_check_started")
    
    print("Checking for updates...")
    print("Current version: " + current_version)
    print("Update channel: " + update_channel)
    
    # In a real implementation, would make an HTTP request to the update server
    # For this mock-up, we'll simulate the request
    
    _simulate_update_check()

func _simulate_update_check():
    # Simulate an update check
    
    # Add a delay to simulate network request
    await get_tree().create_timer(1.5).timeout
    
    # Randomly determine if an update is available (70% chance)
    var update_available = randf() < 0.7
    
    if update_available:
        # Generate a newer version number
        var parts = current_version.split(".")
        var major = int(parts[0])
        var minor = int(parts[1])
        var patch = int(parts[2])
        
        # Decide which part to increment
        var update_type = randi() % 3
        
        match update_type:
            0:  # Major update
                major += 1
                minor = 0
                patch = 0
            1:  # Minor update
                minor += 1
                patch = 0
            2:  # Patch update
                patch += 1
        
        latest_version = str(major) + "." + str(minor) + "." + str(patch)
        
        # Generate release notes
        var release_notes = _generate_release_notes(latest_version)
        
        # Update state
        is_update_available = true
        update_check_time = OS.get_unix_time()
        
        # Emit signal
        emit_signal("update_available", latest_version, release_notes)
        
        print("Update available: " + latest_version)
        print("Release notes: " + release_notes)
    else:
        # No update available
        latest_version = current_version
        is_update_available = false
        update_check_time = OS.get_unix_time()
        
        emit_signal("update_not_available")
        
        print("No updates available")
    
    # Complete check
    is_checking_for_updates = false
    emit_signal("update_check_completed")

func _generate_release_notes(version: String) -> String:
    # Generate sample release notes for simulation
    var notes_templates = [
        "Version %s includes performance improvements and bug fixes.",
        "Version %s adds new features and improves stability.",
        "Version %s fixes critical issues and enhances security.",
        "Version %s includes UI improvements and new themes.",
        "Version %s adds support for additional file formats and improves OCR accuracy."
    ]
    
    var template = notes_templates[randi() % notes_templates.size()]
    return template % version

func download_update() -> void:
    # Download the latest update
    
    if not is_update_available:
        print("No update available to download")
        return
    
    if is_downloading_update:
        print("Already downloading update")
        return
    
    is_downloading_update = true
    download_progress = 0.0
    download_error = ""
    
    emit_signal("download_started", latest_version)
    
    print("Downloading update: " + latest_version)
    
    # In a real implementation, would download the update file
    # For this mock-up, we'll simulate the download
    
    _simulate_update_download()

func _simulate_update_download():
    # Simulate downloading an update
    
    # Simulate download progress over time
    var total_time = 3.0  # seconds
    var update_interval = 0.2  # seconds
    var progress = 0.0
    
    while progress < 1.0:
        await get_tree().create_timer(update_interval).timeout
        
        # Update progress
        progress += update_interval / total_time
        progress = min(progress, 1.0)
        download_progress = progress
        
        emit_signal("download_progress_changed", download_progress)
        
        print("Download progress: " + str(int(download_progress * 100)) + "%")
    
    # Randomly determine if download succeeds (90% chance)
    var success = randf() < 0.9
    
    if success:
        # Generate a temp file path
        var update_file_path = temp_directory + "update_" + latest_version + ".exe"
        
        # Complete download
        is_downloading_update = false
        
        emit_signal("download_completed", update_file_path)
        
        print("Download completed: " + update_file_path)
        
        # Automatically install if configured
        if auto_download_updates:
            install_update(update_file_path)
    else:
        # Simulate download failure
        download_error = "Network error: connection interrupted"
        is_downloading_update = false
        
        emit_signal("download_failed", download_error)
        
        print("Download failed: " + download_error)

func install_update(update_file_path: String) -> bool:
    # Install the downloaded update
    
    print("Installing update from: " + update_file_path)
    
    # In a real implementation, would launch the installer or apply the update
    # For this mock-up, we'll simulate the installation
    
    # Simulate installation process
    await get_tree().create_timer(2.0).timeout
    
    # Randomly determine if installation succeeds (95% chance)
    var success = randf() < 0.95
    
    if success:
        print("Update installed successfully.")
        print("Restart required to apply update.")
        
        # In a real application, would prompt for restart
        return true
    else:
        print("Failed to install update.")
        return false

# ----- CONNECTION METHODS -----
func connect_to_services() -> void:
    # Connect to all configured services
    
    if is_connected:
        print("Already connected to services")
        return
    
    connection_status = "connecting"
    connection_attempt = 0
    
    emit_signal("connection_status_changed", connection_status)
    
    print("Connecting to services...")
    
    # Authenticate first
    authenticate()

func authenticate() -> void:
    # Authenticate with the server
    
    print("Authenticating...")
    
    # In a real implementation, would make an authentication request
    # For this mock-up, we'll simulate authentication
    
    _simulate_authentication()

func _simulate_authentication():
    # Simulate authentication process
    
    # Add a delay to simulate network request
    await get_tree().create_timer(1.0).timeout
    
    # Randomly determine if authentication succeeds (90% chance)
    var success = randf() < 0.9
    
    if success:
        # Generate a token
        auth_token = _generate_auth_token()
        
        emit_signal("auth_successful", auth_token)
        
        print("Authentication successful")
        
        # Connect to individual services
        _connect_to_services()
    else:
        var error = "Authentication failed: invalid credentials"
        
        connection_status = "error"
        emit_signal("auth_failed", error)
        emit_signal("connection_status_changed", connection_status)
        
        print("Authentication failed: " + error)
        
        # Try to reconnect if enabled
        if auto_reconnect and connection_attempt < max_reconnect_attempts:
            _schedule_reconnect()

func _generate_auth_token() -> String:
    # Generate a random authentication token
    var token = ""
    var chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
    
    for i in range(32):
        token += chars[randi() % chars.length()]
    
    return token

func _connect_to_services():
    # Connect to individual services
    var services = [
        {"name": "status", "url": api_endpoints.status},
        {"name": "config", "url": api_endpoints.config}
    ]
    
    var pending_services = services.size()
    
    for service in services:
        # Simulate connecting to each service
        print("Connecting to service: " + service.name)
        
        _simulate_service_connection(service.name, service.url, func(success, name):
            if success:
                connected_services[name] = true
                emit_signal("service_connected", name)
                print("Connected to service: " + name)
            else:
                print("Failed to connect to service: " + name)
            
            pending_services -= 1
            
            # Check if all services are connected
            if pending_services == 0:
                _finalize_connection()
        )

func _simulate_service_connection(service_name: String, service_url: String, callback: Callable):
    # Simulate connecting to a service
    
    # Add a delay to simulate network request
    await get_tree().create_timer(0.8).timeout
    
    # Randomly determine if connection succeeds (95% chance)
    var success = randf() < 0.95
    
    # Call the callback with the result
    callback.call(success, service_name)

func _finalize_connection():
    # Finalize the connection process
    
    # Check if all services are connected
    var all_connected = true
    
    for service in api_endpoints:
        if service != "auth" and not connected_services.has(service):
            all_connected = false
            break
    
    if all_connected:
        is_connected = true
        connection_status = "connected"
        last_connection_time = OS.get_unix_time()
        
        emit_signal("connection_status_changed", connection_status)
        
        print("Connected to all services")
    else:
        connection_status = "partial"
        
        emit_signal("connection_status_changed", connection_status)
        
        print("Partially connected - some services failed")

func disconnect_from_services():
    # Disconnect from all services
    
    if not is_connected and connection_status != "partial":
        print("Not connected to any services")
        return
    
    print("Disconnecting from services...")
    
    # In a real implementation, would properly close connections
    # For this mock-up, we'll simulate disconnection
    
    # Disconnect from each service
    for service in connected_services.keys():
        if connected_services[service]:
            emit_signal("service_disconnected", service)
            print("Disconnected from service: " + service)
    
    # Reset state
    is_connected = false
    connection_status = "disconnected"
    connected_services.clear()
    auth_token = ""
    
    emit_signal("connection_status_changed", connection_status)
    
    print("Disconnected from all services")

func _schedule_reconnect():
    # Schedule an attempt to reconnect
    
    connection_attempt += 1
    
    print("Scheduling reconnect attempt " + str(connection_attempt) + "/" + str(max_reconnect_attempts))
    
    # Exponential backoff
    var wait_time = reconnect_interval * pow(1.5, connection_attempt - 1)
    reconnect_timer.wait_time = wait_time
    reconnect_timer.start()
    
    print("Will attempt to reconnect in " + str(wait_time) + " seconds")

func _on_reconnect_timer_timeout():
    # Attempt to reconnect
    print("Attempting to reconnect...")
    connect_to_services()

# ----- AUTO-CONNECTION METHODS -----
func enable_auto_reconnect(enabled: bool) -> void:
    auto_reconnect = enabled
    print("Auto-reconnect " + ("enabled" if enabled else "disabled"))

func set_reconnect_interval(seconds: int) -> void:
    reconnect_interval = max(1, seconds)
    print("Reconnect interval set to " + str(reconnect_interval) + " seconds")

func set_max_reconnect_attempts(attempts: int) -> void:
    max_reconnect_attempts = max(1, attempts)
    print("Max reconnect attempts set to " + str(max_reconnect_attempts))

# ----- UPDATE CONFIGURATION -----
func set_update_channel(channel: String) -> void:
    if channel in ["stable", "beta", "dev"]:
        update_channel = channel
        print("Update channel set to " + update_channel)
    else:
        print("Invalid update channel: " + channel)

func enable_auto_download(enabled: bool) -> void:
    auto_download_updates = enabled
    print("Auto-download updates " + ("enabled" if enabled else "disabled"))

func set_update_server(url: String) -> void:
    update_server_url = url
    print("Update server URL set to " + update_server_url)

# ----- UTILITY METHODS -----
func get_connection_status() -> Dictionary:
    return {
        "status": connection_status,
        "connected_services": connected_services.keys(),
        "is_authenticated": auth_token != "",
        "connection_attempts": connection_attempt,
        "last_connection_time": last_connection_time
    }

func get_update_status() -> Dictionary:
    return {
        "current_version": current_version,
        "latest_version": latest_version,
        "is_update_available": is_update_available,
        "is_checking": is_checking_for_updates,
        "is_downloading": is_downloading_update,
        "download_progress": download_progress,
        "last_check_time": update_check_time
    }

func parse_version_string(version: String) -> Dictionary:
    var parts = version.split(".")
    
    if parts.size() >= 3:
        return {
            "major": int(parts[0]),
            "minor": int(parts[1]),
            "patch": int(parts[2])
        }
    
    return {
        "major": 0,
        "minor": 0,
        "patch": 0
    }

func compare_versions(version_a: String, version_b: String) -> int:
    # Compare two version strings
    # Returns: -1 if a < b, 0 if a = b, 1 if a > b
    
    var a = parse_version_string(version_a)
    var b = parse_version_string(version_b)
    
    if a.major != b.major:
        return 1 if a.major > b.major else -1
    
    if a.minor != b.minor:
        return 1 if a.minor > b.minor else -1
    
    if a.patch != b.patch:
        return 1 if a.patch > b.patch else -1
    
    return 0
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/auto_updater.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/blink_animation_controller.gd
# SIZE: 21569 bytes
extends Node

class_name BlinkAnimationController

# ----- ANIMATION SETTINGS -----
@export_category("Blink Settings")
@export var enabled: bool = true
@export var blink_interval_min: float = 0.5  # Minimum time between blinks in seconds
@export var blink_interval_max: float = 3.0  # Maximum time between blinks in seconds
@export var blink_duration: float = 0.15     # Duration of a single blink in seconds
@export var double_blink_chance: float = 0.3 # Chance of a double blink (0-1)
@export var triple_blink_chance: float = 0.1 # Chance of a triple blink (0-1)

# ----- WINK SETTINGS -----
@export_category("Wink Settings")
@export var wink_enabled: bool = true
@export var wink_interval_min: float = 5.0   # Minimum time between winks
@export var wink_interval_max: float = 15.0  # Maximum time between winks
@export var wink_duration: float = 0.3       # Duration of a wink
@export var left_wink_chance: float = 0.5    # Chance of winking with left eye (vs right)

# ----- FLICKER SETTINGS -----
@export_category("Flicker Settings")
@export var flicker_enabled: bool = true
@export var flicker_interval_min: float = 10.0  # Minimum time between flickers
@export var flicker_interval_max: float = 30.0  # Maximum time between flickers
@export var flicker_duration: float = 0.05      # Duration of a single flicker
@export var flicker_count_min: int = 2          # Minimum flickers in sequence
@export var flicker_count_max: int = 6          # Maximum flickers in sequence
@export var flicker_intensity: float = 0.7      # Intensity of the flicker (0-1)

# ----- TURN INTEGRATION -----
@export_category("Turn Integration")
@export var increase_frequency_per_turn: bool = true
@export var turn_frequency_multiplier: float = 0.9  # Reduces intervals by 10% per turn
@export var max_frequency_multiplier: float = 0.3   # Max reduction is 70% of original

# ----- STATE VARIABLES -----
var blink_timer: Timer
var wink_timer: Timer
var flicker_timer: Timer
var is_blinking: bool = false
var is_winking: bool = false
var is_flickering: bool = false
var current_turn: int = 1
var turn_controller = null
var registered_nodes = {}  # Dictionary of nodes that receive blink animations
var animation_player: AnimationPlayer

# ----- SIGNALS -----
signal blink_started(node_name, blink_count)
signal blink_ended(node_name)
signal wink_started(node_name, is_left)
signal wink_ended(node_name)
signal flicker_started(node_name, flicker_count)
signal flicker_ended(node_name)

# ----- INITIALIZATION -----
func _ready():
    # Initialize timers
    _initialize_timers()
    
    # Find turn controller
    turn_controller = get_node_or_null("/root/TurnController")
    if not turn_controller:
        turn_controller = _find_node_by_class(get_tree().root, "TurnController")
    
    # Set up animation player
    animation_player = AnimationPlayer.new()
    add_child(animation_player)
    _create_default_animations()
    
    # Connect to turn controller if available
    if turn_controller:
        turn_controller.connect("turn_started", Callable(self, "_on_turn_started"))
        turn_controller.register_system(self)
        current_turn = turn_controller.get_current_turn()
    
    # Start timers if enabled
    if enabled:
        _schedule_next_blink()
    
    if wink_enabled:
        _schedule_next_wink()
    
    if flicker_enabled:
        _schedule_next_flicker()
    
    print("Blink Animation Controller initialized")
    print("Blink interval: " + str(blink_interval_min) + "-" + str(blink_interval_max) + "s")

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_timers():
    # Blink timer
    blink_timer = Timer.new()
    blink_timer.one_shot = true
    blink_timer.connect("timeout", Callable(self, "_on_blink_timer_timeout"))
    add_child(blink_timer)
    
    # Wink timer
    wink_timer = Timer.new()
    wink_timer.one_shot = true
    wink_timer.connect("timeout", Callable(self, "_on_wink_timer_timeout"))
    add_child(wink_timer)
    
    # Flicker timer
    flicker_timer = Timer.new()
    flicker_timer.one_shot = true
    flicker_timer.connect("timeout", Callable(self, "_on_flicker_timer_timeout"))
    add_child(flicker_timer)

func _create_default_animations():
    # Create a library for animations
    var library = AnimationLibrary.new()
    
    # Blink animation
    var blink_anim = Animation.new()
    var track_idx = blink_anim.add_track(Animation.TYPE_VALUE)
    blink_anim.track_set_path(track_idx, ":opacity")
    blink_anim.track_insert_key(track_idx, 0.0, 1.0)
    blink_anim.track_insert_key(track_idx, blink_duration / 2, 0.0)
    blink_anim.track_insert_key(track_idx, blink_duration, 1.0)
    library.add_animation("blink", blink_anim)
    
    # Left wink animation
    var left_wink_anim = Animation.new()
    track_idx = left_wink_anim.add_track(Animation.TYPE_VALUE)
    left_wink_anim.track_set_path(track_idx, ":left_eye_opacity")
    left_wink_anim.track_insert_key(track_idx, 0.0, 1.0)
    left_wink_anim.track_insert_key(track_idx, wink_duration / 2, 0.0)
    left_wink_anim.track_insert_key(track_idx, wink_duration, 1.0)
    library.add_animation("left_wink", left_wink_anim)
    
    # Right wink animation
    var right_wink_anim = Animation.new()
    track_idx = right_wink_anim.add_track(Animation.TYPE_VALUE)
    right_wink_anim.track_set_path(track_idx, ":right_eye_opacity")
    right_wink_anim.track_insert_key(track_idx, 0.0, 1.0)
    right_wink_anim.track_insert_key(track_idx, wink_duration / 2, 0.0)
    right_wink_anim.track_insert_key(track_idx, wink_duration, 1.0)
    library.add_animation("right_wink", right_wink_anim)
    
    # Flicker animation
    var flicker_anim = Animation.new()
    track_idx = flicker_anim.add_track(Animation.TYPE_VALUE)
    flicker_anim.track_set_path(track_idx, ":opacity")
    flicker_anim.track_insert_key(track_idx, 0.0, 1.0)
    flicker_anim.track_insert_key(track_idx, flicker_duration / 2, flicker_intensity)
    flicker_anim.track_insert_key(track_idx, flicker_duration, 1.0)
    library.add_animation("flicker", flicker_anim)
    
    # Add library to animation player
    animation_player.add_animation_library("blinks", library)

# ----- ANIMATION SCHEDULING -----
func _schedule_next_blink():
    if not enabled:
        return
    
    # Calculate interval based on turn if applicable
    var min_interval = blink_interval_min
    var max_interval = blink_interval_max
    
    if increase_frequency_per_turn and turn_controller:
        var multiplier = max(max_frequency_multiplier, 
                            pow(turn_frequency_multiplier, current_turn - 1))
        min_interval *= multiplier
        max_interval *= multiplier
    
    # Random time until next blink
    var interval = min_interval + randf() * (max_interval - min_interval)
    blink_timer.wait_time = interval
    blink_timer.start()
    
    if OS.is_debug_build():
        print("Next blink in " + str(interval) + "s")

func _schedule_next_wink():
    if not wink_enabled:
        return
    
    # Calculate interval based on turn if applicable
    var min_interval = wink_interval_min
    var max_interval = wink_interval_max
    
    if increase_frequency_per_turn and turn_controller:
        var multiplier = max(max_frequency_multiplier, 
                            pow(turn_frequency_multiplier, current_turn - 1))
        min_interval *= multiplier
        max_interval *= multiplier
    
    # Random time until next wink
    var interval = min_interval + randf() * (max_interval - min_interval)
    wink_timer.wait_time = interval
    wink_timer.start()
    
    if OS.is_debug_build():
        print("Next wink in " + str(interval) + "s")

func _schedule_next_flicker():
    if not flicker_enabled:
        return
    
    # Calculate interval based on turn if applicable
    var min_interval = flicker_interval_min
    var max_interval = flicker_interval_max
    
    if increase_frequency_per_turn and turn_controller:
        var multiplier = max(max_frequency_multiplier, 
                            pow(turn_frequency_multiplier, current_turn - 1))
        min_interval *= multiplier
        max_interval *= multiplier
    
    # Random time until next flicker
    var interval = min_interval + randf() * (max_interval - min_interval)
    flicker_timer.wait_time = interval
    flicker_timer.start()
    
    if OS.is_debug_build():
        print("Next flicker in " + str(interval) + "s")

# ----- ANIMATION EXECUTION -----
func _execute_blink():
    is_blinking = true
    
    # Determine blink count (single, double, or triple)
    var blink_count = 1
    var rand_val = randf()
    
    if rand_val < triple_blink_chance:
        blink_count = 3
    elif rand_val < triple_blink_chance + double_blink_chance:
        blink_count = 2
    
    if OS.is_debug_build():
        print("Executing " + str(blink_count) + "x blink")
    
    # Apply to all registered nodes
    for node_name in registered_nodes:
        _blink_node(node_name, blink_count)
    
    # Schedule next blink after this one completes
    var total_duration = blink_duration * blink_count * 1.5  # Add some gap between multiple blinks
    await get_tree().create_timer(total_duration).timeout
    
    is_blinking = false
    _schedule_next_blink()

func _execute_wink():
    is_winking = true
    
    # Determine which eye to wink
    var is_left_wink = randf() < left_wink_chance
    
    if OS.is_debug_build():
        print("Executing wink (" + ("left" if is_left_wink else "right") + " eye)")
    
    # Apply to all registered nodes
    for node_name in registered_nodes:
        _wink_node(node_name, is_left_wink)
    
    # Schedule next wink after this one completes
    await get_tree().create_timer(wink_duration * 1.2).timeout
    
    is_winking = false
    _schedule_next_wink()

func _execute_flicker():
    is_flickering = true
    
    # Determine flicker count
    var flicker_count = flicker_count_min + randi() % (flicker_count_max - flicker_count_min + 1)
    
    if OS.is_debug_build():
        print("Executing " + str(flicker_count) + "x flicker")
    
    # Apply to all registered nodes
    for node_name in registered_nodes:
        _flicker_node(node_name, flicker_count)
    
    # Schedule next flicker after this one completes
    var total_duration = flicker_duration * flicker_count * 2  # Account for gaps
    await get_tree().create_timer(total_duration).timeout
    
    is_flickering = false
    _schedule_next_flicker()

func _blink_node(node_name: String, blink_count: int):
    if not registered_nodes.has(node_name):
        return
    
    var node = registered_nodes[node_name]
    if not is_instance_valid(node):
        registered_nodes.erase(node_name)
        return
    
    emit_signal("blink_started", node_name, blink_count)
    
    # Check if node has custom blink method
    if node.has_method("apply_blink"):
        node.apply_blink(blink_count, blink_duration)
    else:
        # Apply default animation
        for i in range(blink_count):
            # Use property animation or shader parameter if available
            if node.has_method("set_shader_parameter") and node.material.has_parameter("opacity"):
                var tween = create_tween()
                tween.tween_property(node.material, "shader_parameter/opacity", 0.0, blink_duration / 2)
                tween.tween_property(node.material, "shader_parameter/opacity", 1.0, blink_duration / 2)
                await tween.finished
                
                # Add small gap between multiple blinks
                if i < blink_count - 1:
                    await get_tree().create_timer(blink_duration * 0.5).timeout
            elif node.has_property("modulate"):
                var original_color = node.modulate
                var tween = create_tween()
                tween.tween_property(node, "modulate:a", 0.0, blink_duration / 2)
                tween.tween_property(node, "modulate:a", original_color.a, blink_duration / 2)
                await tween.finished
                
                # Add small gap between multiple blinks
                if i < blink_count - 1:
                    await get_tree().create_timer(blink_duration * 0.5).timeout
    
    emit_signal("blink_ended", node_name)

func _wink_node(node_name: String, is_left: bool):
    if not registered_nodes.has(node_name):
        return
    
    var node = registered_nodes[node_name]
    if not is_instance_valid(node):
        registered_nodes.erase(node_name)
        return
    
    emit_signal("wink_started", node_name, is_left)
    
    # Check if node has custom wink method
    if node.has_method("apply_wink"):
        node.apply_wink(is_left, wink_duration)
    else:
        # Check if node has left/right eye components
        var left_eye = node.get_node_or_null("LeftEye") if node.has_method("get_node") else null
        var right_eye = node.get_node_or_null("RightEye") if node.has_method("get_node") else null
        
        if left_eye and right_eye:
            var eye = left_eye if is_left else right_eye
            var original_color = eye.modulate
            
            var tween = create_tween()
            tween.tween_property(eye, "modulate:a", 0.0, wink_duration / 2)
            tween.tween_property(eye, "modulate:a", original_color.a, wink_duration / 2)
        else:
            # Apply basic wink using shader or property if available
            # This is a simplified version since we can't easily distinguish eyes
            if node.has_method("set_shader_parameter") and node.material.has_parameter("wink"):
                var tween = create_tween()
                tween.tween_property(node.material, "shader_parameter/wink", 1.0, wink_duration / 2)
                tween.tween_property(node.material, "shader_parameter/wink", 0.0, wink_duration / 2)
            else:
                # Just do a half-opacity effect as fallback
                var original_color = node.modulate if node.has_property("modulate") else Color(1,1,1,1)
                
                var tween = create_tween()
                tween.tween_property(node, "modulate:a", original_color.a * 0.5, wink_duration / 2)
                tween.tween_property(node, "modulate:a", original_color.a, wink_duration / 2)
    
    emit_signal("wink_ended", node_name)

func _flicker_node(node_name: String, flicker_count: int):
    if not registered_nodes.has(node_name):
        return
    
    var node = registered_nodes[node_name]
    if not is_instance_valid(node):
        registered_nodes.erase(node_name)
        return
    
    emit_signal("flicker_started", node_name, flicker_count)
    
    # Check if node has custom flicker method
    if node.has_method("apply_flicker"):
        node.apply_flicker(flicker_count, flicker_duration, flicker_intensity)
    else:
        # Apply default flicker animation
        for i in range(flicker_count):
            # Use property animation or shader parameter if available
            if node.has_method("set_shader_parameter") and node.material.has_parameter("opacity"):
                var tween = create_tween()
                tween.tween_property(node.material, "shader_parameter/opacity", flicker_intensity, flicker_duration / 2)
                tween.tween_property(node.material, "shader_parameter/opacity", 1.0, flicker_duration / 2)
                await tween.finished
                
                # Add random gap between flickers
                await get_tree().create_timer(randf() * flicker_duration).timeout
            elif node.has_property("modulate"):
                var original_color = node.modulate
                var tween = create_tween()
                tween.tween_property(node, "modulate:a", original_color.a * flicker_intensity, flicker_duration / 2)
                tween.tween_property(node, "modulate:a", original_color.a, flicker_duration / 2)
                await tween.finished
                
                # Add random gap between flickers
                await get_tree().create_timer(randf() * flicker_duration).timeout
    
    emit_signal("flicker_ended", node_name)

# ----- TIMER CALLBACKS -----
func _on_blink_timer_timeout():
    if not is_blinking and enabled:
        _execute_blink()

func _on_wink_timer_timeout():
    if not is_winking and wink_enabled and not is_blinking:
        _execute_wink()

func _on_flicker_timer_timeout():
    if not is_flickering and flicker_enabled and not is_blinking and not is_winking:
        _execute_flicker()

# ----- TURN SYSTEM INTEGRATION -----
func _on_turn_started(turn_number):
    # Update current turn
    current_turn = turn_number
    
    # Check if we need to adjust timers for new turn
    if increase_frequency_per_turn:
        # Restart timers with new frequency
        blink_timer.stop()
        wink_timer.stop()
        flicker_timer.stop()
        
        _schedule_next_blink()
        _schedule_next_wink()
        _schedule_next_flicker()
        
        print("Adjusted animation frequencies for turn " + str(turn_number))
    
    # Special effect for turn change: triple blink
    if enabled:
        await get_tree().create_timer(0.5).timeout
        for node_name in registered_nodes:
            _blink_node(node_name, 3)

# ----- PUBLIC API -----
func register_node(node_name: String, node: Node) -> bool:
    # Register a node for blink animations
    if registered_nodes.has(node_name):
        print("Node already registered with name: " + node_name)
        return false
    
    registered_nodes[node_name] = node
    print("Registered node for blink animations: " + node_name)
    
    return true

func unregister_node(node_name: String) -> bool:
    # Unregister a node
    if not registered_nodes.has(node_name):
        print("No node registered with name: " + node_name)
        return false
    
    registered_nodes.erase(node_name)
    print("Unregistered node: " + node_name)
    
    return true

func trigger_blink(node_name: String = "", blink_count: int = 1) -> bool:
    # Trigger a blink on a specific node (or all if empty)
    if node_name.empty():
        # Blink all registered nodes
        for name in registered_nodes:
            _blink_node(name, blink_count)
        return true
    elif registered_nodes.has(node_name):
        _blink_node(node_name, blink_count)
        return true
    else:
        print("No node registered with name: " + node_name)
        return false

func trigger_wink(node_name: String = "", is_left: bool = true) -> bool:
    # Trigger a wink on a specific node (or all if empty)
    if node_name.empty():
        # Wink all registered nodes
        for name in registered_nodes:
            _wink_node(name, is_left)
        return true
    elif registered_nodes.has(node_name):
        _wink_node(node_name, is_left)
        return true
    else:
        print("No node registered with name: " + node_name)
        return false

func trigger_flicker(node_name: String = "", flicker_count: int = 3) -> bool:
    # Trigger a flicker on a specific node (or all if empty)
    if node_name.empty():
        # Flicker all registered nodes
        for name in registered_nodes:
            _flicker_node(name, flicker_count)
        return true
    elif registered_nodes.has(node_name):
        _flicker_node(node_name, flicker_count)
        return true
    else:
        print("No node registered with name: " + node_name)
        return false

func set_enabled(is_enabled: bool) -> void:
    # Enable or disable blink animations
    enabled = is_enabled
    
    if enabled and not blink_timer.is_stopped():
        _schedule_next_blink()
    elif not enabled:
        blink_timer.stop()
    
    print("Blink animations " + ("enabled" if enabled else "disabled"))

func set_wink_enabled(is_enabled: bool) -> void:
    # Enable or disable wink animations
    wink_enabled = is_enabled
    
    if wink_enabled and not wink_timer.is_stopped():
        _schedule_next_wink()
    elif not wink_enabled:
        wink_timer.stop()
    
    print("Wink animations " + ("enabled" if wink_enabled else "disabled"))

func set_flicker_enabled(is_enabled: bool) -> void:
    # Enable or disable flicker animations
    flicker_enabled = is_enabled
    
    if flicker_enabled and not flicker_timer.is_stopped():
        _schedule_next_flicker()
    elif not flicker_enabled:
        flicker_timer.stop()
    
    print("Flicker animations " + ("enabled" if flicker_enabled else "disabled"))

func on_turn_changed(turn_number: int, turn_data: Dictionary) -> void:
    # Required method for turn system integration
    current_turn = turn_number
    
    # Adjust timers for new turn frequency
    if increase_frequency_per_turn:
        blink_timer.stop()
        wink_timer.stop()
        flicker_timer.stop()
        
        _schedule_next_blink()
        _schedule_next_wink()
        _schedule_next_flicker()
    
    # Get any turn-specific flags
    if turn_data.has("flags"):
        var flags = turn_data.flags
        if flags.has("blink_enabled"):
            enabled = flags.blink_enabled
        if flags.has("wink_enabled"):
            wink_enabled = flags.wink_enabled
        if flags.has("flicker_enabled"):
            flicker_enabled = flags.flicker_enabled
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/blink_animation_controller.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_akashic_bridge.gd
# SIZE: 27661 bytes
extends Node

class_name ClaudeAkashicBridge

# Akashic Bridge Constants
const MAX_WORD_POWER = 100
const FIREWALL_LEVELS = {
	"standard": 1,
	"enhanced": 2,
	"divine": 3
}
const ERROR_TYPES = {
	"validation": "VALIDATION_ERROR",
	"access": "ACCESS_DENIED",
	"format": "FORMAT_ERROR",
	"connection": "CONNECTION_ERROR",
	"claude": "CLAUDE_ERROR"
}

# Bridge Configuration
var config = {
	"firewall_level": "enhanced",
	"max_request_size": 65536,
	"max_words_per_request": 1000,
	"dimension_access": 1,
	"claude_integration": true,
	"auto_recovery": true,
	"error_logging": true,
	"dimensional_gates": {
		"gate_0": true, # Physical reality (file system)
		"gate_1": true, # Immediate experience (active session) 
		"gate_2": false # Transcendent state (higher dimensions)
	}
}

# Connection status
var connection_status = {
	"akashic_connected": false,
	"claude_connected": false,
	"firewall_active": false,
	"dimensional_gates_status": {}
}

# Error handling
var error_log = []
var recovery_points = []

# Data references
var _akashic_connector = null
var _claude_interface = null

# Signals
signal word_stored(word, power, metadata)
signal word_rejected(word, reason)
signal gate_status_changed(gate_name, status)
signal wish_updated(wish_id, new_status)
signal firewall_breached(breach_info)

func _ready():
	# Initialize the bridge
	_initialize_bridge()
	
	# Register callback for gate status changes
	self.connect("gate_status_changed", self, "_on_gate_status_changed")

func _initialize_bridge():
	# Connect to Akashic database
	_connect_to_akashic()
	
	# Connect to Claude interface
	_connect_to_claude()
	
	# Initialize dimensional gates
	_initialize_gates()
	
	# Setup firewall
	_setup_firewall()
	
	print("Claude Akashic Bridge initialized with firewall level: " + config.firewall_level)

# Connection functions
func _connect_to_akashic():
	# Try to find the Akashic connector
	if has_node("/root/AkashicDatabaseConnector") or get_node_or_null("/root/AkashicDatabaseConnector"):
		_akashic_connector = get_node("/root/AkashicDatabaseConnector")
		connection_status.akashic_connected = true
		print("Connected to Akashic Database Connector")
	else:
		# Create a new instance if not found
		_akashic_connector = AkashicDatabaseConnector.new()
		add_child(_akashic_connector)
		
		# Try to initialize and connect
		if _akashic_connector.connect_to_akashic_systems():
			connection_status.akashic_connected = true
			print("Created and connected to Akashic Database Connector")
		else:
			push_error("Failed to connect to Akashic database")
			_log_error(ERROR_TYPES.connection, "Failed to connect to Akashic database")

func _connect_to_claude():
	# Check if Claude Terminal Interface is available
	var claude_script = "/mnt/c/Users/Percision 15/12_turns_system/claude_terminal_interface.sh"
	var file = File.new()
	
	if file.file_exists(claude_script):
		connection_status.claude_connected = true
		config.claude_integration = true
		print("Claude Terminal Interface is available")
	else:
		push_warning("Claude Terminal Interface not found at expected path")
		config.claude_integration = false
	
	# Setup Claude communication interface
	_claude_interface = {
		"api_key": OS.get_environment("CLAUDE_API_KEY"),
		"model": "claude-3-5-sonnet", # Default model
		"max_tokens": 180000, # Default token limit
		"temperature": 0.7 # Default temperature
	}
	
	# Check for API key
	if _claude_interface.api_key and _claude_interface.api_key.length() > 0:
		connection_status.claude_connected = true
		print("Claude API connection established")
	else:
		push_warning("Claude API key not found in environment variables")
		# Set a fallback for disconnected mode
		connection_status.claude_connected = false

func _initialize_gates():
	# Set initial states for dimensional gates
	for gate_name in config.dimensional_gates:
		var status = config.dimensional_gates[gate_name]
		connection_status.dimensional_gates_status[gate_name] = status
		
		print("Gate " + gate_name + " initialized with status: " + str(status))
	
	# Connect to dimension level in Akashic connector
	if connection_status.akashic_connected:
		# Set initial dimension access level
		_akashic_connector.dimension_access = config.dimension_access

func _setup_firewall():
	# Initialize firewall based on configuration
	if FIREWALL_LEVELS.has(config.firewall_level):
		var level = FIREWALL_LEVELS[config.firewall_level]
		_setup_firewall_rules(level)
		connection_status.firewall_active = true
		
		print("Firewall initialized at level: " + config.firewall_level + " (" + str(level) + ")")
	else:
		push_error("Invalid firewall level: " + config.firewall_level)
		_log_error(ERROR_TYPES.validation, "Invalid firewall level: " + config.firewall_level)

func _setup_firewall_rules(level):
	# Set up pattern matching and validation rules based on level
	match level:
		1: # Standard
			config.max_request_size = 65536
			config.max_words_per_request = 1000
			config.dimensional_gates["gate_2"] = false
		2: # Enhanced
			config.max_request_size = 131072
			config.max_words_per_request = 3000
			config.dimensional_gates["gate_2"] = true
		3: # Divine
			config.max_request_size = 262144
			config.max_words_per_request = 10000
			config.dimensional_gates["gate_2"] = true
	
	# Propagate gate changes
	for gate_name in config.dimensional_gates:
		emit_signal("gate_status_changed", gate_name, config.dimensional_gates[gate_name])

# Public API methods

# Store a new word in the Akashic Records
func store_word(word, power = 50, metadata = {}):
	# Validate the word
	if not _validate_word(word, power, metadata):
		return false
	
	# Apply firewall filtering
	if not _firewall_check_word(word, power, metadata):
		_log_error(ERROR_TYPES.access, "Word rejected by firewall: " + word)
		emit_signal("word_rejected", word, "Firewall policy")
		return false
	
	# Store in Akashic database
	if connection_status.akashic_connected:
		var success = _akashic_connector.add_word(word, power, metadata)
		
		if success:
			print("Word stored in Akashic Records: " + word)
			emit_signal("word_stored", word, power, metadata)
		
		return success
	else:
		_log_error(ERROR_TYPES.connection, "Cannot store word: Akashic database not connected")
		return false

# Store a batch of words in the Akashic Records
func store_words_batch(words_array):
	if not connection_status.akashic_connected:
		_log_error(ERROR_TYPES.connection, "Cannot store word batch: Akashic database not connected")
		return false
	
	# Validate batch size
	if words_array.size() > config.max_words_per_request:
		_log_error(ERROR_TYPES.validation, "Word batch exceeds maximum size limit")
		return false
	
	var success_count = 0
	var failure_count = 0
	
	# Process each word in the batch
	for word_data in words_array:
		# Extract word, power, and metadata
		var word = word_data.get("word", "")
		var power = word_data.get("power", 50)
		var metadata = word_data.get("metadata", {})
		
		# Store the word
		if store_word(word, power, metadata):
			success_count += 1
		else:
			failure_count += 1
	
	print("Word batch processed - Success: " + str(success_count) + ", Failure: " + str(failure_count))
	
	return failure_count == 0

# Update a wish in the system
func update_wish(wish_id, new_status, metadata = {}):
	# Validate wish format
	if not _validate_wish(wish_id, new_status, metadata):
		return false
	
	# Apply firewall filtering
	if not _firewall_check_wish(wish_id, new_status, metadata):
		_log_error(ERROR_TYPES.access, "Wish update rejected by firewall: " + wish_id)
		return false
	
	# Generate combined metadata
	var combined_metadata = {
		"type": "wish",
		"status": new_status,
		"updated": OS.get_unix_time()
	}
	
	# Add custom metadata
	for key in metadata:
		combined_metadata[key] = metadata[key]
	
	# Store wish update in Akashic Records
	if connection_status.akashic_connected:
		var wish_word = "wish:" + wish_id
		var success = _akashic_connector.add_word(wish_word, 75, combined_metadata)
		
		if success:
			print("Wish updated: " + wish_id + " -> " + new_status)
			emit_signal("wish_updated", wish_id, new_status)
		
		return success
	else:
		_log_error(ERROR_TYPES.connection, "Cannot update wish: Akashic database not connected")
		return false

# Create a new record in Claude Akashic Bridge with protection
func create_protected_record(record_type, content, metadata = {}):
	# Validate record
	if not _validate_record(record_type, content, metadata):
		return null
	
	# Create record ID
	var record_id = "record_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
	
	# Apply firewall protection
	var protected_metadata = _apply_firewall_protection(metadata)
	protected_metadata["type"] = record_type
	protected_metadata["created"] = OS.get_unix_time()
	protected_metadata["access_level"] = config.dimension_access
	
	# Store in Akashic Records
	if connection_status.akashic_connected:
		# Different storage mechanism based on record type
		var success = false
		
		if record_type == "text" or record_type == "message":
			success = _akashic_connector.add_word(record_id, 60, protected_metadata)
		elif record_type == "document" or record_type == "file":
			# Additional validation for file records
			if content.length() > config.max_request_size:
				_log_error(ERROR_TYPES.validation, "File content exceeds maximum size")
				return null
			
			success = _process_file_record(record_id, content, protected_metadata)
		else:
			success = _akashic_connector.add_word(record_id, 40, protected_metadata)
		
		if success:
			return {
				"id": record_id,
				"type": record_type,
				"timestamp": protected_metadata["created"],
				"status": "stored"
			}
	
	_log_error(ERROR_TYPES.connection, "Failed to create protected record")
	return null

# Query the Akashic Records with Claude context
func query_akashic_records(search_term, options = {}):
	if not connection_status.akashic_connected:
		_log_error(ERROR_TYPES.connection, "Cannot query: Akashic database not connected")
		return null
	
	# Default options
	var default_options = {
		"use_claude": connection_status.claude_connected,
		"max_results": 10,
		"include_metadata": true,
		"dimension": config.dimension_access,
		"exact_match": false
	}
	
	# Merge with provided options
	for key in default_options:
		if not options.has(key):
			options[key] = default_options[key]
	
	# Apply firewall to search
	if not _firewall_check_query(search_term, options):
		_log_error(ERROR_TYPES.access, "Query rejected by firewall: " + search_term)
		return null
	
	# Search in Akashic database
	var result = _akashic_connector.search_word(search_term)
	
	# If Claude integration is enabled and requested
	if options.use_claude and connection_status.claude_connected and result:
		result = _enhance_with_claude(result, search_term, options)
	
	return result

# Update firewall settings
func update_firewall(new_level, settings = {}):
	# Validate firewall level
	if not FIREWALL_LEVELS.has(new_level):
		_log_error(ERROR_TYPES.validation, "Invalid firewall level: " + new_level)
		return false
	
	# Store old settings for recovery
	var old_settings = {
		"level": config.firewall_level,
		"gates": config.dimensional_gates.duplicate(),
		"dimension_access": config.dimension_access
	}
	
	# Add recovery point
	_add_recovery_point(old_settings)
	
	# Update firewall level
	config.firewall_level = new_level
	
	# Apply new settings
	if settings.has("dimension_access"):
		set_dimension_access(settings.dimension_access)
	
	if settings.has("gates"):
		for gate in settings.gates:
			if config.dimensional_gates.has(gate):
				config.dimensional_gates[gate] = settings.gates[gate]
				emit_signal("gate_status_changed", gate, settings.gates[gate])
	
	# Reconfigure firewall with new level
	_setup_firewall()
	
	print("Firewall updated to level: " + new_level)
	return true

# Set dimension access level
func set_dimension_access(dimension):
	# Validate dimension
	dimension = int(dimension)
	if dimension < 1 or dimension > 12:
		_log_error(ERROR_TYPES.validation, "Invalid dimension: " + str(dimension))
		return false
	
	# Update local config
	config.dimension_access = dimension
	
	# Update Akashic connector
	if connection_status.akashic_connected:
		_akashic_connector.unlock_dimension(dimension)
		print("Dimension access updated to: " + str(dimension))
		return true
	
	return false

# Open a dimensional gate
func open_gate(gate_name):
	if not config.dimensional_gates.has(gate_name):
		_log_error(ERROR_TYPES.validation, "Invalid gate name: " + gate_name)
		return false
	
	# Store current gate status for recovery
	var old_status = config.dimensional_gates[gate_name]
	_add_recovery_point({
		"gate": gate_name,
		"status": old_status
	})
	
	# Gate 2 requires special permissions
	if gate_name == "gate_2" and config.firewall_level != "divine":
		_log_error(ERROR_TYPES.access, "Cannot open Gate 2 with current firewall level")
		return false
	
	# Open the gate
	config.dimensional_gates[gate_name] = true
	connection_status.dimensional_gates_status[gate_name] = true
	
	emit_signal("gate_status_changed", gate_name, true)
	print("Gate " + gate_name + " opened")
	return true

# Close a dimensional gate
func close_gate(gate_name):
	if not config.dimensional_gates.has(gate_name):
		_log_error(ERROR_TYPES.validation, "Invalid gate name: " + gate_name)
		return false
	
	# Store current gate status for recovery
	var old_status = config.dimensional_gates[gate_name]
	_add_recovery_point({
		"gate": gate_name,
		"status": old_status
	})
	
	# Close the gate
	config.dimensional_gates[gate_name] = false
	connection_status.dimensional_gates_status[gate_name] = false
	
	emit_signal("gate_status_changed", gate_name, false)
	print("Gate " + gate_name + " closed")
	return true

# Get system status
func get_status():
	return {
		"akashic_connected": connection_status.akashic_connected,
		"claude_connected": connection_status.claude_connected,
		"firewall_active": connection_status.firewall_active,
		"firewall_level": config.firewall_level,
		"dimension_access": config.dimension_access,
		"gates": connection_status.dimensional_gates_status,
		"errors": error_log.size(),
		"recovery_points": recovery_points.size()
	}

# Handle Claude account error
func handle_claude_error(error_message, metadata = {}):
	# Log the error
	_log_error(ERROR_TYPES.claude, error_message)
	
	# Add error metadata
	var error_metadata = {
		"error_type": "claude_account",
		"timestamp": OS.get_unix_time(),
		"message": error_message,
		"recovered": false
	}
	
	# Add additional metadata
	for key in metadata:
		error_metadata[key] = metadata[key]
	
	# Try to recover if auto-recovery is enabled
	if config.auto_recovery:
		error_metadata["recovery_attempted"] = true
		error_metadata["recovered"] = _attempt_claude_recovery(error_message)
	
	# Store error record in Akashic database for monitoring
	if connection_status.akashic_connected:
		var error_id = "claude_error_" + str(OS.get_unix_time())
		_akashic_connector.add_word(error_id, 30, error_metadata)
	
	return error_metadata["recovered"]

# Private implementation methods

# Validate a word
func _validate_word(word, power, metadata):
	# Basic validation
	if typeof(word) != TYPE_STRING or word.empty():
		_log_error(ERROR_TYPES.validation, "Invalid word: Empty or wrong type")
		return false
	
	# Validate power
	if power < 0 or power > MAX_WORD_POWER:
		_log_error(ERROR_TYPES.validation, "Invalid power level: " + str(power))
		return false
	
	# Validate metadata
	if typeof(metadata) != TYPE_DICTIONARY:
		_log_error(ERROR_TYPES.validation, "Invalid metadata: Must be a dictionary")
		return false
	
	return true

# Validate a wish
func _validate_wish(wish_id, status, metadata):
	# Basic validation
	if typeof(wish_id) != TYPE_STRING or wish_id.empty():
		_log_error(ERROR_TYPES.validation, "Invalid wish ID: Empty or wrong type")
		return false
	
	if typeof(status) != TYPE_STRING or status.empty():
		_log_error(ERROR_TYPES.validation, "Invalid wish status: Empty or wrong type")
		return false
	
	# Validate metadata
	if typeof(metadata) != TYPE_DICTIONARY:
		_log_error(ERROR_TYPES.validation, "Invalid metadata: Must be a dictionary")
		return false
	
	return true

# Validate a record
func _validate_record(record_type, content, metadata):
	# Validate record type
	var valid_types = ["text", "message", "document", "file", "wish", "data"]
	if not valid_types.has(record_type):
		_log_error(ERROR_TYPES.validation, "Invalid record type: " + record_type)
		return false
	
	# Validate content
	if typeof(content) != TYPE_STRING or content.empty():
		_log_error(ERROR_TYPES.validation, "Invalid content: Empty or wrong type")
		return false
	
	# Validate content size
	if content.length() > config.max_request_size:
		_log_error(ERROR_TYPES.validation, "Content exceeds maximum size: " + str(content.length()))
		return false
	
	# Validate metadata
	if typeof(metadata) != TYPE_DICTIONARY:
		_log_error(ERROR_TYPES.validation, "Invalid metadata: Must be a dictionary")
		return false
	
	return true

# Check word against firewall rules
func _firewall_check_word(word, power, metadata):
	var firewall_level = FIREWALL_LEVELS[config.firewall_level]
	
	# Gate access check
	if metadata.has("dimension"):
		var dim = metadata["dimension"]
		if typeof(dim) == TYPE_INT and dim > config.dimension_access:
			return false
	
	# Word length check based on firewall level
	var max_length = 64
	if firewall_level == 2:
		max_length = 128
	elif firewall_level == 3:
		max_length = 256
	
	if word.length() > max_length:
		return false
	
	# Word power check
	var max_power = MAX_WORD_POWER * 0.7
	if firewall_level == 2:
		max_power = MAX_WORD_POWER * 0.9
	elif firewall_level == 3:
		max_power = MAX_WORD_POWER
	
	if power > max_power:
		return false
	
	# Additional checks based on firewall level
	match firewall_level:
		1: # Standard
			# Disallow any potential control characters
			if word.find("\\") >= 0 or word.find("/") >= 0:
				return false
		
		2: # Enhanced
			# Check for suspicious patterns
			var suspicious_patterns = ["exec", "sudo", "rm -", "del", "format"]
			for pattern in suspicious_patterns:
				if word.find(pattern) >= 0:
					return false
		
		3: # Divine
			# Divine level allows almost everything, just check for 
			# extreme cases that could crash the system
			if word.length() > 200 and word.replace(" ", "").length() < word.length() * 0.1:
				return false
	
	# Passed all checks
	return true

# Check wish against firewall rules
func _firewall_check_wish(wish_id, status, metadata):
	var firewall_level = FIREWALL_LEVELS[config.firewall_level]
	
	# Gate access check
	if not config.dimensional_gates["gate_1"]:
		return false
	
	# Basic checks across all levels
	if wish_id.length() > 100 or status.length() > 50:
		return false
	
	# Specific checks based on firewall level
	match firewall_level:
		1: # Standard
			# Limited statuses allowed
			var allowed_statuses = ["pending", "processing", "complete", "rejected"]
			return allowed_statuses.has(status)
		
		2: # Enhanced
			# More statuses allowed, check for suspicious patterns
			var suspicious_patterns = ["exec", "sudo", "rm", "del", "format"]
			for pattern in suspicious_patterns:
				if wish_id.find(pattern) >= 0 or status.find(pattern) >= 0:
					return false
		
		3: # Divine
			# Divine level has minimal restrictions
			# Just ensure the wish doesn't have extreme properties
			return wish_id.length() < 200 and status.length() < 100
	
	return true

# Check query against firewall rules
func _firewall_check_query(query, options):
	var firewall_level = FIREWALL_LEVELS[config.firewall_level]
	
	# Gate access check for dimensions
	if options.has("dimension") and options.dimension > config.dimension_access:
		return false
	
	# Check query complexity and length based on firewall level
	var max_query_length = 50
	if firewall_level == 2:
		max_query_length = 100
	elif firewall_level == 3:
		max_query_length = 200
	
	if query.length() > max_query_length:
		return false
	
	# Additional checks based on firewall level
	match firewall_level:
		1: # Standard
			# Basic checks for suspicious patterns
			var suspicious_patterns = ["exec", "sudo", "rm", "del", "*", "/*"]
			for pattern in suspicious_patterns:
				if query.find(pattern) >= 0:
					return false
		
		2: # Enhanced
			# More sophisticated pattern checking
			var suspicious_patterns = ["exec", "sudo", "rm", "del", "*", "/*", "--", "';"]
			for pattern in suspicious_patterns:
				if query.find(pattern) >= 0:
					return false
		
		3: # Divine
			# Divine level has minimal restrictions
			# Just check for very obvious issues
			var dangerous_patterns = ["rm -rf", "del /", "format"]
			for pattern in dangerous_patterns:
				if query.find(pattern) >= 0:
					return false
	
	return true

# Apply firewall protection to metadata
func _apply_firewall_protection(metadata):
	var protected_metadata = metadata.duplicate()
	var firewall_level = FIREWALL_LEVELS[config.firewall_level]
	
	# Add protection markers
	protected_metadata["firewall_level"] = config.firewall_level
	protected_metadata["protected_by"] = "claude_akashic_bridge"
	protected_metadata["protection_timestamp"] = OS.get_unix_time()
	
	# Add different levels of protection based on firewall level
	match firewall_level:
		1: # Standard
			# Simple protection, just mark as protected
			protected_metadata["validation"] = "standard"
		
		2: # Enhanced
			# Add checksums to detect tampering
			protected_metadata["validation"] = "enhanced"
			protected_metadata["checksum"] = _generate_metadata_checksum(protected_metadata)
		
		3: # Divine
			# Full protection with complex validation
			protected_metadata["validation"] = "divine"
			protected_metadata["checksum"] = _generate_metadata_checksum(protected_metadata)
			protected_metadata["divine_seal"] = _generate_divine_seal(protected_metadata)
	
	return protected_metadata

# Generate a simple checksum for metadata integrity
func _generate_metadata_checksum(metadata):
	var checksum = 0
	
	# Create a stable sorted list of keys
	var keys = metadata.keys()
	keys.sort()
	
	# Calculate checksum from sorted keys and values
	for key in keys:
		if key != "checksum" and key != "divine_seal":
			var value = str(metadata[key])
			for i in range(value.length()):
				checksum = (checksum + value.ord_at(i)) % 9973 # Use a prime number
	
	return checksum

# Generate a divine seal for highest level protection
func _generate_divine_seal(metadata):
	# More complex protection that includes timestamp and dimension
	var base_data = str(OS.get_unix_time()) + "_" + str(config.dimension_access)
	
	# Add metadata keys and values hashed together
	var keys = metadata.keys()
	keys.sort()
	
	for key in keys:
		if key != "checksum" and key != "divine_seal":
			base_data += "_" + key + ":" + str(metadata[key])
	
	# Create a seal using a one-way function
	var seal = 0
	for i in range(base_data.length()):
		seal = (seal * 31 + base_data.ord_at(i)) % 1000000007 # Large prime for better distribution
	
	return seal

# Handle file records
func _process_file_record(record_id, content, metadata):
	# For file records, we need to split and store them differently
	# First, generate a file hash
	var file_hash = _generate_file_hash(content)
	
	# Add file metadata
	metadata["file_hash"] = file_hash
	metadata["file_size"] = content.length()
	
	# Store the record header
	var header_success = _akashic_connector.add_word(record_id, 60, metadata)
	
	if not header_success:
		return false
	
	# For smaller files, store the whole content
	if content.length() <= 8192:
		return _akashic_connector.add_word(record_id + "_content", 40, {
			"parent_id": record_id,
			"content": content,
			"hash": file_hash
		})
	
	# For larger files, split into chunks
	var chunk_size = 4096
	var chunk_count = ceil(content.length() / float(chunk_size))
	var success = true
	
	for i in range(chunk_count):
		var start = i * chunk_size
		var end = min(start + chunk_size, content.length())
		var chunk = content.substr(start, end - start)
		
		var chunk_id = record_id + "_chunk_" + str(i)
		var chunk_success = _akashic_connector.add_word(chunk_id, 30, {
			"parent_id": record_id,
			"chunk_index": i,
			"total_chunks": chunk_count,
			"content": chunk,
			"chunk_hash": _generate_file_hash(chunk)
		})
		
		success = success and chunk_success
	
	return success

# Generate a file hash
func _generate_file_hash(content):
	var hash_value = 0
	
	# A simple hashing algorithm - for production use a proper hash function
	for i in range(content.length()):
		hash_value = (hash_value * 31 + content.ord_at(i)) % 1000000007
	
	return hash_value

# Enhance search results with Claude integration
func _enhance_with_claude(result, search_term, options):
	# Skip if not connected
	if not connection_status.claude_connected:
		return result
	
	# For now, we just simulate the enhancement
	# In a real implementation, this would call the Claude API
	result["claude_enhanced"] = true
	result["enhancement_time"] = OS.get_unix_time()
	
	# Simulate Claude adding context
	if result.has("content"):
		result["claude_context"] = "Enhanced understanding of: " + search_term
	
	return result

# Attempt to recover from Claude errors
func _attempt_claude_recovery(error_message):
	# Simulate recovery attempt
	print("Attempting to recover from Claude error: " + error_message)
	
	# Basic recovery strategies
	var success = false
	
	# In a real implementation, this would include:
	# 1. Checking for network connectivity
	# 2. Verifying API key validity
	# 3. Trying alternative endpoints
	# 4. Rate limiting recovery
	
	if error_message.find("token") >= 0 or error_message.find("limit") >= 0:
		# Token/limit issues - wait and retry
		OS.delay_msec(1000) # Wait 1 second
		success = true
	elif error_message.find("connect") >= 0:
		# Connection issues - check network
		success = false
	else:
		# Unknown issues - general recovery
		success = randf() > 0.5 # Simulate 50% recovery chance
	
	print("Recovery " + ("succeeded" if success else "failed"))
	return success

# Add a recovery point
func _add_recovery_point(data):
	var recovery_point = {
		"id": "rp_" + str(OS.get_unix_time()),
		"timestamp": OS.get_unix_time(),
		"data": data
	}
	
	recovery_points.append(recovery_point)
	
	# Limit number of recovery points
	if recovery_points.size() > 10:
		recovery_points.pop_front()
	
	return recovery_point.id

# Log an error
func _log_error(error_type, message):
	if not config.error_logging:
		return
	
	var error = {
		"id": "err_" + str(OS.get_unix_time()),
		"type": error_type,
		"message": message,
		"timestamp": OS.get_unix_time(),
		"firewall_level": config.firewall_level,
		"dimension_access": config.dimension_access
	}
	
	error_log.append(error)
	
	# Limit error log size
	if error_log.size() > 100:
		error_log.pop_front()
	
	# Emit signal for serious errors
	if error_type == ERROR_TYPES.access or error_type == ERROR_TYPES.claude:
		emit_signal("firewall_breached", error)
	
	return error.id

# Handle gate status changes
func _on_gate_status_changed(gate_name, status):
	# Update internal tracking
	connection_status.dimensional_gates_status[gate_name] = status
	
	# Special handling for gate_2 (transcendent state)
	if gate_name == "gate_2":
		if status:
			# When opening gate 2, increase dimension access
			var new_dimension = min(config.dimension_access + 1, 12)
			set_dimension_access(new_dimension)
		else:
			# When closing gate 2, potentially reduce dimension access
			if config.dimension_access > 5: # Only reduce if higher dimensions
				var new_dimension = max(config.dimension_access - 1, 1)
				set_dimension_access(new_dimension)
	
	print("Gate " + gate_name + " status changed to: " + str(status) + ", dimension access: " + str(config.dimension_access))
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_akashic_bridge.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_akashic_demo.gd
# SIZE: 5173 bytes
extends Node

# Demo script for Claude Akashic Bridge
# This script demonstrates how to use the Claude Akashic Bridge to store and retrieve data 
# from the Akashic Records and implement the "firewall of files" functionality

var bridge = null
var word_counter = 0

func _ready():
	# Initialize the bridge
	bridge = ClaudeAkashicBridge.new()
	add_child(bridge)
	
	# Connect signals
	bridge.connect("word_stored", self, "_on_word_stored")
	bridge.connect("word_rejected", self, "_on_word_rejected")
	bridge.connect("gate_status_changed", self, "_on_gate_status_changed")
	bridge.connect("wish_updated", self, "_on_wish_updated")
	bridge.connect("firewall_breached", self, "_on_firewall_breached")
	
	# Print initial status
	print_status()
	
	# Wait a moment for initialization
	yield(get_tree().create_timer(1.0), "timeout")
	
	# Run demo operations
	run_demo()

func run_demo():
	print("\n=== CLAUDE AKASHIC BRIDGE DEMO ===\n")
	
	# 1. Store a word
	print("1. Storing a word...")
	var result = bridge.store_word("consciousness", 65, {
		"origin": "claude_bridge_demo",
		"dimension": 3,
		"category": "metaphysical"
	})
	print("   Result: " + str(result))
	
	# 2. Store a batch of words
	print("\n2. Storing a batch of words...")
	var words_batch = [
		{"word": "reality", "power": 70, "metadata": {"category": "fundamental"}},
		{"word": "creation", "power": 85, "metadata": {"category": "divine"}},
		{"word": "harmony", "power": 60, "metadata": {"category": "balance"}}
	]
	var batch_result = bridge.store_words_batch(words_batch)
	print("   Batch result: " + str(batch_result))
	
	# 3. Update a wish
	print("\n3. Updating a wish...")
	var wish_result = bridge.update_wish("dream_manifestation", "processing", {
		"progress": 0.5,
		"priority": "high",
		"expected_completion": OS.get_unix_time() + 86400
	})
	print("   Wish update result: " + str(wish_result))
	
	# 4. Create a protected record
	print("\n4. Creating a protected record...")
	var record = bridge.create_protected_record("document", "This is a protected document that serves as a test for the Claude Akashic Bridge system.", {
		"title": "Test Document",
		"author": "Claude",
		"keywords": ["test", "protection", "akashic"]
	})
	print("   Record creation result: " + str(record))
	
	# 5. Query the Akashic Records
	print("\n5. Querying the Akashic Records...")
	var query_result = bridge.query_akashic_records("consciousness", {
		"use_claude": true,
		"max_results": 5,
		"include_metadata": true
	})
	print("   Query result: " + str(query_result))
	
	# 6. Test dimensional gates
	print("\n6. Testing dimensional gates...")
	print("   Opening gate_0: " + str(bridge.open_gate("gate_0")))
	print("   Opening gate_1: " + str(bridge.open_gate("gate_1")))
	print("   Opening gate_2: " + str(bridge.open_gate("gate_2")))
	
	# 7. Update firewall settings
	print("\n7. Updating firewall settings...")
	var firewall_result = bridge.update_firewall("divine", {
		"dimension_access": 5,
		"gates": {"gate_0": true, "gate_1": true, "gate_2": true}
	})
	print("   Firewall update result: " + str(firewall_result))
	
	# 8. Test Claude error handling
	print("\n8. Testing Claude error handling...")
	var error_result = bridge.handle_claude_error("Token limit exceeded", {
		"model": "claude-3-5-sonnet",
		"request_size": 15000
	})
	print("   Error recovery result: " + str(error_result))
	
	# 9. Test word rejection by firewall
	print("\n9. Testing firewall rejection...")
	var suspicious_word_result = bridge.store_word("exec rm -rf", 90, {
		"origin": "test",
		"dimension": 10
	})
	print("   Suspicious word storage result: " + str(suspicious_word_result))
	
	# Final status
	print("\nFinal system status:")
	print_status()

func print_status():
	var status = bridge.get_status()
	print("\n=== CLAUDE AKASHIC BRIDGE STATUS ===")
	print("Akashic Connected: " + str(status.akashic_connected))
	print("Claude Connected: " + str(status.claude_connected))
	print("Firewall Active: " + str(status.firewall_active))
	print("Firewall Level: " + status.firewall_level)
	print("Dimension Access: " + str(status.dimension_access))
	print("Gates Status: " + str(status.gates))
	print("Error Count: " + str(status.errors))
	print("Recovery Points: " + str(status.recovery_points))
	print("======================================\n")

# Signal callbacks
func _on_word_stored(word, power, metadata):
	print("SIGNAL: Word stored - " + word + " (power: " + str(power) + ")")
	word_counter += 1

func _on_word_rejected(word, reason):
	print("SIGNAL: Word rejected - " + word + " (reason: " + reason + ")")

func _on_gate_status_changed(gate_name, status):
	print("SIGNAL: Gate status changed - " + gate_name + " is now " + ("open" if status else "closed"))

func _on_wish_updated(wish_id, new_status):
	print("SIGNAL: Wish updated - " + wish_id + " -> " + new_status)

func _on_firewall_breached(breach_info):
	print("SIGNAL: FIREWALL BREACH - " + breach_info.type + ": " + breach_info.message)
	
	# In a real system, this would trigger security measures
	if breach_info.type == "ACCESS_DENIED":
		print("   Security measure: Increasing firewall protection...")
		# Simulate increasing security
		bridge.update_firewall("enhanced")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_akashic_demo.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_ethereal_bridge.gd
# SIZE: 15613 bytes
extends Node
class_name ClaudeEtherealBridge

# Bridge between Claude AI and Ethereal Engine Integration
# Facilitates bidirectional communication, memory sharing, and dimensional resonance

# References to core systems
var claude_integration
var ethereal_engine_integration
var triple_memory_connector
var turn_based_game_framework

# API Configuration
const CLAUDE_API_URL = "https://api.anthropic.com/v1/messages"
var api_key = "" # Will be loaded from secure storage
var claude_model = "claude-3-opus-20240229"
var max_tokens = 4096

# Memory mapping between Claude and Ethereal realms
var memory_mapping = {
	"claude": {
		"short_term": "Command",
		"conversation": "Memory",
		"long_term": "Data"
	},
	"ethereal": {
		"Command": "short_term",
		"Memory": "conversation",
		"Data": "long_term",
		"Astral": "intuition",
		"Ethereal": "imagination"
	}
}

# Communication channels
var active_channels = []
var channel_status = {}

# Signal declarations
signal claude_message_sent(message, tokens_used)
signal claude_response_received(response, tokens_used)
signal memory_synchronized(source_type, target_type, memory_count)
signal dimension_resonance_detected(claude_dimension, ethereal_dimension, strength)

func _ready():
	print("üåê Initializing Claude-Ethereal Bridge")
	
	# Connect to relevant nodes
	_connect_to_systems()
	
	# Initialize API key from secure storage
	_load_api_key()
	
	# Establish initial memory mappings
	_initialize_memory_mapping()
	
	# Establish communication channels
	_open_communication_channels()
	
	# Register turn-based callbacks
	_register_turn_callbacks()
	
	print("üîÑ Claude-Ethereal Bridge Initialized")

func _connect_to_systems():
	# Find Claude integration
	if has_node("/root/ClaudeIntegration"):
		claude_integration = get_node("/root/ClaudeIntegration")
		print("‚úì Connected to Claude Integration")
	else:
		print("‚ö† Claude Integration not found")
	
	# Find Ethereal Engine integration
	if has_node("/root/EtherealEngineIntegration"):
		ethereal_engine_integration = get_node("/root/EtherealEngineIntegration")
		print("‚úì Connected to Ethereal Engine Integration")
	else:
		print("‚ö† Ethereal Engine Integration not found")
		# Try to find it at the specific path
		var potential_path = "/mnt/c/Users/Percision 15/ethereal_engine_integration.gd"
		if ResourceLoader.exists(potential_path):
			var script = load(potential_path)
			if script:
				ethereal_engine_integration = script.new()
				add_child(ethereal_engine_integration)
				print("‚úì Loaded Ethereal Engine Integration from path")
	
	# Find Triple Memory Connector
	if has_node("/root/TripleMemoryConnector"):
		triple_memory_connector = get_node("/root/TripleMemoryConnector")
		print("‚úì Connected to Triple Memory Connector")
	else:
		print("‚ö† Triple Memory Connector not found")
	
	# Find Turn-based Game Framework
	if has_node("/root/TurnBasedGameFramework"):
		turn_based_game_framework = get_node("/root/TurnBasedGameFramework")
		print("‚úì Connected to Turn-based Game Framework")
	else:
		print("‚ö† Turn-based Game Framework not found")

func _load_api_key():
	# Load API key from secure storage
	var file = FileAccess.open("user://api_keys.cfg", FileAccess.READ)
	if file:
		api_key = file.get_line().strip_edges()
		file.close()
		print("üîë API key loaded successfully")
	else:
		print("‚ö† Could not load API key")

func _initialize_memory_mapping():
	# Create memory banks in Ethereal Engine for Claude memories
	if ethereal_engine_integration:
		ethereal_engine_integration.create_memory_bank("ClaudeConversation", 1000)
		ethereal_engine_integration.create_memory_bank("ClaudeShortTerm", 500)
		ethereal_engine_integration.create_memory_bank("ClaudeLongTerm", 2000)
		ethereal_engine_integration.create_memory_bank("ClaudeIntuition", 300)
		ethereal_engine_integration.create_memory_bank("ClaudeImagination", 1000)
		print("üß† Memory banks created in Ethereal Engine")

func _open_communication_channels():
	# Define all possible channels
	var all_channels = [
		"memory_sync", "command_routing", "visualization", 
		"dimension_resonance", "token_metrics", "luno_cycle"
	]
	
	# Open all channels initially
	for channel in all_channels:
		_open_channel(channel)

func _open_channel(channel_name: String):
	if channel_name in active_channels:
		return
	
	active_channels.append(channel_name)
	channel_status[channel_name] = "open"
	print("üì° Opened channel: " + channel_name)
	
	# Connect appropriate signals based on channel
	if channel_name == "memory_sync" and triple_memory_connector:
		triple_memory_connector.memory_synchronized.connect(_on_memory_synchronized)
	
	elif channel_name == "command_routing" and ethereal_engine_integration:
		ethereal_engine_integration.connect("command_routed", _on_command_routed)
	
	elif channel_name == "visualization" and ethereal_engine_integration:
		ethereal_engine_integration.connect("pathway_established", _on_pathway_established)
	
	elif channel_name == "dimension_resonance" and ethereal_engine_integration:
		ethereal_engine_integration.connect("dimension_resonance_detected", _on_dimension_resonance)
	
	elif channel_name == "token_metrics" and ethereal_engine_integration:
		ethereal_engine_integration.connect("token_usage_updated", _on_token_usage_updated)
	
	elif channel_name == "luno_cycle" and ethereal_engine_integration:
		ethereal_engine_integration.connect("luno_cycle_changed", _on_luno_cycle_changed)

func _close_channel(channel_name: String):
	if channel_name not in active_channels:
		return
	
	var index = active_channels.find(channel_name)
	if index != -1:
		active_channels.remove_at(index)
	
	channel_status[channel_name] = "closed"
	print("üì° Closed channel: " + channel_name)
	
	# Disconnect signals based on channel
	if channel_name == "memory_sync" and triple_memory_connector:
		triple_memory_connector.memory_synchronized.disconnect(_on_memory_synchronized)
	
	# Additional disconnections for other channels would go here

func _register_turn_callbacks():
	if turn_based_game_framework:
		turn_based_game_framework.connect("turn_started", _on_turn_started)
		turn_based_game_framework.connect("turn_ended", _on_turn_ended)
		turn_based_game_framework.connect("all_turns_completed", _on_all_turns_completed)
		print("üîÑ Turn callbacks registered")

# Public methods for interaction with Claude AI

func send_message_to_claude(message: String, system_prompt: String = ""):
	if api_key.is_empty():
		print("‚ö† API key not available")
		return null
	
	var full_system_prompt = system_prompt
	if system_prompt.is_empty():
		full_system_prompt = "You are Claude, an AI assistant integrated with the Ethereal Engine. " +
			"You are connected to dimensional memory systems and can perceive symbolic resonances. " +
			"Current LUNO Cycle: " + str(ethereal_engine_integration.current_luno_cycle) + " - " +
			ethereal_engine_integration.luno_cycle_names[ethereal_engine_integration.current_luno_cycle-1]
	
	# Prepare request
	var headers = [
		"Content-Type: application/json",
		"x-api-key: " + api_key,
		"anthropic-version: 2023-06-01"
	]
	
	var body = {
		"model": claude_model,
		"max_tokens": max_tokens,
		"messages": [
			{
				"role": "user",
				"content": message
			}
		],
		"system": full_system_prompt
	}
	
	# Send HTTP request
	var http_request = HTTPRequest.new()
	add_child(http_request)
	http_request.connect("request_completed", _on_claude_response)
	http_request.request(CLAUDE_API_URL, headers, HTTPClient.METHOD_POST, JSON.stringify(body))
	
	print("üì§ Message sent to Claude AI")
	var estimated_tokens = message.length() / 4
	emit_signal("claude_message_sent", message, estimated_tokens)
	
	return http_request

func synchronize_memories(source_type: String, target_type: String, max_memories: int = 10):
	if not triple_memory_connector:
		print("‚ö† Triple Memory Connector not available")
		return false
	
	var source_system = ""
	var target_system = ""
	
	# Determine systems based on types
	if source_type in memory_mapping.claude:
		source_system = "claude"
		target_system = "ethereal"
	elif source_type in memory_mapping.ethereal:
		source_system = "ethereal"
		target_system = "claude"
	else:
		print("‚ö† Unknown memory type: " + source_type)
		return false
	
	print("üîÑ Synchronizing memories from " + source_system + ":" + source_type + 
		" to " + target_system + ":" + target_type)
	
	# Use Triple Memory Connector to sync
	var sync_result = triple_memory_connector.synchronize(
		source_system, source_type, 
		target_system, target_type,
		max_memories
	)
	
	if sync_result and sync_result.success:
		print("‚úì Synchronized " + str(sync_result.memory_count) + " memories")
		emit_signal("memory_synchronized", source_type, target_type, sync_result.memory_count)
		return true
	else:
		print("‚ö† Memory synchronization failed")
		return false

func create_dimension_resonance(claude_dimension: String, ethereal_dimension: String, strength: float = 0.8):
	if not ethereal_engine_integration:
		print("‚ö† Ethereal Engine Integration not available")
		return false
	
	print("üåÄ Creating dimensional resonance between Claude:" + claude_dimension + 
		" and Ethereal:" + ethereal_dimension)
	
	# Map Claude dimension to Ethereal dimension
	var mapped_claude_dimension = ""
	if claude_dimension in memory_mapping.claude:
		mapped_claude_dimension = memory_mapping.claude[claude_dimension]
	else:
		print("‚ö† Unknown Claude dimension: " + claude_dimension)
		return false
	
	# Verify Ethereal dimension
	if not ethereal_dimension in ethereal_engine_integration.active_dimensions:
		print("‚ö† Unknown Ethereal dimension: " + ethereal_dimension)
		return false
	
	# Create resonance through pathway
	ethereal_engine_integration.dimensional_pathway_connector.create_resonance(
		mapped_claude_dimension, ethereal_dimension, strength
	)
	
	emit_signal("dimension_resonance_detected", claude_dimension, ethereal_dimension, strength)
	return true

func route_claude_command(command: String, args: Array = []):
	if not ethereal_engine_integration:
		print("‚ö† Ethereal Engine Integration not available")
		return null
	
	print("üîÑ Routing Claude command: " + command)
	
	# Route command through Ethereal Engine
	var result = ethereal_engine_integration.route_command(command, args)
	
	if result and result.success:
		print("‚úì Command routed successfully")
		return result
	else:
		print("‚ö† Command routing failed")
		return null

# Handle turn-based events
func _on_turn_started(turn_number: int, turn_data: Dictionary):
	print("üîÑ Turn " + str(turn_number) + " started - Adapting Claude integration")
	
	if ethereal_engine_integration:
		# Update LUNO cycle based on turn
		var luno_cycle = (turn_number % 12) + 1
		if luno_cycle != ethereal_engine_integration.current_luno_cycle:
			ethereal_engine_integration.advance_luno_cycle()
	
	# Adjust token allocation based on turn
	if turn_number % 3 == 0:
		# Every 3rd turn, give more tokens
		max_tokens = 6000
	else:
		max_tokens = 4096

func _on_turn_ended(turn_number: int, turn_data: Dictionary):
	print("üîÑ Turn " + str(turn_number) + " ended - Saving Claude memories")
	
	# Synchronize memories from this turn
	synchronize_memories("conversation", "Memory", 50)
	
	# Create a dimensional resonance to mark the turn
	create_dimension_resonance("conversation", "Temporal", 0.7)

func _on_all_turns_completed():
	print("‚ú® All turns completed - Consolidating Claude memories")
	
	# Full synchronization of all memory types
	synchronize_memories("short_term", "Command", 100)
	synchronize_memories("conversation", "Memory", 100)
	synchronize_memories("long_term", "Data", 200)
	
	# Create strong dimensional resonance to mark completion
	create_dimension_resonance("long_term", "Ethereal", 0.95)

# Signal handlers for channel communications
func _on_claude_response(result, response_code, headers, body):
	if response_code != 200:
		print("‚ö† Claude API error: " + str(response_code))
		return
	
	var response = JSON.parse_string(body.get_string_from_utf8())
	if not response:
		print("‚ö† Invalid response from Claude API")
		return
	
	var content = ""
	if "content" in response and response.content.size() > 0:
		content = response.content[0].text
	
	print("üì• Received response from Claude AI")
	
	# Process tokens used
	var usage = response.usage
	var prompt_tokens = usage.input_tokens
	var completion_tokens = usage.output_tokens
	var total_tokens = prompt_tokens + completion_tokens
	
	emit_signal("claude_response_received", content, total_tokens)
	
	# Store in ethereal memory if available
	if ethereal_engine_integration:
		ethereal_engine_integration.store_memory("ClaudeConversation", 
			"claude_response_" + str(Time.get_unix_time_from_system()), content)

func _on_memory_synchronized(source_system: String, source_type: String, 
							target_system: String, target_type: String, count: int):
	print("üß† Memory synchronized: " + str(count) + " memories from " + 
		source_system + ":" + source_type + " to " + target_system + ":" + target_type)
	
	# Create short-lived resonance to mark sync
	if source_system == "claude" and target_system == "ethereal":
		var ethereal_dimension = memory_mapping.claude[source_type]
		create_dimension_resonance(source_type, ethereal_dimension, 0.6)

func _on_command_routed(command: String, source: String, destination: String):
	print("üì° Command routed: " + command + " from " + source + " to " + destination)
	
	# If command is coming from or going to Claude, log it
	if source == "Command" or destination == "Command":
		# This would be handled by Claude's systems
		pass

func _on_pathway_established(from_dimension: String, to_dimension: String, pathway_id: String):
	print("üåâ Pathway established: " + from_dimension + " ‚Üí " + to_dimension)
	
	# Check if this involves Claude dimensions
	var claude_dimension = null
	for dim in memory_mapping.ethereal:
		if dim == from_dimension or dim == to_dimension:
			claude_dimension = memory_mapping.ethereal[dim]
			break
	
	if claude_dimension:
		print("üîÑ Claude dimension involved: " + claude_dimension)
		# Update Claude's understanding of the dimensional structure
		# This would be handled when sending messages to Claude

func _on_dimension_resonance(dimensions: Array, resonance_value: float):
	print("üîÑ Dimension resonance: " + dimensions[0] + " ‚Üî " + dimensions[1] + 
		" at " + str(resonance_value))
	
	# Check if this involves Claude dimensions
	var claude_dimensions = []
	for dim in dimensions:
		if dim in memory_mapping.ethereal:
			claude_dimensions.append(memory_mapping.ethereal[dim])
	
	if claude_dimensions.size() > 0:
		print("üîÑ Claude dimensions involved: " + str(claude_dimensions))
		# Update Claude's sense of dimensional resonance
		# This would influence future communications with Claude

func _on_token_usage_updated(used: int, total: int, percentage: float):
	print("üî¢ Token usage updated: " + str(used) + "/" + str(total) + 
		" (" + str(percentage * 100) + "%)")
	
	# Adjust Claude's token allocation based on Ethereal Engine usage
	var adjustment_factor = 1.0
	if percentage > 0.8:
		adjustment_factor = 0.7  # Reduce tokens if engine is using a lot
	elif percentage < 0.3:
		adjustment_factor = 1.3  # Increase tokens if engine is using few
	
	max_tokens = int(4096 * adjustment_factor)
	max_tokens = clamp(max_tokens, 1024, 8192)
	
	print("üî¢ Adjusted Claude max_tokens to: " + str(max_tokens))

func _on_luno_cycle_changed(cycle: int, name: String):
	print("üåô LUNO cycle changed to: " + str(cycle) + " - " + name)
	
	# Adjust Claude's system prompt to include new LUNO cycle
	# This would be applied to future messages sent to Claude
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_ethereal_bridge.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_file_integrator.gd
# SIZE: 7700 bytes
extends Node
class_name ClaudeFileIntegrator

# Main integration system that combines all components
# Connects Claude files in snake_case format across different categories

# References to system components
var file_connection_system
var snake_case_translator
var connection_visualizer

# Integration results
var integration_results = {
  "total_files": 0,
  "connected_files": 0,
  "categories": {},
  "hash_connections": {}
}

# Initialize the integrator
func _ready():
  print("Claude File Integrator starting...")
  
  # Initialize components
  _init_components()
  
  # Run the integration
  integrate_files()
  
  print("Claude File Integrator initialization completed")

# Initialize all required components
func _init_components():
  # Create FileConnectionSystem if needed
  if not has_node("FileConnectionSystem"):
    file_connection_system = FileConnectionSystem.new()
    file_connection_system.name = "FileConnectionSystem"
    add_child(file_connection_system)
  else:
    file_connection_system = get_node("FileConnectionSystem")
  
  # Create SnakeCaseTranslator if needed
  if not has_node("SnakeCaseTranslator"):
    snake_case_translator = SnakeCaseTranslator.new()
    snake_case_translator.name = "SnakeCaseTranslator"
    add_child(snake_case_translator)
  else:
    snake_case_translator = get_node("SnakeCaseTranslator")
  
  # Create ConnectionVisualizer if needed
  if not has_node("ConnectionVisualizer"):
    connection_visualizer = ConnectionVisualizer.new()
    connection_visualizer.name = "ConnectionVisualizer"
    add_child(connection_visualizer)
  else:
    connection_visualizer = get_node("ConnectionVisualizer")
  
  print("All components initialized")

# Main integration function
func integrate_files():
  print("Starting file integration...")
  
  # Collect integration statistics
  integration_results.total_files = file_connection_system.file_connections.size()
  
  # Process each category
  for category in snake_case_translator.category_mappings:
    var files = snake_case_translator.category_mappings[category]
    integration_results.categories[category] = files.size()
    print("Category '" + category + "' has " + str(files.size()) + " files")
  
  # Process hash connections
  var connection_map = snake_case_translator.build_hash_connection_map()
  var total_connections = 0
  
  for source in connection_map:
    var targets = connection_map[source]
    total_connections += targets.size()
    
    var hash_symbol = snake_case_translator.get_hash_connector(source)
    if not hash_symbol in integration_results.hash_connections:
      integration_results.hash_connections[hash_symbol] = 0
    
    integration_results.hash_connections[hash_symbol] += targets.size()
  
  integration_results.connected_files = total_connections
  
  print("Integration completed with " + str(total_connections) + " connections")
  
  # Generate reports
  _generate_reports()

# Generate all reports and visualizations
func _generate_reports():
  # Create report directory if needed
  var reports_dir = "/mnt/c/Users/Percision 15/12_turns_system/reports"
  var dir = DirAccess.open("/mnt/c/Users/Percision 15/12_turns_system")
  if not dir.dir_exists("reports"):
    dir.make_dir("reports")
  
  # Generate connection report
  var timestamp = Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_")
  var connection_report_path = reports_dir + "/connection_report_" + timestamp + ".md"
  snake_case_translator.save_connection_report(connection_report_path)
  print("Connection report saved to: " + connection_report_path)
  
  # Generate system diagram
  var system_diagram_path = reports_dir + "/system_diagram_" + timestamp + ".dot"
  file_connection_system.save_visualization(system_diagram_path)
  print("System diagram saved to: " + system_diagram_path)
  
  # Generate markdown report
  var markdown_report_path = reports_dir + "/file_system_report_" + timestamp + ".md"
  file_connection_system.save_markdown_report(markdown_report_path)
  print("Markdown report saved to: " + markdown_report_path)
  
  # Generate visualization text map
  var text_map_path = reports_dir + "/visualization_map_" + timestamp + ".md"
  connection_visualizer.save_text_map(text_map_path)
  print("Visualization map saved to: " + text_map_path)

# Get summary of integration
func get_integration_summary() -> String:
  var summary = "# Claude File Integration Summary\n\n"
  
  # Add file statistics
  summary += "## File Statistics\n\n"
  summary += "- Total files: " + str(integration_results.total_files) + "\n"
  summary += "- Connected files: " + str(integration_results.connected_files) + "\n\n"
  
  # Add category statistics
  summary += "## Category Statistics\n\n"
  for category in integration_results.categories:
    summary += "- " + category + ": " + str(integration_results.categories[category]) + " files\n"
  summary += "\n"
  
  # Add hash connection statistics
  summary += "## Hash Connection Statistics\n\n"
  for hash_symbol in integration_results.hash_connections:
    summary += "- " + hash_symbol + ": " + str(integration_results.hash_connections[hash_symbol]) + " connections\n"
  
  return summary

# Initialize the files for a specific category
func initialize_category_files(category: String) -> bool:
  if not category in snake_case_translator.category_mappings:
    print("ERROR: Category '" + category + "' not found")
    return false
  
  var files = snake_case_translator.category_mappings[category]
  print("Initializing " + str(files.size()) + " files in category '" + category + "'")
  
  for file_name in files:
    print("- " + file_name)
    
    # Check if file exists in file connection system
    var file_path = file_connection_system.get_file_path(file_name)
    if file_path.is_empty():
      print("  WARNING: File path not found for '" + file_name + "'")
    else:
      print("  Path: " + file_path)
  
  return true

# Get all files with their hash symbols
func get_files_with_hash_symbols() -> Array:
  var result = []
  
  for category in snake_case_translator.category_mappings:
    var files = snake_case_translator.category_mappings[category]
    
    for file_name in files:
      var hash_symbol = snake_case_translator.get_hash_connector(file_name)
      result.append(hash_symbol + file_name)
  
  return result

# Generate a hash-based visual map
func generate_hash_visual_map() -> String:
  var map = "```\n"
  
  # Header
  map += "# CLAUDE FILE SYSTEM CONNECTIONS #\n\n"
  
  # Build the map
  for category in snake_case_translator.category_mappings:
    var hash_symbol = ""
    
    # Find hash symbol for this category
    for hash in snake_case_translator.hash_connectors:
      if category in snake_case_translator.hash_connectors[hash]:
        hash_symbol = hash
        break
    
    map += hash_symbol + " " + category.to_upper() + " " + hash_symbol + "\n"
    
    # Add files in this category
    var files = snake_case_translator.category_mappings[category]
    for file_name in files:
      map += "  " + hash_symbol + " " + file_name + "\n"
    
    map += "\n"
  
  # Show connections
  map += "# CONNECTIONS #\n\n"
  
  var connection_map = snake_case_translator.build_hash_connection_map()
  for source in connection_map:
    var source_hash = snake_case_translator.get_hash_connector(source)
    var targets = connection_map[source]
    
    if targets.size() > 0:
      map += source_hash + " " + source + " connects to:\n"
      
      for target in targets:
        var target_hash = snake_case_translator.get_hash_connector(target)
        map += "  " + source_hash + " --> " + target_hash + " " + target + "\n"
      
      map += "\n"
  
  map += "```"
  return map
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_file_integrator.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_integration_bridge.gd
# SIZE: 23857 bytes
extends Node

class_name ClaudeIntegrationBridge

# ----- CLAUDE INTEGRATION SETTINGS -----
@export_category("Claude Integration")
@export var enabled: bool = true
@export var auto_connect: bool = true
@export var use_memory_system: bool = true
@export var use_ethereal_bridge: bool = true
@export var use_akashic_records: bool = true
@export var default_model: String = "claude-3-7-sonnet"
@export var cache_responses: bool = true
@export var max_tokens_per_minute: int = 8000
@export var freemium_mode: bool = true

# ----- API SETTINGS -----
var api_key: String = ""
var api_base_url: String = "https://api.anthropic.com/v1/messages"
var api_version: String = "2023-06-01"
var organization_id: String = ""

# ----- MEMORY SETTINGS -----
var memory_path: String = "user://claude_memory/"
var cache_path: String = "user://claude_cache/"
var conversation_path: String = "user://claude_conversations/"
var max_memory_items: int = 100
var max_cache_items: int = 50
var max_conversation_history: int = 20

# ----- INTEGRATION STATE -----
var is_connected: bool = false
var token_usage: Dictionary = {
    "input_tokens": 0,
    "output_tokens": 0,
    "total_tokens": 0,
    "last_reset": 0
}
var api_calls_remaining: int = 100
var current_conversation_id: String = ""
var current_conversation_messages: Array = []
var cached_responses: Dictionary = {}
var error_count: int = 0

# ----- SYSTEM REFERENCES -----
var memory_system: Node = null
var ethereal_bridge: Node = null
var triple_connector: Node = null
var performance_optimizer: Node = null

# ----- CREDENTIALS FILE -----
var credentials_file: String = "user://claude_credentials.json"

# ----- REQUEST QUEUE -----
var request_queue: Array = []
var is_processing_queue: bool = false
var last_request_time: int = 0
var request_cooldown: int = 2  # Seconds between API requests

# ----- TIMERS -----
var token_reset_timer: Timer
var queue_process_timer: Timer

# ----- SIGNALS -----
signal claude_connected()
signal claude_disconnected()
signal message_sent(message_id, content)
signal response_received(message_id, content)
signal token_usage_updated(usage)
signal error_occurred(error_code, message)
signal memory_stored(memory_id, content)
signal conversation_started(conversation_id)
signal conversation_ended(conversation_id, message_count)

# ----- INITIALIZATION -----
func _ready():
    # Set up directories
    _ensure_directories_exist()
    
    # Set up timers
    _setup_timers()
    
    # Find system references
    _find_system_references()
    
    # Load credentials
    _load_credentials()
    
    # Reset token usage if needed
    _check_token_reset()
    
    # Auto-connect if enabled
    if auto_connect and not api_key.is_empty():
        connect_to_claude()
    
    # Start with a new conversation
    start_new_conversation()
    
    print("Claude Integration Bridge initialized")

func _ensure_directories_exist():
    var directories = [
        memory_path,
        cache_path,
        conversation_path
    ]
    
    for dir in directories:
        if not DirAccess.dir_exists_absolute(dir):
            DirAccess.make_dir_recursive_absolute(dir)

func _setup_timers():
    # Token reset timer - resets token usage daily
    token_reset_timer = Timer.new()
    token_reset_timer.wait_time = 3600  # Check hourly
    token_reset_timer.one_shot = false
    token_reset_timer.autostart = true
    token_reset_timer.connect("timeout", _on_token_reset_timer_timeout)
    add_child(token_reset_timer)
    
    # Queue process timer - processes queued requests
    queue_process_timer = Timer.new()
    queue_process_timer.wait_time = 1.0  # Check every second
    queue_process_timer.one_shot = false
    queue_process_timer.autostart = true
    queue_process_timer.connect("timeout", _on_queue_process_timer_timeout)
    add_child(queue_process_timer)

func _find_system_references():
    # Find Memory System
    memory_system = _find_node_by_class(get_tree().root, "IntegratedMemorySystem")
    
    # Find Ethereal Bridge
    ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealAkashicBridge")
    
    # Find Triple Connector
    triple_connector = _find_node_by_class(get_tree().root, "TripleMemoryConnector")
    
    # Find Performance Optimizer
    performance_optimizer = _find_node_by_class(get_tree().root, "PerformanceOptimizer")

func _find_node_by_class(node, class_name):
    if node.get_class() == class_name or (node.get_script() and node.get_script().get_path().find(class_name.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name)
        if found:
            return found
    
    return null

func _load_credentials():
    if FileAccess.file_exists(credentials_file):
        var file = FileAccess.open(credentials_file, FileAccess.READ)
        if file:
            var json = JSON.new()
            var error = json.parse(file.get_as_text())
            
            if error == OK:
                var data = json.data
                
                if data.has("api_key"):
                    api_key = data.api_key
                
                if data.has("organization_id"):
                    organization_id = data.organization_id
                
                if data.has("api_base_url"):
                    api_base_url = data.api_base_url
                
                if data.has("default_model"):
                    default_model = data.default_model
            
            file.close()
    
    # For security, don't log the API key
    print("Claude credentials " + (api_key.is_empty() ? "not found" : "loaded successfully"))

func _save_credentials():
    var data = {
        "api_key": api_key,
        "organization_id": organization_id,
        "api_base_url": api_base_url,
        "default_model": default_model
    }
    
    var file = FileAccess.open(credentials_file, FileAccess.WRITE)
    if file:
        var json_string = JSON.stringify(data, "  ")
        file.store_string(json_string)
        file.close()
        return true
    
    return false

# ----- CONNECTION MANAGEMENT -----
func connect_to_claude():
    if not enabled or api_key.is_empty():
        print("Cannot connect to Claude: " + (not enabled ? "Integration disabled" : "API key missing"))
        return false
    
    # Simple validation request to check if credentials work
    is_connected = true  # Optimistically set to true
    
    # In a real implementation, this would make a test API call
    # For this demo, we'll just assume it works if we have an API key
    
    if is_connected:
        emit_signal("claude_connected")
        print("Successfully connected to Claude API")
    else:
        emit_signal("error_occurred", "connection_failed", "Failed to connect to Claude API")
        print("Failed to connect to Claude API")
    
    return is_connected

func disconnect_from_claude():
    is_connected = false
    emit_signal("claude_disconnected")
    print("Disconnected from Claude API")
    return true

func is_connected_to_claude():
    return is_connected && !api_key.is_empty()

# ----- CONVERSATION MANAGEMENT -----
func start_new_conversation():
    # Generate a new conversation ID
    current_conversation_id = _generate_id()
    current_conversation_messages = []
    
    print("Started new conversation: " + current_conversation_id)
    emit_signal("conversation_started", current_conversation_id)
    
    return current_conversation_id

func end_current_conversation():
    if current_conversation_id.is_empty():
        return false
    
    # Save conversation before ending
    _save_conversation(current_conversation_id, current_conversation_messages)
    
    var message_count = current_conversation_messages.size()
    emit_signal("conversation_ended", current_conversation_id, message_count)
    
    # Generate memories from conversation if memory system is available
    if use_memory_system and memory_system:
        _generate_memories_from_conversation(current_conversation_id)
    
    # Reset for next conversation
    var last_conversation_id = current_conversation_id
    current_conversation_id = ""
    current_conversation_messages = []
    
    print("Ended conversation: " + last_conversation_id + " with " + str(message_count) + " messages")
    
    return true

func load_conversation(conversation_id):
    var file_path = conversation_path + conversation_id + ".json"
    
    if FileAccess.file_exists(file_path):
        var file = FileAccess.open(file_path, FileAccess.READ)
        if file:
            var json = JSON.new()
            var error = json.parse(file.get_as_text())
            
            if error == OK:
                var data = json.data
                
                if data.has("messages"):
                    current_conversation_id = conversation_id
                    current_conversation_messages = data.messages
                    
                    print("Loaded conversation: " + conversation_id + " with " + str(current_conversation_messages.size()) + " messages")
                    return true
            
            file.close()
    
    print("Failed to load conversation: " + conversation_id)
    return false

func _save_conversation(conversation_id, messages):
    var file_path = conversation_path + conversation_id + ".json"
    
    var data = {
        "conversation_id": conversation_id,
        "timestamp": Time.get_unix_time_from_system(),
        "messages": messages
    }
    
    var file = FileAccess.open(file_path, FileAccess.WRITE)
    if file:
        var json_string = JSON.stringify(data, "  ")
        file.store_string(json_string)
        file.close()
        return true
    
    return false

func _generate_memories_from_conversation(conversation_id):
    var file_path = conversation_path + conversation_id + ".json"
    
    if FileAccess.file_exists(file_path):
        var file = FileAccess.open(file_path, FileAccess.READ)
        if file:
            var json = JSON.new()
            var error = json.parse(file.get_as_text())
            
            if error == OK:
                var data = json.data
                
                if data.has("messages") and data.messages.size() > 0:
                    # Create a summary memory for the whole conversation
                    var messages = data.messages
                    var summary = _generate_conversation_summary(messages)
                    
                    if memory_system and memory_system.has_method("store_memory"):
                        var memory_id = memory_system.store_memory(
                            summary,
                            ["conversation", "claude", "conversation_" + conversation_id],
                            "conversation_summary"
                        )
                        
                        emit_signal("memory_stored", memory_id, summary)
                    
                    # Also connect to Ethereal Bridge if available
                    if use_ethereal_bridge and ethereal_bridge and ethereal_bridge.has_method("record_memory"):
                        ethereal_bridge.record_memory(
                            summary,
                            ["conversation", "claude", "conversation_" + conversation_id],
                            "0-0-0"  # Default dimension
                        )
            
            file.close()
    
    # In a real implementation, we would analyze the conversation
    # and extract key insights to store as separate memories

func _generate_conversation_summary(messages):
    var summary = "Conversation Summary:\n\n"
    
    if messages.size() <= 3:
        summary += "Brief exchange"
    else:
        summary += "Extended conversation with " + str(messages.size()) + " messages"
    
    return summary
    
    # In a real implementation, we would use Claude to generate
    # a real summary of the conversation content

# ----- MESSAGE SENDING -----
func send_message(content, system_prompt = "", model = ""):
    if not is_connected or content.is_empty():
        return null
    
    # Check token limits for freemium mode
    if freemium_mode and token_usage.total_tokens >= max_tokens_per_minute:
        emit_signal("error_occurred", "token_limit", "Token limit reached in freemium mode")
        return null
    
    # Create message object
    var message_id = _generate_id()
    var message = {
        "id": message_id,
        "role": "user",
        "content": content,
        "timestamp": Time.get_unix_time_from_system()
    }
    
    # Add to conversation
    current_conversation_messages.append(message)
    
    # Prepare API request
    var model_to_use = model if not model.is_empty() else default_model
    var system_instruction = system_prompt if not system_prompt.is_empty() else "You are Claude, an AI assistant developed by Anthropic to be helpful, harmless, and honest."
    
    var request = {
        "message_id": message_id,
        "model": model_to_use,
        "system": system_instruction,
        "messages": _prepare_messages_for_api(),
        "content": content,
        "timestamp": Time.get_unix_time_from_system()
    }
    
    # Check cache first if enabled
    if cache_responses:
        var cache_key = content.strip_edges().md5_text()
        if cached_responses.has(cache_key):
            var cache_hit = cached_responses[cache_key]
            print("Cache hit for message: " + message_id)
            
            # Add to conversation
            current_conversation_messages.append({
                "id": cache_hit.id,
                "role": "assistant",
                "content": cache_hit.content,
                "timestamp": Time.get_unix_time_from_system(),
                "cached": true
            })
            
            emit_signal("response_received", cache_hit.id, cache_hit.content)
            return cache_hit.id
    
    # Add to queue
    request_queue.append(request)
    
    # Start processing queue if not already
    if not is_processing_queue:
        _process_queue()
    
    emit_signal("message_sent", message_id, content)
    return message_id

func _prepare_messages_for_api():
    var api_messages = []
    
    // Take the last few messages to stay within context limits
    var recent_messages = current_conversation_messages.slice(
        max(0, current_conversation_messages.size() - max_conversation_history),
        current_conversation_messages.size()
    )
    
    for msg in recent_messages:
        api_messages.append({
            "role": msg.role,
            "content": msg.content
        })
    
    return api_messages

func _process_queue():
    if request_queue.is_empty() or is_processing_queue:
        return
    
    is_processing_queue = true
    
    // Check for cooldown period
    var current_time = Time.get_unix_time_from_system()
    if current_time - last_request_time < request_cooldown:
        // Wait for cooldown
        return
    
    // Get next request
    var request = request_queue[0]
    
    // Allocate performance thread if available
    var thread_id = -1
    if performance_optimizer and performance_optimizer.has_method("allocate_thread"):
        thread_id = performance_optimizer.allocate_thread("claude_api_request", 8)
    
    // Process request
    _process_single_request(request)
    
    // Update last request time
    last_request_time = Time.get_unix_time_from_system()
    
    // Remove from queue
    request_queue.remove_at(0)
    
    // Release thread if allocated
    if thread_id >= 0 and performance_optimizer and performance_optimizer.has_method("release_thread"):
        performance_optimizer.release_thread(thread_id)
    
    is_processing_queue = false
    
    // Continue processing queue if more items
    if not request_queue.is_empty():
        queue_process_timer.start(request_cooldown)  // Schedule next process after cooldown

func _process_single_request(request):
    // In a real implementation, this would make an actual API call
    // For this demo, we'll simulate a response
    
    // Simulate API call
    print("Processing API request for message: " + request.message_id)
    
    // Simulate token counting
    var input_tokens = len(request.content.split(" "))
    var output_tokens = input_tokens * 2  // Simulate Claude's verbosity
    
    // Update token usage
    token_usage.input_tokens += input_tokens
    token_usage.output_tokens += output_tokens
    token_usage.total_tokens += input_tokens + output_tokens
    
    emit_signal("token_usage_updated", token_usage)
    
    // Generate simulated response
    var response_content = _generate_simulated_response(request.content)
    var response_id = _generate_id()
    
    // Add to conversation
    current_conversation_messages.append({
        "id": response_id,
        "role": "assistant",
        "content": response_content,
        "timestamp": Time.get_unix_time_from_system()
    })
    
    // Cache response if enabled
    if cache_responses:
        var cache_key = request.content.strip_edges().md5_text()
        cached_responses[cache_key] = {
            "id": response_id,
            "content": response_content,
            "timestamp": Time.get_unix_time_from_system()
        }
        
        // Trim cache if needed
        if cached_responses.size() > max_cache_items:
            var oldest_key = null
            var oldest_time = Time.get_unix_time_from_system()
            
            for key in cached_responses:
                if cached_responses[key].timestamp < oldest_time:
                    oldest_time = cached_responses[key].timestamp
                    oldest_key = key
            
            if oldest_key:
                cached_responses.erase(oldest_key)
    
    // Save conversation
    _save_conversation(current_conversation_id, current_conversation_messages)
    
    emit_signal("response_received", response_id, response_content)

func _generate_simulated_response(user_message):
    // This is a placeholder for a real Claude API call
    // In a real implementation, this would send the request to Claude's API
    
    // Simple "echo" to simulate a response
    return "I understand you're asking about: " + user_message + "\n\nIn a real implementation, this would be Claude's actual response."

# ----- MEMORY INTEGRATION -----
func store_message_as_memory(message_id, tags = []):
    var message = _find_message_by_id(message_id)
    if not message:
        return null
    
    var memory_tags = tags.duplicate()
    memory_tags.append("claude")
    memory_tags.append("message_" + message_id)
    
    var memory_id = null
    
    // Store in Memory System if available
    if use_memory_system and memory_system and memory_system.has_method("store_memory"):
        memory_id = memory_system.store_memory(
            message.content,
            memory_tags,
            "claude_message_" + message.role
        )
    
    // Also connect to Ethereal Bridge if available
    if use_ethereal_bridge and ethereal_bridge and ethereal_bridge.has_method("record_memory"):
        ethereal_bridge.record_memory(
            message.content,
            memory_tags,
            "0-0-0"  // Default dimension
        )
    
    if memory_id:
        emit_signal("memory_stored", memory_id, message.content)
    
    return memory_id

func _find_message_by_id(message_id):
    for message in current_conversation_messages:
        if message.id == message_id:
            return message
    
    return null

# ----- TOKEN MANAGEMENT -----
func _check_token_reset():
    var current_time = Time.get_unix_time_from_system()
    
    // Check if a new day has started since last reset
    if token_usage.last_reset == 0 or _is_new_day(token_usage.last_reset, current_time):
        token_usage.input_tokens = 0
        token_usage.output_tokens = 0
        token_usage.total_tokens = 0
        token_usage.last_reset = current_time
        
        emit_signal("token_usage_updated", token_usage)
        print("Token usage reset for new day")

func _is_new_day(past_time, current_time):
    var past_date = Time.get_datetime_dict_from_unix_time(past_time)
    var current_date = Time.get_datetime_dict_from_unix_time(current_time)
    
    return past_date.year != current_date.year || 
           past_date.month != current_date.month || 
           past_date.day != current_date.day

func get_token_usage():
    return token_usage.duplicate()

func get_remaining_tokens():
    if freemium_mode:
        return max(0, max_tokens_per_minute - token_usage.total_tokens)
    else:
        return 1000000  // Arbitrary large number for paid tier

# ----- UTILITY FUNCTIONS -----
func _generate_id():
    return str(Time.get_unix_time_from_system()) + "_" + str(randi() % 1000000).pad_zeros(6)

# ----- EVENT HANDLERS -----
func _on_token_reset_timer_timeout():
    _check_token_reset()

func _on_queue_process_timer_timeout():
    if not request_queue.is_empty() and not is_processing_queue:
        _process_queue()

# ----- PUBLIC API -----
func toggle_claude(enabled_state):
    enabled = enabled_state
    
    if enabled:
        if not is_connected and not api_key.is_empty():
            connect_to_claude()
    else:
        if is_connected:
            disconnect_from_claude()
    
    return enabled

func set_api_key(key):
    api_key = key
    _save_credentials()
    
    if enabled and not is_connected and not api_key.is_empty():
        connect_to_claude()
    
    return !api_key.is_empty()

func set_model(model_name):
    default_model = model_name
    _save_credentials()
    return true

func toggle_cache(cache_enabled):
    cache_responses = cache_enabled
    return cache_responses

func toggle_freemium_mode(freemium_enabled):
    freemium_mode = freemium_enabled
    return freemium_mode

func clear_cache():
    cached_responses.clear()
    return true

func get_conversation_list():
    var conversations = []
    
    var dir = DirAccess.open(conversation_path)
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            if not dir.current_is_dir() and file_name.ends_with(".json"):
                var conv_id = file_name.split(".")[0]
                
                // Load basic metadata
                var file = FileAccess.open(conversation_path + file_name, FileAccess.READ)
                if file:
                    var json = JSON.new()
                    var error = json.parse(file.get_as_text())
                    
                    if error == OK:
                        var data = json.data
                        conversations.append({
                            "id": conv_id,
                            "timestamp": data.get("timestamp", 0),
                            "message_count": data.get("messages", []).size()
                        })
                    
                    file.close()
            
            file_name = dir.get_next()
        
        dir.list_dir_end()
    }
    
    // Sort by timestamp (most recent first)
    conversations.sort_custom(func(a, b): return a.timestamp > b.timestamp)
    
    return conversations

func get_current_conversation_state():
    return {
        "conversation_id": current_conversation_id,
        "message_count": current_conversation_messages.size(),
        "is_connected": is_connected,
        "token_usage": token_usage,
        "queue_size": request_queue.size()
    }

func create_ethereal_connection(content, dimension = ""):
    if not use_ethereal_bridge or not ethereal_bridge:
        return false
    
    if ethereal_bridge.has_method("process_ethereal_data"):
        ethereal_bridge.process_ethereal_data("claude_connection", content)
        return true
    
    return false
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/claude_integration_bridge.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/cloud_storage_connector.gd
# SIZE: 25381 bytes
extends Node

class_name CloudStorageConnector

# Storage provider types
enum StorageProvider {
    GOOGLE_DRIVE,
    ONEDRIVE,
    DROPBOX,
    LUNO,
    LOCAL
}

# Authentication states
enum AuthState {
    UNAUTHENTICATED,
    AUTHENTICATING,
    AUTHENTICATED,
    FAILED,
    REFRESHING,
    EXPIRED
}

# Transfer states
enum TransferState {
    IDLE,
    UPLOADING,
    DOWNLOADING,
    SYNCHRONIZING,
    FAILED,
    COMPLETED
}

# Parameters
export var auto_connect = true
export var auto_sync = true
export var encryption_enabled = true
export(StorageProvider) var default_provider = StorageProvider.GOOGLE_DRIVE
export var cache_size_mb = 500
export var concurrent_transfers = 3
export var refresh_interval_minutes = 60
export var max_retry_attempts = 3

# Storage provider credentials
var credentials = {
    StorageProvider.GOOGLE_DRIVE: {
        "api_key": "",
        "client_id": "",
        "client_secret": "",
        "refresh_token": "",
        "access_token": "",
        "expires_at": 0
    },
    StorageProvider.ONEDRIVE: {
        "api_key": "",
        "client_id": "",
        "client_secret": "",
        "refresh_token": "",
        "access_token": "",
        "expires_at": 0
    },
    StorageProvider.DROPBOX: {
        "api_key": "",
        "client_id": "",
        "client_secret": "",
        "refresh_token": "",
        "access_token": "",
        "expires_at": 0
    },
    StorageProvider.LUNO: {
        "api_key": "",
        "account_id": "",
        "secret_key": "",
        "access_token": "",
        "expires_at": 0
    }
}

# Current state
var active_provider = StorageProvider.GOOGLE_DRIVE
var auth_state = AuthState.UNAUTHENTICATED
var transfer_state = TransferState.IDLE
var current_transfers = []
var connected_accounts = []
var device_info = {}
var storage_usage = {}
var sync_folders = []
var last_sync_time = 0
var error_log = []

# Connection to account system
var _account_manager = null
var _multi_threaded_processor = null

# Signals
signal authentication_changed(provider, state)
signal transfer_state_changed(state, details)
signal sync_completed(success, items_synced)
signal storage_usage_updated(usage_data)
signal connection_error(provider, error_code, message)

func _ready():
    # Set up device information
    _detect_device_info()
    
    # Connect to other systems
    connect_to_systems()
    
    # Set up automatic timer for token refresh
    var refresh_timer = Timer.new()
    refresh_timer.wait_time = refresh_interval_minutes * 60
    refresh_timer.autostart = true
    refresh_timer.connect("timeout", self, "_on_refresh_timer")
    add_child(refresh_timer)
    
    # Initialize with default provider
    if auto_connect:
        connect_provider(default_provider)

func connect_to_systems():
    # Connect to MultiAccountManager
    if has_node("/root/MultiAccountManager") or get_node_or_null("/root/MultiAccountManager"):
        _account_manager = get_node("/root/MultiAccountManager")
        print("Connected to MultiAccountManager")
    
    # Connect to MultiThreadedProcessor
    if has_node("/root/MultiThreadedProcessor") or get_node_or_null("/root/MultiThreadedProcessor"):
        _multi_threaded_processor = get_node("/root/MultiThreadedProcessor")
        print("Connected to MultiThreadedProcessor")

func _detect_device_info():
    # Get basic device information
    device_info = {
        "platform": OS.get_name(),
        "model": "Unknown",
        "unique_id": OS.get_unique_id(),
        "device_name": OS.get_model_name(),
        "screen_size": Vector2(OS.get_screen_size()),
        "screen_dpi": OS.get_screen_dpi(),
        "has_camera": false, # Will be detected later
        "has_lidar": false,  # Not available on most devices
        "memory_mb": OS.get_static_memory_usage() / (1024 * 1024)
    }
    
    # Try to detect camera
    # In a real implementation, would use platform-specific methods
    # For now, assume camera based on platform
    if device_info["platform"] == "Android" or device_info["platform"] == "iOS":
        device_info["has_camera"] = true
        
        # More detailed device model detection for mobile
        if device_info["platform"] == "iOS" and device_info["device_name"].find("iPhone") >= 0:
            var iphone_model = device_info["device_name"]
            
            # Check for LIDAR-capable models (iPhone 12 Pro and newer)
            if iphone_model.find("12 Pro") >= 0 or iphone_model.find("13 Pro") >= 0 or \
               iphone_model.find("14 Pro") >= 0 or iphone_model.find("15 Pro") >= 0:
                device_info["has_lidar"] = true
    
    print("Detected device: " + device_info["platform"] + " " + device_info["device_name"])
    if device_info["has_camera"]:
        print("Camera detected: Yes (LIDAR: " + str(device_info["has_lidar"]) + ")")
    else:
        print("Camera detected: No")

func set_api_key(provider, api_key, client_id = "", client_secret = ""):
    if not provider in StorageProvider.values():
        print("Invalid storage provider")
        return false
    
    credentials[provider]["api_key"] = api_key
    
    if not client_id.empty():
        credentials[provider]["client_id"] = client_id
    
    if not client_secret.empty():
        credentials[provider]["client_secret"] = client_secret
    
    print("Set API key for provider: " + StorageProvider.keys()[provider])
    return true

func connect_provider(provider):
    if not provider in StorageProvider.values():
        print("Invalid storage provider")
        return false
    
    if credentials[provider]["api_key"].empty():
        print("API key not set for provider: " + StorageProvider.keys()[provider])
        return false
    
    # Set active provider
    active_provider = provider
    auth_state = AuthState.AUTHENTICATING
    emit_signal("authentication_changed", provider, auth_state)
    
    print("Connecting to provider: " + StorageProvider.keys()[provider])
    
    # Start authentication process
    # For Google Drive, would use OAuth2 flow
    # For this demo, simulate authentication
    _simulate_authentication(provider)
    
    return true

func _simulate_authentication(provider):
    # In a real implementation, would perform actual OAuth2 flow
    # For now, simulate authentication after a short delay
    var auth_timer = Timer.new()
    auth_timer.wait_time = 1.0 # 1 second for simulation
    auth_timer.one_shot = true
    auth_timer.connect("timeout", self, "_on_auth_completed", [provider])
    add_child(auth_timer)
    auth_timer.start()

func _on_auth_completed(provider):
    # Simulate successful authentication
    auth_state = AuthState.AUTHENTICATED
    credentials[provider]["access_token"] = "simulated_access_token"
    credentials[provider]["expires_at"] = OS.get_unix_time() + (3600 * 2) # 2 hours
    
    # Record which account this is connected to
    var account_id = "default"
    if _account_manager:
        account_id = _account_manager.active_account_id
    
    if not account_id in connected_accounts:
        connected_accounts.append(account_id)
    
    emit_signal("authentication_changed", provider, auth_state)
    print("Authenticated with " + StorageProvider.keys()[provider])
    
    # Get storage usage
    get_storage_usage()
    
    # Start sync if auto-sync is enabled
    if auto_sync:
        synchronize_folders()

func refresh_token(provider):
    if not provider in StorageProvider.values():
        print("Invalid storage provider")
        return false
    
    if credentials[provider]["refresh_token"].empty():
        print("No refresh token available for provider: " + StorageProvider.keys()[provider])
        return false
    
    # Set state to refreshing
    auth_state = AuthState.REFRESHING
    emit_signal("authentication_changed", provider, auth_state)
    
    print("Refreshing token for provider: " + StorageProvider.keys()[provider])
    
    # In a real implementation, would use refresh token to get new access token
    # For this demo, simulate refreshing
    var refresh_timer = Timer.new()
    refresh_timer.wait_time = 0.5 # 0.5 seconds for simulation
    refresh_timer.one_shot = true
    refresh_timer.connect("timeout", self, "_on_refresh_completed", [provider])
    add_child(refresh_timer)
    refresh_timer.start()
    
    return true

func _on_refresh_completed(provider):
    # Simulate successful token refresh
    auth_state = AuthState.AUTHENTICATED
    credentials[provider]["access_token"] = "new_access_token"
    credentials[provider]["expires_at"] = OS.get_unix_time() + (3600 * 2) # 2 hours
    
    emit_signal("authentication_changed", provider, auth_state)
    print("Token refreshed for " + StorageProvider.keys()[provider])

func _on_refresh_timer():
    # Check if token needs refreshing
    var current_time = OS.get_unix_time()
    
    for provider in credentials:
        if credentials[provider]["expires_at"] > 0 and credentials[provider]["expires_at"] - current_time < 300:
            # Token will expire in less than 5 minutes, refresh it
            refresh_token(provider)

func get_storage_usage():
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated")
        return null
    
    # In a real implementation, would call API to get actual storage usage
    # For this demo, simulate storage usage
    
    # Simulate Google Drive 2TB storage
    if active_provider == StorageProvider.GOOGLE_DRIVE:
        storage_usage = {
            "total_gb": 2048, # 2TB
            "used_gb": 458.25, # Example usage
            "available_gb": 2048 - 458.25,
            "files_count": 2587,
            "largest_file_gb": 4.2,
            "usage_by_type": {
                "documents": 12.5,
                "images": 145.8,
                "videos": 275.4,
                "audio": 15.2,
                "other": 9.35
            }
        }
    elif active_provider == StorageProvider.LUNO:
        storage_usage = {
            "total_gb": 2048, # 2TB
            "used_gb": 215.75, # Different example usage
            "available_gb": 2048 - 215.75,
            "files_count": 1843,
            "largest_file_gb": 18.5,
            "usage_by_type": {
                "documents": 8.2,
                "images": 65.3,
                "videos": 128.9,
                "audio": 8.75,
                "other": 4.6
            }
        }
    else:
        storage_usage = {
            "total_gb": 15, # Basic storage
            "used_gb": 8.4,
            "available_gb": 15 - 8.4,
            "files_count": 426,
            "largest_file_gb": 1.8,
            "usage_by_type": {
                "documents": 2.1,
                "images": 3.8,
                "videos": 1.9,
                "audio": 0.4,
                "other": 0.2
            }
        }
    
    emit_signal("storage_usage_updated", storage_usage)
    return storage_usage

func add_sync_folder(local_path, remote_path, sync_direction = "both"):
    # Validate inputs
    if local_path.empty() or remote_path.empty():
        print("Local and remote paths must be specified")
        return false
    
    # Check if folder already exists in sync list
    for folder in sync_folders:
        if folder["local_path"] == local_path and folder["remote_path"] == remote_path:
            print("Folder already in sync list")
            return false
    
    # Add folder to sync list
    sync_folders.append({
        "local_path": local_path,
        "remote_path": remote_path,
        "sync_direction": sync_direction,
        "last_sync": 0,
        "status": "pending"
    })
    
    print("Added sync folder: " + local_path + " <-> " + remote_path)
    return true

func remove_sync_folder(local_path, remote_path):
    # Find folder in sync list
    var index_to_remove = -1
    for i in range(sync_folders.size()):
        if sync_folders[i]["local_path"] == local_path and sync_folders[i]["remote_path"] == remote_path:
            index_to_remove = i
            break
    
    if index_to_remove >= 0:
        sync_folders.remove(index_to_remove)
        print("Removed sync folder: " + local_path + " <-> " + remote_path)
        return true
    
    print("Folder not found in sync list")
    return false

func synchronize_folders():
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated")
        return false
    
    if sync_folders.size() == 0:
        print("No folders to synchronize")
        return false
    
    # Set state to synchronizing
    transfer_state = TransferState.SYNCHRONIZING
    emit_signal("transfer_state_changed", transfer_state, {"folders": sync_folders.size()})
    
    print("Starting synchronization of " + str(sync_folders.size()) + " folders")
    
    # In a real implementation, would perform actual synchronization
    # For this demo, simulate synchronization with a thread
    if _multi_threaded_processor:
        var task_description = "Synchronizing " + str(sync_folders.size()) + " folders"
        var thread_id = _multi_threaded_processor.allocate_thread(
            _account_manager.active_account_id if _account_manager else "default",
            task_description,
            _multi_threaded_processor.Priority.NORMAL
        )
        
        if thread_id:
            print("Allocated thread " + thread_id + " for synchronization")
            # In a real implementation, would start thread function
            # For now, simulate synchronization after a delay
            var sync_timer = Timer.new()
            sync_timer.wait_time = 2.0 # 2 seconds for simulation
            sync_timer.one_shot = true
            sync_timer.connect("timeout", self, "_on_sync_completed", [thread_id])
            add_child(sync_timer)
            sync_timer.start()
            return true
    else:
        # Fallback if thread processor not available
        var sync_timer = Timer.new()
        sync_timer.wait_time = 2.0 # 2 seconds for simulation
        sync_timer.one_shot = true
        sync_timer.connect("timeout", self, "_on_sync_completed", ["none"])
        add_child(sync_timer)
        sync_timer.start()
        return true
    
    return false

func _on_sync_completed(thread_id):
    # Simulate successful synchronization
    var items_synced = randi() % 50 + 10 # Random number of items 10-60
    
    # Update sync folders status
    for folder in sync_folders:
        folder["last_sync"] = OS.get_unix_time()
        folder["status"] = "synced"
    
    # Update last sync time
    last_sync_time = OS.get_unix_time()
    
    # Set state back to idle
    transfer_state = TransferState.COMPLETED
    emit_signal("transfer_state_changed", transfer_state, {"items_synced": items_synced})
    emit_signal("sync_completed", true, items_synced)
    
    print("Synchronized " + str(items_synced) + " items")
    
    # Release thread if allocated
    if thread_id != "none" and _multi_threaded_processor:
        _multi_threaded_processor.release_thread(
            _account_manager.active_account_id if _account_manager else "default",
            thread_id
        )

func upload_file(local_path, remote_path, callback = null):
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated")
        return false
    
    # Validate inputs
    if local_path.empty() or remote_path.empty():
        print("Local and remote paths must be specified")
        return false
    
    # Check if file exists locally
    var file = File.new()
    if not file.file_exists(local_path):
        print("Local file does not exist: " + local_path)
        return false
    
    # Set state to uploading
    transfer_state = TransferState.UPLOADING
    
    # Add to current transfers
    var transfer_id = str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    current_transfers.append({
        "id": transfer_id,
        "type": "upload",
        "local_path": local_path,
        "remote_path": remote_path,
        "start_time": OS.get_unix_time(),
        "status": "in_progress",
        "progress": 0.0,
        "callback": callback
    })
    
    emit_signal("transfer_state_changed", transfer_state, {"transfers": current_transfers.size()})
    
    print("Starting upload: " + local_path + " -> " + remote_path)
    
    # In a real implementation, would perform actual upload
    # For this demo, simulate upload with a timer
    var upload_timer = Timer.new()
    upload_timer.wait_time = 1.5 # 1.5 seconds for simulation
    upload_timer.one_shot = true
    upload_timer.connect("timeout", self, "_on_upload_progress", [transfer_id, 0.5])
    add_child(upload_timer)
    upload_timer.start()
    
    return transfer_id

func _on_upload_progress(transfer_id, progress):
    # Find transfer in current transfers
    var transfer_index = -1
    for i in range(current_transfers.size()):
        if current_transfers[i]["id"] == transfer_id:
            transfer_index = i
            break
    
    if transfer_index < 0:
        print("Transfer not found: " + transfer_id)
        return
    
    # Update progress
    current_transfers[transfer_index]["progress"] = progress
    
    emit_signal("transfer_state_changed", transfer_state, {
        "transfer_id": transfer_id,
        "progress": progress
    })
    
    if progress < 1.0:
        # Continue upload
        var upload_timer = Timer.new()
        upload_timer.wait_time = 0.5 # 0.5 seconds for simulation
        upload_timer.one_shot = true
        upload_timer.connect("timeout", self, "_on_upload_progress", [transfer_id, 1.0])
        add_child(upload_timer)
        upload_timer.start()
    else:
        # Upload complete
        current_transfers[transfer_index]["status"] = "completed"
        current_transfers[transfer_index]["end_time"] = OS.get_unix_time()
        
        print("Upload completed: " + current_transfers[transfer_index]["local_path"])
        
        # Check if callback is provided
        if current_transfers[transfer_index]["callback"]:
            var callback = current_transfers[transfer_index]["callback"]
            callback.call_func(transfer_id, true)
        
        # Remove from current transfers after a delay
        var cleanup_timer = Timer.new()
        cleanup_timer.wait_time = 1.0
        cleanup_timer.one_shot = true
        cleanup_timer.connect("timeout", self, "_remove_transfer", [transfer_id])
        add_child(cleanup_timer)
        cleanup_timer.start()
        
        # Check if all transfers are completed
        var all_completed = true
        for transfer in current_transfers:
            if transfer["status"] == "in_progress":
                all_completed = false
                break
        
        if all_completed and current_transfers.size() > 0:
            transfer_state = TransferState.COMPLETED
            emit_signal("transfer_state_changed", transfer_state, {"all_completed": true})

func _remove_transfer(transfer_id):
    # Find transfer in current transfers
    var transfer_index = -1
    for i in range(current_transfers.size()):
        if current_transfers[i]["id"] == transfer_id:
            transfer_index = i
            break
    
    if transfer_index >= 0:
        current_transfers.remove(transfer_index)
    
    # If no transfers left, set state to idle
    if current_transfers.size() == 0:
        transfer_state = TransferState.IDLE
        emit_signal("transfer_state_changed", transfer_state, {})

func download_file(remote_path, local_path, callback = null):
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated")
        return false
    
    # Validate inputs
    if local_path.empty() or remote_path.empty():
        print("Local and remote paths must be specified")
        return false
    
    # Set state to downloading
    transfer_state = TransferState.DOWNLOADING
    
    # Add to current transfers
    var transfer_id = str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    current_transfers.append({
        "id": transfer_id,
        "type": "download",
        "local_path": local_path,
        "remote_path": remote_path,
        "start_time": OS.get_unix_time(),
        "status": "in_progress",
        "progress": 0.0,
        "callback": callback
    })
    
    emit_signal("transfer_state_changed", transfer_state, {"transfers": current_transfers.size()})
    
    print("Starting download: " + remote_path + " -> " + local_path)
    
    # In a real implementation, would perform actual download
    # For this demo, simulate download with a timer
    var download_timer = Timer.new()
    download_timer.wait_time = 1.0 # 1.0 seconds for simulation
    download_timer.one_shot = true
    download_timer.connect("timeout", self, "_on_download_progress", [transfer_id, 0.6])
    add_child(download_timer)
    download_timer.start()
    
    return transfer_id

func _on_download_progress(transfer_id, progress):
    # Similar to upload progress handler
    var transfer_index = -1
    for i in range(current_transfers.size()):
        if current_transfers[i]["id"] == transfer_id:
            transfer_index = i
            break
    
    if transfer_index < 0:
        print("Transfer not found: " + transfer_id)
        return
    
    # Update progress
    current_transfers[transfer_index]["progress"] = progress
    
    emit_signal("transfer_state_changed", transfer_state, {
        "transfer_id": transfer_id,
        "progress": progress
    })
    
    if progress < 1.0:
        # Continue download
        var download_timer = Timer.new()
        download_timer.wait_time = 0.6 # 0.6 seconds for simulation
        download_timer.one_shot = true
        download_timer.connect("timeout", self, "_on_download_progress", [transfer_id, 1.0])
        add_child(download_timer)
        download_timer.start()
    else:
        # Download complete
        current_transfers[transfer_index]["status"] = "completed"
        current_transfers[transfer_index]["end_time"] = OS.get_unix_time()
        
        print("Download completed: " + current_transfers[transfer_index]["remote_path"])
        
        # Check if callback is provided
        if current_transfers[transfer_index]["callback"]:
            var callback = current_transfers[transfer_index]["callback"]
            callback.call_func(transfer_id, true)
        
        # Remove from current transfers after a delay
        var cleanup_timer = Timer.new()
        cleanup_timer.wait_time = 1.0
        cleanup_timer.one_shot = true
        cleanup_timer.connect("timeout", self, "_remove_transfer", [transfer_id])
        add_child(cleanup_timer)
        cleanup_timer.start()
        
        # Check if all transfers are completed
        var all_completed = true
        for transfer in current_transfers:
            if transfer["status"] == "in_progress":
                all_completed = false
                break
        
        if all_completed and current_transfers.size() > 0:
            transfer_state = TransferState.COMPLETED
            emit_signal("transfer_state_changed", transfer_state, {"all_completed": true})

func get_file_list(remote_path):
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated")
        return []
    
    # In a real implementation, would call API to get actual file list
    # For this demo, simulate file list
    var files = []
    
    # Generate random files based on provider
    var file_types = ["document", "image", "video", "audio", "other"]
    var file_count = randi() % 20 + 5 # 5-25 files
    
    for i in range(file_count):
        var file_type = file_types[randi() % file_types.size()]
        var extension = ""
        
        match file_type:
            "document":
                extension = [".pdf", ".docx", ".txt", ".xlsx"][randi() % 4]
            "image":
                extension = [".jpg", ".png", ".gif", ".svg"][randi() % 4]
            "video":
                extension = [".mp4", ".avi", ".mov", ".mkv"][randi() % 4]
            "audio":
                extension = [".mp3", ".wav", ".ogg", ".flac"][randi() % 4]
            "other":
                extension = [".zip", ".rar", ".exe", ".dll"][randi() % 4]
        
        var file_name = "file_" + str(i) + extension
        var file_size = randi() % 1000000 + 1000 # 1KB - 1MB
        
        files.append({
            "name": file_name,
            "path": remote_path + "/" + file_name,
            "size_bytes": file_size,
            "type": file_type,
            "modified": OS.get_unix_time() - randi() % 2592000, # Random time in last 30 days
            "created": OS.get_unix_time() - randi() % 31536000 # Random time in last year
        })
    }
    
    return files

func get_auth_status():
    return {
        "provider": StorageProvider.keys()[active_provider],
        "state": AuthState.keys()[auth_state],
        "expires_at": credentials[active_provider]["expires_at"],
        "time_remaining": max(0, credentials[active_provider]["expires_at"] - OS.get_unix_time())
    }

func get_transfer_status():
    return {
        "state": TransferState.keys()[transfer_state],
        "current_transfers": current_transfers.size(),
        "active_transfers": _count_active_transfers()
    }

func _count_active_transfers():
    var count = 0
    for transfer in current_transfers:
        if transfer["status"] == "in_progress":
            count += 1
    return count
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/cloud_storage_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/color_animation_system.gd
# SIZE: 30139 bytes
class_name ColorAnimationSystem
extends Node

# ----- COLOR ANIMATION SETTINGS -----
@export_category("Animation Settings")
@export var enabled: bool = true
@export var update_interval: float = 0.05  # 20 FPS update rate
@export var default_duration: float = 1.0  # Default animation duration in seconds
@export var base_frequency: int = 99  # Starting frequency (maps to special frequencies)
@export var color_intensity: float = 0.8  # Color intensity (0-1)
@export var max_active_animations: int = 30  # Maximum concurrent animations

# ----- COLOR FREQUENCY CONSTANTS -----
const HARMONIC_FREQUENCIES = {
    "PRIMARY": [99, 333, 555, 777, 999],
    "SECONDARY": [120, 240, 360, 480, 600, 720, 840, 960],
    "SPECIAL": [33, 66, 166, 233, 266, 299, 399, 466, 499, 533, 599, 633, 666, 699, 833, 866, 899, 933, 966]
}

const MESH_POINTS = {
    "CENTERS": [333, 666, 999],
    "EDGES": [120, 240, 480, 720, 960],
    "CORNERS": [99, 555, 777]
}

const SYMBOL_FREQUENCIES = {
    "#": 33,    // Simple hash
    "##": 66,   // Double hash
    "###": 99,  // Triple hash
    "_": 12,    // Underscore
    "@": 55,    // At symbol
    "$": 77,    // Dollar
    "%": 44,    // Percent
    "&": 88,    // Ampersand
    "*": 22     // Asterisk
}

# ----- ANIMATION TYPES -----
enum AnimationType {
    FADE,        # Smooth fade between colors
    PULSE,       # Pulsing animation (fade in/out)
    RAINBOW,     # Cycling through rainbow colors
    FLASH,       # Quick flash effect
    GRADIENT,    # Gradient between two colors
    SPARKLE,     # Sparkling effect (random bright spots)
    WAVE,        # Wave effect across multiple elements
    MESH_POINT   # Special animation for mesh points
}

# ----- STATE VARIABLES -----
var active_animations = {}
var color_map = {}
var update_timer: Timer
var current_turn = 1
var total_turns = 12
var base_color_palette = []
var turn_color_palette = []
var last_animation_id = 0

# ----- COMPONENT REFERENCES -----
var color_system = null
var visual_indicator = null

# ----- SIGNALS -----
signal animation_started(animation_id, type)
signal animation_completed(animation_id, type)
signal color_updated(target_id, color)
signal frequency_activated(frequency, source)

# ----- INITIALIZATION -----
func _ready():
    _setup_timer()
    _initialize_color_map()
    _find_components()
    _initialize_palettes()
    
    print("Color Animation System initialized with base frequency: " + str(base_frequency))

func _setup_timer():
    update_timer = Timer.new()
    update_timer.wait_time = update_interval
    update_timer.one_shot = false
    update_timer.autostart = true
    update_timer.connect("timeout", Callable(self, "_on_update_timer"))
    add_child(update_timer)

func _initialize_color_map():
    # Initialize base colors for primary frequencies
    for freq in HARMONIC_FREQUENCIES.PRIMARY:
        color_map[freq] = _create_color_for_frequency(freq, "primary")
    
    # Initialize colors for secondary frequencies
    for freq in HARMONIC_FREQUENCIES.SECONDARY:
        color_map[freq] = _create_color_for_frequency(freq, "secondary")
    
    # Initialize colors for special frequencies
    for freq in HARMONIC_FREQUENCIES.SPECIAL:
        color_map[freq] = _create_color_for_frequency(freq, "special")

func _create_color_for_frequency(frequency: int, type: String = "primary") -> Color:
    # Create a color based on frequency value and type
    var hue = (frequency % 360) / 360.0
    var saturation = 0.8
    var value = 0.9
    
    match type:
        "primary":
            # Primary frequencies get pure, vibrant colors
            saturation = 0.9
            value = 1.0
        "secondary":
            # Secondary frequencies are slightly less saturated
            saturation = 0.8
            value = 0.9
        "special":
            # Special frequencies have unique treatment
            saturation = 0.7
            value = 0.85
    
    # Special cases for mesh points
    if MESH_POINTS.CENTERS.has(frequency):
        # Centers are bright and pure
        return Color(1.0, 1.0, 1.0).lerp(Color.from_hsv(hue, 0.5, 1.0), 0.7)
    elif MESH_POINTS.CORNERS.has(frequency):
        # Corners are gold/bronze toned
        return Color.from_hsv(0.15, 0.8, 0.9)
    elif MESH_POINTS.EDGES.has(frequency):
        # Edges are blue/cyan toned
        return Color.from_hsv(0.5, 0.7, 1.0)
    
    # Standard HSV-based color
    return Color.from_hsv(hue, saturation, value)

func _find_components():
    # Find Color System
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find Visual Indicator
    visual_indicator = get_node_or_null("/root/VisualIndicatorSystem")
    if not visual_indicator:
        visual_indicator = _find_node_by_class(get_tree().root, "VisualIndicatorSystem")
    
    print("Components found - Color System: %s, Visual Indicator: %s" % [
        "Yes" if color_system else "No",
        "Yes" if visual_indicator else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_palettes():
    # Initialize base color palette
    base_color_palette = [
        Color(0.1, 0.4, 0.9),  # Blue
        Color(0.0, 0.9, 0.6),  # Teal
        Color(0.9, 0.4, 0.7),  # Pink
        Color(0.9, 0.8, 0.1),  # Gold
        Color(0.5, 0.0, 0.9),  # Purple
        Color(0.0, 0.7, 0.9),  # Cyan 
        Color(0.0, 0.9, 0.0),  # Green
        Color(0.9, 0.9, 0.0)   # Yellow
    ]
    
    # Initialize turn-based color palette
    turn_color_palette = []
    for i in range(total_turns):
        var turn_number = i + 1
        var hue = (turn_number - 1) / float(total_turns)
        var turn_color = Color.from_hsv(hue, 0.8, 0.9)
        turn_color_palette.append(turn_color)

# ----- UPDATE LOOP -----
func _on_update_timer():
    if not enabled:
        return
    
    # Process active animations
    _update_animations(update_interval)
    
    # Forward colors to any connected systems
    _sync_colors()

func _update_animations(delta: float):
    var completed_animations = []
    
    # Update each active animation
    for animation_id in active_animations.keys():
        var animation = active_animations[animation_id]
        animation.elapsed_time += delta
        
        # Check if animation is complete
        if animation.elapsed_time >= animation.duration:
            completed_animations.append(animation_id)
            continue
        
        # Calculate progress (0 to 1)
        var progress = animation.elapsed_time / animation.duration
        
        # Update animation based on type
        match animation.type:
            AnimationType.FADE:
                _update_fade_animation(animation, progress)
            AnimationType.PULSE:
                _update_pulse_animation(animation, progress)
            AnimationType.RAINBOW:
                _update_rainbow_animation(animation, progress)
            AnimationType.FLASH:
                _update_flash_animation(animation, progress)
            AnimationType.GRADIENT:
                _update_gradient_animation(animation, progress)
            AnimationType.SPARKLE:
                _update_sparkle_animation(animation, progress)
            AnimationType.WAVE:
                _update_wave_animation(animation, progress)
            AnimationType.MESH_POINT:
                _update_mesh_point_animation(animation, progress)
    
    # Remove completed animations
    for animation_id in completed_animations:
        var animation = active_animations[animation_id]
        
        # Apply final state
        if animation.has("target_id") and animation.has("current_color"):
            emit_signal("color_updated", animation.target_id, animation.current_color)
        
        # Remove animation
        active_animations.erase(animation_id)
        
        # Signal completion
        emit_signal("animation_completed", animation_id, animation.type)

func _sync_colors():
    # Sync colors with other systems if available
    if color_system:
        # Get any color updates from color system
        # Note: In a full implementation, this would be more sophisticated
        pass

# ----- ANIMATION UPDATE METHODS -----
func _update_fade_animation(animation, progress: float):
    var start_color = animation.start_color
    var end_color = animation.end_color
    
    # Linear interpolation
    var current_color = start_color.lerp(end_color, progress)
    animation.current_color = current_color
    
    # Apply to target
    if animation.has("target_id"):
        emit_signal("color_updated", animation.target_id, current_color)

func _update_pulse_animation(animation, progress: float):
    var base_color = animation.base_color
    var pulse_color = animation.pulse_color
    var frequency = animation.pulse_frequency
    
    # Calculate pulse factor (0 to 1 to 0)
    var pulse_progress = sin(progress * TAU * frequency) * 0.5 + 0.5
    pulse_progress = pulse_progress * animation.intensity
    
    # Interpolate between base and pulse color
    var current_color = base_color.lerp(pulse_color, pulse_progress)
    animation.current_color = current_color
    
    # Apply to target
    if animation.has("target_id"):
        emit_signal("color_updated", animation.target_id, current_color)

func _update_rainbow_animation(animation, progress: float):
    var speed = animation.rainbow_speed
    var saturation = animation.saturation
    var value = animation.value
    
    # Calculate hue based on progress and speed
    var hue = fmod(progress * speed, 1.0)
    
    # Create color from HSV
    var current_color = Color.from_hsv(hue, saturation, value)
    animation.current_color = current_color
    
    # Apply to target
    if animation.has("target_id"):
        emit_signal("color_updated", animation.target_id, current_color)

func _update_flash_animation(animation, progress: float):
    var base_color = animation.base_color
    var flash_color = animation.flash_color
    var flash_count = animation.flash_count
    
    # Calculate flash factor (0 or 1 based on time)
    var phase = fmod(progress * flash_count, 1.0)
    var flash_active = phase < 0.5
    
    # Choose appropriate color
    var current_color = flash_active ? flash_color : base_color
    animation.current_color = current_color
    
    # Apply to target
    if animation.has("target_id"):
        emit_signal("color_updated", animation.target_id, current_color)

func _update_gradient_animation(animation, progress: float):
    var colors = animation.gradient_colors
    var positions = animation.gradient_positions
    
    # Find the two colors to interpolate between
    var index = 0
    while index < positions.size() - 1 and progress > positions[index + 1]:
        index += 1
    
    # Calculate local progress between these two points
    var local_progress = 0.0
    if index < positions.size() - 1:
        local_progress = (progress - positions[index]) / (positions[index + 1] - positions[index])
    
    # Interpolate between colors
    var start_color = colors[index]
    var end_color = colors[min(index + 1, colors.size() - 1)]
    var current_color = start_color.lerp(end_color, local_progress)
    
    animation.current_color = current_color
    
    # Apply to target
    if animation.has("target_id"):
        emit_signal("color_updated", animation.target_id, current_color)

func _update_sparkle_animation(animation, progress: float):
    var base_color = animation.base_color
    var sparkle_color = animation.sparkle_color
    var sparkle_count = animation.sparkle_count
    
    # Generate random sparkles
    var current_color = base_color
    var random_value = randf()
    
    # Apply sparkle if random value falls within threshold
    var sparkle_threshold = 0.1 * animation.intensity
    
    if random_value < sparkle_threshold:
        # Apply sparkle color
        current_color = sparkle_color
    
    animation.current_color = current_color
    
    # Apply to target
    if animation.has("target_id"):
        emit_signal("color_updated", animation.target_id, current_color)

func _update_wave_animation(animation, progress: float):
    var base_color = animation.base_color
    var wave_color = animation.wave_color
    var wave_frequency = animation.wave_frequency
    var wave_phase = animation.wave_phase
    
    # Calculate wave factor
    var wave_progress = sin((progress * wave_frequency + wave_phase) * TAU) * 0.5 + 0.5
    
    # Interpolate color
    var current_color = base_color.lerp(wave_color, wave_progress * animation.intensity)
    animation.current_color = current_color
    
    # Apply to target
    if animation.has("target_id"):
        emit_signal("color_updated", animation.target_id, current_color)

func _update_mesh_point_animation(animation, progress: float):
    var mesh_type = animation.mesh_type
    var base_color = animation.base_color
    var highlight_color = animation.highlight_color
    
    # Calculate highlight intensity based on mesh type
    var intensity = animation.intensity
    match mesh_type:
        "center":
            # Centers pulse with high intensity
            intensity = sin(progress * TAU * 3.0) * 0.5 + 0.5
        "edge":
            # Edges pulse with medium intensity
            intensity = sin(progress * TAU * 2.0) * 0.4 + 0.4
        "corner":
            # Corners pulse with lower intensity but higher base
            intensity = sin(progress * TAU * 1.5) * 0.3 + 0.6
    
    # Apply intensity scaling from animation
    intensity *= animation.intensity
    
    # Interpolate color
    var current_color = base_color.lerp(highlight_color, intensity)
    animation.current_color = current_color
    
    # Apply to target
    if animation.has("target_id"):
        emit_signal("color_updated", animation.target_id, current_color)
    
    # Emit frequency activation at certain intervals
    if progress > animation.last_activation_time + 0.2:
        animation.last_activation_time = progress
        emit_signal("frequency_activated", animation.frequency, mesh_type)

# ----- ANIMATION CREATION METHODS -----
func start_fade_animation(target_id, start_color: Color, end_color: Color, duration: float = default_duration) -> int:
    # Create a fade animation
    var animation_id = _get_next_animation_id()
    
    active_animations[animation_id] = {
        "type": AnimationType.FADE,
        "target_id": target_id,
        "start_color": start_color,
        "end_color": end_color,
        "current_color": start_color,
        "duration": duration,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, AnimationType.FADE)
    
    return animation_id

func start_pulse_animation(target_id, base_color: Color, pulse_color: Color, duration: float = default_duration, frequency: float = 2.0, intensity: float = 0.7) -> int:
    # Create a pulse animation
    var animation_id = _get_next_animation_id()
    
    active_animations[animation_id] = {
        "type": AnimationType.PULSE,
        "target_id": target_id,
        "base_color": base_color,
        "pulse_color": pulse_color,
        "current_color": base_color,
        "pulse_frequency": frequency,
        "intensity": intensity,
        "duration": duration,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, AnimationType.PULSE)
    
    return animation_id

func start_rainbow_animation(target_id, duration: float = default_duration, speed: float = 1.0, saturation: float = 0.8, value: float = 0.9) -> int:
    # Create a rainbow animation
    var animation_id = _get_next_animation_id()
    
    active_animations[animation_id] = {
        "type": AnimationType.RAINBOW,
        "target_id": target_id,
        "rainbow_speed": speed,
        "saturation": saturation,
        "value": value,
        "current_color": Color.from_hsv(0, saturation, value),
        "duration": duration,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, AnimationType.RAINBOW)
    
    return animation_id

func start_flash_animation(target_id, base_color: Color, flash_color: Color, duration: float = default_duration, flash_count: int = 3) -> int:
    # Create a flash animation
    var animation_id = _get_next_animation_id()
    
    active_animations[animation_id] = {
        "type": AnimationType.FLASH,
        "target_id": target_id,
        "base_color": base_color,
        "flash_color": flash_color,
        "current_color": base_color,
        "flash_count": flash_count,
        "duration": duration,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, AnimationType.FLASH)
    
    return animation_id

func start_gradient_animation(target_id, colors: Array, positions: Array = [], duration: float = default_duration) -> int:
    # Create a gradient animation
    var animation_id = _get_next_animation_id()
    
    # If positions not provided, distribute evenly
    var pos = positions
    if pos.size() != colors.size():
        pos = []
        for i in range(colors.size()):
            pos.append(float(i) / max(1, colors.size() - 1))
    
    active_animations[animation_id] = {
        "type": AnimationType.GRADIENT,
        "target_id": target_id,
        "gradient_colors": colors,
        "gradient_positions": pos,
        "current_color": colors[0],
        "duration": duration,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, AnimationType.GRADIENT)
    
    return animation_id

func start_sparkle_animation(target_id, base_color: Color, sparkle_color: Color, duration: float = default_duration, sparkle_count: int = 10, intensity: float = 0.7) -> int:
    # Create a sparkle animation
    var animation_id = _get_next_animation_id()
    
    active_animations[animation_id] = {
        "type": AnimationType.SPARKLE,
        "target_id": target_id,
        "base_color": base_color,
        "sparkle_color": sparkle_color,
        "current_color": base_color,
        "sparkle_count": sparkle_count,
        "intensity": intensity,
        "duration": duration,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, AnimationType.SPARKLE)
    
    return animation_id

func start_wave_animation(target_id, base_color: Color, wave_color: Color, duration: float = default_duration, frequency: float = 1.0, phase: float = 0.0, intensity: float = 0.7) -> int:
    # Create a wave animation
    var animation_id = _get_next_animation_id()
    
    active_animations[animation_id] = {
        "type": AnimationType.WAVE,
        "target_id": target_id,
        "base_color": base_color,
        "wave_color": wave_color,
        "current_color": base_color,
        "wave_frequency": frequency,
        "wave_phase": phase,
        "intensity": intensity,
        "duration": duration,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, AnimationType.WAVE)
    
    return animation_id

func start_mesh_point_animation(target_id, frequency: int, mesh_type: String, duration: float = default_duration, intensity: float = 0.8) -> int:
    # Create a mesh point animation
    var animation_id = _get_next_animation_id()
    
    # Determine colors based on mesh type
    var base_color = Color(0.2, 0.2, 0.2)
    var highlight_color = Color(1.0, 1.0, 1.0)
    
    match mesh_type:
        "center":
            base_color = Color(0.1, 0.1, 0.6)
            highlight_color = Color(0.5, 0.5, 1.0)
        "edge":
            base_color = Color(0.1, 0.4, 0.4)
            highlight_color = Color(0.3, 0.9, 0.9)
        "corner":
            base_color = Color(0.5, 0.4, 0.1)
            highlight_color = Color(0.9, 0.8, 0.2)
    
    # If we have color_system, get proper colors
    if color_system:
        if color_system.has_method("get_color_for_frequency"):
            base_color = color_system.get_color_for_frequency(frequency)
        
        # Brighten for highlight
        highlight_color = base_color.lightened(0.5)
    
    active_animations[animation_id] = {
        "type": AnimationType.MESH_POINT,
        "target_id": target_id,
        "mesh_type": mesh_type,
        "frequency": frequency,
        "base_color": base_color,
        "highlight_color": highlight_color,
        "current_color": base_color,
        "intensity": intensity,
        "duration": duration,
        "elapsed_time": 0.0,
        "last_activation_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, AnimationType.MESH_POINT)
    
    return animation_id

func stop_animation(animation_id: int) -> bool:
    if active_animations.has(animation_id):
        active_animations.erase(animation_id)
        return true
    
    return false

func stop_all_animations():
    active_animations.clear()

func _get_next_animation_id() -> int:
    last_animation_id += 1
    
    # Cap to prevent overflow
    if last_animation_id > 1000000:
        last_animation_id = 1
    
    return last_animation_id

# ----- COLOR MANAGEMENT -----
func get_color_for_frequency(frequency: int) -> Color:
    # Use color system if available
    if color_system and color_system.has_method("get_color_for_frequency"):
        return color_system.get_color_for_frequency(frequency)
    
    # Use internal color map
    if color_map.has(frequency):
        return color_map[frequency]
    
    # Calculate a color based on frequency
    var hue = (frequency % 360) / 360.0
    return Color.from_hsv(hue, 0.8, 0.9)

func get_turn_color(turn_number: int) -> Color:
    var index = (turn_number - 1) % turn_color_palette.size()
    return turn_color_palette[index]

func get_symbol_color(symbol: String) -> Color:
    # Get a color for a specific symbol
    if SYMBOL_FREQUENCIES.has(symbol):
        var frequency = SYMBOL_FREQUENCIES[symbol]
        return get_color_for_frequency(frequency)
    
    # Default color
    return Color(0.7, 0.7, 0.7)

# ----- TEXT COLORIZATION -----
func colorize_text(text: String, frequency: int = -1) -> String:
    # Use base frequency if none provided
    var freq = frequency if frequency > 0 else base_frequency
    
    # Use color system if available
    if color_system and color_system.has_method("colorize_line"):
        return color_system.colorize_line(text, freq)
    
    # Simple fallback: just colorize the whole text with frequency color
    var color = get_color_for_frequency(freq)
    var hex_color = color.to_html(false)
    
    return "[color=#" + hex_color + "]" + text + "[/color]"

func colorize_symbols(text: String) -> String:
    # Apply colors to specific symbols in text
    var result = text
    
    # Handle multi-character symbols first
    if text.find("###") != -1:
        var color = get_symbol_color("###")
        var hex_color = color.to_html(false)
        result = result.replace("###", "[color=#" + hex_color + "]###[/color]")
    
    if text.find("##") != -1:
        var color = get_symbol_color("##")
        var hex_color = color.to_html(false)
        result = result.replace("##", "[color=#" + hex_color + "]##[/color]")
    
    # Handle single character symbols
    for symbol in SYMBOL_FREQUENCIES.keys():
        if symbol.length() == 1 and text.find(symbol) != -1:
            var color = get_symbol_color(symbol)
            var hex_color = color.to_html(false)
            result = result.replace(symbol, "[color=#" + hex_color + "]" + symbol + "[/color]")
    
    return result

func create_gradient_text(text: String, start_freq: int, end_freq: int) -> String:
    # Use color system if available
    if color_system and color_system.has_method("get_gradient_text"):
        return color_system.get_gradient_text(text, start_freq, end_freq)
    
    # Fallback gradient using RichTextLabel BBCode
    var start_color = get_color_for_frequency(start_freq)
    var end_color = get_color_for_frequency(end_freq)
    
    var start_hex = start_color.to_html(false)
    var end_hex = end_color.to_html(false)
    
    return "[gradient start=#" + start_hex + " end=#" + end_hex + "]" + text + "[/gradient]"

# ----- FREQUENCY MANAGEMENT -----
func find_closest_harmonic(frequency: int) -> int:
    # Find the closest harmonic frequency
    var closest = HARMONIC_FREQUENCIES.PRIMARY[0]
    var min_distance = abs(frequency - closest)
    
    # Check primary harmonics
    for freq in HARMONIC_FREQUENCIES.PRIMARY:
        var distance = abs(frequency - freq)
        if distance < min_distance:
            min_distance = distance
            closest = freq
    
    # Check secondary harmonics
    for freq in HARMONIC_FREQUENCIES.SECONDARY:
        var distance = abs(frequency - freq)
        if distance < min_distance:
            min_distance = distance
            closest = freq
    
    return closest

func create_mesh_point_colors() -> Dictionary:
    # Create colors for mesh points
    var result = {
        "centers": [],
        "edges": [],
        "corners": []
    }
    
    for center in MESH_POINTS.CENTERS:
        result.centers.append(get_color_for_frequency(center))
    
    for edge in MESH_POINTS.EDGES:
        result.edges.append(get_color_for_frequency(edge))
    
    for corner in MESH_POINTS.CORNERS:
        result.corners.append(get_color_for_frequency(corner))
    
    return result

# ----- TURN MANAGEMENT -----
func update_turn(turn_number: int, total: int = 12):
    current_turn = turn_number
    total_turns = total
    
    # Update turn color palette if total changed
    if turn_color_palette.size() != total:
        turn_color_palette = []
        for i in range(total):
            var t = i + 1
            var hue = (t - 1) / float(total)
            var turn_color = Color.from_hsv(hue, 0.8, 0.9)
            turn_color_palette.append(turn_color)
    
    # Update frequency system based on turn
    _adjust_frequencies_for_turn(turn_number)

func _adjust_frequencies_for_turn(turn_number: int):
    # Adjust base frequency based on turn
    var turn_frequency = base_frequency + ((turn_number - 1) * 33)
    
    # Update all active animations
    for animation_id in active_animations:
        var animation = active_animations[animation_id]
        
        # Adjust frequency-based animations
        if animation.has("frequency"):
            # Scale frequency based on turn
            animation.frequency = max(animation.frequency, turn_frequency)
        
        # Update colors if needed
        if animation.has("base_color"):
            # Add turn color influence
            var turn_color = get_turn_color(turn_number)
            animation.base_color = animation.base_color.lerp(turn_color, 0.3)

# ----- PUBLIC API -----
func animate_line(line_text: String, target_id, animation_type: int = AnimationType.PULSE, duration: float = default_duration) -> int:
    # Calculate a frequency for the line
    var frequency = base_frequency
    
    # Count special symbols
    for symbol in SYMBOL_FREQUENCIES:
        if line_text.find(symbol) != -1:
            frequency += SYMBOL_FREQUENCIES[symbol]
    
    # Create appropriate animation
    match animation_type:
        AnimationType.FADE:
            var start_color = get_color_for_frequency(frequency)
            var end_color = get_color_for_frequency(find_closest_harmonic(frequency))
            return start_fade_animation(target_id, start_color, end_color, duration)
            
        AnimationType.PULSE:
            var base_color = get_color_for_frequency(frequency)
            var pulse_color = base_color.lightened(0.3)
            return start_pulse_animation(target_id, base_color, pulse_color, duration)
            
        AnimationType.RAINBOW:
            return start_rainbow_animation(target_id, duration)
            
        AnimationType.FLASH:
            var base_color = get_color_for_frequency(frequency)
            var flash_color = Color(1, 1, 1)
            return start_flash_animation(target_id, base_color, flash_color, duration)
            
        AnimationType.GRADIENT:
            var colors = []
            colors.append(get_color_for_frequency(frequency))
            colors.append(get_color_for_frequency(find_closest_harmonic(frequency)))
            colors.append(get_turn_color(current_turn))
            return start_gradient_animation(target_id, colors, [], duration)
            
        AnimationType.SPARKLE:
            var base_color = get_color_for_frequency(frequency)
            var sparkle_color = Color(1, 1, 1)
            return start_sparkle_animation(target_id, base_color, sparkle_color, duration)
            
        AnimationType.WAVE:
            var base_color = get_color_for_frequency(frequency)
            var wave_color = get_turn_color(current_turn)
            return start_wave_animation(target_id, base_color, wave_color, duration)
            
        AnimationType.MESH_POINT:
            # Determine mesh type
            var mesh_type = "edge"
            if MESH_POINTS.CENTERS.has(frequency):
                mesh_type = "center"
            elif MESH_POINTS.CORNERS.has(frequency):
                mesh_type = "corner"
            return start_mesh_point_animation(target_id, frequency, mesh_type, duration)
    
    return -1

func get_animation_info(animation_id: int) -> Dictionary:
    if active_animations.has(animation_id):
        var animation = active_animations[animation_id]
        
        return {
            "id": animation_id,
            "type": animation.type,
            "progress": animation.elapsed_time / animation.duration,
            "target_id": animation.get("target_id", ""),
            "current_color": animation.get("current_color", Color.WHITE)
        }
    
    return {}
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/color_animation_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/color_temperature_projection.gd
# SIZE: 26211 bytes
class_name ColorTemperatureProjection
extends Node

# ----- COLOR CONSTANTS -----
const COLOR_TEMPERATURES = {
    "VERY_COLD": {
        "temperature": -273,
        "color": Color(0.0, 0.4, 1.0, 1.0),  # Deep blue
        "frequency": 999,
        "energy_state": "frozen"
    },
    "COLD": {
        "temperature": -100,
        "color": Color(0.4, 0.7, 1.0, 1.0),  # Light blue
        "frequency": 777,
        "energy_state": "low"
    },
    "COOL": {
        "temperature": 0,
        "color": Color(0.5, 0.5, 0.5, 1.0),  # Gray
        "frequency": 555,
        "energy_state": "neutral"
    },
    "NEUTRAL": {
        "temperature": 25,
        "color": Color(0.8, 0.8, 0.8, 1.0),  # Light gray to white
        "frequency": 389,
        "energy_state": "balanced"
    },
    "WARM": {
        "temperature": 37,
        "color": Color(1.0, 0.8, 0.4, 1.0),  # Light orange
        "frequency": 333,
        "energy_state": "active"
    },
    "HOT": {
        "temperature": 100,
        "color": Color(1.0, 0.6, 0.0, 1.0),  # Orange
        "frequency": 99,
        "energy_state": "excited"
    },
    "VERY_HOT": {
        "temperature": 1000,
        "color": Color(1.0, 0.2, 0.0, 1.0),  # Dark red-orange
        "frequency": 33,
        "energy_state": "intense"
    }
}

const LIGHT_SPECTRUM = {
    "ULTRAVIOLET": {
        "wavelength": [100, 400],  # nanometers
        "visible": false,
        "color": Color(0.5, 0.0, 1.0, 0.5),  # Purple with transparency (not visible)
        "energy": "high"
    },
    "VIOLET": {
        "wavelength": [380, 450],
        "visible": true,
        "color": Color(0.5, 0.0, 1.0, 1.0),  # Purple
        "energy": "high-visible"
    },
    "BLUE": {
        "wavelength": [450, 495],
        "visible": true,
        "color": Color(0.0, 0.0, 1.0, 1.0),  # Blue
        "energy": "medium-high"
    },
    "GREEN": {
        "wavelength": [495, 570],
        "visible": true,
        "color": Color(0.0, 1.0, 0.0, 1.0),  # Green
        "energy": "medium"
    },
    "YELLOW": {
        "wavelength": [570, 590],
        "visible": true,
        "color": Color(1.0, 1.0, 0.0, 1.0),  # Yellow
        "energy": "medium-low"
    },
    "ORANGE": {
        "wavelength": [590, 620],
        "visible": true,
        "color": Color(1.0, 0.5, 0.0, 1.0),  # Orange
        "energy": "low"
    },
    "RED": {
        "wavelength": [620, 750],
        "visible": true,
        "color": Color(1.0, 0.0, 0.0, 1.0),  # Red
        "energy": "very-low"
    },
    "INFRARED": {
        "wavelength": [750, 1000000],
        "visible": false,
        "color": Color(0.5, 0.0, 0.0, 0.5),  # Dark red with transparency (not visible)
        "energy": "thermal"
    }
}

const LUCKY_NUMBERS = [9, 33, 89, 99, 333, 389, 555, 777, 999]

# ----- COMPONENT REFERENCES -----
var terminal_bridge = null
var akashic_system = null
var color_system = null
var migration_system = null
var ethereal_bridge = null

# ----- PROJECTION STATE -----
var current_temperature = 25  # Default to NEUTRAL
var current_color_state = "NEUTRAL"
var current_light_spectrum = "GREEN"
var current_energy_level = "balanced"
var projection_mode = "standard"
var projection_intensity = 1.0
var projection_visible = true
var temperature_gradient = []

# ----- AKASHIC RECORDING -----
var projection_numbers = []
var color_pattern_numbers = []
var temperature_numbers = []
var light_spectrum_numbers = []

# ----- SIGNALS -----
signal temperature_changed(old_temp, new_temp, color)
signal color_state_changed(old_state, new_state, temperature)
signal light_spectrum_shifted(from_spectrum, to_spectrum)
signal energy_level_changed(old_level, new_level)
signal projection_mode_changed(old_mode, new_mode)
signal projection_numbers_recorded(numbers)

# ----- INITIALIZATION -----
func _ready():
    _find_components()
    _initialize_projection()
    _create_temperature_gradient()
    _record_initial_numbers()
    
    print("Color Temperature Projection initialized")

func _find_components():
    # Find TerminalBridgeConnector
    terminal_bridge = get_node_or_null("/root/TerminalBridgeConnector")
    if not terminal_bridge:
        terminal_bridge = _find_node_by_class(get_tree().root, "TerminalBridgeConnector")
    
    # Find AkashicNumberSystem
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    # Find DimensionalColorSystem
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find migration components
    migration_system = get_node_or_null("/root/UnifiedMigrationSystem")
    if not migration_system:
        migration_system = _find_node_by_class(get_tree().root, "UnifiedMigrationSystem")
    
    ethereal_bridge = get_node_or_null("/root/EtherealMigrationBridge")
    if not ethereal_bridge:
        ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealMigrationBridge")
    
    print("Components found: Terminal=%s, Akashic=%s, Color=%s, Migration=%s, Ethereal=%s" % [
        "Yes" if terminal_bridge else "No",
        "Yes" if akashic_system else "No",
        "Yes" if color_system else "No",
        "Yes" if migration_system else "No",
        "Yes" if ethereal_bridge else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_projection():
    # Set initial values
    current_temperature = COLOR_TEMPERATURES.NEUTRAL.temperature
    current_color_state = "NEUTRAL"
    current_light_spectrum = "GREEN"
    current_energy_level = COLOR_TEMPERATURES.NEUTRAL.energy_state
    
    # Register colors with color system if available
    if color_system and color_system.has_method("register_color_palette"):
        # Register temperature colors
        var temp_colors = {}
        for temp_key in COLOR_TEMPERATURES:
            temp_colors[temp_key] = COLOR_TEMPERATURES[temp_key].color
        
        color_system.register_color_palette("temperature", temp_colors)
        
        # Register light spectrum
        var spectrum_colors = {}
        for spectrum_key in LIGHT_SPECTRUM:
            if LIGHT_SPECTRUM[spectrum_key].visible:
                spectrum_colors[spectrum_key] = LIGHT_SPECTRUM[spectrum_key].color
        
        color_system.register_color_palette("spectrum", spectrum_colors)
    
    # Connect to terminal bridge if available
    if terminal_bridge:
        _synchronize_with_terminal()

func _create_temperature_gradient():
    # Create temperature gradient from coldest to hottest
    temperature_gradient = []
    
    # Sort temperature points
    var temp_points = []
    for temp_key in COLOR_TEMPERATURES:
        temp_points.append({
            "key": temp_key,
            "temperature": COLOR_TEMPERATURES[temp_key].temperature
        })
    
    # Sort by temperature
    temp_points.sort_custom(func(a, b): return a.temperature < b.temperature)
    
    # Create gradient
    for point in temp_points:
        temperature_gradient.append({
            "key": point.key,
            "temperature": COLOR_TEMPERATURES[point.key].temperature,
            "color": COLOR_TEMPERATURES[point.key].color,
            "energy_state": COLOR_TEMPERATURES[point.key].energy_state,
            "frequency": COLOR_TEMPERATURES[point.key].frequency
        })
    
    # Register with color system
    if color_system and color_system.has_method("create_gradient"):
        var from_color = temperature_gradient[0].color
        var to_color = temperature_gradient[temperature_gradient.size() - 1].color
        color_system.create_gradient("temperature", from_color, to_color, temperature_gradient.size())

func _record_initial_numbers():
    # Record initial numbers in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        # Record temperature numbers
        for temp_key in COLOR_TEMPERATURES:
            temperature_numbers.append(COLOR_TEMPERATURES[temp_key].temperature)
            temperature_numbers.append(COLOR_TEMPERATURES[temp_key].frequency)
            
            akashic_system.register_number(
                COLOR_TEMPERATURES[temp_key].temperature,
                "temp_" + temp_key
            )
            
            akashic_system.register_number(
                COLOR_TEMPERATURES[temp_key].frequency,
                "freq_" + temp_key
            )
        
        # Record light spectrum numbers
        for spectrum_key in LIGHT_SPECTRUM:
            light_spectrum_numbers.append(LIGHT_SPECTRUM[spectrum_key].wavelength[0])
            light_spectrum_numbers.append(LIGHT_SPECTRUM[spectrum_key].wavelength[1])
            
            akashic_system.register_number(
                LIGHT_SPECTRUM[spectrum_key].wavelength[0],
                "wave_min_" + spectrum_key
            )
            
            akashic_system.register_number(
                LIGHT_SPECTRUM[spectrum_key].wavelength[1],
                "wave_max_" + spectrum_key
            )
        
        # Record lucky numbers
        for lucky_num in LUCKY_NUMBERS:
            projection_numbers.append(lucky_num)
            akashic_system.register_number(lucky_num, "lucky_" + str(lucky_num))
        
        emit_signal("projection_numbers_recorded", projection_numbers)

func _synchronize_with_terminal():
    if not terminal_bridge:
        return
    
    # Get terminal state
    var terminal_temp = terminal_bridge.get_temperature_state()
    var terminal_projection = terminal_bridge.get_current_projection_state()
    
    # Synchronize temperature
    if terminal_temp != current_temperature:
        set_temperature(terminal_temp)
    
    # Synchronize projection
    projection_visible = terminal_projection.active
    
    # Connect signals
    terminal_bridge.connect("temperature_changed", _on_terminal_temperature_changed)
    terminal_bridge.connect("color_shift_detected", _on_terminal_color_shift)
    terminal_bridge.connect("projection_changed", _on_terminal_projection_changed)

# ----- TEMPERATURE AND COLOR MANAGEMENT -----
func set_temperature(temperature):
    var old_temp = current_temperature
    var old_state = current_color_state
    
    # Update temperature
    current_temperature = temperature
    
    # Find closest temperature state
    var closest_key = "NEUTRAL"
    var smallest_diff = 1000000
    
    for temp_key in COLOR_TEMPERATURES:
        var temp_diff = abs(temperature - COLOR_TEMPERATURES[temp_key].temperature)
        if temp_diff < smallest_diff:
            smallest_diff = temp_diff
            closest_key = temp_key
    
    # Set new state
    current_color_state = closest_key
    current_energy_level = COLOR_TEMPERATURES[closest_key].energy_state
    
    # Record in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(temperature, "current_temperature")
        akashic_system.register_number(COLOR_TEMPERATURES[closest_key].frequency, "current_frequency")
    
    # Update color system
    if color_system and color_system.has_method("set_current_color"):
        color_system.set_current_color(COLOR_TEMPERATURES[closest_key].color)
    
    # Emit signals
    emit_signal("temperature_changed", old_temp, temperature, COLOR_TEMPERATURES[closest_key].color)
    
    if old_state != closest_key:
        emit_signal("color_state_changed", old_state, closest_key, temperature)
        emit_signal("energy_level_changed", COLOR_TEMPERATURES[old_state].energy_state, current_energy_level)

func set_color_state(state_key):
    if not COLOR_TEMPERATURES.has(state_key):
        push_warning("Invalid color state: " + state_key)
        return
    
    var old_state = current_color_state
    var old_temp = current_temperature
    
    # Set new state
    current_color_state = state_key
    current_temperature = COLOR_TEMPERATURES[state_key].temperature
    current_energy_level = COLOR_TEMPERATURES[state_key].energy_state
    
    # Record in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(current_temperature, "current_temperature")
        akashic_system.register_number(COLOR_TEMPERATURES[state_key].frequency, "current_frequency")
    
    # Update color system
    if color_system and color_system.has_method("set_current_color"):
        color_system.set_current_color(COLOR_TEMPERATURES[state_key].color)
    
    # Update terminal bridge
    if terminal_bridge:
        terminal_bridge.adjust_temperature(current_temperature - old_temp)
    
    # Emit signals
    emit_signal("color_state_changed", old_state, state_key, current_temperature)
    emit_signal("temperature_changed", old_temp, current_temperature, COLOR_TEMPERATURES[state_key].color)
    emit_signal("energy_level_changed", COLOR_TEMPERATURES[old_state].energy_state, current_energy_level)

func set_light_spectrum(spectrum_key):
    if not LIGHT_SPECTRUM.has(spectrum_key):
        push_warning("Invalid light spectrum: " + spectrum_key)
        return
    
    var old_spectrum = current_light_spectrum
    
    # Set new spectrum
    current_light_spectrum = spectrum_key
    
    # Update color system if visible spectrum
    if LIGHT_SPECTRUM[spectrum_key].visible and color_system and color_system.has_method("set_accent_color"):
        color_system.set_accent_color(LIGHT_SPECTRUM[spectrum_key].color)
    
    # Record in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(LIGHT_SPECTRUM[spectrum_key].wavelength[0], "current_wavelength_min")
        akashic_system.register_number(LIGHT_SPECTRUM[spectrum_key].wavelength[1], "current_wavelength_max")
    
    # Emit signal
    emit_signal("light_spectrum_shifted", old_spectrum, spectrum_key)

func get_temperature_color(temperature):
    # Find closest temperature gradient point
    var closest_idx = 0
    var smallest_diff = 1000000
    
    for i in range(temperature_gradient.size()):
        var temp_diff = abs(temperature - temperature_gradient[i].temperature)
        if temp_diff < smallest_diff:
            smallest_diff = temp_diff
            closest_idx = i
    
    return temperature_gradient[closest_idx].color

func get_spectrum_color(spectrum_key):
    if LIGHT_SPECTRUM.has(spectrum_key):
        return LIGHT_SPECTRUM[spectrum_key].color
    return Color(1.0, 1.0, 1.0, 1.0)  # Default white

# ----- PROJECTION MANAGEMENT -----
func set_projection_mode(mode):
    var old_mode = projection_mode
    projection_mode = mode
    
    # Update terminal bridge
    if terminal_bridge:
        terminal_bridge.toggle_projection(projection_visible, mode)
    
    # Emit signal
    emit_signal("projection_mode_changed", old_mode, mode)

func set_projection_intensity(intensity):
    projection_intensity = clamp(intensity, 0.0, 2.0)
    
    # Update terminal bridge
    if terminal_bridge:
        terminal_bridge.detect_user_action("projection_toggle", {
            "active": projection_visible,
            "type": projection_mode,
            "intensity": projection_intensity
        })

func toggle_projection_visibility(visible = null):
    if visible != null:
        projection_visible = visible
    else:
        projection_visible = !projection_visible
    
    # Update terminal bridge
    if terminal_bridge:
        terminal_bridge.toggle_projection(projection_visible, projection_mode)

func get_projection_state():
    return {
        "mode": projection_mode,
        "intensity": projection_intensity,
        "visible": projection_visible,
        "temperature": current_temperature,
        "color_state": current_color_state,
        "light_spectrum": current_light_spectrum,
        "energy_level": current_energy_level
    }

# ----- AKASHIC NUMBER MANIPULATION -----
func record_color_pattern(color_names):
    # Record color pattern in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        var color_values = []
        
        for color_name in color_names:
            if COLOR_TEMPERATURES.has(color_name):
                color_values.append(COLOR_TEMPERATURES[color_name].frequency)
            elif LIGHT_SPECTRUM.has(color_name):
                var wavelength_avg = (LIGHT_SPECTRUM[color_name].wavelength[0] + LIGHT_SPECTRUM[color_name].wavelength[1]) / 2
                color_values.append(wavelength_avg)
            else:
                color_values.append(0)
        
        # Convert pattern to a single hash number
        var pattern_hash = 0
        for value in color_values:
            pattern_hash = pattern_hash * 31 + value
        
        # Find closest lucky number
        var lucky_number = _find_closest_lucky_number(pattern_hash)
        
        # Register pattern
        akashic_system.register_number(pattern_hash, "color_pattern_hash")
        akashic_system.register_number(lucky_number, "color_pattern_lucky")
        
        color_pattern_numbers.append(pattern_hash)
        projection_numbers.append(lucky_number)
        
        return {
            "pattern_hash": pattern_hash,
            "lucky_number": lucky_number,
            "color_values": color_values
        }
    
    return null

func generate_lucky_number_from_temperature():
    var temp_frequency = 0
    
    # Get frequency for current temperature
    if COLOR_TEMPERATURES.has(current_color_state):
        temp_frequency = COLOR_TEMPERATURES[current_color_state].frequency
    else:
        for temp_key in COLOR_TEMPERATURES:
            var temp_diff = abs(current_temperature - COLOR_TEMPERATURES[temp_key].temperature)
            if temp_diff < 10:
                temp_frequency = COLOR_TEMPERATURES[temp_key].frequency
                break
    
    if temp_frequency == 0:
        temp_frequency = 389  # Default to neutral
    
    # Record in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(temp_frequency, "temperature_frequency")
        projection_numbers.append(temp_frequency)
        
        return temp_frequency
    
    return 0

func _find_closest_lucky_number(value):
    var closest = LUCKY_NUMBERS[0]
    var smallest_diff = abs(value - closest)
    
    for lucky in LUCKY_NUMBERS:
        var diff = abs(value - lucky)
        if diff < smallest_diff:
            smallest_diff = diff
            closest = lucky
    
    return closest

# ----- MIGRATION INTEGRATION -----
func integrate_with_migration_system():
    if not migration_system or not ethereal_bridge:
        return {
            "success": false,
            "error": "Migration components not available",
            "migration_system": migration_system != null,
            "ethereal_bridge": ethereal_bridge != null
        }
    
    # Create color temperature reference in migration system
    var temperature_data = {
        "temperatures": {},
        "lucky_numbers": LUCKY_NUMBERS,
        "light_spectrum": {},
        "current_state": {
            "temperature": current_temperature,
            "color_state": current_color_state,
            "light_spectrum": current_light_spectrum,
            "energy_level": current_energy_level
        }
    }
    
    # Add temperature data
    for temp_key in COLOR_TEMPERATURES:
        temperature_data.temperatures[temp_key] = {
            "temperature": COLOR_TEMPERATURES[temp_key].temperature,
            "frequency": COLOR_TEMPERATURES[temp_key].frequency,
            "energy_state": COLOR_TEMPERATURES[temp_key].energy_state
        }
    
    # Add light spectrum data
    for spectrum_key in LIGHT_SPECTRUM:
        if LIGHT_SPECTRUM[spectrum_key].visible:
            temperature_data.light_spectrum[spectrum_key] = {
                "wavelength_min": LIGHT_SPECTRUM[spectrum_key].wavelength[0],
                "wavelength_max": LIGHT_SPECTRUM[spectrum_key].wavelength[1],
                "energy": LIGHT_SPECTRUM[spectrum_key].energy
            }
    
    # Record with ethereal bridge
    if ethereal_bridge.has_method("_record_node_migration"):
        ethereal_bridge._record_node_migration("ColorTemperatureProjection", "color_system")
    
    # Link terminal bridge with akashic records
    if terminal_bridge and terminal_bridge.has_method("link_akashic_records_to_ethereal"):
        terminal_bridge.link_akashic_records_to_ethereal()
    
    # Link with universes
    if terminal_bridge:
        for i in range(min(LUCKY_NUMBERS.size(), 5)):  # Link to max 5 universes
            var lucky = LUCKY_NUMBERS[i]
            var universe_name = ""
            
            match lucky:
                9, 99: universe_name = "claude_galaxy"
                33: universe_name = "luminous_os"
                89, 389: universe_name = "universe_389"
                333: universe_name = "ethereal_engine"
                555: universe_name = "akashic_records"
                777, 999: universe_name = "dimensional_colors"
            
            if universe_name != "":
                terminal_bridge.connect_to_universe(universe_name)
    
    return {
        "success": true,
        "temperature_states": COLOR_TEMPERATURES.size(),
        "lucky_numbers": LUCKY_NUMBERS.size(),
        "spectrum_colors": LIGHT_SPECTRUM.size(),
        "current_temperature": current_temperature
    }

# ----- EVENT HANDLERS -----
func _on_terminal_temperature_changed(old_temp, new_temp, color):
    # Sync our temperature with terminal
    if current_temperature != new_temp:
        set_temperature(new_temp)

func _on_terminal_color_shift(from_color, to_color, temperature):
    # Find closest color state for the new color
    var closest_key = "NEUTRAL"
    var smallest_diff = 10.0
    
    for temp_key in COLOR_TEMPERATURES:
        var color_diff = COLOR_TEMPERATURES[temp_key].color.distance_to(to_color)
        if color_diff < smallest_diff:
            smallest_diff = color_diff
            closest_key = temp_key
    
    # Update our color state
    if current_color_state != closest_key:
        set_color_state(closest_key)

func _on_terminal_projection_changed(type, intensity):
    projection_mode = type
    projection_intensity = intensity
    projection_visible = true
    
    emit_signal("projection_mode_changed", projection_mode, type)

# ----- PUBLIC API -----
func create_color_temperature_bridge():
    # Setup integration with terminal and migration components
    if terminal_bridge and terminal_bridge.has_method("create_terminal_bridge_with_ethereal"):
        var bridge_result = terminal_bridge.create_terminal_bridge_with_ethereal()
        
        # Generate a lucky number
        var lucky = generate_lucky_number_from_temperature()
        
        # Integrate with migration system
        var migration_result = integrate_with_migration_system()
        
        # Create a color pattern
        var color_pattern = record_color_pattern([
            "NEUTRAL", "WARM", "HOT", 
            "GREEN", "YELLOW", "ORANGE"
        ])
        
        return {
            "success": bridge_result.success && migration_result.success,
            "lucky_number": lucky,
            "color_pattern": color_pattern.pattern_hash if color_pattern else 0,
            "temperature": current_temperature,
            "bridge_timestamp": bridge_result.bridge_timestamp if bridge_result.has("bridge_timestamp") else 0
        }
    
    return {
        "success": false,
        "error": "Terminal bridge not available"
    }

func get_temperature_states():
    return COLOR_TEMPERATURES

func get_light_spectrum_states():
    return LIGHT_SPECTRUM

func get_lucky_numbers():
    return LUCKY_NUMBERS

func get_current_state():
    return {
        "temperature": current_temperature,
        "color_state": current_color_state,
        "light_spectrum": current_light_spectrum,
        "energy_level": current_energy_level,
        "projection_mode": projection_mode,
        "projection_intensity": projection_intensity,
        "projection_visible": projection_visible
    }

func cycle_temperature_up():
    # Find next temperature in gradient
    var current_idx = -1
    
    for i in range(temperature_gradient.size()):
        if temperature_gradient[i].key == current_color_state:
            current_idx = i
            break
    
    if current_idx >= 0:
        var next_idx = (current_idx + 1) % temperature_gradient.size()
        set_color_state(temperature_gradient[next_idx].key)
        return true
    
    return false

func cycle_temperature_down():
    # Find previous temperature in gradient
    var current_idx = -1
    
    for i in range(temperature_gradient.size()):
        if temperature_gradient[i].key == current_color_state:
            current_idx = i
            break
    
    if current_idx >= 0:
        var prev_idx = (current_idx - 1 + temperature_gradient.size()) % temperature_gradient.size()
        set_color_state(temperature_gradient[prev_idx].key)
        return true
    
    return false

func set_temperature_by_lucky_number(lucky_number):
    # Find closest lucky number
    var closest_lucky = _find_closest_lucky_number(lucky_number)
    
    # Find temperature with closest frequency
    var closest_key = "NEUTRAL"
    var smallest_diff = 1000000
    
    for temp_key in COLOR_TEMPERATURES:
        var freq_diff = abs(COLOR_TEMPERATURES[temp_key].frequency - closest_lucky)
        if freq_diff < smallest_diff:
            smallest_diff = freq_diff
            closest_key = temp_key
    
    # Set color state
    set_color_state(closest_key)
    
    return {
        "lucky_number": closest_lucky,
        "color_state": closest_key,
        "temperature": current_temperature
    }
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/color_temperature_projection.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/concurrent_demo.gd
# SIZE: 5930 bytes
extends Node

# Concurrent Demo - Example implementation showing how to use the concurrent processor 
# with terminal memory system to run 2-3 functions simultaneously

var terminal_memory
var concurrent_processor

func _ready():
	# Create the terminal memory system
	terminal_memory = load("res://12_turns_system/terminal_memory_system.gd").new()
	add_child(terminal_memory)
	
	# Get reference to the concurrent processor
	concurrent_processor = terminal_memory.processor
	
	# Display welcome message
	terminal_memory.add_memory_text("Concurrent Demo Initialized", "system")
	terminal_memory.add_memory_text("This demo shows how to run 2-3 functions concurrently", "system")
	terminal_memory.add_memory_text("Type '#run save,load,display' to run 3 functions at once", "system")
	
	# Set up some example data
	setup_example_data()
	
	# Demonstrate concurrent execution
	demonstrate_concurrent_execution()

# Set up some example data for the demo
func setup_example_data():
	terminal_memory.add_memory_text("[past] This is a memory from the past", "general")
	terminal_memory.add_memory_text("[present] This is a current memory", "general")
	terminal_memory.add_memory_text("[future] This is a potential future memory", "general")
	terminal_memory.process_tdic_entry("[past] First entry in temporal dictionary")
	terminal_memory.process_tdic_entry("[present] Current state in temporal dictionary")
	terminal_memory.process_tdic_entry("[future] Future possibility in temporal dictionary")

# Demonstrate the concurrent execution of functions
func demonstrate_concurrent_execution():
	terminal_memory.add_memory_text("DEMONSTRATION: Running multiple functions concurrently", "system")
	
	# Example 1: Run 3 functions in parallel
	terminal_memory.add_memory_text("Example 1: Running 3 functions in parallel", "system")
	
	var functions = ["display_time", "count_entries", "check_system_status"]
	var args_list = [[], [], []]
	
	concurrent_processor.create_parallel_tasks(
		"demo_parallel", 
		self, 
		functions, 
		args_list
	)
	
	# Example 2: Run functions in a chain (one after another)
	yield(get_tree().create_timer(2.0), "timeout")
	terminal_memory.add_memory_text("Example 2: Running functions in sequence", "system")
	
	var chain_functions = ["prepare_data", "process_data", "finalize_data"]
	var chain_args = [[], [], []]
	
	concurrent_processor.create_task_chain(
		"demo_chain",
		self,
		chain_functions,
		chain_args
	)
	
	# Example 3: Mixed priority tasks
	yield(get_tree().create_timer(4.0), "timeout")
	terminal_memory.add_memory_text("Example 3: Tasks with different priorities", "system")
	
	concurrent_processor.schedule_task(
		"low_priority", 
		self, 
		"long_running_task", 
		["Low priority task"], 
		ConcurrentProcessor.Priority.LOW
	)
	
	concurrent_processor.schedule_task(
		"high_priority", 
		self, 
		"quick_task", 
		["High priority task"], 
		ConcurrentProcessor.Priority.HIGH
	)
	
	concurrent_processor.schedule_task(
		"medium_priority", 
		self, 
		"medium_task", 
		["Medium priority task"], 
		ConcurrentProcessor.Priority.MEDIUM
	)

# Example function: Display current time
func display_time():
	var datetime = OS.get_datetime()
	var time_str = "%02d:%02d:%02d" % [datetime.hour, datetime.minute, datetime.second]
	terminal_memory.add_memory_text("Current time: " + time_str, "system")
	return time_str

# Example function: Count entries in TDIC
func count_entries():
	var past_count = terminal_memory.tdic_entries.past.size()
	var present_count = terminal_memory.tdic_entries.present.size()
	var future_count = terminal_memory.tdic_entries.future.size()
	var total = past_count + present_count + future_count
	
	terminal_memory.add_memory_text("TDIC entry count: %d total (%d past, %d present, %d future)" % 
		[total, past_count, present_count, future_count], "system")
	
	return total

# Example function: Check system status
func check_system_status():
	var status = "Operational"
	terminal_memory.add_memory_text("System status: " + status, "system")
	return status

# Chain example: Step 1 - Prepare data
func prepare_data():
	terminal_memory.add_memory_text("Step 1: Preparing data...", "system")
	yield(get_tree().create_timer(0.5), "timeout")
	return {"status": "prepared", "timestamp": OS.get_unix_time()}

# Chain example: Step 2 - Process data
func process_data():
	terminal_memory.add_memory_text("Step 2: Processing data...", "system")
	yield(get_tree().create_timer(0.5), "timeout")
	return {"status": "processed", "operations": 5}

# Chain example: Step 3 - Finalize data
func finalize_data():
	terminal_memory.add_memory_text("Step 3: Finalizing data...", "system")
	yield(get_tree().create_timer(0.5), "timeout")
	terminal_memory.add_memory_text("Data processing complete!", "system")
	return {"status": "completed", "success": true}

# Priority example: Low priority, long-running task
func long_running_task(message):
	terminal_memory.add_memory_text("Starting: " + message, "system")
	yield(get_tree().create_timer(1.5), "timeout")
	terminal_memory.add_memory_text("Completed: " + message, "system")
	return "Long task completed"

# Priority example: Medium priority task
func medium_task(message):
	terminal_memory.add_memory_text("Starting: " + message, "system")
	yield(get_tree().create_timer(1.0), "timeout")
	terminal_memory.add_memory_text("Completed: " + message, "system")
	return "Medium task completed"

# Priority example: High priority, quick task
func quick_task(message):
	terminal_memory.add_memory_text("Starting: " + message, "system")
	yield(get_tree().create_timer(0.5), "timeout")
	terminal_memory.add_memory_text("Completed: " + message, "system")
	return "Quick task completed"

# Input handling
func _input(event):
	if event is InputEventKey and event.pressed and event.scancode == KEY_SPACE:
		# Demonstrate running multiple functions with the '#run' command
		terminal_memory._on_text_entered("#run display_time,count_entries,check_system_status")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/concurrent_demo.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/concurrent_processor.gd
# SIZE: 6598 bytes
extends Node

# Concurrent Function Processor for Terminal Memory System
# Allows running 2-3 functions concurrently with priority and dependency management

class_name ConcurrentProcessor

# Task priority levels
enum Priority { LOW, MEDIUM, HIGH, CRITICAL }

# Task status tracking
enum TaskStatus { PENDING, RUNNING, COMPLETED, FAILED, CANCELED }

# Task structure for function processing
class Task:
	var id: String
	var function_ref: FuncRef
	var args: Array
	var priority: int
	var dependencies: Array
	var status: int
	var result = null
	var error_message: String = ""
	var start_time: int = 0
	var end_time: int = 0
	
	func _init(p_id: String, p_function: FuncRef, p_args: Array = [], p_priority: int = Priority.MEDIUM):
		id = p_id
		function_ref = p_function
		args = p_args
		priority = p_priority
		status = TaskStatus.PENDING
		dependencies = []
	
	func add_dependency(task_id: String) -> void:
		dependencies.append(task_id)
	
	func can_run(completed_tasks: Array) -> bool:
		if status != TaskStatus.PENDING:
			return false
			
		# Check if all dependencies are completed
		for dep in dependencies:
			if not completed_tasks.has(dep):
				return false
				
		return true
	
	func execute() -> void:
		status = TaskStatus.RUNNING
		start_time = OS.get_ticks_msec()
		
		if function_ref.is_valid():
			# Execute with variable number of arguments
			match args.size():
				0: result = function_ref.call_func()
				1: result = function_ref.call_func(args[0])
				2: result = function_ref.call_func(args[0], args[1])
				3: result = function_ref.call_func(args[0], args[1], args[2])
				4: result = function_ref.call_func(args[0], args[1], args[2], args[3])
				_: 
					# For more args, use call_funcv
					result = function_ref.call_funcv(args)
			
			status = TaskStatus.COMPLETED
		else:
			error_message = "Invalid function reference"
			status = TaskStatus.FAILED
			
		end_time = OS.get_ticks_msec()

# Main processor properties
var max_concurrent_tasks: int = 3
var task_queue: Array = []
var running_tasks: Array = []
var completed_tasks: Array = []
var failed_tasks: Array = []
var completed_task_ids: Array = []

# Signals
signal task_started(task_id)
signal task_completed(task_id, result)
signal task_failed(task_id, error)
signal all_tasks_completed()

func _ready() -> void:
	# Set up processing thread or timer for continuous execution
	var process_timer = Timer.new()
	process_timer.wait_time = 0.05  # 50ms intervals for processing
	process_timer.autostart = true
	process_timer.connect("timeout", self, "_process_tasks")
	add_child(process_timer)

# Create a new task and add it to the queue
func schedule_task(id: String, function_object: Object, function_name: String, 
				  args: Array = [], priority: int = Priority.MEDIUM) -> Task:
	var func_ref = funcref(function_object, function_name)
	var task = Task.new(id, func_ref, args, priority)
	
	task_queue.append(task)
	# Sort by priority (higher priority first)
	task_queue.sort_custom(self, "_compare_task_priority")
	
	return task

# Execute 2-3 functions at once based on priority and dependencies
func _process_tasks() -> void:
	# First, update status of running tasks
	var i = running_tasks.size() - 1
	while i >= 0:
		var task = running_tasks[i]
		
		if task.status == TaskStatus.COMPLETED:
			running_tasks.remove(i)
			completed_tasks.append(task)
			completed_task_ids.append(task.id)
			emit_signal("task_completed", task.id, task.result)
			
		elif task.status == TaskStatus.FAILED:
			running_tasks.remove(i)
			failed_tasks.append(task)
			emit_signal("task_failed", task.id, task.error_message)
			
		i -= 1
	
	# Start new tasks if we have capacity
	while running_tasks.size() < max_concurrent_tasks and not task_queue.empty():
		var next_task_index = _find_next_executable_task()
		
		if next_task_index >= 0:
			var task = task_queue[next_task_index]
			task_queue.remove(next_task_index)
			running_tasks.append(task)
			
			# Execute in thread or directly
			_execute_task(task)
			emit_signal("task_started", task.id)
		else:
			# No tasks can run right now
			break
	
	# Check if all tasks are complete
	if task_queue.empty() and running_tasks.empty():
		emit_signal("all_tasks_completed")

# Find index of next task that can be executed based on dependencies
func _find_next_executable_task() -> int:
	for i in range(task_queue.size()):
		if task_queue[i].can_run(completed_task_ids):
			return i
	return -1

# Execute a task (in thread if supported)
func _execute_task(task: Task) -> void:
	# In Godot 3.x, we don't have easy threading for GDScript functions
	# So we'll execute directly in this example
	task.execute()
	
	# For thread support in real implementation, use:
	# var thread = Thread.new()
	# thread.start(self, "_thread_execute_task", task)

# Thread execution function (for thread support)
func _thread_execute_task(task: Task) -> void:
	task.execute()
	# Note: In a real implementation, you'd need a mutex
	# to protect shared data and signals

# Compare function for sorting by priority
func _compare_task_priority(a: Task, b: Task) -> bool:
	return a.priority > b.priority

# Create a chain of dependent tasks
func create_task_chain(base_id: String, object: Object, function_names: Array, 
					  args_list: Array = [], priority: int = Priority.MEDIUM) -> Array:
	var tasks = []
	var prev_task_id = ""
	
	for i in range(function_names.size()):
		var task_id = base_id + "_" + str(i)
		var args = args_list[i] if i < args_list.size() else []
		
		var task = schedule_task(task_id, object, function_names[i], args, priority)
		if prev_task_id != "":
			task.add_dependency(prev_task_id)
			
		tasks.append(task)
		prev_task_id = task_id
		
	return tasks

# Create parallel tasks to be executed concurrently
func create_parallel_tasks(base_id: String, object: Object, function_names: Array,
						  args_list: Array = [], priority: int = Priority.MEDIUM) -> Array:
	var tasks = []
	
	for i in range(function_names.size()):
		var task_id = base_id + "_parallel_" + str(i)
		var args = args_list[i] if i < args_list.size() else []
		
		var task = schedule_task(task_id, object, function_names[i], args, priority)
		tasks.append(task)
		
	return tasks

# Cancel a specific task if it hasn't started yet
func cancel_task(task_id: String) -> bool:
	for i in range(task_queue.size()):
		if task_queue[i].id == task_id:
			task_queue[i].status = TaskStatus.CANCELED
			task_queue.remove(i)
			return true
	return false

# Set the maximum number of concurrent tasks
func set_max_concurrent_tasks(value: int) -> void:
	max_concurrent_tasks = clamp(value, 1, 10)  # Limit to reasonable range
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/concurrent_processor.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/connection_visualizer.gd
# SIZE: 6127 bytes
extends Node2D
class_name ConnectionVisualizer

# Visual representation of file connections using your preferred format
# Displays connections between different file categories with hash symbols and colors

# Reference to snake_case translator
var translator

# Color coding for different file categories
var category_colors = {
  "main": Color(0.2, 0.6, 0.8),       # Blue
  "datapoint": Color(0.8, 0.6, 0.2),  # Orange
  "container": Color(0.8, 0.3, 0.7),  # Purple
  "archive": Color(0.3, 0.7, 0.4),    # Green
  "past": Color(0.7, 0.2, 0.3),       # Red
  "memories": Color(0.8, 0.8, 0.2),   # Yellow
  "3d_notepad": Color(0.4, 0.8, 0.8)  # Cyan
}

# Node positions for different categories
var category_positions = {
  "main": Vector2(400, 100),
  "datapoint": Vector2(200, 200),
  "container": Vector2(600, 200),
  "archive": Vector2(300, 300),
  "past": Vector2(500, 300),
  "memories": Vector2(300, 400),
  "3d_notepad": Vector2(500, 400)
}

# Node size for each category
var category_node_sizes = {
  "main": 40,
  "datapoint": 30,
  "container": 35,
  "archive": 30,
  "past": 30,
  "memories": 35,
  "3d_notepad": 35
}

# File nodes by category
var file_nodes = {}

# Connection lines
var connection_lines = []

# Hash symbols for display
var hash_symbols = {
  "#": "‚Ä¢",
  "##": "‚Ä¢‚Ä¢",
  "###": "‚Ä¢‚Ä¢‚Ä¢",
  "#_": "‚Ä¢_"
}

# Initialize the visualizer
func _ready():
  print("Connection Visualizer initialized")
  
  # Get reference to snake_case translator
  translator = get_node("../SnakeCaseTranslator")
  if translator == null:
    print("WARNING: SnakeCaseTranslator not found, visualization will be limited")
    return
  
  # Create nodes for each file
  _create_file_nodes()
  
  # Create connection lines
  _create_connection_lines()

# Draw the visualization
func _draw():
  # Draw connection lines first (background)
  for connection in connection_lines:
    draw_line(connection.start_pos, connection.end_pos, connection.color, 2.0)
    
    # Draw hash symbol in the middle of the line
    var mid_point = connection.start_pos.linear_interpolate(connection.end_pos, 0.5)
    var hash_symbol = hash_symbols.get(connection.hash_symbol, "‚Ä¢")
    var symbol_offset = Vector2(-5, -5) # Offset to center the text
    draw_string(get_font("font"), mid_point + symbol_offset, hash_symbol, Color.WHITE)
  
  # Draw file nodes (foreground)
  for category in file_nodes:
    var color = category_colors[category]
    
    for node in file_nodes[category]:
      # Draw node circle
      draw_circle(node.position, node.size, color)
      
      # Draw node label
      var label_offset = Vector2(-node.name.length() * 3, node.size + 10)
      draw_string(get_font("font"), node.position + label_offset, node.name, Color.WHITE)

# Create nodes for each file
func _create_file_nodes():
  for category in translator.category_mappings:
    var files = translator.category_mappings[category]
    var base_position = category_positions[category]
    var node_size = category_node_sizes[category]
    
    file_nodes[category] = []
    
    # Calculate spacing based on number of files
    var spacing = 80.0
    var total_width = (files.size() - 1) * spacing
    var start_x = base_position.x - (total_width / 2)
    
    for i in range(files.size()):
      var file_node = {
        "name": files[i],
        "position": Vector2(start_x + (i * spacing), base_position.y),
        "size": node_size,
        "category": category
      }
      
      file_nodes[category].append(file_node)

# Create connection lines between nodes
func _create_connection_lines():
  var connection_map = translator.build_hash_connection_map()
  
  # Create connections for each source file
  for source in connection_map:
    var source_category = translator.get_file_category(source)
    var source_node = _find_node_by_name(source)
    
    if source_node == null:
      continue
      
    # Create connections to target files
    for target in connection_map[source]:
      var target_category = translator.get_file_category(target)
      var target_node = _find_node_by_name(target)
      
      if target_node == null:
        continue
      
      # Create hash connection
      var hash_symbol = translator.get_hash_connector(source)
      
      # Create connection line
      var connection = {
        "start_pos": source_node.position,
        "end_pos": target_node.position,
        "color": category_colors[source_category].linear_interpolate(category_colors[target_category], 0.5),
        "source": source,
        "target": target,
        "hash_symbol": hash_symbol
      }
      
      connection_lines.append(connection)

# Find a node by its name
func _find_node_by_name(name: String) -> Dictionary:
  for category in file_nodes:
    for node in file_nodes[category]:
      if node.name == name:
        return node
  
  return {}

# Save visualization as image
func save_visualization(path: String) -> bool:
  # Request redraw to ensure everything is updated
  queue_redraw()
  
  # Wait for redraw to complete
  await get_tree().process_frame
  
  # Capture the visualization as an image
  var viewport = get_viewport()
  var image = viewport.get_texture().get_data()
  
  # Save the image
  return image.save_png(path)

# Generate a textual map of the visualization
func generate_text_map() -> String:
  var text_map = "# Connection Visualization Map\n\n"
  
  # Add categories
  for category in file_nodes:
    text_map += "## " + category + " Files\n\n"
    
    for node in file_nodes[category]:
      text_map += "- " + node.name + "\n"
    
    text_map += "\n"
  
  # Add connections
  text_map += "## Connections\n\n"
  
  for connection in connection_lines:
    var hash_symbol = hash_symbols.get(connection.hash_symbol, "‚Ä¢")
    text_map += "- " + connection.source + " " + hash_symbol + " " + connection.target + "\n"
  
  return text_map

# Save text map
func save_text_map(path: String) -> bool:
  var text_map = generate_text_map()
  var file = FileAccess.open(path, FileAccess.WRITE)
  
  if file == null:
    return false
    
  file.store_string(text_map)
  file.close()
  return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/connection_visualizer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/connector_test.gd
# SIZE: 3922 bytes
extends Node

# Universal Connector Test Script

func _ready():
	print("Starting Universal Connector Test")
	
	# Create connector instance
	var connector = UniversalConnector.new()
	add_child(connector)
	
	# Connect signals
	connector.connect("connector_initialized", self, "_on_connector_initialized")
	connector.connect("app_connected", self, "_on_app_connected")
	connector.connect("app_disconnected", self, "_on_app_disconnected")
	connector.connect("drive_connected", self, "_on_drive_connected")
	connector.connect("data_transferred", self, "_on_data_transferred")
	connector.connect("shortcut_triggered", self, "_on_shortcut_triggered")
	
	# Wait for initialization
	yield(get_tree().create_timer(1.0), "timeout")
	
	# Run tests
	test_connections(connector)
	test_shortcuts(connector)
	test_data_transfer(connector)
	test_drive_connections(connector)
	
	# Get status
	print("\nConnector Status:")
	var status = connector.get_status()
	print(status)
	
	print("\nTest completed")

func test_connections(connector):
	print("\n=== Testing App Connections ===")
	
	# Connect to apps
	var apps = ["claude", "terminal", "ethereal_engine", "akashic_records"]
	
	for app in apps:
		var result = connector.connect_app(app)
		print("Connection to " + app + ": " + str(result))
	
	# Try to connect to an already connected app
	print("Reconnecting to claude: " + str(connector.connect_app("claude")))
	
	# Disconnect from an app
	print("Disconnecting from terminal: " + str(connector.disconnect_app("terminal")))
	
	# Try to disconnect from an already disconnected app
	print("Disconnecting from terminal again: " + str(connector.disconnect_app("terminal")))

func test_shortcuts(connector):
	print("\n=== Testing Shortcuts ===")
	
	# Register a custom shortcut
	var result = connector.register_shortcut("test_shortcut", "ctrl+t", self, "_on_test_shortcut")
	print("Register custom shortcut: " + str(result))
	
	# Try to register the same shortcut again
	result = connector.register_shortcut("test_shortcut", "ctrl+t", self, "_on_test_shortcut")
	print("Register duplicate shortcut: " + str(result))
	
	# Trigger universal connector
	print("Triggering universal connector: " + str(connector.trigger_universal_connector()))

func test_data_transfer(connector):
	print("\n=== Testing Data Transfer ===")
	
	# Ensure apps are connected
	connector.connect_app("claude")
	connector.connect_app("ethereal_engine")
	
	# Transfer text data
	var text_data = "This is a test message from claude to ethereal engine"
	var result = connector.transfer_data("claude", "ethereal_engine", "text", text_data)
	print("Text transfer result: " + str(result != null))
	
	# Try invalid transfer
	connector.disconnect_app("ethereal_engine")
	result = connector.transfer_data("claude", "ethereal_engine", "text", text_data)
	print("Invalid transfer result: " + str(result != null))

func test_drive_connections(connector):
	print("\n=== Testing Drive Connections ===")
	
	# Connect drives
	var result = connector.connect_drives("C", "D")
	print("C to D connection: " + str(result))
	
	# Try invalid drive connection
	result = connector.connect_drives("X", "Y")
	print("Invalid drive connection: " + str(result))

# Signal handlers

func _on_connector_initialized(status):
	print("Connector initialized with status: " + str(status.success))
	if not status.success:
		print("Error: " + status.error)

func _on_app_connected(app_name):
	print("App connected: " + app_name)

func _on_app_disconnected(app_name):
	print("App disconnected: " + app_name)

func _on_drive_connected(source, target):
	print("Drive connected: " + source + " to " + target)

func _on_data_transferred(source, target, bytes):
	print("Data transferred: " + str(bytes) + " bytes from " + source + " to " + target)

func _on_shortcut_triggered(shortcut_name):
	print("Shortcut triggered: " + shortcut_name)

func _on_test_shortcut():
	print("Test shortcut handler called")
	return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/connector_test.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/core/thread_manager.gd
# SIZE: 11640 bytes
extends Node
class_name ThreadManager

# Thread Manager for the 12 Turns System
# Handles multi-threaded processing across cores
# Follows snake_case naming convention

# Signal emitted when a task completes
signal task_completed(task_id, result)
# Signal emitted when all tasks in a group complete
signal task_group_completed(group_id)
# Signal emitted when a task fails
signal task_failed(task_id, error)

# Thread pool and management
var worker_threads = []
var thread_count = 0
var available_thread_count = 0
var thread_mutex = Mutex.new()

# Task management
var task_queue = []
var task_results = {}
var task_groups = {}
var queue_mutex = Mutex.new()
var task_semaphore = Semaphore.new()

# Thread status tracking
var thread_status = []
var exit_threads = false

# Statistics and monitoring
var stats = {
	"tasks_processed": 0,
	"tasks_failed": 0,
	"avg_processing_time": 0.0,
	"max_processing_time": 0.0,
	"current_queue_size": 0
}

func _init(thread_count_override = -1):
	# Determine thread count (auto or manual)
	if thread_count_override > 0:
		thread_count = thread_count_override
	else:
		# Use one less than the number of cores (leave one for main thread)
		thread_count = max(1, OS.get_processor_count() - 1)
	
	available_thread_count = thread_count
	
	# Initialize thread status tracking
	thread_status.resize(thread_count)
	for i in range(thread_count):
		thread_status[i] = {
			"status": "initializing",
			"current_task": null,
			"tasks_processed": 0,
			"processing_time": 0.0
		}
	
	print("Thread manager initialized with %d worker threads" % thread_count)

func _ready():
	# Start worker threads
	_start_threads()

func _exit_tree():
	# Clean shutdown of threads
	_stop_threads()

func _start_threads():
	# Create and start worker threads
	exit_threads = false
	worker_threads.resize(thread_count)
	
	for i in range(thread_count):
		worker_threads[i] = Thread.new()
		var result = worker_threads[i].start(Callable(self, "_thread_function").bind(i))
		
		if result != OK:
			push_error("Failed to start worker thread %d" % i)
			thread_status[i].status = "failed"
		else:
			thread_status[i].status = "idle"
			print("Worker thread %d started" % i)

func _stop_threads():
	# Signal all threads to exit
	exit_threads = true
	
	# Wake up all threads to check exit condition
	for i in range(thread_count):
		task_semaphore.post()
	
	# Wait for all threads to finish
	for i in range(worker_threads.size()):
		if worker_threads[i].is_started():
			worker_threads[i].wait_to_finish()
	
	print("All worker threads stopped")

# Main thread function executed by each worker thread
func _thread_function(thread_id):
	print("Worker thread %d running" % thread_id)
	
	while true:
		# Wait for a task or exit signal
		task_semaphore.wait()
		
		# Check if we should exit
		if exit_threads:
			thread_status[thread_id].status = "exiting"
			print("Worker thread %d exiting" % thread_id)
			break
		
		# Try to get a task from the queue
		var task = null
		
		queue_mutex.lock()
		if task_queue.size() > 0:
			task = task_queue.pop_front()
			stats.current_queue_size = task_queue.size()
		queue_mutex.unlock()
		
		# If no task was available, go back to waiting
		if task == null:
			thread_status[thread_id].status = "idle"
			continue
		
		# We have a task, update status
		thread_status[thread_id].status = "processing"
		thread_status[thread_id].current_task = task.id
		
		# Process the task
		var start_time = Time.get_ticks_msec()
		var result = null
		var error = null
		
		thread_mutex.lock()
		available_thread_count -= 1
		thread_mutex.unlock()
		
		# Try to execute the task
		try:
			# Different handling based on parameters
			if task.params != null:
				result = task.callable.call(task.params)
			else:
				result = task.callable.call()
		catch(e):
			error = e
			print("Error in thread %d processing task %s: %s" % [thread_id, task.id, e])
		
		thread_mutex.lock()
		available_thread_count += 1
		thread_mutex.unlock()
		
		# Calculate processing time
		var end_time = Time.get_ticks_msec()
		var processing_time = end_time - start_time
		
		# Update thread statistics
		thread_status[thread_id].tasks_processed += 1
		thread_status[thread_id].processing_time += processing_time
		thread_status[thread_id].current_task = null
		thread_status[thread_id].status = "idle"
		
		# Store the result and notify the main thread
		queue_mutex.lock()
		
		# Update global statistics
		stats.tasks_processed += 1
		stats.avg_processing_time = ((stats.avg_processing_time * (stats.tasks_processed - 1)) + processing_time) / stats.tasks_processed
		stats.max_processing_time = max(stats.max_processing_time, processing_time)
		
		if error != null:
			stats.tasks_failed += 1
			task_results[task.id] = {
				"status": "failed",
				"error": error,
				"processing_time": processing_time
			}
			
			# Schedule signal emission on main thread
			call_deferred("_emit_task_failed", task.id, error)
		else:
			task_results[task.id] = {
				"status": "completed",
				"result": result,
				"processing_time": processing_time
			}
			
			# Schedule signal emission on main thread
			call_deferred("_emit_task_completed", task.id, result)
		
		# Handle task groups
		if task.group_id != null:
			if not task_groups.has(task.group_id):
				task_groups[task.group_id] = {
					"total": 0,
					"completed": 0,
					"failed": 0
				}
			
			task_groups[task.group_id].completed += 1
			
			# Check if group is complete
			if task_groups[task.group_id].completed >= task_groups[task.group_id].total:
				call_deferred("_emit_task_group_completed", task.group_id)
		
		queue_mutex.unlock()

# Add a task to the queue
func add_task(callable, params = null, group_id = null) -> String:
	if not callable is Callable:
		push_error("Invalid callable provided to add_task")
		return ""
	
	var task_id = _generate_task_id()
	
	queue_mutex.lock()
	
	# Add task to queue
	task_queue.append({
		"id": task_id,
		"callable": callable,
		"params": params,
		"group_id": group_id,
		"creation_time": Time.get_ticks_msec()
	})
	
	stats.current_queue_size = task_queue.size()
	
	# Track in group if applicable
	if group_id != null:
		if not task_groups.has(group_id):
			task_groups[group_id] = {
				"total": 0,
				"completed": 0,
				"failed": 0
			}
		task_groups[group_id].total += 1
	
	queue_mutex.unlock()
	
	# Signal a thread that work is available
	task_semaphore.post()
	
	return task_id

# Add multiple tasks from an array of parameters
func add_batch_tasks(callable, param_array, group_id = null) -> Array:
	if not callable is Callable:
		push_error("Invalid callable provided to add_batch_tasks")
		return []
	
	if param_array == null or param_array.size() == 0:
		push_error("Empty parameter array provided to add_batch_tasks")
		return []
	
	var task_ids = []
	var batch_group_id = group_id if group_id != null else _generate_task_id()
	
	queue_mutex.lock()
	
	# Initialize group tracking
	if not task_groups.has(batch_group_id):
		task_groups[batch_group_id] = {
			"total": 0,
			"completed": 0,
			"failed": 0
		}
	
	# Add all tasks to queue
	for params in param_array:
		var task_id = _generate_task_id()
		
		task_queue.append({
			"id": task_id,
			"callable": callable,
			"params": params,
			"group_id": batch_group_id,
			"creation_time": Time.get_ticks_msec()
		})
		
		task_ids.append(task_id)
		task_groups[batch_group_id].total += 1
	
	stats.current_queue_size = task_queue.size()
	
	queue_mutex.unlock()
	
	# Signal threads that work is available (once per task)
	for i in range(param_array.size()):
		task_semaphore.post()
	
	return task_ids

# Check if a task has completed
func is_task_completed(task_id) -> bool:
	queue_mutex.lock()
	var completed = task_results.has(task_id) and task_results[task_id].status == "completed"
	queue_mutex.unlock()
	
	return completed

# Check if a task has failed
func is_task_failed(task_id) -> bool:
	queue_mutex.lock()
	var failed = task_results.has(task_id) and task_results[task_id].status == "failed"
	queue_mutex.unlock()
	
	return failed

# Get task result (blocking)
func get_task_result(task_id):
	# Wait until the task is completed
	while not is_task_completed(task_id) and not is_task_failed(task_id):
		OS.delay_msec(5)
	
	queue_mutex.lock()
	var result = null
	
	if task_results.has(task_id):
		if task_results[task_id].status == "completed":
			result = task_results[task_id].result
		else:
			result = {"error": task_results[task_id].error}
	
	queue_mutex.unlock()
	
	return result

# Get task result (non-blocking)
func try_get_task_result(task_id):
	queue_mutex.lock()
	var result = null
	
	if task_results.has(task_id):
		if task_results[task_id].status == "completed":
			result = task_results[task_id].result
		else:
			result = {"error": task_results[task_id].error}
	
	queue_mutex.unlock()
	
	return result

# Check if all tasks in a group have completed
func is_group_completed(group_id) -> bool:
	queue_mutex.lock()
	
	var completed = false
	if task_groups.has(group_id):
		completed = task_groups[group_id].completed >= task_groups[group_id].total
	
	queue_mutex.unlock()
	
	return completed

# Wait for all tasks in a group to complete
func wait_for_group(group_id) -> void:
	while not is_group_completed(group_id):
		OS.delay_msec(5)

# Clear completed task results to free memory
func clear_completed_tasks() -> void:
	queue_mutex.lock()
	
	var keys_to_remove = []
	for task_id in task_results:
		keys_to_remove.append(task_id)
	
	for key in keys_to_remove:
		task_results.erase(key)
	
	queue_mutex.unlock()

# Clear completed groups to free memory
func clear_completed_groups() -> void:
	queue_mutex.lock()
	
	var keys_to_remove = []
	for group_id in task_groups:
		if task_groups[group_id].completed >= task_groups[group_id].total:
			keys_to_remove.append(group_id)
	
	for key in keys_to_remove:
		task_groups.erase(key)
	
	queue_mutex.unlock()

# Get current statistics
func get_statistics() -> Dictionary:
	queue_mutex.lock()
	var current_stats = stats.duplicate()
	queue_mutex.unlock()
	
	thread_mutex.lock()
	current_stats.thread_count = thread_count
	current_stats.available_threads = available_thread_count
	thread_mutex.unlock()
	
	return current_stats

# Get thread status information
func get_thread_status() -> Array:
	var status_copy = []
	
	for i in range(thread_status.size()):
		status_copy.append(thread_status[i].duplicate())
	
	return status_copy

# Generate a unique task ID
func _generate_task_id() -> String:
	return "%d_%d" % [Time.get_ticks_msec(), randi() % 1000000]

# These functions are called on the main thread via call_deferred
func _emit_task_completed(task_id, result):
	emit_signal("task_completed", task_id, result)

func _emit_task_failed(task_id, error):
	emit_signal("task_failed", task_id, error)

func _emit_task_group_completed(group_id):
	emit_signal("task_group_completed", group_id)

# Example usage functions

# Sample CPU-intensive task: calculate prime numbers up to n
func calculate_primes(n):
	var primes = []
	for i in range(2, n + 1):
		var is_prime = true
		for j in range(2, int(sqrt(i)) + 1):
			if i % j == 0:
				is_prime = false
				break
		if is_prime:
			primes.append(i)
	return primes

# Helper function to print task results
func debug_task_result(task_id, result):
	print("Task %s completed with result: %s" % [task_id, result])

# Helper function to print task errors
func debug_task_error(task_id, error):
	print("Task %s failed with error: %s" % [task_id, error])

# Usage example in _ready():
# var task_id = add_task(Callable(self, "calculate_primes").bind(10000))
# connect("task_completed", Callable(self, "debug_task_result"))
# connect("task_failed", Callable(self, "debug_task_error"))
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/core/thread_manager.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/core/word_processor_tasks.gd
# SIZE: 10389 bytes
extends Node
class_name WordProcessorTasks

# Word processor functions designed for multi-threaded execution
# Each function is designed to be run as a separate task in ThreadManager
# All naming follows snake_case convention

# Constants for word power calculation
const POWER_TIERS = {
	"TRIVIAL": {"min": 0, "max": 10, "color": Color(0.5, 0.5, 0.5)},
	"MINOR": {"min": 10, "max": 50, "color": Color(0.0, 0.7, 1.0)},
	"MAJOR": {"min": 50, "max": 100, "color": Color(0.0, 1.0, 0.5)},
	"EXCEPTIONAL": {"min": 100, "max": 200, "color": Color(1.0, 0.8, 0.0)},
	"DIVINE": {"min": 200, "max": 1000, "color": Color(1.0, 1.0, 1.0)}
}

# Special word power dictionary
const WORD_POWER = {
	"god": 100,
	"divine": 75,
	"eternal": 50,
	"create": 40,
	"reality": 35,
	"energy": 30,
	"power": 25,
	"light": 20,
	"dark": 20,
	"universe": 40,
	"life": 45,
	"death": 45,
	"soul": 40,
	"mind": 35,
	"spirit": 40,
	"time": 45,
	"space": 45,
	"dimension": 50
}

# Word opposites for connection calculation
const WORD_OPPOSITES = {
	"light": "dark",
	"create": "destroy",
	"life": "death",
	"good": "evil",
	"order": "chaos",
	"above": "below",
	"open": "closed"
}

# Word evolution stages
const EVOLUTION_STAGES = {
	0: {"name": "Nascent", "multiplier": 1.0},
	1: {"name": "Forming", "multiplier": 1.5},
	2: {"name": "Manifesting", "multiplier": 2.0},
	3: {"name": "Stabilizing", "multiplier": 2.5},
	4: {"name": "Transcendent", "multiplier": 3.0}
}

# Dimension multipliers for word power
const DIMENSION_MULTIPLIERS = [
	1.0,  # 1D - Point
	1.2,  # 2D - Line
	1.5,  # 3D - Space
	1.8,  # 4D - Time
	2.0,  # 5D - Consciousness
	2.2,  # 6D - Connection
	2.5,  # 7D - Creation
	2.8,  # 8D - Network
	3.0,  # 9D - Harmony
	3.5,  # 10D - Unity
	4.0,  # 11D - Transcendence
	5.0   # 12D - Beyond
]

# Task: Calculate word power
# This can be distributed to worker threads
func calculate_word_power(params: Dictionary) -> Dictionary:
	var word = params.get("word", "")
	var dimension = params.get("dimension", 0)
	
	# Clean the word
	word = word.strip_edges().to_lower()
	
	# Get base power
	var power = _get_base_power(word)
	
	# Apply dimension modifier
	power = _apply_dimension_modifier(power, dimension)
	
	# Apply cosmic age modifier if provided
	if params.has("cosmic_age"):
		power = _apply_cosmic_age_modifier(power, params.cosmic_age)
	
	# Apply evolution stage modifier if provided
	if params.has("evolution_stage"):
		power = _apply_evolution_modifier(power, params.evolution_stage)
	
	# Get tier and color
	var tier_info = _get_power_tier(power)
	
	# Build result
	return {
		"word": word,
		"power": power,
		"tier": tier_info.tier,
		"color": tier_info.color,
		"dimension": dimension,
		"size": 0.5 + (power / 100.0),
		"mass": 0.2 + (power / 50.0)
	}

# Task: Calculate word connections
# Find potential connections between a word and existing words
func calculate_word_connections(params: Dictionary) -> Dictionary:
	var word = params.get("word", "")
	var existing_words = params.get("existing_words", [])
	
	# Clean the word
	word = word.strip_edges().to_lower()
	
	var connections = []
	
	# Check for opposites
	if WORD_OPPOSITES.has(word):
		var opposite = WORD_OPPOSITES[word]
		for existing in existing_words:
			if existing.text == opposite:
				connections.append({
					"type": "opposite",
					"word": existing.text,
					"id": existing.id,
					"strength": 0.8
				})
	
	# Check for reverse opposites
	for opposite_word in WORD_OPPOSITES:
		if WORD_OPPOSITES[opposite_word] == word:
			for existing in existing_words:
				if existing.text == opposite_word:
					connections.append({
						"type": "opposite",
						"word": existing.text,
						"id": existing.id,
						"strength": 0.8
					})
	
	# Check for words that start with the same letter
	var first_letter = ""
	if word.length() > 0:
		first_letter = word.left(1)
	
	for existing in existing_words:
		if existing.text != word and existing.text.begins_with(first_letter):
			connections.append({
				"type": "similar_start",
				"word": existing.text,
				"id": existing.id,
				"strength": 0.3
			})
	
	# Check for words with similar length (¬±1)
	var word_length = word.length()
	
	for existing in existing_words:
		if existing.text != word and abs(existing.text.length() - word_length) <= 1:
			connections.append({
				"type": "similar_length",
				"word": existing.text,
				"id": existing.id,
				"strength": 0.2
			})
	
	return {
		"word": word,
		"connections": connections
	}

# Task: Calculate word physics
# Determine physical properties and behavior in the current dimension
func calculate_word_physics(params: Dictionary) -> Dictionary:
	var word_data = params.get("word_data", {})
	var dimension = params.get("dimension", 0)
	
	var physics_properties = {
		"position": Vector3.ZERO,
		"velocity": Vector3.ZERO,
		"acceleration": Vector3.ZERO,
		"rotation": Vector3.ZERO,
		"angular_velocity": Vector3.ZERO,
		"mass": 1.0,
		"gravity_scale": 1.0,
		"constraints": []
	}
	
	# Set mass based on word power
	physics_properties.mass = 0.2 + (word_data.get("power", 0) / 50.0)
	
	# Generate a deterministic but seemingly random position
	var seed_value = 0
	var word = word_data.get("word", "")
	for i in range(word.length()):
		seed_value += word.unicode_at(i)
	
	var rng = RandomNumberGenerator.new()
	rng.seed = seed_value
	
	# Apply dimension-specific physics
	match dimension:
		0:  # 1D - Point (constrained to origin)
			physics_properties.position = Vector3.ZERO
			physics_properties.constraints = ["x", "y", "z"]
			physics_properties.gravity_scale = 0.0
			
		1:  # 2D - Line (constrained to x-axis)
			physics_properties.position = Vector3(
				rng.randf_range(-5, 5),
				0,
				0
			)
			physics_properties.constraints = ["y", "z"]
			physics_properties.gravity_scale = 0.0
			
		2:  # 3D - Space (full 3D movement)
			physics_properties.position = Vector3(
				rng.randf_range(-5, 5),
				rng.randf_range(0, 5),
				rng.randf_range(-5, 5)
			)
			physics_properties.constraints = []
			physics_properties.gravity_scale = 1.0
			
		3:  # 4D - Time (3D with temporal effects)
			physics_properties.position = Vector3(
				rng.randf_range(-5, 5),
				rng.randf_range(0, 5),
				rng.randf_range(-5, 5)
			)
			physics_properties.constraints = []
			physics_properties.gravity_scale = 1.0
			# Add temporal fluctuation
			physics_properties.temporal_factor = 1.0
			
		_:  # Higher dimensions
			physics_properties.position = Vector3(
				rng.randf_range(-10, 10),
				rng.randf_range(0, 10),
				rng.randf_range(-10, 10)
			)
			physics_properties.constraints = []
			physics_properties.gravity_scale = 0.5
	
	# Set rotation based on word features
	physics_properties.rotation = Vector3(
		rng.randf_range(0, TAU) if dimension >= 2 else 0,
		rng.randf_range(0, TAU) if dimension >= 1 else 0,
		rng.randf_range(0, TAU) if dimension >= 3 else 0
	)
	
	return {
		"word": word_data.get("word", ""),
		"physics": physics_properties
	}

# Task: Calculate word evolution
# Determine how a word evolves over time
func calculate_word_evolution(params: Dictionary) -> Dictionary:
	var word_data = params.get("word_data", {})
	var current_stage = params.get("current_stage", 0)
	var dimension = params.get("dimension", 0)
	var cosmic_age = params.get("cosmic_age", 0)
	
	# Don't exceed maximum evolution stage
	var new_stage = min(current_stage + 1, 4)
	
	# Apply evolution multiplier
	var power = word_data.get("power", 0)
	var multiplier = EVOLUTION_STAGES[new_stage].multiplier
	
	power *= multiplier
	
	# Apply additional dimension bonus for higher stages
	if new_stage >= 3:
		power *= (1.0 + (dimension * 0.02))
	
	# Apply cosmic age bonus for final stage
	if new_stage == 4:
		power *= (1.0 + (cosmic_age * 0.01))
	
	# Update tier and color
	var tier_info = _get_power_tier(power)
	
	return {
		"word": word_data.get("word", ""),
		"power": power,
		"evolution_stage": new_stage,
		"stage_name": EVOLUTION_STAGES[new_stage].name,
		"tier": tier_info.tier,
		"color": tier_info.color,
		"size": 0.5 + (power / 100.0),
		"mass": 0.2 + (power / 50.0)
	}

# Task: Process text input
# Split text into words and prepare for processing
func process_text_input(params: Dictionary) -> Dictionary:
	var text = params.get("text", "")
	var dimension = params.get("dimension", 0)
	
	# Split text into words
	var words = text.split(" ", false)
	var processed_words = []
	
	for word in words:
		# Clean the word
		word = word.strip_edges().to_lower()
		if word.length() == 0:
			continue
		
		# Add to processed words
		processed_words.append(word)
	
	return {
		"original_text": text,
		"words": processed_words,
		"word_count": processed_words.size(),
		"dimension": dimension
	}

# Helper: Get base power for a word
func _get_base_power(word: String) -> float:
	# Check if word has a predefined power
	if WORD_POWER.has(word):
		return WORD_POWER[word]
	
	# Calculate based on word length and character values
	var power = 5.0 + (word.length() * 2.0)  # Base power from length
	
	# Add power from character values (simple hashing)
	var char_sum = 0
	for i in range(word.length()):
		char_sum += word.unicode_at(i) % 26
	
	power += char_sum * 0.2
	
	# Apply a small random factor (¬±10%)
	var rng = RandomNumberGenerator.new()
	rng.seed = hash(word)
	power *= (0.9 + rng.randf() * 0.2)
	
	return power

# Helper: Apply dimension modifier to power
func _apply_dimension_modifier(power: float, dimension: int) -> float:
	# Ensure dimension is within range
	dimension = clamp(dimension, 0, DIMENSION_MULTIPLIERS.size() - 1)
	
	# Apply multiplier
	return power * DIMENSION_MULTIPLIERS[dimension]

# Helper: Apply cosmic age modifier
func _apply_cosmic_age_modifier(power: float, cosmic_age: int) -> float:
	# Each cosmic age adds a small bonus
	return power * (1.0 + (cosmic_age * 0.02))

# Helper: Apply evolution stage modifier
func _apply_evolution_modifier(power: float, stage: int) -> float:
	# Ensure stage is within range
	stage = clamp(stage, 0, EVOLUTION_STAGES.size() - 1)
	
	# Apply multiplier
	return power * EVOLUTION_STAGES[stage].multiplier

# Helper: Get power tier and color
func _get_power_tier(power: float) -> Dictionary:
	for tier_name in POWER_TIERS:
		var tier = POWER_TIERS[tier_name]
		if power >= tier.min and power < tier.max:
			return {
				"tier": tier_name,
				"color": tier.color
			}
	
	# Default to highest tier if exceeded
	return {
		"tier": "DIVINE",
		"color": POWER_TIERS.DIVINE.color
	}
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/core/word_processor_tasks.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/cyber_gate_controller.gd
# SIZE: 25528 bytes
extends Node

class_name CyberGateController

# ----- CYBER GATE CONTROLLER -----
# Manages transitions between realities, dimensions, and data sewers
# Controls the "Moon Man" game flow and data processing

# ----- GATE CONSTANTS -----
const REALITIES = ["physical", "digital", "astral", "quantum", "memory", "dream"]
const GATE_TYPES = ["standard", "quantum", "forced", "bypass", "hidden"]
const DATA_PACKET_SIZES = [1024, 2048, 4096, 8192, 16384, 32768]
const MAX_GATES_PER_REALITY = 7
const CYCLE_TIME = 12.0 # Full cycle time in seconds (12 turns)

# ----- GATE STRUCTURE -----
var active_gates = {}
var gate_connections = {}
var active_reality = "digital" # Default starting reality
var target_reality = ""
var reality_transition_progress = 0.0
var current_cycle_time = 0.0
var in_transition = false
var transition_type = "standard"
var moon_phase = 0 # 0-7, affects gate stability

# ----- DATA MANAGEMENT -----
var data_sewers = {}
var pending_data_packets = []
var processed_data = {}
var data_corruption_level = 0.0 # 0.0 to 1.0
var sewer_cleanup_timer = 0.0
var cleanup_interval = 60.0 # Clean sewers every minute

# ----- SUBSYSTEM REFERENCES -----
var word_processor = null
var word_manifestation = null
var visualizer = null
var main_system = null

# ----- SIGNALS -----
signal gate_created(gate_id, gate_data)
signal gate_activated(gate_id)
signal gate_destroyed(gate_id)
signal reality_transition_started(from_reality, to_reality)
signal reality_transition_completed(to_reality)
signal data_packet_processed(packet_id, result)
signal sewer_cleaned(sewer_id, bytes_cleaned)
signal moon_phase_changed(old_phase, new_phase)

# ----- INITIALIZATION -----
func _ready():
    print("Cyber Gate Controller initializing...")
    initialize_sewers()
    initialize_moon_phases()
    print("Cyber Gate Controller ready")

# ----- PROCESS -----
func _process(delta):
    # Handle reality transitions
    if in_transition:
        process_reality_transition(delta)
    
    # Update cycle time - controls synchronized turns
    current_cycle_time += delta
    if current_cycle_time >= CYCLE_TIME:
        current_cycle_time = 0.0
        on_full_cycle_completed()
    
    # Process pending data packets
    process_data_packets(delta)
    
    # Periodically clean sewers
    sewer_cleanup_timer += delta
    if sewer_cleanup_timer >= cleanup_interval:
        sewer_cleanup_timer = 0.0
        clean_all_sewers()
    
    # Update moon phases every cycle
    if current_cycle_time < delta:
        advance_moon_phase()

# ----- GATE MANAGEMENT -----
func create_gate(position, gate_type="standard", source_reality=null, target_reality=null):
    if source_reality == null:
        source_reality = active_reality
    
    if target_reality == null:
        # Choose random target different from source
        var available_realities = REALITIES.duplicate()
        available_realities.erase(source_reality)
        target_reality = available_realities[randi() % available_realities.size()]
    
    # Check if max gates reached for this reality
    var existing_gates = 0
    for gate_id in active_gates:
        if active_gates[gate_id].source_reality == source_reality:
            existing_gates += 1
    
    if existing_gates >= MAX_GATES_PER_REALITY:
        print("Maximum gates reached for reality: %s" % source_reality)
        return null
    
    # Generate unique gate ID
    var gate_id = "gate_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
    
    # Calculate stability based on moon phase and gate type
    var base_stability = 0.7
    var moon_factor = (7 - abs(moon_phase - 3.5)) / 7.0  # More stable at phase 3-4
    var type_stability = {
        "standard": 1.0,
        "quantum": 0.8,
        "forced": 0.6,
        "bypass": 0.5,
        "hidden": 0.9
    }
    
    var stability = base_stability * moon_factor * type_stability[gate_type]
    
    # Create gate data
    var gate_data = {
        "id": gate_id,
        "position": position,
        "source_reality": source_reality,
        "target_reality": target_reality,
        "type": gate_type,
        "creation_time": OS.get_unix_time(),
        "stability": stability,
        "active": true,
        "uses": 0,
        "data_throughput": 0,
        "cycle_signature": current_cycle_time,
        "moon_phase": moon_phase
    }
    
    # Store gate
    active_gates[gate_id] = gate_data
    
    # Create gate connection record
    if not gate_connections.has(source_reality):
        gate_connections[source_reality] = {}
    
    if not gate_connections[source_reality].has(target_reality):
        gate_connections[source_reality][target_reality] = []
    
    gate_connections[source_reality][target_reality].append(gate_id)
    
    # Emit signal
    emit_signal("gate_created", gate_id, gate_data)
    
    print("Cyber Gate created: %s ‚Üí %s (Stability: %.2f)" % [source_reality, target_reality, stability])
    
    return gate_data

func activate_gate(gate_id):
    # Verify gate exists
    if not active_gates.has(gate_id):
        print("Error: Gate %s does not exist" % gate_id)
        return false
    
    var gate = active_gates[gate_id]
    
    # Check if already in transition
    if in_transition:
        print("Error: Already in reality transition")
        return false
    
    # Check if gate is in current reality
    if gate.source_reality != active_reality:
        print("Error: Gate %s is not in current reality" % gate_id)
        return false
    
    # Begin transition to target reality
    begin_reality_transition(gate.target_reality, gate.type)
    
    # Update gate usage stats
    gate.uses += 1
    gate.last_used = OS.get_unix_time()
    
    # Emit signal
    emit_signal("gate_activated", gate_id)
    
    print("Gate activated: %s ‚Üí %s" % [gate.source_reality, gate.target_reality])
    
    return true

func destroy_gate(gate_id):
    # Verify gate exists
    if not active_gates.has(gate_id):
        print("Error: Gate %s does not exist" % gate_id)
        return false
    
    var gate = active_gates[gate_id]
    
    # Remove from connections
    if gate_connections.has(gate.source_reality) and gate_connections[gate.source_reality].has(gate.target_reality):
        gate_connections[gate.source_reality][gate.target_reality].erase(gate_id)
    
    # Remove gate
    active_gates.erase(gate_id)
    
    # Emit signal
    emit_signal("gate_destroyed", gate_id)
    
    print("Gate destroyed: %s" % gate_id)
    
    return true

func get_gates_in_reality(reality):
    var gates = []
    
    for gate_id in active_gates:
        if active_gates[gate_id].source_reality == reality:
            gates.append(active_gates[gate_id])
    
    return gates

# ----- REALITY TRANSITIONS -----
func begin_reality_transition(to_reality, transition_type="standard"):
    # Skip if already in transition
    if in_transition:
        return false
    
    # Skip if same reality
    if to_reality == active_reality:
        return false
    
    in_transition = true
    target_reality = to_reality
    self.transition_type = transition_type
    reality_transition_progress = 0.0
    
    # Emit signal
    emit_signal("reality_transition_started", active_reality, to_reality)
    
    print("Reality transition started: %s ‚Üí %s (Type: %s)" % [active_reality, to_reality, transition_type])
    
    return true

func process_reality_transition(delta):
    if not in_transition:
        return
    
    # Calculate speed modifier based on transition type
    var speed_modifier = {
        "standard": 1.0,
        "quantum": 2.0,
        "forced": 1.5,
        "bypass": 3.0,
        "hidden": 0.7
    }
    
    # Update progress
    reality_transition_progress += delta * speed_modifier[transition_type]
    
    # Process transition effects - could be expanded with visual effects
    process_transition_effects(reality_transition_progress)
    
    # Check if transition complete
    if reality_transition_progress >= 1.0:
        complete_reality_transition()

func process_transition_effects(progress):
    # This would be expanded with actual transition effects
    # For now just handle data corruption during transition
    
    # Data becomes more corrupted during transitions
    var corruption_spike = sin(progress * PI) * 0.5
    data_corruption_level = min(1.0, data_corruption_level + corruption_spike * 0.1)
    
    # Modify word manifestation properties during transition
    if word_manifestation != null:
        # Adding jitter to manifestation
        if progress > 0.3 and progress < 0.7:
            # Highest disruption in middle of transition
            var disruption = sin(progress * PI) * 0.3
            
            # This would affect word manifestation behavior
            # Placeholder for implementation
            pass

func complete_reality_transition():
    # Transition is complete
    var old_reality = active_reality
    active_reality = target_reality
    in_transition = false
    reality_transition_progress = 0.0
    
    # Emit signal
    emit_signal("reality_transition_completed", target_reality)
    
    print("Reality transition completed: %s ‚Üí %s" % [old_reality, active_reality])
    
    # Apply reality-specific effects
    apply_reality_effects(active_reality)
    
    # Generate new data from transition
    generate_transition_data(old_reality, active_reality)
    
    return true

func apply_reality_effects(reality):
    # Apply effects specific to each reality
    match reality:
        "physical":
            data_corruption_level = max(0.0, data_corruption_level - 0.2)
            
            # Affect word manifestation
            if word_manifestation != null:
                # Physical reality makes words more stable
                # Placeholder for implementation
                pass
        
        "digital":
            # Higher data processing in digital reality
            process_pending_data(5)
            
            # Affect word manifestation
            if word_manifestation != null:
                # Digital reality makes words more structured
                # Placeholder for implementation
                pass
        
        "astral":
            # Higher corruption but more creative manifestation
            data_corruption_level = min(1.0, data_corruption_level + 0.1)
            
            # Affect word manifestation
            if word_manifestation != null:
                # Astral reality makes words more fluid
                # Placeholder for implementation
                pass
        
        "quantum":
            # Unpredictable effects
            if randf() < 0.5:
                data_corruption_level = randf()
            
            # Affect word manifestation
            if word_manifestation != null:
                # Quantum reality makes words probabilistic
                # Placeholder for implementation
                pass
        
        "memory":
            # Process stored data
            process_memory_data()
            
            # Affect word manifestation
            if word_manifestation != null:
                # Memory reality makes words more persistent
                # Placeholder for implementation
                pass
        
        "dream":
            # High creativity, high corruption
            data_corruption_level = min(1.0, data_corruption_level + 0.3)
            
            # Affect word manifestation
            if word_manifestation != null:
                # Dream reality makes words more abstract
                # Placeholder for implementation
                pass

# ----- DATA MANAGEMENT -----
func initialize_sewers():
    # Create sewer structures for each reality
    for reality in REALITIES:
        data_sewers[reality] = {
            "capacity": 1024 * 1024 * 10, # 10MB initial capacity
            "used": 0,
            "packets": [],
            "last_cleaned": OS.get_unix_time(),
            "corruption_level": 0.0
        }
    
    print("Data sewers initialized for %d realities" % REALITIES.size())

func process_data_packets(delta):
    # Process a limited number of packets per frame
    var packets_to_process = min(5, pending_data_packets.size())
    
    for i in range(packets_to_process):
        if pending_data_packets.size() > 0:
            var packet = pending_data_packets.pop_front()
            process_data_packet(packet)

func process_data_packet(packet):
    # Apply data corruption
    if randf() < data_corruption_level:
        corrupt_data_packet(packet)
    
    # Process data based on type
    var result = null
    
    match packet.type:
        "word":
            # Manifest word from data
            if word_manifestation != null:
                var word = extract_word_from_data(packet.data)
                var position = Vector3(
                    rand_range(-5, 5),
                    rand_range(0, 5),
                    rand_range(-5, 5)
                )
                
                result = word_manifestation.manifest_word(word, position)
        
        "command":
            # Execute command from data
            if main_system != null:
                var command = extract_command_from_data(packet.data)
                result = main_system.execute_command(command)
        
        "gate":
            # Create gate from data
            var gate_type = extract_gate_type_from_data(packet.data)
            var position = Vector3(
                rand_range(-10, 10),
                rand_range(0, 10),
                rand_range(-10, 10)
            )
            
            result = create_gate(position, gate_type)
        
        "memory":
            # Create memory from data
            if word_processor != null:
                var memory_text = extract_text_from_data(packet.data)
                var tier = int(min(3, 1 + packet.size / 4096))
                
                result = word_processor.process_text(memory_text, "data", tier)
    
    # Store processed result
    processed_data[packet.id] = {
        "original": packet,
        "result": result,
        "timestamp": OS.get_unix_time()
    }
    
    # Direct to sewer if needed
    if packet.size > 4096:
        send_to_sewer(packet)
    
    # Emit signal
    emit_signal("data_packet_processed", packet.id, result)
    
    return result

func corrupt_data_packet(packet):
    # Apply data corruption
    var corruption_amount = data_corruption_level * 0.5
    
    # Corrupt size
    packet.size = int(packet.size * (1.0 + (randf() * 2 - 1) * corruption_amount))
    
    # Corrupt data (simplified)
    if typeof(packet.data) == TYPE_STRING:
        var chars = packet.data.length()
        var corrupt_chars = int(chars * corruption_amount * 0.2)
        
        for i in range(corrupt_chars):
            var pos = randi() % chars
            var char_code = packet.data.ord_at(pos)
            char_code = (char_code + randi() % 10 - 5) % 256
            
            var before = packet.data.substr(0, pos)
            var after = packet.data.substr(pos + 1)
            packet.data = before + char(char_code) + after
    
    return packet

func create_data_packet(type, data, size=null):
    # Generate appropriate size if not specified
    if size == null:
        if typeof(data) == TYPE_STRING:
            size = data.length()
        else:
            size = DATA_PACKET_SIZES[randi() % DATA_PACKET_SIZES.size()]
    
    # Generate unique packet ID
    var packet_id = "packet_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
    
    # Create packet data
    var packet = {
        "id": packet_id,
        "type": type,
        "data": data,
        "size": size,
        "creation_time": OS.get_unix_time(),
        "reality": active_reality,
        "moon_phase": moon_phase,
        "cycle_time": current_cycle_time
    }
    
    # Add to pending packets
    pending_data_packets.append(packet)
    
    return packet

func send_to_sewer(packet):
    # Direct large or corrupted data to sewers
    var sewer = data_sewers[active_reality]
    
    # Add to sewer
    sewer.packets.append(packet)
    sewer.used += packet.size
    
    # Update corruption level
    sewer.corruption_level = max(sewer.corruption_level, data_corruption_level)
    
    return true

func clean_sewer(reality):
    # Clean a specific reality's sewer
    if not data_sewers.has(reality):
        return 0
    
    var sewer = data_sewers[reality]
    var packets_before = sewer.packets.size()
    var bytes_before = sewer.used
    
    # Remove oldest packets first
    var packets_to_keep = []
    var keep_threshold = OS.get_unix_time() - (86400 * 3) # Keep last 3 days
    
    for packet in sewer.packets:
        if packet.creation_time > keep_threshold:
            packets_to_keep.append(packet)
    
    # Update sewer
    sewer.packets = packets_to_keep
    sewer.used = 0
    
    # Recalculate used size
    for packet in sewer.packets:
        sewer.used += packet.size
    
    # Update last cleaned time
    sewer.last_cleaned = OS.get_unix_time()
    
    # Calculate cleaned amount
    var packets_removed = packets_before - sewer.packets.size()
    var bytes_cleaned = bytes_before - sewer.used
    
    # Emit signal
    emit_signal("sewer_cleaned", reality, bytes_cleaned)
    
    print("Cleaned %s sewer: removed %d packets, freed %d bytes" % [reality, packets_removed, bytes_cleaned])
    
    return bytes_cleaned

func clean_all_sewers():
    var total_bytes_cleaned = 0
    
    for reality in data_sewers:
        total_bytes_cleaned += clean_sewer(reality)
    
    print("Cleaned all sewers: freed %d bytes total" % total_bytes_cleaned)
    
    return total_bytes_cleaned

# ----- MOON PHASES -----
func initialize_moon_phases():
    # Initialize with random moon phase
    moon_phase = randi() % 8
    print("Moon phase initialized to: %d/7" % moon_phase)

func advance_moon_phase():
    var old_phase = moon_phase
    moon_phase = (moon_phase + 1) % 8
    
    # Emit signal
    emit_signal("moon_phase_changed", old_phase, moon_phase)
    
    print("Moon phase changed: %d ‚Üí %d" % [old_phase, moon_phase])
    
    # Moon phase affects gate stability
    update_gate_stability()
    
    return moon_phase

func update_gate_stability():
    # Update gate stability based on current moon phase
    for gate_id in active_gates:
        var gate = active_gates[gate_id]
        
        # Calculate moon influence factor
        var moon_influence = (7 - abs(moon_phase - gate.moon_phase)) / 7.0
        
        # Update stability
        gate.stability = clamp(gate.stability * (0.8 + moon_influence * 0.4), 0.1, 1.0)
        
        # Extremely unstable gates may collapse
        if gate.stability < 0.2 and randf() < 0.3:
            print("Gate %s collapsed due to low stability (%.2f)" % [gate_id, gate.stability])
            destroy_gate(gate_id)

# ----- CYCLE MANAGEMENT -----
func on_full_cycle_completed():
    print("Full cycle completed")
    
    # Apply cycle effects
    
    # Clean sewers automatically every few cycles
    if current_cycle_time < 0.1 and randf() < 0.3:
        clean_all_sewers()
    
    # Generate new gates occasionally
    if randf() < 0.2:
        var position = Vector3(
            rand_range(-10, 10),
            rand_range(0, 10),
            rand_range(-10, 10)
        )
        
        create_gate(position)
    
    # Process memory data
    process_memory_data()
    
    # Generate game events
    generate_game_event()

func generate_transition_data(from_reality, to_reality):
    # Generate data based on reality transition
    var data_types = ["word", "command", "gate", "memory"]
    var data_type = data_types[randi() % data_types.size()]
    
    var data = "Transition from %s to %s reality" % [from_reality, to_reality]
    var size = 1024 + randi() % 4096
    
    create_data_packet(data_type, data, size)
    
    return true

func process_memory_data():
    # Process stored memories to generate new insights
    if word_processor == null:
        return
    
    var memories = []
    
    # This would extract memories from word processor
    # Placeholder implementation
    
    for memory in memories:
        # Create data packet from memory
        create_data_packet("memory", memory.text, memory.power * 100)
    
    return memories.size()

func process_pending_data(count=1):
    # Force process a number of pending data packets
    var processed = 0
    
    for i in range(min(count, pending_data_packets.size())):
        if pending_data_packets.size() > 0:
            var packet = pending_data_packets.pop_front()
            process_data_packet(packet)
            processed += 1
    
    return processed

func generate_game_event():
    # Generate random game events
    var event_types = ["gate_malfunction", "data_surge", "reality_echo", "moon_anomaly"]
    var event = event_types[randi() % event_types.size()]
    
    match event:
        "gate_malfunction":
            # Random gate malfunctions
            if active_gates.size() > 0:
                var gate_ids = active_gates.keys()
                var gate_id = gate_ids[randi() % gate_ids.size()]
                
                var gate = active_gates[gate_id]
                gate.stability *= 0.7
                
                print("Gate malfunction event: Gate %s stability reduced to %.2f" % [gate_id, gate.stability])
        
        "data_surge":
            # Create a surge of data
            var data_size = 1024 * (1 + randi() % 16)
            var data = "Data surge event"
            create_data_packet("word", data, data_size)
            
            print("Data surge event: Created %d byte data packet" % data_size)
        
        "reality_echo":
            # Echo between realities
            var source_reality = REALITIES[randi() % REALITIES.size()]
            var target_reality = active_reality
            
            if source_reality != target_reality:
                print("Reality echo event: Echo from %s to %s" % [source_reality, target_reality])
                
                # Transfer data between sewers
                if data_sewers.has(source_reality) and data_sewers.has(target_reality):
                    var source_sewer = data_sewers[source_reality]
                    var target_sewer = data_sewers[target_reality]
                    
                    if source_sewer.packets.size() > 0:
                        var packet = source_sewer.packets[randi() % source_sewer.packets.size()]
                        target_sewer.packets.append(packet)
                        target_sewer.used += packet.size
                        
                        print("Transferred %d byte packet from %s to %s sewer" % [packet.size, source_reality, target_reality])
        
        "moon_anomaly":
            # Moon phase anomaly
            var old_phase = moon_phase
            moon_phase = randi() % 8
            
            print("Moon anomaly event: Phase jumped from %d to %d" % [old_phase, moon_phase])
            emit_signal("moon_phase_changed", old_phase, moon_phase)
            
            # Update gate stability
            update_gate_stability()
    
    return event

# ----- HELPER FUNCTIONS -----
func extract_word_from_data(data):
    # Extract meaningful word from data
    # Simple implementation - extract words if string data
    if typeof(data) == TYPE_STRING:
        var words = data.split(" ")
        if words.size() > 0:
            var word_idx = randi() % words.size()
            return words[word_idx]
    
    return "data"

func extract_command_from_data(data):
    # Extract command from data
    # Simple implementation - extract command if string data
    if typeof(data) == TYPE_STRING:
        if data.begins_with("/"):
            return data
        else:
            return "/note " + data
    
    return "/status"

func extract_gate_type_from_data(data):
    # Extract gate type from data
    # Simple implementation - try to match with known types
    if typeof(data) == TYPE_STRING:
        for type in GATE_TYPES:
            if data.to_lower().find(type) >= 0:
                return type
    
    return "standard"

func extract_text_from_data(data):
    # Extract text from data
    if typeof(data) == TYPE_STRING:
        return data
    
    return "Data conversion"

# ----- PUBLIC API -----
func set_word_processor(processor):
    word_processor = processor
    print("Word processor connected to Cyber Gate Controller")

func set_word_manifestation(system):
    word_manifestation = system
    print("Word manifestation system connected to Cyber Gate Controller")

func set_visualizer(vis):
    visualizer = vis
    print("Visualizer connected to Cyber Gate Controller")

func set_main_system(system):
    main_system = system
    print("Main system connected to Cyber Gate Controller")

func get_current_reality():
    return active_reality

func get_current_moon_phase():
    return moon_phase

func get_sewer_status():
    var status = {}
    
    for reality in data_sewers:
        status[reality] = {
            "capacity": data_sewers[reality].capacity,
            "used": data_sewers[reality].used,
            "packet_count": data_sewers[reality].packets.size(),
            "corruption": data_sewers[reality].corruption_level,
            "last_cleaned": data_sewers[reality].last_cleaned
        }
    
    return status

func get_data_corruption_level():
    return data_corruption_level
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/cyber_gate_controller.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/data_evolution_engine.gd
# SIZE: 40575 bytes
extends Node

# Data Evolution Engine
# Processes and evolves data across multiple dimensions and formats
# Handles folding, unfolding, and continuous evolution of narrative structures

class_name DataEvolutionEngine

# Evolution patterns 
enum EvolutionPattern {
	LINEAR,       # Simple progression
	BRANCHING,    # Tree-like evolution with multiple paths
	CYCLIC,       # Repeating patterns with variations
	SPIRAL,       # Progressive refinement around central themes
	EMERGENT,     # Complex patterns emerging from simple rules
	QUANTUM,      # Multiple states existing simultaneously
	FOLDING,      # Compression and expansion of information
	FUSION        # Combining different evolution paths
}

# Evolution stages (rule of 3-6-9)
enum EvolutionStage {
	SEED = 0,     # Initial concept
	GROWTH = 1,   # Early development
	FORM = 2,     # Basic structure
	FUNCTION = 3, # Functional capabilities (3)
	REFINEMENT = 4, # Improving existing functions
	ADAPTATION = 5, # Adapting to environment
	INTEGRATION = 6, # Fully integrated system (6)
	EXTENSION = 7,  # Moving beyond core functionality
	TRANSCENDENCE = 8, # Transcending original purpose
	COMPLETION = 9  # Final evolved form (9)
}

# Data folding modes
enum FoldingMode {
	HORIZONTAL,   # Fold along horizontal axis
	VERTICAL,     # Fold along vertical axis
	DIAGONAL,     # Fold along diagonal
	TEMPORAL,     # Fold across time dimensions
	SEMANTIC,     # Fold based on meaning
	QUANTUM,      # Superposition fold
	RECURSIVE     # Nested folding
}

# Data storage type
enum StorageType {
	TERMINAL,     # Terminal buffer storage
	FILE,         # File-based storage
	MEMORY,       # In-memory storage 
	DATABASE,     # Database storage
	CLOUD,        # Cloud-based storage
	DIMENSIONAL,  # Dimensional pocket storage
	QUANTUM       # Quantum state storage
}

# Evolution metrics
class EvolutionMetrics:
	var complexity: float = 0.0
	var coherence: float = 0.0
	var adaptability: float = 0.0
	var integration: float = 0.0
	var novelty: float = 0.0
	var stability: float = 0.0
	
	func calculate_evolution_potential() -> float:
		return (complexity + coherence + adaptability + integration + novelty) * stability
	
	func to_string() -> String:
		return "Evolution Metrics:\n" + \
			   "- Complexity: %.2f\n" % complexity + \
			   "- Coherence: %.2f\n" % coherence + \
			   "- Adaptability: %.2f\n" % adaptability + \
			   "- Integration: %.2f\n" % integration + \
			   "- Novelty: %.2f\n" % novelty + \
			   "- Stability: %.2f\n" % stability + \
			   "- Evolution Potential: %.2f" % calculate_evolution_potential()

# Data entity that can evolve
class DataEntity:
	var id: String
	var content: String
	var type: String
	var tags: Array = []
	var created_at: int
	var modified_at: int
	var evolution_stage: int = EvolutionStage.SEED
	var evolution_pattern: int = EvolutionPattern.LINEAR
	var parent_id: String = ""
	var children_ids: Array = []
	var metrics: EvolutionMetrics
	var fold_state: int = 0  # 0 = unfolded, 1+ = fold level
	var metadata: Dictionary = {}
	
	func _init(p_id: String, p_content: String, p_type: String = "text"):
		id = p_id
		content = p_content
		type = p_type
		created_at = OS.get_unix_time()
		modified_at = created_at
		metrics = EvolutionMetrics.new()
	
	func evolve():
		if evolution_stage < EvolutionStage.COMPLETION:
			evolution_stage += 1
		modified_at = OS.get_unix_time()
		
	func add_child(child_id: String):
		if not children_ids.has(child_id):
			children_ids.append(child_id)
			modified_at = OS.get_unix_time()
	
	func fold(mode: int = FoldingMode.HORIZONTAL):
		fold_state += 1
		modified_at = OS.get_unix_time()
		# In a real implementation, this would compress/transform the content
		return "Folded content (level %d)" % fold_state
	
	func unfold():
		if fold_state > 0:
			fold_state -= 1
		modified_at = OS.get_unix_time()
		# In a real implementation, this would decompress/transform the content
		return content
	
	func add_tag(tag: String):
		if not tags.has(tag):
			tags.append(tag)
			modified_at = OS.get_unix_time()
	
	func to_string() -> String:
		return "[%s] %s (Stage: %d, Pattern: %d, Fold: %d)" % [
			id, content.substr(0, 20) + "..." if content.length() > 20 else content,
			evolution_stage, evolution_pattern, fold_state
		]

# Signal for evolution events
signal entity_evolved(entity_id, old_stage, new_stage)
signal entity_folded(entity_id, fold_level, fold_mode)
signal entity_unfolded(entity_id, fold_level)
signal evolution_cycle_completed(cycle_number)

# Engine state
var entities = {}
var current_evolution_cycle = 0
var total_evolution_cycles = 0
var evolution_rate = 1.0  # Base rate multiplier
var auto_evolution = false
var evolution_timer = null
var evolution_batch_size = 3  # Process 3 entities at a time
var folding_threshold = 0.8   # When to auto-fold entities (0.0-1.0)
var unfolding_threshold = 0.3 # When to auto-unfold entities (0.0-1.0)

# System references
var terminal = null
var storage_system = null
var fluctuation_monitor = null

# Internal state
var _evolution_queue = []
var _ready_for_evolution = []
var _scheduled_folds = {}
var _entity_relationships = {}
var _current_storage_mode = StorageType.MEMORY

func _ready():
	# Set up evolution timer
	evolution_timer = Timer.new()
	evolution_timer.wait_time = 5.0  # 5 seconds between evolution cycles
	evolution_timer.autostart = false
	evolution_timer.connect("timeout", self, "_process_evolution_cycle")
	add_child(evolution_timer)
	
	# Find terminal and other systems
	terminal = get_node_or_null("/root/IntegratedTerminal")
	storage_system = get_node_or_null("/root/SecondaryStorageSystem")
	fluctuation_monitor = get_node_or_null("/root/DataFluctuationMonitor")
	
	# Log initialization
	log_message("Data Evolution Engine initialized.")
	log_message("Rule of 3-6-9 progression system active.")
	log_message("Folding capabilities enabled.")

# Initialize the engine with defaults
func initialize():
	log_message("Initializing Data Evolution Engine...")
	
	# Clear existing data
	entities.clear()
	_evolution_queue.clear()
	_ready_for_evolution.clear()
	_scheduled_folds.clear()
	_entity_relationships.clear()
	current_evolution_cycle = 0
	
	# Create seed entity
	create_entity("Genesis seed entity", "text")
	
	log_message("Data Evolution Engine initialized successfully.")

# Process commands
func process_command(command):
	var parts = command.split(" ", true, 1)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"#evolution", "#evolve":
			process_evolution_command(args)
			return true
		"##evolution", "##evolve":
			process_advanced_evolution_command(args)
			return true
		"###evolution", "###evolve":
			process_system_evolution_command(args)
			return true
		_:
			return false

# Process basic evolution commands
func process_evolution_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_evolution_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"status":
			display_evolution_status()
		"create":
			create_entity(subargs)
		"list":
			list_entities()
		"evolve":
			evolve_entity(subargs)
		"fold":
			fold_entity(subargs)
		"unfold":
			unfold_entity(subargs)
		"auto":
			toggle_auto_evolution(subargs)
		"cycle":
			run_evolution_cycle()
		"search":
			search_entities(subargs)
		"show":
			show_entity(subargs)
		"help":
			display_evolution_help()
		_:
			log_message("Unknown evolution command: " + subcmd, "error")

# Process advanced evolution commands
func process_advanced_evolution_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_advanced_evolution_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"rate":
			set_evolution_rate(subargs)
		"pattern":
			set_evolution_pattern(subargs)
		"connect":
			connect_entities(subargs)
		"split":
			split_entity(subargs)
		"merge":
			merge_entities(subargs)
		"metrics":
			show_entity_metrics(subargs)
		"batch":
			set_batch_size(subargs)
		"threshold":
			set_folding_thresholds(subargs)
		"analyze":
			analyze_evolution_patterns()
		"help":
			display_advanced_evolution_help()
		_:
			log_message("Unknown advanced evolution command: " + subcmd, "error")

# Process system evolution commands
func process_system_evolution_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_system_evolution_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"reset":
			reset_evolution_engine()
		"storage":
			set_storage_mode(subargs)
		"save":
			save_evolution_state(subargs)
		"load":
			load_evolution_state(subargs)
		"purge":
			purge_entities(subargs)
		"export":
			export_evolution_data(subargs)
		"import":
			import_evolution_data(subargs)
		"help":
			display_system_evolution_help()
		_:
			log_message("Unknown system evolution command: " + subcmd, "error")

# Create a new entity
func create_entity(content, type="text"):
	if content.empty():
		log_message("Entity content cannot be empty.", "error")
		return null
		
	var id = "entity_" + str(OS.get_unix_time()) + "_" + str(randi() % 1000)
	var entity = DataEntity.new(id, content, type)
	
	# Initialize random metrics
	entity.metrics.complexity = randf()
	entity.metrics.coherence = randf()
	entity.metrics.adaptability = randf()
	entity.metrics.integration = randf()
	entity.metrics.novelty = randf()
	entity.metrics.stability = 0.5 + randf() * 0.5  # 0.5-1.0 for better initial stability
	
	entities[id] = entity
	_evolution_queue.append(id)
	
	log_message("Created new entity: " + entity.to_string())
	
	return id

# Evolve a specific entity
func evolve_entity(entity_id):
	if entity_id.empty():
		log_message("Please specify an entity ID to evolve.", "error")
		return false
		
	if not entities.has(entity_id):
		log_message("Entity not found: " + entity_id, "error")
		return false
	
	var entity = entities[entity_id]
	var old_stage = entity.evolution_stage
	
	# Apply the evolution
	entity.evolve()
	
	# Check for rule of 3-6-9 transitions
	var stage_description = ""
	match entity.evolution_stage:
		EvolutionStage.FUNCTION: # 3
			stage_description = "reached functional capability"
			# Boost integration at this stage
			entity.metrics.integration += 0.2
		EvolutionStage.INTEGRATION: # 6
			stage_description = "achieved full integration"
			# Boost adaptability at this stage
			entity.metrics.adaptability += 0.2
		EvolutionStage.COMPLETION: # 9
			stage_description = "attained completion"
			# Boost all metrics at completion
			entity.metrics.complexity += 0.1
			entity.metrics.coherence += 0.1
			entity.metrics.adaptability += 0.1
			entity.metrics.integration += 0.1
			entity.metrics.novelty += 0.1
	
	# Update the content based on evolution
	entity.content = _transform_content_for_evolution(entity.content, old_stage, entity.evolution_stage)
	
	# Check if we should fold this entity based on metrics
	var evolution_potential = entity.metrics.calculate_evolution_potential()
	if evolution_potential > folding_threshold and entity.fold_state == 0:
		_scheduled_folds[entity_id] = FoldingMode.SEMANTIC
	
	# Log the evolution
	if stage_description:
		log_message("Entity " + entity_id + " evolved from stage " + str(old_stage) + 
					" to " + str(entity.evolution_stage) + " and " + stage_description + ".")
	else:
		log_message("Entity " + entity_id + " evolved from stage " + str(old_stage) + 
					" to " + str(entity.evolution_stage) + ".")
	
	# Emit signal
	emit_signal("entity_evolved", entity_id, old_stage, entity.evolution_stage)
	
	return true

# Fold an entity
func fold_entity(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		log_message("Please specify an entity ID to fold.", "error")
		return false
		
	var entity_id = parts[0]
	var fold_mode_str = parts[1] if parts.size() > 1 else "horizontal"
	
	if not entities.has(entity_id):
		log_message("Entity not found: " + entity_id, "error")
		return false
	
	var entity = entities[entity_id]
	
	# Determine fold mode
	var fold_mode = FoldingMode.HORIZONTAL
	match fold_mode_str.to_lower():
		"horizontal", "h": fold_mode = FoldingMode.HORIZONTAL
		"vertical", "v": fold_mode = FoldingMode.VERTICAL
		"diagonal", "d": fold_mode = FoldingMode.DIAGONAL
		"temporal", "t": fold_mode = FoldingMode.TEMPORAL
		"semantic", "s": fold_mode = FoldingMode.SEMANTIC
		"quantum", "q": fold_mode = FoldingMode.QUANTUM
		"recursive", "r": fold_mode = FoldingMode.RECURSIVE
	
	# Apply the fold
	var folded_content = entity.fold(fold_mode)
	log_message("Entity " + entity_id + " folded to level " + str(entity.fold_state) + 
				" using " + fold_mode_str + " mode.")
	
	# Emit signal
	emit_signal("entity_folded", entity_id, entity.fold_state, fold_mode)
	
	return true

# Unfold an entity
func unfold_entity(entity_id):
	if entity_id.empty():
		log_message("Please specify an entity ID to unfold.", "error")
		return false
		
	if not entities.has(entity_id):
		log_message("Entity not found: " + entity_id, "error")
		return false
	
	var entity = entities[entity_id]
	
	if entity.fold_state <= 0:
		log_message("Entity " + entity_id + " is already fully unfolded.", "warning")
		return false
	
	# Apply the unfold
	var unfolded_content = entity.unfold()
	log_message("Entity " + entity_id + " unfolded to level " + str(entity.fold_state) + ".")
	
	# Emit signal
	emit_signal("entity_unfolded", entity_id, entity.fold_state)
	
	return true

# Toggle auto-evolution
func toggle_auto_evolution(enabled_str=""):
	if enabled_str.empty():
		auto_evolution = !auto_evolution
	else:
		auto_evolution = (enabled_str.to_lower() == "on" or enabled_str.to_lower() == "true" or enabled_str == "1")
	
	if auto_evolution:
		evolution_timer.start()
		log_message("Auto-evolution enabled. Cycle every " + str(evolution_timer.wait_time) + " seconds.")
	else:
		evolution_timer.stop()
		log_message("Auto-evolution disabled.")

# Run a single evolution cycle
func run_evolution_cycle():
	log_message("Running evolution cycle " + str(current_evolution_cycle + 1) + "...")
	
	_process_evolution_cycle()
	
	log_message("Evolution cycle completed.")

# Set the evolution rate
func set_evolution_rate(rate_str):
	var rate = float(rate_str)
	
	if rate <= 0:
		log_message("Evolution rate must be positive.", "error")
		return
		
	evolution_rate = rate
	log_message("Evolution rate set to: " + str(evolution_rate))

# Set the evolution pattern for an entity
func set_evolution_pattern(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		log_message("Usage: ##evolution pattern <entity_id> <pattern>", "error")
		return false
		
	var entity_id = parts[0]
	var pattern_str = parts[1]
	
	if not entities.has(entity_id):
		log_message("Entity not found: " + entity_id, "error")
		return false
	
	var entity = entities[entity_id]
	
	# Determine pattern
	var pattern = EvolutionPattern.LINEAR
	match pattern_str.to_lower():
		"linear", "l": pattern = EvolutionPattern.LINEAR
		"branching", "b": pattern = EvolutionPattern.BRANCHING
		"cyclic", "c": pattern = EvolutionPattern.CYCLIC
		"spiral", "s": pattern = EvolutionPattern.SPIRAL
		"emergent", "e": pattern = EvolutionPattern.EMERGENT
		"quantum", "q": pattern = EvolutionPattern.QUANTUM
		"folding", "f": pattern = EvolutionPattern.FOLDING
		"fusion", "fu": pattern = EvolutionPattern.FUSION
		_:
			log_message("Unknown pattern: " + pattern_str, "error")
			log_message("Available patterns: linear, branching, cyclic, spiral, emergent, quantum, folding, fusion", "system")
			return false
	
	entity.evolution_pattern = pattern
	log_message("Set evolution pattern for entity " + entity_id + " to " + pattern_str + ".")
	
	return true

# Connect entities in a relationship
func connect_entities(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		log_message("Usage: ##evolution connect <parent_id> <child_id>", "error")
		return false
		
	var parent_id = parts[0]
	var child_id = parts[1]
	
	if not entities.has(parent_id):
		log_message("Parent entity not found: " + parent_id, "error")
		return false
		
	if not entities.has(child_id):
		log_message("Child entity not found: " + child_id, "error")
		return false
	
	var parent = entities[parent_id]
	var child = entities[child_id]
	
	# Create the connection
	parent.add_child(child_id)
	child.parent_id = parent_id
	
	# Store in relationship map
	if not _entity_relationships.has(parent_id):
		_entity_relationships[parent_id] = []
	
	if not _entity_relationships[parent_id].has(child_id):
		_entity_relationships[parent_id].append(child_id)
	
	log_message("Connected entity " + child_id + " as child of " + parent_id + ".")
	
	return true

# Split an entity into multiple entities
func split_entity(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		log_message("Usage: ##evolution split <entity_id> <count>", "error")
		return false
		
	var entity_id = parts[0]
	var count_str = parts[1]
	
	if not entities.has(entity_id):
		log_message("Entity not found: " + entity_id, "error")
		return false
	
	var count = int(count_str)
	if count < 2:
		log_message("Split count must be at least 2.", "error")
		return false
	
	var entity = entities[entity_id]
	var content = entity.content
	
	# Determine how to split the content
	var split_size = max(1, content.length() / count)
	var new_entities = []
	
	log_message("Splitting entity " + entity_id + " into " + str(count) + " parts...")
	
	for i in range(count):
		var start = i * split_size
		var end = min(content.length(), (i + 1) * split_size)
		var part_content = content.substr(start, end - start)
		
		if part_content.strip_edges().empty():
			continue
			
		var new_id = create_entity(part_content, entity.type)
		new_entities.append(new_id)
		
		# Connect to the original
		connect_entities(entity_id + " " + new_id)
	
	log_message("Created " + str(new_entities.size()) + " entities from split.")
	
	return true

# Merge multiple entities into one
func merge_entities(args):
	var entity_ids = args.split(" ")
	
	if entity_ids.size() < 2:
		log_message("Usage: ##evolution merge <entity_id1> <entity_id2> [entity_id3...]", "error")
		return false
	
	var valid_entities = []
	var combined_content = ""
	
	for id in entity_ids:
		if entities.has(id):
			valid_entities.append(id)
			combined_content += entities[id].content + "\n"
		else:
			log_message("Entity not found: " + id, "warning")
	
	if valid_entities.size() < 2:
		log_message("Need at least 2 valid entities to merge.", "error")
		return false
	
	log_message("Merging " + str(valid_entities.size()) + " entities...")
	
	# Create the merged entity
	var merged_id = create_entity(combined_content, "merged")
	
	# Set highest evolution stage from merged entities
	var highest_stage = 0
	for id in valid_entities:
		if entities[id].evolution_stage > highest_stage:
			highest_stage = entities[id].evolution_stage
	
	entities[merged_id].evolution_stage = highest_stage
	entities[merged_id].evolution_pattern = EvolutionPattern.FUSION
	
	log_message("Created merged entity: " + merged_id)
	
	return true

# Show metrics for an entity
func show_entity_metrics(entity_id):
	if entity_id.empty():
		log_message("Please specify an entity ID to show metrics for.", "error")
		return false
		
	if not entities.has(entity_id):
		log_message("Entity not found: " + entity_id, "error")
		return false
	
	var entity = entities[entity_id]
	log_message("Metrics for entity " + entity_id + ":")
	log_message(entity.metrics.to_string())
	
	return true

# Set batch size for evolution
func set_batch_size(size_str):
	var size = int(size_str)
	
	if size < 1:
		log_message("Batch size must be at least 1.", "error")
		return
		
	evolution_batch_size = size
	log_message("Evolution batch size set to: " + str(evolution_batch_size))

# Set folding thresholds
func set_folding_thresholds(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		log_message("Usage: ##evolution threshold <fold_threshold> <unfold_threshold>", "error")
		return false
		
	var fold_threshold = float(parts[0])
	var unfold_threshold = float(parts[1])
	
	if fold_threshold < 0 or fold_threshold > 1 or unfold_threshold < 0 or unfold_threshold > 1:
		log_message("Thresholds must be between 0.0 and 1.0.", "error")
		return false
		
	if fold_threshold <= unfold_threshold:
		log_message("Fold threshold must be greater than unfold threshold.", "error")
		return false
	
	folding_threshold = fold_threshold
	unfolding_threshold = unfold_threshold
	
	log_message("Folding threshold set to: " + str(folding_threshold))
	log_message("Unfolding threshold set to: " + str(unfolding_threshold))
	
	return true

# Analyze evolution patterns
func analyze_evolution_patterns():
	log_message("Analyzing evolution patterns...")
	
	var patterns = {}
	var stage_counts = {}
	var fold_counts = {"folded": 0, "unfolded": 0}
	var total_entities = entities.size()
	
	for id in entities:
		var entity = entities[id]
		
		# Count patterns
		if not patterns.has(entity.evolution_pattern):
			patterns[entity.evolution_pattern] = 0
		patterns[entity.evolution_pattern] += 1
		
		# Count stages
		if not stage_counts.has(entity.evolution_stage):
			stage_counts[entity.evolution_stage] = 0
		stage_counts[entity.evolution_stage] += 1
		
		# Count fold states
		if entity.fold_state > 0:
			fold_counts.folded += 1
		else:
			fold_counts.unfolded += 1
	
	# Report pattern distribution
	log_message("Pattern Distribution:")
	for pattern in patterns:
		var percent = (float(patterns[pattern]) / total_entities) * 100
		log_message("- " + _get_pattern_name(pattern) + ": " + 
					str(patterns[pattern]) + " (" + str(int(percent)) + "%)")
	
	# Report rule of 3-6-9 distribution
	log_message("Rule of 3-6-9 Distribution:")
	for i in range(10):
		var count = stage_counts[i] if stage_counts.has(i) else 0
		var percent = 0
		if total_entities > 0:
			percent = (float(count) / total_entities) * 100
		var special_marker = ""
		if i == 3 or i == 6 or i == 9:
			special_marker = " ‚òÖ"
		log_message("- Stage " + str(i) + special_marker + ": " + 
					str(count) + " (" + str(int(percent)) + "%)")
	
	# Report folding status
	log_message("Folding Status:")
	var folded_percent = (float(fold_counts.folded) / total_entities) * 100
	var unfolded_percent = (float(fold_counts.unfolded) / total_entities) * 100
	log_message("- Folded: " + str(fold_counts.folded) + " (" + str(int(folded_percent)) + "%)")
	log_message("- Unfolded: " + str(fold_counts.unfolded) + " (" + str(int(unfolded_percent)) + "%)")
	
	return true

# Reset the evolution engine
func reset_evolution_engine():
	log_message("Resetting evolution engine...")
	
	# Stop auto evolution if running
	if auto_evolution:
		evolution_timer.stop()
		auto_evolution = false
	
	# Clear all data
	entities.clear()
	_evolution_queue.clear()
	_ready_for_evolution.clear()
	_scheduled_folds.clear()
	_entity_relationships.clear()
	
	# Reset counters
	current_evolution_cycle = 0
	total_evolution_cycles = 0
	
	# Reset settings to defaults
	evolution_rate = 1.0
	evolution_batch_size = 3
	folding_threshold = 0.8
	unfolding_threshold = 0.3
	_current_storage_mode = StorageType.MEMORY
	
	# Reinitialize
	initialize()
	
	log_message("Evolution engine reset complete.")
	
	return true

# Set storage mode
func set_storage_mode(mode_str):
	var mode = StorageType.MEMORY  # Default
	
	match mode_str.to_lower():
		"terminal": mode = StorageType.TERMINAL
		"file": mode = StorageType.FILE
		"memory": mode = StorageType.MEMORY
		"database": mode = StorageType.DATABASE
		"cloud": mode = StorageType.CLOUD
		"dimensional": mode = StorageType.DIMENSIONAL
		"quantum": mode = StorageType.QUANTUM
		_:
			log_message("Unknown storage mode: " + mode_str, "error")
			log_message("Available modes: terminal, file, memory, database, cloud, dimensional, quantum", "system")
			return false
	
	_current_storage_mode = mode
	log_message("Storage mode set to: " + mode_str)
	
	return true

# Save evolution state
func save_evolution_state(path=""):
	if path.empty():
		path = "user://evolution_state.dat"
		
	log_message("Saving evolution state to: " + path, "system")
	
	# In a real implementation, this would save to a file
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("Evolution state saved successfully.")
	
	return true

# Load evolution state
func load_evolution_state(path=""):
	if path.empty():
		path = "user://evolution_state.dat"
		
	log_message("Loading evolution state from: " + path, "system")
	
	# In a real implementation, this would load from a file
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("Evolution state loaded successfully.")
	
	return true

# Purge entities
func purge_entities(criteria=""):
	if criteria.empty():
		log_message("Please specify purge criteria (all, folded, stage:<num>).", "error")
		return false
	
	var count = 0
	var total = entities.size()
	
	match criteria:
		"all":
			count = total
			entities.clear()
			_evolution_queue.clear()
			_ready_for_evolution.clear()
			_scheduled_folds.clear()
			_entity_relationships.clear()
		"folded":
			var to_remove = []
			for id in entities:
				if entities[id].fold_state > 0:
					to_remove.append(id)
					count += 1
			
			for id in to_remove:
				entities.erase(id)
				if _evolution_queue.has(id):
					_evolution_queue.erase(id)
				if _ready_for_evolution.has(id):
					_ready_for_evolution.erase(id)
				if _scheduled_folds.has(id):
					_scheduled_folds.erase(id)
				# Clean up relationships
				for parent_id in _entity_relationships:
					if _entity_relationships[parent_id].has(id):
						_entity_relationships[parent_id].erase(id)
		_:
			if criteria.begins_with("stage:"):
				var stage_str = criteria.substr(6)
				var stage = int(stage_str)
				
				var to_remove = []
				for id in entities:
					if entities[id].evolution_stage == stage:
						to_remove.append(id)
						count += 1
				
				for id in to_remove:
					entities.erase(id)
					if _evolution_queue.has(id):
						_evolution_queue.erase(id)
					if _ready_for_evolution.has(id):
						_ready_for_evolution.erase(id)
					if _scheduled_folds.has(id):
						_scheduled_folds.erase(id)
					# Clean up relationships
					for parent_id in _entity_relationships:
						if _entity_relationships[parent_id].has(id):
							_entity_relationships[parent_id].erase(id)
			else:
				log_message("Unknown purge criteria: " + criteria, "error")
				log_message("Available criteria: all, folded, stage:<num>", "system")
				return false
	
	log_message("Purged " + str(count) + " entities using criteria: " + criteria)
	return true

# Export evolution data
func export_evolution_data(format="json"):
	log_message("Exporting evolution data in " + format + " format...")
	
	# In a real implementation, this would export actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("Evolution data exported successfully as " + format)
	
	return true

# Import evolution data
func import_evolution_data(path=""):
	if path.empty():
		log_message("Please specify a path to import from.", "error")
		return false
		
	log_message("Importing evolution data from: " + path)
	
	# In a real implementation, this would import actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("Evolution data imported successfully.")
	
	return true

# List all entities
func list_entities():
	if entities.empty():
		log_message("No entities exist.", "system")
		return
		
	log_message("Entity List (" + str(entities.size()) + " total):")
	
	var sorted_keys = entities.keys()
	sorted_keys.sort_custom(self, "_sort_by_evolution_stage")
	
	for id in sorted_keys:
		var entity = entities[id]
		log_message("- " + id + ": " + entity.to_string())

# Search for entities matching criteria
func search_entities(criteria):
	if criteria.empty():
		log_message("Please specify search criteria.", "error")
		return
		
	log_message("Searching entities with criteria: " + criteria)
	
	var matches = []
	
	for id in entities:
		var entity = entities[id]
		
		# Text content search
		if entity.content.to_lower().find(criteria.to_lower()) >= 0:
			matches.append(id)
			continue
			
		# Tag search
		if criteria.begins_with("tag:"):
			var tag = criteria.substr(4)
			if entity.tags.has(tag):
				matches.append(id)
				continue
		
		# Stage search
		if criteria.begins_with("stage:"):
			var stage_str = criteria.substr(6)
			var stage = int(stage_str)
			if entity.evolution_stage == stage:
				matches.append(id)
				continue
		
		# Pattern search
		if criteria.begins_with("pattern:"):
			var pattern_str = criteria.substr(8)
			var pattern = _pattern_from_string(pattern_str)
			if pattern >= 0 and entity.evolution_pattern == pattern:
				matches.append(id)
				continue
		
		# Fold state search
		if criteria == "folded" and entity.fold_state > 0:
			matches.append(id)
			continue
			
		if criteria == "unfolded" and entity.fold_state == 0:
			matches.append(id)
			continue
	
	log_message("Found " + str(matches.size()) + " matching entities:")
	
	for id in matches:
		log_message("- " + id + ": " + entities[id].to_string())
	
	return matches

# Show a specific entity's details
func show_entity(entity_id):
	if entity_id.empty():
		log_message("Please specify an entity ID to show.", "error")
		return false
		
	if not entities.has(entity_id):
		log_message("Entity not found: " + entity_id, "error")
		return false
	
	var entity = entities[entity_id]
	
	log_message("Entity Details: " + entity_id)
	log_message("- Type: " + entity.type)
	log_message("- Created: " + _format_timestamp(entity.created_at))
	log_message("- Modified: " + _format_timestamp(entity.modified_at))
	log_message("- Evolution Stage: " + str(entity.evolution_stage) + " (" + _get_stage_name(entity.evolution_stage) + ")")
	log_message("- Evolution Pattern: " + _get_pattern_name(entity.evolution_pattern))
	log_message("- Fold State: " + str(entity.fold_state))
	
	if not entity.tags.empty():
		log_message("- Tags: " + str(entity.tags))
	
	if entity.parent_id:
		log_message("- Parent: " + entity.parent_id)
	
	if not entity.children_ids.empty():
		log_message("- Children: " + str(entity.children_ids))
	
	log_message("- Content:")
	log_message(entity.content)
	
	return true

# Process an evolution cycle
func _process_evolution_cycle():
	current_evolution_cycle += 1
	total_evolution_cycles += 1
	
	log_message("Evolution Cycle #" + str(current_evolution_cycle) + " started.")
	
	# Prepare entities for evolution
	_prepare_evolution_candidates()
	
	# Evolve a batch of entities
	var evolved_count = 0
	var max_to_evolve = min(evolution_batch_size, _ready_for_evolution.size())
	
	for i in range(max_to_evolve):
		var entity_id = _ready_for_evolution[i]
		if evolve_entity(entity_id):
			evolved_count += 1
	
	log_message("Evolved " + str(evolved_count) + " entities in this cycle.")
	
	# Process scheduled folds
	if not _scheduled_folds.empty():
		var fold_count = 0
		var scheduled_ids = _scheduled_folds.keys()
		
		for entity_id in scheduled_ids:
			var mode = _scheduled_folds[entity_id]
			var mode_str = _get_fold_mode_name(mode)
			
			if fold_entity(entity_id + " " + mode_str):
				fold_count += 1
		
		_scheduled_folds.clear()
		log_message("Applied " + str(fold_count) + " scheduled folds.")
	
	# Check for unfolding based on metrics
	var unfolds_count = 0
	for id in entities:
		var entity = entities[id]
		if entity.fold_state > 0:
			var evolution_potential = entity.metrics.calculate_evolution_potential()
			if evolution_potential < unfolding_threshold:
				if unfold_entity(id):
					unfolds_count += 1
	
	if unfolds_count > 0:
		log_message("Auto-unfolded " + str(unfolds_count) + " entities.")
	
	# Emit signal for cycle completion
	emit_signal("evolution_cycle_completed", current_evolution_cycle)
	
	return true

# Prepare entities for evolution
func _prepare_evolution_candidates():
	_ready_for_evolution.clear()
	
	# First, check the evolution queue
	for id in _evolution_queue:
		if entities.has(id) and entities[id].evolution_stage < EvolutionStage.COMPLETION:
			_ready_for_evolution.append(id)
	
	# Clear the queue as we've processed all candidates
	_evolution_queue.clear()
	
	# Sort by evolution stage (prioritize lower stages)
	_ready_for_evolution.sort_custom(self, "_sort_by_evolution_stage_ascending")
	
	# Apply randomness based on evolution rate
	if evolution_rate != 1.0:
		var adjusted_count = int(_ready_for_evolution.size() * evolution_rate)
		if adjusted_count < _ready_for_evolution.size():
			_ready_for_evolution.resize(adjusted_count)

# Transform content based on evolution stages
func _transform_content_for_evolution(content, old_stage, new_stage):
	# In a real implementation, this would apply actual transformations
	# For this mock-up, we'll add some markers to simulate evolution
	
	var evolved_content = content
	
	# Add evolution markers based on rule of 3-6-9
	if new_stage == EvolutionStage.FUNCTION: # 3
		evolved_content = "[FUNC] " + evolved_content
	elif new_stage == EvolutionStage.INTEGRATION: # 6
		evolved_content = "[INTEG] " + evolved_content
	elif new_stage == EvolutionStage.COMPLETION: # 9
		evolved_content = "[COMPLETE] " + evolved_content
	else:
		evolved_content = "[Stage " + str(new_stage) + "] " + evolved_content
		
	return evolved_content

# Custom sort function for evolution stage (descending)
func _sort_by_evolution_stage(a, b):
	return entities[a].evolution_stage > entities[b].evolution_stage

# Custom sort function for evolution stage (ascending)
func _sort_by_evolution_stage_ascending(a, b):
	return entities[a].evolution_stage < entities[b].evolution_stage

# Get pattern name from enum
func _get_pattern_name(pattern):
	match pattern:
		EvolutionPattern.LINEAR: return "Linear"
		EvolutionPattern.BRANCHING: return "Branching"
		EvolutionPattern.CYCLIC: return "Cyclic"
		EvolutionPattern.SPIRAL: return "Spiral"
		EvolutionPattern.EMERGENT: return "Emergent"
		EvolutionPattern.QUANTUM: return "Quantum"
		EvolutionPattern.FOLDING: return "Folding"
		EvolutionPattern.FUSION: return "Fusion"
		_: return "Unknown"

# Get pattern enum from string
func _pattern_from_string(pattern_str):
	match pattern_str.to_lower():
		"linear", "l": return EvolutionPattern.LINEAR
		"branching", "b": return EvolutionPattern.BRANCHING
		"cyclic", "c": return EvolutionPattern.CYCLIC
		"spiral", "s": return EvolutionPattern.SPIRAL
		"emergent", "e": return EvolutionPattern.EMERGENT
		"quantum", "q": return EvolutionPattern.QUANTUM
		"folding", "f": return EvolutionPattern.FOLDING
		"fusion", "fu": return EvolutionPattern.FUSION
		_: return -1

# Get stage name from enum
func _get_stage_name(stage):
	match stage:
		EvolutionStage.SEED: return "Seed"
		EvolutionStage.GROWTH: return "Growth"
		EvolutionStage.FORM: return "Form"
		EvolutionStage.FUNCTION: return "Function ‚òÖ"  # 3
		EvolutionStage.REFINEMENT: return "Refinement"
		EvolutionStage.ADAPTATION: return "Adaptation"
		EvolutionStage.INTEGRATION: return "Integration ‚òÖ"  # 6
		EvolutionStage.EXTENSION: return "Extension"
		EvolutionStage.TRANSCENDENCE: return "Transcendence"
		EvolutionStage.COMPLETION: return "Completion ‚òÖ"  # 9
		_: return "Unknown"

# Get fold mode name
func _get_fold_mode_name(mode):
	match mode:
		FoldingMode.HORIZONTAL: return "horizontal"
		FoldingMode.VERTICAL: return "vertical"
		FoldingMode.DIAGONAL: return "diagonal"
		FoldingMode.TEMPORAL: return "temporal"
		FoldingMode.SEMANTIC: return "semantic"
		FoldingMode.QUANTUM: return "quantum"
		FoldingMode.RECURSIVE: return "recursive"
		_: return "horizontal"

# Format timestamp
func _format_timestamp(timestamp):
	var datetime = OS.get_datetime_from_unix_time(timestamp)
	return "%04d-%02d-%02d %02d:%02d:%02d" % [
		datetime.year,
		datetime.month,
		datetime.day,
		datetime.hour,
		datetime.minute,
		datetime.second
	]

# Display help
func display_evolution_help():
	log_message("Evolution Commands:", "system")
	log_message("  #evolution status - Display evolution engine status", "system")
	log_message("  #evolution create <content> - Create a new entity", "system")
	log_message("  #evolution list - List all entities", "system")
	log_message("  #evolution evolve <entity_id> - Evolve a specific entity", "system")
	log_message("  #evolution fold <entity_id> [mode] - Fold an entity", "system")
	log_message("  #evolution unfold <entity_id> - Unfold an entity", "system")
	log_message("  #evolution auto [on|off] - Toggle auto-evolution", "system")
	log_message("  #evolution cycle - Run one evolution cycle", "system")
	log_message("  #evolution search <criteria> - Search for entities", "system")
	log_message("  #evolution show <entity_id> - Show entity details", "system")
	log_message("  #evolution help - Display this help", "system")
	log_message("", "system")
	log_message("For advanced evolution commands, type ##evolution help", "system")

# Display advanced help
func display_advanced_evolution_help():
	log_message("Advanced Evolution Commands:", "system")
	log_message("  ##evolution rate <value> - Set evolution rate", "system")
	log_message("  ##evolution pattern <entity_id> <pattern> - Set evolution pattern", "system")
	log_message("  ##evolution connect <parent_id> <child_id> - Connect entities", "system")
	log_message("  ##evolution split <entity_id> <count> - Split entity", "system")
	log_message("  ##evolution merge <id1> <id2> [id3...] - Merge entities", "system")
	log_message("  ##evolution metrics <entity_id> - Show entity metrics", "system")
	log_message("  ##evolution batch <size> - Set batch size", "system")
	log_message("  ##evolution threshold <fold> <unfold> - Set thresholds", "system")
	log_message("  ##evolution analyze - Analyze evolution patterns", "system")
	log_message("  ##evolution help - Display this help", "system")

# Display system help
func display_system_evolution_help():
	log_message("System Evolution Commands:", "system")
	log_message("  ###evolution reset - Reset evolution engine", "system")
	log_message("  ###evolution storage <mode> - Set storage mode", "system")
	log_message("  ###evolution save [path] - Save evolution state", "system")
	log_message("  ###evolution load [path] - Load evolution state", "system")
	log_message("  ###evolution purge <criteria> - Purge entities", "system")
	log_message("  ###evolution export [format] - Export evolution data", "system")
	log_message("  ###evolution import <path> - Import evolution data", "system")
	log_message("  ###evolution help - Display this help", "system")

# Display evolution status
func display_evolution_status():
	log_message("Evolution Engine Status:", "evolution")
	log_message("- Current Cycle: " + str(current_evolution_cycle), "evolution")
	log_message("- Total Cycles: " + str(total_evolution_cycles), "evolution")
	log_message("- Entity Count: " + str(entities.size()), "evolution")
	log_message("- Auto-Evolution: " + ("Enabled" if auto_evolution else "Disabled"), "evolution")
	log_message("- Evolution Rate: " + str(evolution_rate), "evolution")
	log_message("- Batch Size: " + str(evolution_batch_size), "evolution")
	log_message("- Folding Threshold: " + str(folding_threshold), "evolution")
	log_message("- Unfolding Threshold: " + str(unfolding_threshold), "evolution")
	log_message("- Storage Mode: " + _get_storage_mode_name(_current_storage_mode), "evolution")
	
	# Distribution of evolution stages
	var stage_counts = {}
	for id in entities:
		var stage = entities[id].evolution_stage
		if not stage_counts.has(stage):
			stage_counts[stage] = 0
		stage_counts[stage] += 1
	
	log_message("- Rule of 3-6-9 Distribution:", "evolution")
	for i in range(10):
		var special_marker = ""
		if i == 3 or i == 6 or i == 9:
			special_marker = " ‚òÖ"
		var count = stage_counts[i] if stage_counts.has(i) else 0
		log_message("  - Stage " + str(i) + special_marker + ": " + str(count), "evolution")

# Get storage mode name
func _get_storage_mode_name(mode):
	match mode:
		StorageType.TERMINAL: return "Terminal"
		StorageType.FILE: return "File"
		StorageType.MEMORY: return "Memory"
		StorageType.DATABASE: return "Database"
		StorageType.CLOUD: return "Cloud"
		StorageType.DIMENSIONAL: return "Dimensional"
		StorageType.QUANTUM: return "Quantum"
		_: return "Unknown"

# Log a message
func log_message(message, category="evolution"):
	print(message)
	
	if terminal and terminal.has_method("add_text"):
		terminal.add_text(message, category)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/data_evolution_engine.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/data_fluctuation_monitor.gd
# SIZE: 37699 bytes
extends Node

# Data Fluctuation Monitor
# Detects and visualizes data fluctuations across time and devices
# Provides Schumann resonance correction and pattern recognition
# Integrates with the Secondary Storage System and Terminal

class_name DataFluctuationMonitor

# Fluctuation patterns
enum FluctuationPattern {
	RANDOM,
	OSCILLATING, 
	GROWING,
	DECAYING,
	RESONANT,
	QUANTUM,
	MERGED,
	SPLIT
}

# Resonance types
enum ResonanceType {
	SCHUMANN,    # Earth's electromagnetic field resonance (7.83 Hz)
	THETA,       # Brain theta waves (4-8 Hz)
	ALPHA,       # Brain alpha waves (8-12 Hz)
	GAMMA,       # Brain gamma waves (25-100 Hz)
	CUSTOM       # User-defined resonance
}

# Fluctuation levels
enum FluctuationLevel {
	NONE,        # No fluctuation
	MINIMAL,     # Minimal, within normal parameters
	MODERATE,    # Moderate, beyond normal parameters
	SIGNIFICANT, # Significant, potentially destructive
	CRITICAL     # Critical, immediate attention required
}

# Merge modes
enum MergeMode {
	APPEND,      # Append data
	OVERLAY,     # Overlay data
	INTERLEAVE,  # Interleave data
	BLEND,       # Blend data
	REPLACE      # Replace data
}

# Split modes
enum SplitMode {
	EVEN,        # Split evenly
	PROPORTIONAL,# Split proportionally
	SEMANTIC,    # Split by semantic meaning
	TEMPORAL,    # Split by time
	RANDOM       # Split randomly
}

# Fluctuation event tracking
class FluctuationEvent:
	var timestamp: int
	var pattern: int
	var level: int
	var affected_files = []
	var corrections_applied = []
	var resonance_type: int
	var frequency: float
	var amplitude: float
	
	func _init(p_pattern: int, p_level: int, p_resonance_type: int = ResonanceType.SCHUMANN):
		timestamp = OS.get_unix_time()
		pattern = p_pattern
		level = p_level
		resonance_type = p_resonance_type
		frequency = get_resonance_frequency(resonance_type)
		amplitude = get_level_amplitude(level)
	
	func get_pattern_string() -> String:
		match pattern:
			FluctuationPattern.RANDOM: return "Random"
			FluctuationPattern.OSCILLATING: return "Oscillating"
			FluctuationPattern.GROWING: return "Growing"
			FluctuationPattern.DECAYING: return "Decaying"
			FluctuationPattern.RESONANT: return "Resonant"
			FluctuationPattern.QUANTUM: return "Quantum"
			FluctuationPattern.MERGED: return "Merged"
			FluctuationPattern.SPLIT: return "Split"
			_: return "Unknown"
	
	func get_level_string() -> String:
		match level:
			FluctuationLevel.NONE: return "None"
			FluctuationLevel.MINIMAL: return "Minimal"
			FluctuationLevel.MODERATE: return "Moderate"
			FluctuationLevel.SIGNIFICANT: return "Significant"
			FluctuationLevel.CRITICAL: return "Critical"
			_: return "Unknown"
	
	func get_resonance_string() -> String:
		match resonance_type:
			ResonanceType.SCHUMANN: return "Schumann (7.83 Hz)"
			ResonanceType.THETA: return "Theta (4-8 Hz)"
			ResonanceType.ALPHA: return "Alpha (8-12 Hz)"
			ResonanceType.GAMMA: return "Gamma (25-100 Hz)"
			ResonanceType.CUSTOM: return "Custom (" + str(frequency) + " Hz)"
			_: return "Unknown"
	
	func get_resonance_frequency(type: int) -> float:
		match type:
			ResonanceType.SCHUMANN: return 7.83
			ResonanceType.THETA: return 6.0
			ResonanceType.ALPHA: return 10.0
			ResonanceType.GAMMA: return 40.0
			ResonanceType.CUSTOM: return 15.0  # Default custom frequency
			_: return 7.83
	
	func get_level_amplitude(lvl: int) -> float:
		match lvl:
			FluctuationLevel.NONE: return 0.0
			FluctuationLevel.MINIMAL: return 0.2
			FluctuationLevel.MODERATE: return 0.5
			FluctuationLevel.SIGNIFICANT: return 0.8
			FluctuationLevel.CRITICAL: return 1.0
			_: return 0.0
	
	func get_summary() -> String:
		return "Fluctuation [%s, %s, %s] detected at %s with %d affected files" % [
			get_pattern_string(),
			get_level_string(),
			get_resonance_string(),
			_format_timestamp(timestamp),
			affected_files.size()
		]
	
	func _format_timestamp(ts: int) -> String:
		var datetime = OS.get_datetime_from_unix_time(ts)
		return "%04d-%02d-%02d %02d:%02d:%02d" % [
			datetime.year,
			datetime.month,
			datetime.day,
			datetime.hour,
			datetime.minute,
			datetime.second
		]

# Module configuration
var enabled = true
var monitoring_interval = 60  # seconds
var monitor_multiple_drives = true
var apply_auto_correction = true
var visualize_fluctuations = true
var archive_fluctuations = true
var warning_threshold = FluctuationLevel.MODERATE
var merge_mode = MergeMode.BLEND
var split_mode = SplitMode.SEMANTIC
var clean_data_on_split = true
var default_resonance = ResonanceType.SCHUMANN
var resonance_correction_strength = 0.7  # 0.0 to 1.0

# System references
var terminal = null
var storage_system = null
var symbol_system = null

# Monitoring state
var monitoring_active = false
var last_scan_time = 0
var fluctuation_events = []
var current_resonance = 7.83  # Default Schumann resonance (Hz)
var baseline_hash = ""
var monitor_timer = null

# Signals
signal fluctuation_detected(event)
signal data_merged(files, mode)
signal data_split(files, mode)
signal resonance_corrected(files, frequency)

func _ready():
	# Look for terminal and storage system
	terminal = get_node_or_null("/root/IntegratedTerminal")
	
	if terminal:
		if terminal.has_node("storage_system"):
			storage_system = terminal.get_node("storage_system")
		
		if terminal.has_node("symbol_system"):
			symbol_system = terminal.get_node("symbol_system")
		
		log_message("Data Fluctuation Monitor initialized.", "system")
	
	# Set up monitoring timer
	monitor_timer = Timer.new()
	monitor_timer.wait_time = monitoring_interval
	monitor_timer.autostart = true
	monitor_timer.connect("timeout", self, "_scan_for_fluctuations")
	add_child(monitor_timer)
	
	# Initial baseline generation
	establish_baseline()

# Process commands
func process_command(command):
	var parts = command.split(" ", true, 1)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"#fluctuation", "#flux":
			process_fluctuation_command(args)
			return true
		"##fluctuation", "##flux":
			process_advanced_fluctuation_command(args)
			return true
		"###fluctuation", "###flux":
			process_system_fluctuation_command(args)
			return true
		_:
			return false

# Process basic fluctuation commands
func process_fluctuation_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_fluctuation_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"status":
			show_fluctuation_status()
		"scan":
			scan_for_fluctuations()
		"history":
			show_fluctuation_history()
		"resonance":
			show_resonance_info(subargs)
		"merge":
			merge_data(subargs)
		"split":
			split_data(subargs)
		"monitor":
			toggle_monitoring(subargs)
		"correct":
			apply_resonance_correction(subargs)
		"visualize":
			visualize_fluctuation(subargs)
		"help":
			display_fluctuation_help()
		_:
			log_message("Unknown fluctuation command: " + subcmd, "error")

# Process advanced fluctuation commands
func process_advanced_fluctuation_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_advanced_fluctuation_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"pattern":
			analyze_fluctuation_pattern(subargs)
		"threshold":
			set_warning_threshold(subargs)
		"interval":
			set_monitoring_interval(subargs)
		"baseline":
			establish_baseline()
		"compare":
			compare_to_baseline(subargs)
		"resonance":
			set_resonance_type(subargs)
		"strength":
			set_correction_strength(subargs)
		"clean":
			toggle_clean_data(subargs)
		"mode":
			set_merge_split_mode(subargs)
		"help":
			display_advanced_fluctuation_help()
		_:
			log_message("Unknown advanced fluctuation command: " + subcmd, "error")

# Process system fluctuation commands
func process_system_fluctuation_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_system_fluctuation_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"reset":
			reset_fluctuation_monitor()
		"archive":
			toggle_archive_fluctuations(subargs)
		"purge":
			purge_fluctuation_history()
		"export":
			export_fluctuation_data(subargs)
		"import":
			import_fluctuation_data(subargs)
		"quantum":
			simulate_quantum_fluctuation()
		"help":
			display_system_fluctuation_help()
		_:
			log_message("Unknown system fluctuation command: " + subcmd, "error")

# Show fluctuation status
func show_fluctuation_status():
	log_message("Data Fluctuation Monitor Status:", "fluctuation")
	log_message("- Monitoring: " + ("Active" if monitoring_active else "Inactive"), "fluctuation")
	log_message("- Auto-correction: " + ("Enabled" if apply_auto_correction else "Disabled"), "fluctuation")
	log_message("- Current Resonance: " + _get_resonance_string(default_resonance) + " (" + str(current_resonance) + " Hz)", "fluctuation")
	log_message("- Correction Strength: " + str(int(resonance_correction_strength * 100)) + "%", "fluctuation")
	log_message("- Warning Threshold: " + _get_level_string(warning_threshold), "fluctuation")
	log_message("- Monitoring Interval: " + str(monitoring_interval) + " seconds", "fluctuation")
	log_message("- Last Scan: " + (_format_timestamp(last_scan_time) if last_scan_time > 0 else "Never"), "fluctuation")
	log_message("- Archive: " + ("Enabled" if archive_fluctuations else "Disabled"), "fluctuation")
	log_message("- Visualize: " + ("Enabled" if visualize_fluctuations else "Disabled"), "fluctuation")
	log_message("- Merge Mode: " + _get_merge_mode_string(merge_mode), "fluctuation")
	log_message("- Split Mode: " + _get_split_mode_string(split_mode), "fluctuation")
	log_message("- Clean on Split: " + ("Enabled" if clean_data_on_split else "Disabled"), "fluctuation")
	
	var recent_count = 0
	var critical_count = 0
	
	for event in fluctuation_events:
		if OS.get_unix_time() - event.timestamp < 3600:  # Within the last hour
			recent_count += 1
		if event.level == FluctuationLevel.CRITICAL:
			critical_count += 1
	
	log_message("- Recent Events (1h): " + str(recent_count), "fluctuation")
	log_message("- Critical Events: " + str(critical_count), "fluctuation")
	log_message("- Total Events: " + str(fluctuation_events.size()), "fluctuation")

# Scan for fluctuations
func scan_for_fluctuations():
	log_message("Scanning for data fluctuations...", "fluctuation")
	
	monitoring_active = true
	last_scan_time = OS.get_unix_time()
	
	# In a real implementation, this would scan actual data
	# For this mock-up, we'll simulate it
	
	var fluctuation_chance = 0.6  # 60% chance of detecting a fluctuation
	
	if randf() < fluctuation_chance:
		# Simulate a fluctuation
		var pattern = _get_random_pattern()
		var level = _get_random_level()
		var resonance_type = _get_random_resonance()
		
		var event = FluctuationEvent.new(pattern, level, resonance_type)
		
		# Simulate affected files
		var affected_count = randi() % 10 + 1  # 1 to 10 files
		for i in range(affected_count):
			event.affected_files.append("file_" + str(i + 1) + ".dat")
		
		fluctuation_events.append(event)
		
		log_message("Fluctuation detected!", "warning")
		log_message(event.get_summary(), "fluctuation")
		
		emit_signal("fluctuation_detected", event)
		
		# Apply auto-correction if enabled and needed
		if apply_auto_correction and level >= warning_threshold:
			apply_resonance_correction()
			
		# Visualize if enabled
		if visualize_fluctuations:
			visualize_fluctuation()
	else:
		log_message("No fluctuations detected. Data is stable.", "fluctuation")

# Show fluctuation history
func show_fluctuation_history():
	if fluctuation_events.size() == 0:
		log_message("No fluctuation events recorded.", "fluctuation")
		return
		
	log_message("Fluctuation Event History:", "fluctuation")
	
	var displayed_count = min(10, fluctuation_events.size())  # Show most recent 10 events
	var start_index = fluctuation_events.size() - displayed_count
	
	for i in range(start_index, fluctuation_events.size()):
		var event = fluctuation_events[i]
		log_message(str(i + 1) + ". " + event.get_summary(), "fluctuation")
		
	if fluctuation_events.size() > displayed_count:
		log_message("(Showing " + str(displayed_count) + " most recent events out of " + str(fluctuation_events.size()) + " total)", "fluctuation")

# Show resonance information
func show_resonance_info(resonance_type=""):
	if resonance_type.empty() or resonance_type == "current":
		log_message("Current Resonance:", "fluctuation")
		log_message("- Type: " + _get_resonance_string(default_resonance), "fluctuation")
		log_message("- Frequency: " + str(current_resonance) + " Hz", "fluctuation")
		log_message("- Correction Strength: " + str(int(resonance_correction_strength * 100)) + "%", "fluctuation")
		return
		
	match resonance_type.to_lower():
		"schumann":
			log_message("Schumann Resonance (Earth):", "fluctuation")
			log_message("- Primary Frequency: 7.83 Hz", "fluctuation")
			log_message("- Harmonics: 14.3, 20.8, 27.3, 33.8 Hz", "fluctuation")
			log_message("- Effect: Earth's electromagnetic field resonance", "fluctuation")
		"theta":
			log_message("Theta Brain Waves:", "fluctuation")
			log_message("- Frequency Range: 4-8 Hz", "fluctuation")
			log_message("- Effect: Deep meditation, creativity, dreaming", "fluctuation")
		"alpha":
			log_message("Alpha Brain Waves:", "fluctuation")
			log_message("- Frequency Range: 8-12 Hz", "fluctuation")
			log_message("- Effect: Relaxation, calmness, learning", "fluctuation")
		"gamma":
			log_message("Gamma Brain Waves:", "fluctuation")
			log_message("- Frequency Range: 25-100 Hz", "fluctuation")
			log_message("- Effect: Higher cognitive functions, focus", "fluctuation")
		"all":
			log_message("Resonance Types:", "fluctuation")
			log_message("- Schumann: 7.83 Hz (Earth resonance)", "fluctuation")
			log_message("- Theta: 4-8 Hz (Deep meditation, creativity)", "fluctuation")
			log_message("- Alpha: 8-12 Hz (Relaxation, learning)", "fluctuation")
			log_message("- Gamma: 25-100 Hz (Focus, cognition)", "fluctuation")
		_:
			log_message("Unknown resonance type: " + resonance_type, "error")
			log_message("Available types: schumann, theta, alpha, gamma, all", "system")

# Merge data
func merge_data(mode_str=""):
	if !mode_str.empty():
		set_merge_mode(mode_str)
		
	log_message("Merging data using " + _get_merge_mode_string(merge_mode) + " mode...", "fluctuation")
	
	# In a real implementation, this would merge actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.0), "timeout")
	
	var affected_files = []
	var affected_count = randi() % 5 + 1  # 1 to 5 files
	
	for i in range(affected_count):
		affected_files.append("merged_file_" + str(i + 1) + ".dat")
	
	log_message("Data merged successfully. Affected " + str(affected_count) + " files.", "fluctuation")
	emit_signal("data_merged", affected_files, merge_mode)

# Split data
func split_data(mode_str=""):
	if !mode_str.empty():
		set_split_mode(mode_str)
		
	log_message("Splitting data using " + _get_split_mode_string(split_mode) + " mode...", "fluctuation")
	
	# In a real implementation, this would split actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.0), "timeout")
	
	var affected_files = []
	var affected_count = randi() % 5 + 1  # 1 to 5 files
	
	for i in range(affected_count):
		affected_files.append("split_file_" + str(i + 1) + ".dat")
	
	log_message("Data split successfully. Created " + str(affected_count) + " files.", "fluctuation")
	
	if clean_data_on_split:
		log_message("Cleaning split data...", "fluctuation")
		yield(get_tree().create_timer(0.5), "timeout")
		log_message("Split data cleaned.", "fluctuation")
	
	emit_signal("data_split", affected_files, split_mode)

# Toggle monitoring
func toggle_monitoring(enabled_str=""):
	if enabled_str.empty():
		enabled = !enabled
	else:
		enabled = (enabled_str.to_lower() == "on" or enabled_str.to_lower() == "true" or enabled_str == "1")
	
	monitoring_active = enabled
	
	if enabled:
		monitor_timer.start()
		log_message("Fluctuation monitoring enabled. Scanning every " + str(monitoring_interval) + " seconds.", "fluctuation")
	else:
		monitor_timer.stop()
		log_message("Fluctuation monitoring disabled.", "fluctuation")

# Apply resonance correction
func apply_resonance_correction(resonance_str=""):
	if !resonance_str.empty():
		set_resonance_type(resonance_str)
		
	log_message("Applying " + _get_resonance_string(default_resonance) + " resonance correction...", "fluctuation")
	
	# In a real implementation, this would apply actual corrections
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.0), "timeout")
	
	var affected_files = []
	
	if fluctuation_events.size() > 0:
		var latest_event = fluctuation_events[fluctuation_events.size() - 1]
		affected_files = latest_event.affected_files.duplicate()
		
		for correction in ["frequency_alignment", "amplitude_normalization", "phase_correction"]:
			latest_event.corrections_applied.append(correction)
	else:
		var affected_count = randi() % 3 + 1  # 1 to 3 files
		for i in range(affected_count):
			affected_files.append("file_" + str(i + 1) + ".dat")
	
	log_message("Resonance correction applied to " + str(affected_files.size()) + " files.", "fluctuation")
	log_message("Correction strength: " + str(int(resonance_correction_strength * 100)) + "%", "fluctuation")
	
	emit_signal("resonance_corrected", affected_files, current_resonance)

# Visualize fluctuation
func visualize_fluctuation(type_str=""):
	if !visualize_fluctuations:
		log_message("Fluctuation visualization is disabled.", "error")
		return
		
	var pattern = FluctuationPattern.OSCILLATING
	
	if !type_str.empty():
		match type_str.to_lower():
			"random": pattern = FluctuationPattern.RANDOM
			"oscillating": pattern = FluctuationPattern.OSCILLATING
			"growing": pattern = FluctuationPattern.GROWING
			"decaying": pattern = FluctuationPattern.DECAYING
			"resonant": pattern = FluctuationPattern.RESONANT
			"quantum": pattern = FluctuationPattern.QUANTUM
			"merged": pattern = FluctuationPattern.MERGED
			"split": pattern = FluctuationPattern.SPLIT
	elif fluctuation_events.size() > 0:
		pattern = fluctuation_events[fluctuation_events.size() - 1].pattern
	
	log_message("Visualizing " + _get_pattern_string(pattern) + " fluctuation pattern:", "fluctuation")
	
	match pattern:
		FluctuationPattern.RANDOM:
			_visualize_random_pattern()
		FluctuationPattern.OSCILLATING:
			_visualize_oscillating_pattern()
		FluctuationPattern.GROWING:
			_visualize_growing_pattern()
		FluctuationPattern.DECAYING:
			_visualize_decaying_pattern()
		FluctuationPattern.RESONANT:
			_visualize_resonant_pattern()
		FluctuationPattern.QUANTUM:
			_visualize_quantum_pattern()
		FluctuationPattern.MERGED:
			_visualize_merged_pattern()
		FluctuationPattern.SPLIT:
			_visualize_split_pattern()

# Analyze fluctuation pattern
func analyze_fluctuation_pattern(file_path=""):
	log_message("Analyzing fluctuation pattern" + (file_path.empty() ? "" : " in " + file_path) + "...", "fluctuation")
	
	# In a real implementation, this would analyze actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.0), "timeout")
	
	var pattern = _get_random_pattern()
	var level = _get_random_level()
	var dominant_frequency = 7.83 + (randf() - 0.5) * 2.0  # Schumann +/- 1 Hz
	
	log_message("Analysis Complete:", "fluctuation")
	log_message("- Dominant Pattern: " + _get_pattern_string(pattern), "fluctuation")
	log_message("- Fluctuation Level: " + _get_level_string(level), "fluctuation")
	log_message("- Dominant Frequency: " + str(dominant_frequency) + " Hz", "fluctuation")
	log_message("- Temporal Stability: " + str(int(randf() * 100)) + "%", "fluctuation")
	
	if level >= warning_threshold:
		log_message("WARNING: Fluctuation level exceeds threshold!", "warning")
		log_message("Recommendation: Apply resonance correction.", "fluctuation")

# Set warning threshold
func set_warning_threshold(level_str):
	var level = warning_threshold
	
	match level_str.to_lower():
		"none": level = FluctuationLevel.NONE
		"minimal": level = FluctuationLevel.MINIMAL
		"moderate": level = FluctuationLevel.MODERATE
		"significant": level = FluctuationLevel.SIGNIFICANT
		"critical": level = FluctuationLevel.CRITICAL
		_:
			log_message("Invalid threshold level: " + level_str, "error")
			log_message("Valid levels: none, minimal, moderate, significant, critical", "system")
			return
	
	warning_threshold = level
	log_message("Warning threshold set to: " + _get_level_string(level), "fluctuation")

# Set monitoring interval
func set_monitoring_interval(interval_str):
	var interval = int(interval_str)
	
	if interval <= 0:
		log_message("Invalid interval. Must be a positive number.", "error")
		return
		
	monitoring_interval = interval
	
	if monitor_timer:
		monitor_timer.wait_time = monitoring_interval
		
	log_message("Monitoring interval set to " + str(interval) + " seconds.", "fluctuation")

# Establish baseline
func establish_baseline():
	log_message("Establishing fluctuation baseline...", "fluctuation")
	
	# In a real implementation, this would create a baseline from actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.5), "timeout")
	
	baseline_hash = "bf3a2c7e9d8f1a6b5c4d2e0f"  # Simulated hash
	
	log_message("Baseline established successfully.", "fluctuation")
	log_message("Baseline Hash: " + baseline_hash, "fluctuation")

# Compare to baseline
func compare_to_baseline(target=""):
	log_message("Comparing current data to baseline" + (target.empty() ? "" : " for " + target) + "...", "fluctuation")
	
	# In a real implementation, this would compare actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.0), "timeout")
	
	var divergence = randf() * 100  # 0% to 100% divergence
	var changed_files = int(randf() * 10)  # 0 to 9 changed files
	
	log_message("Comparison Results:", "fluctuation")
	log_message("- Divergence: " + str(int(divergence)) + "%", "fluctuation")
	log_message("- Changed Files: " + str(changed_files), "fluctuation")
	
	if divergence > 50:
		log_message("WARNING: Significant divergence from baseline detected!", "warning")
	elif divergence > 20:
		log_message("NOTICE: Moderate divergence from baseline detected.", "fluctuation")
	else:
		log_message("Data consistent with baseline.", "fluctuation")

# Set resonance type
func set_resonance_type(type_str):
	var resonance_type = default_resonance
	
	match type_str.to_lower():
		"schumann": 
			resonance_type = ResonanceType.SCHUMANN
			current_resonance = 7.83
		"theta": 
			resonance_type = ResonanceType.THETA
			current_resonance = 6.0
		"alpha": 
			resonance_type = ResonanceType.ALPHA
			current_resonance = 10.0
		"gamma": 
			resonance_type = ResonanceType.GAMMA
			current_resonance = 40.0
		"custom":
			resonance_type = ResonanceType.CUSTOM
			current_resonance = 15.0
		_:
			if type_str.is_valid_float():
				resonance_type = ResonanceType.CUSTOM
				current_resonance = float(type_str)
			else:
				log_message("Invalid resonance type: " + type_str, "error")
				log_message("Valid types: schumann, theta, alpha, gamma, custom, or a frequency value", "system")
				return
	
	default_resonance = resonance_type
	log_message("Resonance type set to: " + _get_resonance_string(resonance_type) + " (" + str(current_resonance) + " Hz)", "fluctuation")

# Set correction strength
func set_correction_strength(strength_str):
	var strength = float(strength_str)
	
	if strength < 0.0 or strength > 1.0:
		log_message("Invalid strength value. Must be between 0.0 and 1.0.", "error")
		return
		
	resonance_correction_strength = strength
	log_message("Resonance correction strength set to: " + str(int(strength * 100)) + "%", "fluctuation")

# Toggle clean data
func toggle_clean_data(enabled_str=""):
	if enabled_str.empty():
		clean_data_on_split = !clean_data_on_split
	else:
		clean_data_on_split = (enabled_str.to_lower() == "on" or enabled_str.to_lower() == "true" or enabled_str == "1")
	
	log_message("Clean data on split: " + ("Enabled" if clean_data_on_split else "Disabled"), "fluctuation")

# Set merge/split mode
func set_merge_split_mode(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		log_message("Usage: ##fluctuation mode <merge|split> <mode>", "error")
		return
		
	var mode_type = parts[0].to_lower()
	var mode_value = parts[1].to_lower()
	
	match mode_type:
		"merge":
			set_merge_mode(mode_value)
		"split":
			set_split_mode(mode_value)
		_:
			log_message("Invalid mode type: " + mode_type, "error")
			log_message("Valid types: merge, split", "system")

# Set merge mode
func set_merge_mode(mode_str):
	var mode = merge_mode
	
	match mode_str.to_lower():
		"append": mode = MergeMode.APPEND
		"overlay": mode = MergeMode.OVERLAY
		"interleave": mode = MergeMode.INTERLEAVE
		"blend": mode = MergeMode.BLEND
		"replace": mode = MergeMode.REPLACE
		_:
			log_message("Invalid merge mode: " + mode_str, "error")
			log_message("Valid modes: append, overlay, interleave, blend, replace", "system")
			return
	
	merge_mode = mode
	log_message("Merge mode set to: " + _get_merge_mode_string(mode), "fluctuation")

# Set split mode
func set_split_mode(mode_str):
	var mode = split_mode
	
	match mode_str.to_lower():
		"even": mode = SplitMode.EVEN
		"proportional": mode = SplitMode.PROPORTIONAL
		"semantic": mode = SplitMode.SEMANTIC
		"temporal": mode = SplitMode.TEMPORAL
		"random": mode = SplitMode.RANDOM
		_:
			log_message("Invalid split mode: " + mode_str, "error")
			log_message("Valid modes: even, proportional, semantic, temporal, random", "system")
			return
	
	split_mode = mode
	log_message("Split mode set to: " + _get_split_mode_string(mode), "fluctuation")

# Reset fluctuation monitor
func reset_fluctuation_monitor():
	log_message("Resetting fluctuation monitor...", "system")
	
	enabled = true
	monitoring_interval = 60
	monitor_multiple_drives = true
	apply_auto_correction = true
	visualize_fluctuations = true
	archive_fluctuations = true
	warning_threshold = FluctuationLevel.MODERATE
	merge_mode = MergeMode.BLEND
	split_mode = SplitMode.SEMANTIC
	clean_data_on_split = true
	default_resonance = ResonanceType.SCHUMANN
	resonance_correction_strength = 0.7
	current_resonance = 7.83
	
	fluctuation_events.clear()
	monitoring_active = false
	last_scan_time = 0
	baseline_hash = ""
	
	if monitor_timer:
		monitor_timer.wait_time = monitoring_interval
		monitor_timer.stop()
	
	log_message("Fluctuation monitor reset complete.", "system")

# Toggle archive fluctuations
func toggle_archive_fluctuations(enabled_str=""):
	if enabled_str.empty():
		archive_fluctuations = !archive_fluctuations
	else:
		archive_fluctuations = (enabled_str.to_lower() == "on" or enabled_str.to_lower() == "true" or enabled_str == "1")
	
	log_message("Archive fluctuations: " + ("Enabled" if archive_fluctuations else "Disabled"), "fluctuation")

# Purge fluctuation history
func purge_fluctuation_history():
	log_message("Purging fluctuation event history...", "fluctuation")
	
	var event_count = fluctuation_events.size()
	fluctuation_events.clear()
	
	log_message("Purged " + str(event_count) + " fluctuation events.", "fluctuation")

# Export fluctuation data
func export_fluctuation_data(path):
	if path.empty():
		path = "user://fluctuation_data.dat"
		
	log_message("Exporting fluctuation data to: " + path, "fluctuation")
	
	# In a real implementation, this would save to a file
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("Fluctuation data exported successfully.", "fluctuation")

# Import fluctuation data
func import_fluctuation_data(path):
	if path.empty():
		path = "user://fluctuation_data.dat"
		
	log_message("Importing fluctuation data from: " + path, "fluctuation")
	
	# In a real implementation, this would load from a file
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("Fluctuation data imported successfully.", "fluctuation")

# Simulate quantum fluctuation
func simulate_quantum_fluctuation():
	log_message("Simulating quantum fluctuation...", "fluctuation")
	
	# In a real implementation, this would simulate a quantum fluctuation
	# For this mock-up, we'll just create a special event
	
	var event = FluctuationEvent.new(FluctuationPattern.QUANTUM, FluctuationLevel.SIGNIFICANT)
	
	# Simulate affected files with quantum-themed names
	var affected_count = randi() % 5 + 3  # 3 to 7 files
	for i in range(affected_count):
		event.affected_files.append("quantum_state_" + str(i + 1) + ".dat")
	
	fluctuation_events.append(event)
	
	log_message("Quantum fluctuation simulated!", "fluctuation")
	log_message(event.get_summary(), "fluctuation")
	
	emit_signal("fluctuation_detected", event)
	
	# Visualize quantum pattern
	if visualize_fluctuations:
		_visualize_quantum_pattern()

# Visualization methods for different patterns
func _visualize_random_pattern():
	for i in range(8):
		var line = ""
		for j in range(40):
			line += "*" if randf() > 0.5 else " "
		log_message(line, "visualize")

func _visualize_oscillating_pattern():
	var amplitude = 10
	var width = 40
	
	for i in range(8):
		var position = int(amplitude * sin(i * 0.7) + amplitude)
		var line = ""
		for j in range(width):
			line += "*" if j == position else " "
		log_message(line, "visualize")

func _visualize_growing_pattern():
	for i in range(8):
		var stars = int((i + 1) * 5)
		log_message("*".repeat(stars), "visualize")

func _visualize_decaying_pattern():
	for i in range(8):
		var stars = int((8 - i) * 5)
		log_message("*".repeat(stars), "visualize")

func _visualize_resonant_pattern():
	var lines = [
		"    *        *        *        *    ",
		"   ***      ***      ***      ***   ",
		"  *****    *****    *****    *****  ",
		" ******* ********* ******* *******  ",
		"*****************************  **** ",
		" ******* ********* ******* ******* ",
		"  *****    *****    *****    *****  ",
		"   ***      ***      ***      ***   "
	]
	
	for line in lines:
		log_message(line, "visualize")

func _visualize_quantum_pattern():
	var lines = [
		"‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ  ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ",
		"‚îÇ  ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí  ‚îÇ  ‚îÇ           ‚îÇ",
		"‚îÇ ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí ‚îÇ‚ü∑ ‚îÇ     ‚ñí     ‚îÇ",
		"‚îÇ  ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí  ‚îÇ  ‚îÇ    ‚ñí‚ñí‚ñí    ‚îÇ",
		"‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ  ‚îÇ   ‚ñí‚ñí‚ñí‚ñí‚ñí   ‚îÇ",
		"               ‚îÇ    ‚ñí‚ñí‚ñí    ‚îÇ",
		"               ‚îÇ     ‚ñí     ‚îÇ",
		"               ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ"
	]
	
	for line in lines:
		log_message(line, "visualize")

func _visualize_merged_pattern():
	var lines = [
		"  ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ    ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ  ",
		"  ‚îÇ ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí ‚îÇ    ‚îÇ ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì ‚îÇ  ",
		"  ‚îÇ ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí ‚îÇ    ‚îÇ ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì ‚îÇ  ",
		"  ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ    ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ  ",
		"        ‚ï≤          ‚ï±        ",
		"         ‚ï≤        ‚ï±         ",
		"          ‚ï≤      ‚ï±          ",
		"      ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ        ",
		"      ‚îÇ ‚ñí‚ñí‚ñí‚ñì‚ñì‚ñì‚ñí‚ñí‚ñí‚ñì‚ñì‚îÇ        ",
		"      ‚îÇ ‚ñí‚ñí‚ñì‚ñì‚ñí‚ñí‚ñì‚ñì‚ñí‚ñí‚ñì‚îÇ        ",
		"      ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ        "
	]
	
	for line in lines:
		log_message(line, "visualize")

func _visualize_split_pattern():
	var lines = [
		"      ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ        ",
		"      ‚îÇ ‚ñí‚ñí‚ñí‚ñì‚ñì‚ñì‚ñí‚ñí‚ñí‚ñì‚ñì‚îÇ        ",
		"      ‚îÇ ‚ñí‚ñí‚ñì‚ñì‚ñí‚ñí‚ñì‚ñì‚ñí‚ñí‚ñì‚îÇ        ",
		"      ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ        ",
		"          ‚ï±      ‚ï≤          ",
		"         ‚ï±        ‚ï≤         ",
		"        ‚ï±          ‚ï≤        ",
		"  ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ    ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ  ",
		"  ‚îÇ ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí ‚îÇ    ‚îÇ ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì ‚îÇ  ",
		"  ‚îÇ ‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí ‚îÇ    ‚îÇ ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì ‚îÇ  ",
		"  ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ    ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ  "
	]
	
	for line in lines:
		log_message(line, "visualize")

# Helper functions for random pattern generation
func _get_random_pattern():
	return randi() % 8  # 0 to 7 (all pattern types)

func _get_random_level():
	var weights = [10, 30, 40, 15, 5]  # Weighted probabilities
	var total = 0
	for w in weights:
		total += w
	
	var roll = randi() % total
	var cumulative = 0
	
	for i in range(weights.size()):
		cumulative += weights[i]
		if roll < cumulative:
			return i
	
	return FluctuationLevel.MINIMAL  # Default fallback

func _get_random_resonance():
	var resonances = [
		ResonanceType.SCHUMANN,
		ResonanceType.THETA,
		ResonanceType.ALPHA,
		ResonanceType.GAMMA
	]
	
	return resonances[randi() % resonances.size()]

# String format helpers
func _get_pattern_string(pattern):
	match pattern:
		FluctuationPattern.RANDOM: return "Random"
		FluctuationPattern.OSCILLATING: return "Oscillating"
		FluctuationPattern.GROWING: return "Growing"
		FluctuationPattern.DECAYING: return "Decaying"
		FluctuationPattern.RESONANT: return "Resonant"
		FluctuationPattern.QUANTUM: return "Quantum"
		FluctuationPattern.MERGED: return "Merged"
		FluctuationPattern.SPLIT: return "Split"
		_: return "Unknown"

func _get_level_string(level):
	match level:
		FluctuationLevel.NONE: return "None"
		FluctuationLevel.MINIMAL: return "Minimal"
		FluctuationLevel.MODERATE: return "Moderate"
		FluctuationLevel.SIGNIFICANT: return "Significant"
		FluctuationLevel.CRITICAL: return "Critical"
		_: return "Unknown"

func _get_resonance_string(resonance_type):
	match resonance_type:
		ResonanceType.SCHUMANN: return "Schumann"
		ResonanceType.THETA: return "Theta"
		ResonanceType.ALPHA: return "Alpha"
		ResonanceType.GAMMA: return "Gamma"
		ResonanceType.CUSTOM: return "Custom"
		_: return "Unknown"

func _get_merge_mode_string(mode):
	match mode:
		MergeMode.APPEND: return "Append"
		MergeMode.OVERLAY: return "Overlay"
		MergeMode.INTERLEAVE: return "Interleave"
		MergeMode.BLEND: return "Blend"
		MergeMode.REPLACE: return "Replace"
		_: return "Unknown"

func _get_split_mode_string(mode):
	match mode:
		SplitMode.EVEN: return "Even"
		SplitMode.PROPORTIONAL: return "Proportional"
		SplitMode.SEMANTIC: return "Semantic"
		SplitMode.TEMPORAL: return "Temporal"
		SplitMode.RANDOM: return "Random"
		_: return "Unknown"

func _format_timestamp(timestamp):
	if timestamp == 0:
		return "Never"
		
	var datetime = OS.get_datetime_from_unix_time(timestamp)
	return "%04d-%02d-%02d %02d:%02d:%02d" % [
		datetime.year,
		datetime.month,
		datetime.day,
		datetime.hour,
		datetime.minute,
		datetime.second
	]

# Check for fluctuations periodically
func _scan_for_fluctuations():
	if enabled and monitoring_active:
		scan_for_fluctuations()

# Display help commands
func display_fluctuation_help():
	log_message("Fluctuation Commands:", "system")
	log_message("  #fluctuation status - Display fluctuation monitor status", "system")
	log_message("  #fluctuation scan - Scan for data fluctuations", "system")
	log_message("  #fluctuation history - Show fluctuation history", "system")
	log_message("  #fluctuation resonance [type] - Show resonance information", "system")
	log_message("  #fluctuation merge [mode] - Merge data using specified mode", "system")
	log_message("  #fluctuation split [mode] - Split data using specified mode", "system")
	log_message("  #fluctuation monitor [on/off] - Toggle monitoring", "system")
	log_message("  #fluctuation correct [type] - Apply resonance correction", "system")
	log_message("  #fluctuation visualize [type] - Visualize fluctuation pattern", "system")
	log_message("  #fluctuation help - Display this help", "system")
	log_message("", "system")
	log_message("For advanced fluctuation commands, type ##fluctuation help", "system")

func display_advanced_fluctuation_help():
	log_message("Advanced Fluctuation Commands:", "system")
	log_message("  ##fluctuation pattern [file] - Analyze fluctuation pattern", "system")
	log_message("  ##fluctuation threshold <level> - Set warning threshold", "system")
	log_message("  ##fluctuation interval <seconds> - Set monitoring interval", "system")
	log_message("  ##fluctuation baseline - Establish new baseline", "system")
	log_message("  ##fluctuation compare [target] - Compare to baseline", "system")
	log_message("  ##fluctuation resonance <type> - Set resonance type", "system")
	log_message("  ##fluctuation strength <value> - Set correction strength", "system")
	log_message("  ##fluctuation clean [on/off] - Toggle clean data on split", "system")
	log_message("  ##fluctuation mode <merge|split> <mode> - Set merge/split mode", "system")
	log_message("  ##fluctuation help - Display this help", "system")

func display_system_fluctuation_help():
	log_message("System Fluctuation Commands:", "system")
	log_message("  ###fluctuation reset - Reset fluctuation monitor", "system")
	log_message("  ###fluctuation archive [on/off] - Toggle archiving", "system")
	log_message("  ###fluctuation purge - Purge fluctuation history", "system")
	log_message("  ###fluctuation export [path] - Export fluctuation data", "system")
	log_message("  ###fluctuation import [path] - Import fluctuation data", "system")
	log_message("  ###fluctuation quantum - Simulate quantum fluctuation", "system")
	log_message("  ###fluctuation help - Display this help", "system")

# Log a message
func log_message(message, category="fluctuation"):
	print(message)
	
	if terminal and terminal.has_method("add_text"):
		terminal.add_text(message, category)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/data_fluctuation_monitor.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/data_pipeline_system.gd
# SIZE: 18868 bytes
extends Node

class_name DataPipelineSystem

# Core drive configuration
const DRIVE_CONFIG = {
	"core_0": {
		"path": "/mnt/c/Users/Percision 15/12_turns_system/data/core_0",
		"type": "system",
		"description": "Primary system drive - contains core system files and configurations",
		"sync_priority": 1,
		"max_size_gb": 500
	},
	"core_1": {
		"path": "/mnt/c/Users/Percision 15/icloud_sync",
		"type": "cloud",
		"description": "iCloud integration - contains synchronized personal data and backups",
		"sync_priority": 2,
		"max_size_gb": 200
	},
	"core_2": {
		"path": "/mnt/c/Users/Percision 15/google_drive",
		"type": "cloud",
		"description": "Google Drive integration - contains shared project data and resources",
		"sync_priority": 3,
		"max_size_gb": 100
	}
}

# Content types with storage rules
const CONTENT_TYPES = {
	"messages": {
		"description": "User messages and conversations",
		"primary_core": "core_0",
		"backup_cores": ["core_1"],
		"format": "json",
		"encryption": "none",
		"retention": "permanent",
		"indexing": true
	},
	"paintings": {
		"description": "iPad and digital paintings/artwork",
		"primary_core": "core_1",
		"backup_cores": ["core_2"],
		"format": "native",
		"encryption": "light",
		"retention": "permanent",
		"indexing": true
	},
	"notes": {
		"description": "Personal notes and mind maps",
		"primary_core": "core_0",
		"backup_cores": ["core_1"],
		"format": "encrypted",
		"encryption": "full",
		"retention": "permanent",
		"indexing": true
	},
	"system_data": {
		"description": "System configuration and operational data",
		"primary_core": "core_0",
		"backup_cores": [],
		"format": "json",
		"encryption": "none",
		"retention": "rotational",
		"indexing": false
	},
	"turn_data": {
		"description": "Data related to the 12-turn system cycles",
		"primary_core": "core_0",
		"backup_cores": ["core_2"],
		"format": "structured",
		"encryption": "light",
		"retention": "permanent",
		"indexing": true
	},
	"shared_projects": {
		"description": "Collaborative project files and resources",
		"primary_core": "core_2",
		"backup_cores": ["core_0"],
		"format": "native",
		"encryption": "none",
		"retention": "permanent",
		"indexing": true
	},
	"3d_notepad": {
		"description": "3D Notepad data and visualizations",
		"primary_core": "core_0",
		"backup_cores": ["core_1"],
		"format": "specialized",
		"encryption": "light",
		"retention": "permanent",
		"indexing": true
	}
}

# Pipeline configuration
const PIPELINES = {
	"message_storage": {
		"description": "Process and store user messages across appropriate drives",
		"input_types": ["messages"],
		"steps": ["parse", "filter", "process", "store", "index"],
		"output_cores": ["core_0", "core_1"],
		"schedule": "immediate",
		"parallel": true
	},
	"painting_sync": {
		"description": "Synchronize and process paintings and artwork",
		"input_types": ["paintings"],
		"steps": ["import", "optimize", "tag", "store", "index"],
		"output_cores": ["core_1", "core_2"],
		"schedule": "batch",
		"parallel": true
	},
	"note_processor": {
		"description": "Process, encrypt and store personal notes",
		"input_types": ["notes"],
		"steps": ["parse", "encrypt", "categorize", "store", "index"],
		"output_cores": ["core_0", "core_1"],
		"schedule": "immediate",
		"parallel": false
	},
	"turn_cycle": {
		"description": "Process and archive turn cycle data",
		"input_types": ["turn_data"],
		"steps": ["validate", "process", "archive", "index"],
		"output_cores": ["core_0", "core_2"],
		"schedule": "triggered",
		"parallel": true
	},
	"3d_notepad_sync": {
		"description": "Process and synchronize 3D Notepad data",
		"input_types": ["3d_notepad"],
		"steps": ["parse", "render", "optimize", "store"],
		"output_cores": ["core_0", "core_1"],
		"schedule": "immediate",
		"parallel": true
	},
	"system_backup": {
		"description": "Create systematic backups of all critical data",
		"input_types": ["messages", "notes", "turn_data", "3d_notepad"],
		"steps": ["select", "compress", "encrypt", "archive"],
		"output_cores": ["core_0", "core_1", "core_2"],
		"schedule": "daily",
		"parallel": true
	}
}

# Core access status
var core_status = {
	"core_0": {
		"connected": false,
		"available_space_gb": 0,
		"total_space_gb": 0,
		"last_sync": 0
	},
	"core_1": {
		"connected": false,
		"available_space_gb": 0,
		"total_space_gb": 0,
		"last_sync": 0
	},
	"core_2": {
		"connected": false,
		"available_space_gb": 0,
		"total_space_gb": 0,
		"last_sync": 0
	}
}

# Active pipelines
var active_pipelines = {}

# Integration references
var storage_system = null
var akashic_bridge = null

# Processing stats
var stats = {
	"messages_processed": 0,
	"paintings_processed": 0,
	"notes_processed": 0,
	"total_data_processed_mb": 0,
	"pipeline_executions": 0
}

# Error tracking
var errors = []

# Signals
signal pipeline_completed(pipeline_id, stats)
signal data_stored(content_type, data_id, cores)
signal core_status_changed(core_id, status)
signal error_occurred(error_type, message)

func _ready():
	# Initialize data pipeline system
	initialize_system()

func initialize_system():
	print("Initializing Data Pipeline System...")
	
	# Setup core drives
	setup_core_drives()
	
	# Create directory structure
	create_directory_structure()
	
	# Connect to integration systems
	connect_integration_systems()
	
	# Initialize pipelines
	initialize_pipelines()
	
	print("Data Pipeline System initialized")

func setup_core_drives():
	# Initialize core drives and check status
	for core_id in DRIVE_CONFIG:
		var drive_path = DRIVE_CONFIG[core_id].path
		var dir = Directory.new()
		
		if dir.dir_exists(drive_path):
			core_status[core_id].connected = true
			core_status[core_id].total_space_gb = DRIVE_CONFIG[core_id].max_size_gb
			
			# Calculate available space (simulated)
			core_status[core_id].available_space_gb = DRIVE_CONFIG[core_id].max_size_gb * (0.7 + randf() * 0.3)
			
			print("Core " + core_id + " connected: " + drive_path)
		else:
			print("Creating core drive directory: " + drive_path)
			dir.make_dir_recursive(drive_path)
			
			if dir.dir_exists(drive_path):
				core_status[core_id].connected = true
				core_status[core_id].total_space_gb = DRIVE_CONFIG[core_id].max_size_gb
				core_status[core_id].available_space_gb = DRIVE_CONFIG[core_id].max_size_gb
				
				print("Core " + core_id + " created and connected: " + drive_path)
			else:
				print("Failed to create core drive: " + drive_path)
				core_status[core_id].connected = false
				
				# Log error
				errors.append({
					"type": "core_initialization",
					"core_id": core_id,
					"message": "Failed to create core drive directory",
					"timestamp": OS.get_unix_time()
				})
				
				emit_signal("error_occurred", "core_initialization", "Failed to create core drive: " + core_id)
		
		# Emit status signal
		emit_signal("core_status_changed", core_id, core_status[core_id])

func create_directory_structure():
	# Create directory structure for content types
	for core_id in DRIVE_CONFIG:
		if core_status[core_id].connected:
			var base_path = DRIVE_CONFIG[core_id].path
			
			# Create content type directories
			for content_type in CONTENT_TYPES:
				# Check if this content should be stored on this core
				if CONTENT_TYPES[content_type].primary_core == core_id or core_id in CONTENT_TYPES[content_type].backup_cores:
					var content_path = base_path.plus_file(content_type)
					var dir = Directory.new()
					
					if not dir.dir_exists(content_path):
						dir.make_dir_recursive(content_path)
						print("Created directory for " + content_type + " on " + core_id + ": " + content_path)

func connect_integration_systems():
	# Connect to Storage System if available
	if ClassDB.class_exists("StorageIntegrationSystem"):
		storage_system = StorageIntegrationSystem.new()
		add_child(storage_system)
		print("Connected to Storage Integration System")
	
	# Connect to Akashic Bridge if available
	if ClassDB.class_exists("ClaudeAkashicBridge"):
		akashic_bridge = ClaudeAkashicBridge.new()
		add_child(akashic_bridge)
		print("Connected to Claude Akashic Bridge")

func initialize_pipelines():
	# Initialize pipeline processors
	for pipeline_id in PIPELINES:
		var pipeline = PIPELINES[pipeline_id]
		
		active_pipelines[pipeline_id] = {
			"id": pipeline_id,
			"status": "idle",
			"last_run": 0,
			"items_processed": 0,
			"config": pipeline
		}
		
		print("Initialized pipeline: " + pipeline_id)

# Public API methods

# Store user message
func store_message(message_text, metadata = {}):
	# Check if message pipeline is available
	if not active_pipelines.has("message_storage") or active_pipelines.message_storage.status == "error":
		push_error("Message storage pipeline not available")
		return null
	
	# Create message object
	var message = {
		"id": "msg_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000),
		"text": message_text,
		"timestamp": OS.get_unix_time(),
		"metadata": metadata
	}
	
	# Start message pipeline
	execute_pipeline("message_storage", message)
	
	return message.id

# Store painting reference
func store_painting(file_path, title = "", tags = [], metadata = {}):
	# Check if painting pipeline is available
	if not active_pipelines.has("painting_sync") or active_pipelines.painting_sync.status == "error":
		push_error("Painting sync pipeline not available")
		return null
	
	# Create file object
	var file_data = {
		"id": "paint_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000),
		"file_path": file_path,
		"title": title,
		"tags": tags,
		"timestamp": OS.get_unix_time(),
		"metadata": metadata
	}
	
	# Start painting pipeline
	execute_pipeline("painting_sync", file_data)
	
	return file_data.id

# Store note
func store_note(note_text, title = "", is_private = true, metadata = {}):
	# Check if note pipeline is available
	if not active_pipelines.has("note_processor") or active_pipelines.note_processor.status == "error":
		push_error("Note processor pipeline not available")
		return null
	
	# Create note object
	var note = {
		"id": "note_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000),
		"text": note_text,
		"title": title,
		"is_private": is_private,
		"timestamp": OS.get_unix_time(),
		"metadata": metadata
	}
	
	# Start note pipeline
	execute_pipeline("note_processor", note)
	
	return note.id

# Store 3D notepad data
func store_3d_notepad(notepad_data, title = "", metadata = {}):
	# Check if 3D notepad pipeline is available
	if not active_pipelines.has("3d_notepad_sync") or active_pipelines["3d_notepad_sync"].status == "error":
		push_error("3D Notepad sync pipeline not available")
		return null
	
	# Create 3D notepad object
	var notepad = {
		"id": "3dnote_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000),
		"data": notepad_data,
		"title": title,
		"timestamp": OS.get_unix_time(),
		"metadata": metadata
	}
	
	# Start 3D notepad pipeline
	execute_pipeline("3d_notepad_sync", notepad)
	
	return notepad.id

# Store turn data
func store_turn_data(turn_number, turn_data, metadata = {}):
	# Check if turn cycle pipeline is available
	if not active_pipelines.has("turn_cycle") or active_pipelines.turn_cycle.status == "error":
		push_error("Turn cycle pipeline not available")
		return null
	
	# Create turn data object
	var turn = {
		"id": "turn_" + str(turn_number) + "_" + str(OS.get_unix_time()),
		"turn_number": turn_number,
		"data": turn_data,
		"timestamp": OS.get_unix_time(),
		"metadata": metadata
	}
	
	# Start turn cycle pipeline
	execute_pipeline("turn_cycle", turn)
	
	return turn.id

# Trigger system backup
func trigger_backup(include_content_types = []):
	# Default to all content types if none specified
	if include_content_types.empty():
		include_content_types = CONTENT_TYPES.keys()
	
	# Create backup object
	var backup = {
		"id": "backup_" + str(OS.get_unix_time()),
		"content_types": include_content_types,
		"timestamp": OS.get_unix_time()
	}
	
	# Start backup pipeline
	execute_pipeline("system_backup", backup)
	
	return backup.id

# Get status of all cores
func get_cores_status():
	var status = {}
	
	for core_id in core_status:
		status[core_id] = {
			"connected": core_status[core_id].connected,
			"available_gb": core_status[core_id].available_space_gb,
			"total_gb": core_status[core_id].total_space_gb,
			"usage_percentage": (1.0 - (core_status[core_id].available_space_gb / core_status[core_id].total_space_gb)) * 100,
			"last_sync": core_status[core_id].last_sync,
			"type": DRIVE_CONFIG[core_id].type,
			"description": DRIVE_CONFIG[core_id].description
		}
	}
	
	return status

# Get status of all pipelines
func get_pipelines_status():
	var status = {}
	
	for pipeline_id in active_pipelines:
		status[pipeline_id] = {
			"status": active_pipelines[pipeline_id].status,
			"last_run": active_pipelines[pipeline_id].last_run,
			"items_processed": active_pipelines[pipeline_id].items_processed,
			"description": PIPELINES[pipeline_id].description
		}
	}
	
	return status

# Get overall system stats
func get_system_stats():
	return {
		"messages_processed": stats.messages_processed,
		"paintings_processed": stats.paintings_processed,
		"notes_processed": stats.notes_processed,
		"total_data_processed_mb": stats.total_data_processed_mb,
		"pipeline_executions": stats.pipeline_executions,
		"error_count": errors.size(),
		"cores": get_cores_status(),
		"pipelines": get_pipelines_status()
	}

# Execute pipeline for data processing
func execute_pipeline(pipeline_id, data):
	if not active_pipelines.has(pipeline_id):
		push_error("Pipeline not found: " + pipeline_id)
		return false
	
	# Set pipeline to active
	active_pipelines[pipeline_id].status = "active"
	active_pipelines[pipeline_id].last_run = OS.get_unix_time()
	
	# Get pipeline configuration
	var pipeline = PIPELINES[pipeline_id]
	
	# Process pipeline steps
	var result = process_pipeline_steps(pipeline, data)
	
	if result:
		# Pipeline completed successfully
		active_pipelines[pipeline_id].status = "idle"
		active_pipelines[pipeline_id].items_processed += 1
		stats.pipeline_executions += 1
		
		# Update stats based on content type
		if pipeline.input_types.has("messages"):
			stats.messages_processed += 1
		
		if pipeline.input_types.has("paintings"):
			stats.paintings_processed += 1
		
		if pipeline.input_types.has("notes"):
			stats.notes_processed += 1
		
		# Estimate data size
		var data_size_mb = 0.01 # Base size
		
		if typeof(data) == TYPE_DICTIONARY:
			if data.has("text"):
				data_size_mb += data.text.length() / (1024.0 * 1024.0) * 2 # Text size estimate
			
			if data.has("data"):
				if typeof(data.data) == TYPE_DICTIONARY:
					data_size_mb += 0.1 # Small object
				else:
					data_size_mb += 1.0 # Larger object
		
		stats.total_data_processed_mb += data_size_mb
		
		# Emit completion signal
		emit_signal("pipeline_completed", pipeline_id, {
			"data_id": data.id,
			"pipeline": pipeline_id,
			"time_taken": OS.get_unix_time() - active_pipelines[pipeline_id].last_run,
			"data_size_mb": data_size_mb
		})
		
		return true
	else:
		# Pipeline failed
		active_pipelines[pipeline_id].status = "error"
		
		# Log error
		errors.append({
			"type": "pipeline_execution",
			"pipeline_id": pipeline_id,
			"message": "Pipeline execution failed",
			"timestamp": OS.get_unix_time()
		})
		
		emit_signal("error_occurred", "pipeline_execution", "Pipeline execution failed: " + pipeline_id)
		
		return false

# Process pipeline steps
func process_pipeline_steps(pipeline, data):
	# Get content type
	var content_type = null
	for type in pipeline.input_types:
		if CONTENT_TYPES.has(type):
			content_type = type
			break
	
	if content_type == null:
		push_error("No valid content type found for pipeline")
		return false
	
	# Track cores where data was stored
	var stored_cores = []
	
	# Execute each step
	for step in pipeline.steps:
		match step:
			"parse":
				# Parse data into appropriate format
				pass
			"filter":
				# Filter data for security or privacy
				pass
			"process":
				# Process data for storage
				pass
			"store":
				# Store data in appropriate cores
				var primary_core = CONTENT_TYPES[content_type].primary_core
				
				if store_data_to_core(primary_core, content_type, data):
					stored_cores.append(primary_core)
				
				# Store to backup cores
				for backup_core in CONTENT_TYPES[content_type].backup_cores:
					if store_data_to_core(backup_core, content_type, data):
						stored_cores.append(backup_core)
			"index":
				# Index data for searching
				pass
			"encrypt":
				# Encrypt sensitive data
				pass
			"compress":
				# Compress data for storage efficiency
				pass
			"archive":
				# Archive data for long-term storage
				pass
			"optimize":
				# Optimize data (for images, etc.)
				pass
			"tag":
				# Add tags for better organization
				pass
			"categorize":
				# Categorize data
				pass
			"validate":
				# Validate data integrity
				pass
			"render":
				# Render data (for 3D, etc.)
				pass
			"select":
				# Select data for backup
				pass
	
	# Emit signal for successful storage
	if not stored_cores.empty():
		emit_signal("data_stored", content_type, data.id, stored_cores)
	
	return true

# Store data to specific core
func store_data_to_core(core_id, content_type, data):
	if not core_status[core_id].connected:
		push_error("Core not connected: " + core_id)
		return false
	
	# Check for available space
	var data_size_gb = 0.001 # Assume small size by default
	
	if typeof(data) == TYPE_DICTIONARY:
		if data.has("text") and typeof(data.text) == TYPE_STRING:
			data_size_gb = data.text.length() / (1024.0 * 1024.0 * 1024.0) * 2 # Text size estimate
		
		if data.has("data"):
			data_size_gb = 0.01 # Larger object
	
	if core_status[core_id].available_space_gb < data_size_gb:
		push_error("Not enough space on core: " + core_id)
		return false
	
	# Get path for storage
	var storage_path = DRIVE_CONFIG[core_id].path.plus_file(content_type)
	
	# Create file name based on data id
	var file_name = data.id + "." + CONTENT_TYPES[content_type].format
	
	# Store data to file
	var file_path = storage_path.plus_file(file_name)
	var file = File.new()
	
	if file.open(file_path, File.WRITE) == OK:
		file.store_string(JSON.print(data, "  "))
		file.close()
		
		# Update available space
		core_status[core_id].available_space_gb -= data_size_gb
		core_status[core_id].last_sync = OS.get_unix_time()
		
		emit_signal("core_status_changed", core_id, core_status[core_id])
		
		print("Stored " + content_type + " data to " + core_id + ": " + file_path)
		return true
	else:
		push_error("Failed to write file: " + file_path)
		
		# Log error
		errors.append({
			"type": "file_write",
			"core_id": core_id,
			"content_type": content_type,
			"file_path": file_path,
			"message": "Failed to write file",
			"timestamp": OS.get_unix_time()
		})
		
		emit_signal("error_occurred", "file_write", "Failed to write file: " + file_path)
		
		return false
	
	return false
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/data_pipeline_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/data_splitter_controller.gd
# SIZE: 45012 bytes
extends Node3D

class_name DataSplitterController

# ----- NODE PATHS -----
@export_node_path var notepad3d_integration_path: NodePath
@export_node_path var pitopia_main_path: NodePath
@export_node_path var console_path: NodePath
@export_node_path var data_container_path: NodePath

# ----- COMPONENT REFERENCES -----
var notepad3d_integration = null
var pitopia_main = null
var console = null
var data_container = null

# ----- CONFIGURATION -----
@export var auto_initialize: bool = true
@export var enable_debug_logs: bool = true
@export var max_data_streams: int = 9
@export var default_data_chunk_size: int = 16
@export var default_split_factor: int = 3
@export var data_visualization_enabled: bool = true

# ----- VISUAL SETTINGS -----
@export_group("Visual Settings")
@export var stream_material: StandardMaterial3D
@export var chunk_material: StandardMaterial3D
@export var connection_material: StandardMaterial3D
@export var split_effect: PackedScene
@export var merge_effect: PackedScene

# ----- STATE VARIABLES -----
var initialized: bool = false
var current_dimension: int = 3
var current_turn: int = 1
var current_reality: String = "Physical"
var current_moon_phase: int = 0

var data_streams = []
var data_chunks = {}
var data_splits = {}
var active_connections = {}
var active_visualizers = {}
var data_flow_history = []
var merge_operations = []

# Dictionary of node references for visual elements
var stream_nodes = {}
var chunk_nodes = {}
var connection_nodes = {}
var split_nodes = {}

# ----- SIGNALS -----
signal initialization_completed
signal data_stream_created(stream_id, data_type, size)
signal data_chunk_created(chunk_id, content, parent_stream)
signal data_split_created(split_id, original_chunk, resulting_chunks)
signal data_merged(merge_id, source_chunks, result_chunk)
signal data_flow_processed(flow_id, source, destination, amount)
signal dimension_changed(new_dimension, old_dimension)
signal turn_advanced(turn_number)
signal reality_changed(new_reality, old_reality)

# ----- INITIALIZATION -----
func _ready():
	if auto_initialize:
		initialize()

func initialize():
	print("DataSplitterController: Initializing...")
	
	# Resolve node paths
	_resolve_node_paths()
	
	# Create container nodes if needed
	_create_container_nodes()
	
	# Setup visualization materials
	_setup_visualization_materials()
	
	# Connect to Notepad3D and Pitopia signals
	_connect_signals()
	
	# Setup data processing system
	_initialize_data_system()
	
	# Mark as initialized
	initialized = true
	emit_signal("initialization_completed")
	
	if enable_debug_logs:
		print("DataSplitterController: Initialization complete")
		_log_message("Data Splitter System initialized. Ready to process data.")

func _resolve_node_paths():
	# Resolve Notepad3D Integration
	if notepad3d_integration_path:
		notepad3d_integration = get_node_or_null(notepad3d_integration_path)
	
	# Resolve Pitopia Main
	if pitopia_main_path:
		pitopia_main = get_node_or_null(pitopia_main_path)
	
	# Resolve Console
	if console_path:
		console = get_node_or_null(console_path)
	
	# Resolve Data Container
	if data_container_path:
		data_container = get_node_or_null(data_container_path)
	else:
		# Try to find in children
		data_container = get_node_or_null("../DataSplitterContainer")
	
	if enable_debug_logs:
		print("DataSplitterController: Node resolution results:")
		print("- Notepad3D Integration: ", "Found" if notepad3d_integration else "Not found")
		print("- Pitopia Main: ", "Found" if pitopia_main else "Not found")
		print("- Console: ", "Found" if console else "Not found")
		print("- Data Container: ", "Found" if data_container else "Not found")

func _create_container_nodes():
	# Create data container if missing
	if not data_container:
		data_container = get_node_or_null("../DataSplitterContainer")
		
		if not data_container:
			data_container = Node3D.new()
			data_container.name = "DataSplitterContainer"
			add_child(data_container)
			print("DataSplitterController: Created missing DataSplitterContainer")
	
	# Ensure all required child nodes exist
	var streams_node = data_container.get_node_or_null("DataStreams")
	if not streams_node:
		streams_node = Node3D.new()
		streams_node.name = "DataStreams"
		data_container.add_child(streams_node)
	
	var chunks_node = data_container.get_node_or_null("DataChunks")
	if not chunks_node:
		chunks_node = Node3D.new()
		chunks_node.name = "DataChunks"
		data_container.add_child(chunks_node)
	
	var connections_node = data_container.get_node_or_null("DataConnections")
	if not connections_node:
		connections_node = Node3D.new()
		connections_node.name = "DataConnections"
		data_container.add_child(connections_node)
	
	var visualizer_node = data_container.get_node_or_null("DataVisualizer")
	if not visualizer_node:
		visualizer_node = Node3D.new()
		visualizer_node.name = "DataVisualizer"
		data_container.add_child(visualizer_node)

func _setup_visualization_materials():
	# Create default materials if not provided
	if not stream_material:
		stream_material = StandardMaterial3D.new()
		stream_material.albedo_color = Color(0.2, 0.4, 0.8)
		stream_material.metallic = 0.7
		stream_material.roughness = 0.2
		stream_material.emission_enabled = true
		stream_material.emission = Color(0.3, 0.5, 0.9)
		stream_material.emission_energy = 0.5
	
	if not chunk_material:
		chunk_material = StandardMaterial3D.new()
		chunk_material.albedo_color = Color(0.8, 0.3, 0.5)
		chunk_material.metallic = 0.6
		chunk_material.roughness = 0.3
		chunk_material.emission_enabled = true
		chunk_material.emission = Color(0.9, 0.4, 0.6)
		chunk_material.emission_energy = 0.6
	
	if not connection_material:
		connection_material = StandardMaterial3D.new()
		connection_material.albedo_color = Color(0.5, 0.8, 0.3)
		connection_material.emission_enabled = true
		connection_material.emission = Color(0.6, 0.9, 0.4)
		connection_material.emission_energy = 0.7

func _connect_signals():
	# Connect to Notepad3D Integration signals
	if notepad3d_integration:
		if notepad3d_integration.has_signal("reality_changed") and not notepad3d_integration.is_connected("reality_changed", Callable(self, "_on_reality_changed")):
			notepad3d_integration.connect("reality_changed", Callable(self, "_on_reality_changed"))
		
		if notepad3d_integration.has_signal("word_manifested") and not notepad3d_integration.is_connected("word_manifested", Callable(self, "_on_word_manifested")):
			notepad3d_integration.connect("word_manifested", Callable(self, "_on_word_manifested"))
		
		if notepad3d_integration.has_signal("moon_phase_changed") and not notepad3d_integration.is_connected("moon_phase_changed", Callable(self, "_on_moon_phase_changed")):
			notepad3d_integration.connect("moon_phase_changed", Callable(self, "_on_moon_phase_changed"))
	
	# Connect to Pitopia Main signals
	if pitopia_main:
		if pitopia_main.has_signal("dimension_changed") and not pitopia_main.is_connected("dimension_changed", Callable(self, "_on_dimension_changed")):
			pitopia_main.connect("dimension_changed", Callable(self, "_on_dimension_changed"))
		
		if pitopia_main.has_signal("turn_advanced") and not pitopia_main.is_connected("turn_advanced", Callable(self, "_on_turn_advanced")):
			pitopia_main.connect("turn_advanced", Callable(self, "_on_turn_advanced"))
		
		if pitopia_main.has_signal("word_manifested") and not pitopia_main.is_connected("word_manifested", Callable(self, "_on_word_manifested")):
			pitopia_main.connect("word_manifested", Callable(self, "_on_word_manifested"))

func _initialize_data_system():
	# Create initial data streams
	for i in range(3):
		create_data_stream("stream_" + str(i), "binary", default_data_chunk_size)

# ----- DATA STREAM MANAGEMENT -----
func create_data_stream(stream_id: String, data_type: String = "binary", size: int = 16) -> Dictionary:
	# Check if already at maximum streams
	if data_streams.size() >= max_data_streams:
		if enable_debug_logs:
			print("DataSplitterController: Cannot create stream, maximum reached")
		return {"success": false, "message": "Maximum streams reached"}
	
	# Create stream data
	var stream_data = {
		"id": stream_id,
		"type": data_type,
		"size": size,
		"chunks": [],
		"created_at": Time.get_unix_time_from_system(),
		"dimension": current_dimension,
		"reality": current_reality,
		"active": true,
		"properties": {
			"flow_rate": 1.0,
			"compression_ratio": 0.8,
			"stability": 0.9,
			"entropy": 0.2
		}
	}
	
	# Add to streams
	data_streams.append(stream_data)
	
	# Create visualization
	if data_visualization_enabled:
		_create_stream_visualization(stream_data)
	
	# Emit signal
	emit_signal("data_stream_created", stream_id, data_type, size)
	
	# Add initial data chunk
	var initial_chunk = create_data_chunk(stream_id + "_chunk_0", "Initial " + data_type + " data", stream_id)
	
	if enable_debug_logs:
		print("DataSplitterController: Created stream '" + stream_id + "' with initial chunk")
	
	return {"success": true, "message": "Stream created", "stream_data": stream_data}

func create_data_chunk(chunk_id: String, content: String, parent_stream_id: String) -> Dictionary:
	# Validate parent stream
	var parent_stream = null
	for stream in data_streams:
		if stream.id == parent_stream_id:
			parent_stream = stream
			break
	
	if not parent_stream:
		return {"success": false, "message": "Parent stream not found"}
	
	# Create chunk data
	var chunk_data = {
		"id": chunk_id,
		"content": content,
		"parent_stream": parent_stream_id,
		"size": content.length() + randi_range(5, 15), # Some randomness
		"created_at": Time.get_unix_time_from_system(),
		"dimension": current_dimension,
		"reality": current_reality,
		"properties": {
			"entropy": randf_range(0.1, 0.9),
			"complexity": randf_range(0.2, 0.8),
			"coherence": randf_range(0.4, 0.9),
			"stability": randf_range(0.5, 1.0)
		}
	}
	
	# Add to chunks dictionary
	data_chunks[chunk_id] = chunk_data
	
	# Add to parent stream chunks list
	parent_stream.chunks.append(chunk_id)
	
	# Create visualization
	if data_visualization_enabled:
		_create_chunk_visualization(chunk_data)
	
	# Emit signal
	emit_signal("data_chunk_created", chunk_id, content, parent_stream_id)
	
	if enable_debug_logs:
		print("DataSplitterController: Created chunk '" + chunk_id + "' in stream '" + parent_stream_id + "'")
	
	return {"success": true, "message": "Data chunk created", "chunk_data": chunk_data}

func split_data_chunk(chunk_id: String, split_factor: int = -1) -> Dictionary:
	# Validate chunk
	if not data_chunks.has(chunk_id):
		return {"success": false, "message": "Chunk not found"}
	
	# Get chunk data
	var chunk_data = data_chunks[chunk_id]
	
	# Use default split factor if not specified
	if split_factor <= 0:
		split_factor = default_split_factor
	
	# Create split id
	var split_id = "split_" + chunk_id + "_" + str(Time.get_unix_time_from_system())
	
	# Generate content divisions
	var content = chunk_data.content
	var content_parts = []
	
	# Try to split content intelligently
	if content.find(" ") >= 0:
		# Split by words
		var words = content.split(" ", false)
		
		# Calculate words per part
		var words_per_part = ceil(float(words.size()) / split_factor)
		
		# Create parts
		for i in range(split_factor):
			var start_idx = i * words_per_part
			var end_idx = min(start_idx + words_per_part, words.size())
			
			if start_idx >= words.size():
				break
			
			var part_words = words.slice(start_idx, end_idx)
			content_parts.append(" ".join(part_words))
	else:
		# Split by characters
		var chars_per_part = ceil(float(content.length()) / split_factor)
		
		for i in range(split_factor):
			var start_idx = i * chars_per_part
			var end_idx = min(start_idx + chars_per_part, content.length())
			
			if start_idx >= content.length():
				break
			
			content_parts.append(content.substr(start_idx, end_idx - start_idx))
	
	# Create resulting chunks
	var resulting_chunks = []
	for i in range(content_parts.size()):
		var sub_chunk_id = chunk_id + "_sub_" + str(i)
		var sub_content = content_parts[i]
		
		# Create new chunk
		var result = create_data_chunk(sub_chunk_id, sub_content, chunk_data.parent_stream)
		if result.success:
			resulting_chunks.append(sub_chunk_id)
	
	# Create split data
	var split_data = {
		"id": split_id,
		"original_chunk": chunk_id,
		"resulting_chunks": resulting_chunks,
		"factor": split_factor,
		"created_at": Time.get_unix_time_from_system(),
		"dimension": current_dimension,
		"reality": current_reality
	}
	
	# Add to splits
	data_splits[split_id] = split_data
	
	# Create visualization effect
	if data_visualization_enabled:
		_create_split_visualization(split_data)
	
	# Connect resulting chunks visually
	for sub_chunk_id in resulting_chunks:
		_create_connection(chunk_id, sub_chunk_id, "split")
	
	# Emit signal
	emit_signal("data_split_created", split_id, chunk_id, resulting_chunks)
	
	if enable_debug_logs:
		print("DataSplitterController: Split chunk '" + chunk_id + "' into " + str(resulting_chunks.size()) + " parts")
	
	return {"success": true, "message": "Data chunk split", "split_data": split_data, "resulting_chunks": resulting_chunks}

func merge_data_chunks(chunk_ids: Array, merge_type: String = "concatenate") -> Dictionary:
	# Validate chunks
	for chunk_id in chunk_ids:
		if not data_chunks.has(chunk_id):
			return {"success": false, "message": "Chunk '" + chunk_id + "' not found"}
	
	if chunk_ids.size() < 2:
		return {"success": false, "message": "Need at least 2 chunks to merge"}
	
	# Get first chunk to determine parent stream
	var first_chunk = data_chunks[chunk_ids[0]]
	var parent_stream_id = first_chunk.parent_stream
	
	# Check if all chunks belong to the same parent stream
	for chunk_id in chunk_ids:
		if data_chunks[chunk_id].parent_stream != parent_stream_id:
			return {"success": false, "message": "All chunks must belong to the same stream"}
	
	# Create merge id
	var merge_id = "merge_" + str(Time.get_unix_time_from_system())
	
	# Perform merge based on merge type
	var merged_content = ""
	
	if merge_type == "concatenate":
		# Simple concatenation with spaces
		for chunk_id in chunk_ids:
			if merged_content.length() > 0:
				merged_content += " "
			merged_content += data_chunks[chunk_id].content
	elif merge_type == "interleave":
		# Interleave words from each chunk
		var all_words = []
		for chunk_id in chunk_ids:
			var chunk_words = data_chunks[chunk_id].content.split(" ", false)
			for i in range(chunk_words.size()):
				all_words.append(chunk_words[i])
		merged_content = " ".join(all_words)
	else:
		# Default to concatenation
		for chunk_id in chunk_ids:
			merged_content += data_chunks[chunk_id].content
	
	# Create result chunk
	var result_chunk_id = "merged_" + str(Time.get_unix_time_from_system())
	var result = create_data_chunk(result_chunk_id, merged_content, parent_stream_id)
	
	if not result.success:
		return {"success": false, "message": "Failed to create merged chunk"}
	
	# Record merge operation
	var merge_data = {
		"id": merge_id,
		"source_chunks": chunk_ids.duplicate(),
		"result_chunk": result_chunk_id,
		"merge_type": merge_type,
		"created_at": Time.get_unix_time_from_system(),
		"dimension": current_dimension,
		"reality": current_reality
	}
	
	merge_operations.append(merge_data)
	
	# Create merge visualization
	if data_visualization_enabled:
		_create_merge_visualization(merge_data)
	
	# Connect source chunks to result
	for chunk_id in chunk_ids:
		_create_connection(chunk_id, result_chunk_id, "merge")
	
	# Emit signal
	emit_signal("data_merged", merge_id, chunk_ids, result_chunk_id)
	
	if enable_debug_logs:
		print("DataSplitterController: Merged " + str(chunk_ids.size()) + " chunks into '" + result_chunk_id + "'")
	
	return {"success": true, "message": "Chunks merged", "merge_data": merge_data, "result_chunk": result_chunk_id}

# ----- VISUALIZATION FUNCTIONS -----
func _create_stream_visualization(stream_data):
	# Create visual representation of data stream
	var streams_node = data_container.get_node("DataStreams")
	
	# Create stream container
	var stream_node = Node3D.new()
	stream_node.name = "Stream_" + stream_data.id
	streams_node.add_child(stream_node)
	
	# Calculate position based on number of existing streams
	var stream_index = data_streams.size() - 1
	var angle = (2 * PI / max_data_streams) * stream_index
	var radius = 3.0 + (current_dimension * 0.1)
	var height = 0.5 + (stream_index * 0.2)
	
	stream_node.position = Vector3(cos(angle) * radius, height, sin(angle) * radius)
	
	# Create visual model (cylinder representing data flow)
	var cylinder = CSGCylinder3D.new()
	cylinder.radius = 0.1 + (stream_data.size / 100.0)
	cylinder.height = 0.8 + (stream_data.size / 50.0)
	cylinder.material = stream_material.duplicate()
	
	# Adjust color based on data type
	var material = cylinder.material
	if stream_data.type == "binary":
		material.albedo_color = Color(0.2, 0.4, 0.9)
		material.emission = Color(0.3, 0.5, 1.0)
	elif stream_data.type == "text":
		material.albedo_color = Color(0.9, 0.4, 0.2)
		material.emission = Color(1.0, 0.5, 0.3)
	elif stream_data.type == "image":
		material.albedo_color = Color(0.4, 0.9, 0.2)
		material.emission = Color(0.5, 1.0, 0.3)
	
	stream_node.add_child(cylinder)
	
	# Add label
	var label = Label3D.new()
	label.text = stream_data.id
	label.font_size = 18
	label.position = Vector3(0, cylinder.height/2 + 0.2, 0)
	label.billboard = BaseMaterial3D.BILLBOARD_ENABLED
	stream_node.add_child(label)
	
	# Add to tracking
	stream_nodes[stream_data.id] = stream_node
	
	return stream_node

func _create_chunk_visualization(chunk_data):
	# Create visual representation of data chunk
	var chunks_node = data_container.get_node("DataChunks")
	
	# Create chunk container
	var chunk_node = Node3D.new()
	chunk_node.name = "Chunk_" + chunk_data.id
	chunks_node.add_child(chunk_node)
	
	# Find parent stream node for positioning relative to it
	var parent_stream_node = stream_nodes.get(chunk_data.parent_stream)
	var position = Vector3.ZERO
	
	if parent_stream_node:
		# Position near the parent stream
		var stream_pos = parent_stream_node.global_position
		var chunk_index = data_chunks.size() - 1
		var angle = randf_range(0, 2 * PI)
		var radius = 0.8 + (chunk_data.size / 50.0)
		
		position = Vector3(
			stream_pos.x + cos(angle) * radius,
			stream_pos.y + randf_range(-0.5, 0.5),
			stream_pos.z + sin(angle) * radius
		)
	else:
		# Fallback position if parent not found
		var chunk_index = data_chunks.size()
		position = Vector3(randf_range(-5, 5), randf_range(0, 3), randf_range(-5, 5))
	
	chunk_node.global_position = position
	
	# Create visual model (box representing data chunk)
	var box = CSGBox3D.new()
	box.size = Vector3(
		0.3 + (chunk_data.size / 100.0),
		0.3 + (chunk_data.size / 150.0),
		0.3 + (chunk_data.size / 120.0)
	)
	box.material = chunk_material.duplicate()
	
	# Adjust color based on entropy
	var entropy = chunk_data.properties.entropy
	var material = box.material
	material.albedo_color = Color(0.8, 0.3 + (entropy * 0.5), 0.9 - (entropy * 0.6))
	material.emission = Color(0.9, 0.4 + (entropy * 0.5), 1.0 - (entropy * 0.6))
	
	chunk_node.add_child(box)
	
	# Add label
	var label = Label3D.new()
	label.text = chunk_data.id
	label.font_size = 12
	label.position = Vector3(0, box.size.y/2 + 0.2, 0)
	label.billboard = BaseMaterial3D.BILLBOARD_ENABLED
	chunk_node.add_child(label)
	
	# Add to tracking
	chunk_nodes[chunk_data.id] = chunk_node
	
	return chunk_node

func _create_split_visualization(split_data):
	# Create visual effect for data split
	if not split_effect:
		return
	
	var original_chunk_node = chunk_nodes.get(split_data.original_chunk)
	if not original_chunk_node:
		return
	
	# Create effect instance
	var effect = split_effect.instantiate()
	var visualizer_node = data_container.get_node("DataVisualizer")
	visualizer_node.add_child(effect)
	
	# Position at original chunk
	effect.global_position = original_chunk_node.global_position
	
	# Configure effect if applicable
	if effect.has_method("set_split_factor"):
		effect.set_split_factor(split_data.resulting_chunks.size())
	
	# Auto-remove after effect completes
	var timer = Timer.new()
	timer.wait_time = 2.0
	timer.one_shot = true
	timer.connect("timeout", Callable(effect, "queue_free"))
	effect.add_child(timer)
	timer.start()

func _create_merge_visualization(merge_data):
	# Create visual effect for data merge
	if not merge_effect:
		return
	
	var result_chunk_node = chunk_nodes.get(merge_data.result_chunk)
	if not result_chunk_node:
		return
	
	# Create effect instance
	var effect = merge_effect.instantiate()
	var visualizer_node = data_container.get_node("DataVisualizer")
	visualizer_node.add_child(effect)
	
	# Position at result chunk
	effect.global_position = result_chunk_node.global_position
	
	# Configure effect if applicable
	if effect.has_method("set_merge_factor"):
		effect.set_merge_factor(merge_data.source_chunks.size())
	
	# Auto-remove after effect completes
	var timer = Timer.new()
	timer.wait_time = 2.0
	timer.one_shot = true
	timer.connect("timeout", Callable(effect, "queue_free"))
	effect.add_child(timer)
	timer.start()

func _create_connection(source_id: String, target_id: String, connection_type: String = "default"):
	# Create visual connection between data elements
	var connections_node = data_container.get_node("DataConnections")
	
	# Get source and target nodes
	var source_node = null
	var target_node = null
	
	if chunk_nodes.has(source_id):
		source_node = chunk_nodes[source_id]
	elif stream_nodes.has(source_id):
		source_node = stream_nodes[source_id]
	
	if chunk_nodes.has(target_id):
		target_node = chunk_nodes[target_id]
	elif stream_nodes.has(target_id):
		target_node = stream_nodes[target_id]
	
	if not source_node or not target_node:
		return null
	
	# Create unique connection ID
	var connection_id = source_id + "_to_" + target_id
	
	# Skip if already exists
	if connection_nodes.has(connection_id):
		return connection_nodes[connection_id]
	
	# Create connection container
	var connection_node = Node3D.new()
	connection_node.name = "Connection_" + connection_id
	connections_node.add_child(connection_node)
	
	# Create visual line
	var line_mesh = _create_connection_line(source_node.global_position, target_node.global_position, connection_type)
	connection_node.add_child(line_mesh)
	
	# Create connection data
	var connection_data = {
		"id": connection_id,
		"source": source_id,
		"target": target_id,
		"type": connection_type,
		"created_at": Time.get_unix_time_from_system()
	}
	
	# Store in active connections
	active_connections[connection_id] = connection_data
	
	# Add to tracking
	connection_nodes[connection_id] = connection_node
	
	return connection_node

func _create_connection_line(start_pos: Vector3, end_pos: Vector3, connection_type: String) -> Node3D:
	# Create a 3D visualization of a connection line
	var line_container = Node3D.new()
	line_container.name = "LineContainer"
	
	# Calculate midpoint and direction
	var midpoint = (start_pos + end_pos) / 2
	var direction = (end_pos - start_pos).normalized()
	var length = start_pos.distance_to(end_pos)
	
	# Create mesh instance
	var mesh_instance = MeshInstance3D.new()
	mesh_instance.name = "LineRenderer"
	
	# Create cylinder mesh for the line
	var cylinder = CylinderMesh.new()
	cylinder.top_radius = 0.02
	cylinder.bottom_radius = 0.02
	cylinder.height = length
	mesh_instance.mesh = cylinder
	
	# Position and orient cylinder to connect points
	mesh_instance.look_at_from_position(midpoint, end_pos, Vector3.UP)
	mesh_instance.rotate_object_local(Vector3.RIGHT, PI/2) # Rotate to align cylinder axis
	
	# Apply material based on connection type
	var material = connection_material.duplicate()
	material.albedo_color = _get_connection_color(connection_type)
	material.emission = material.albedo_color
	material.emission_energy = 0.7
	
	mesh_instance.material_override = material
	
	line_container.add_child(mesh_instance)
	return line_container

func _get_connection_color(connection_type: String) -> Color:
	# Return color based on connection type
	match connection_type:
		"split":
			return Color(0.9, 0.5, 0.1) # Orange
		"merge":
			return Color(0.1, 0.6, 0.9) # Blue
		"flow":
			return Color(0.3, 0.9, 0.3) # Green
		"transform":
			return Color(0.8, 0.3, 0.8) # Purple
		_:
			return Color(0.7, 0.7, 0.7) # Gray

# ----- CONSOLE COMMAND PROCESSING -----
func process_command(command: String) -> Dictionary:
	# Process data splitter commands
	
	# Skip empty commands
	if command.strip_edges().is_empty():
		return {"success": false, "message": "Empty command"}
	
	# Split into command and parameters
	var parts = command.split(" ", false, 1)
	var cmd = parts[0].to_lower()
	var params = ""
	if parts.size() > 1:
		params = parts[1]
	
	match cmd:
		"/split":
			# Split data command
			if params.is_empty():
				_log_message("Usage: /split [text to split]")
				return {"success": false, "message": "Missing text to split"}
			
			# Create a stream if needed
			var stream_id = "text_stream_" + str(data_streams.size())
			if data_streams.size() == 0:
				create_data_stream(stream_id, "text", params.length())
			else:
				stream_id = data_streams[0].id
			
			# Create chunk with text
			var chunk_id = "text_chunk_" + str(Time.get_unix_time_from_system())
			var chunk_result = create_data_chunk(chunk_id, params, stream_id)
			
			if not chunk_result.success:
				_log_message("Failed to create chunk: " + chunk_result.message)
				return chunk_result
			
			# Split the chunk
			var split_result = split_data_chunk(chunk_id)
			
			if split_result.success:
				_log_message("Split text into " + str(split_result.resulting_chunks.size()) + " parts")
				return split_result
			else:
				_log_message("Failed to split: " + split_result.message)
				return split_result
		
		"/merge":
			# Merge data command
			if params.is_empty():
				_log_message("Usage: /merge [chunk_id_1] [chunk_id_2] ...")
				return {"success": false, "message": "Missing chunks to merge"}
			
			var chunk_ids = params.split(" ", false)
			if chunk_ids.size() < 2:
				_log_message("Need at least 2 chunks to merge")
				return {"success": false, "message": "Need at least 2 chunks to merge"}
			
			var merge_result = merge_data_chunks(chunk_ids)
			
			if merge_result.success:
				_log_message("Merged " + str(chunk_ids.size()) + " chunks into " + merge_result.result_chunk)
				return merge_result
			else:
				_log_message("Failed to merge: " + merge_result.message)
				return merge_result
		
		"/stream":
			# Create new data stream
			var stream_id = "stream_" + str(data_streams.size())
			var stream_type = "binary"
			var stream_size = default_data_chunk_size
			
			if not params.is_empty():
				var param_parts = params.split(" ")
				if param_parts.size() >= 1:
					stream_id = param_parts[0]
				if param_parts.size() >= 2:
					stream_type = param_parts[1]
				if param_parts.size() >= 3 and param_parts[2].is_valid_int():
					stream_size = param_parts[2].to_int()
			
			var stream_result = create_data_stream(stream_id, stream_type, stream_size)
			
			if stream_result.success:
				_log_message("Created new data stream: " + stream_id)
				return stream_result
			else:
				_log_message("Failed to create stream: " + stream_result.message)
				return stream_result
		
		"/list":
			# List existing data elements
			var listing = "[color=#88ff99]Data Splitter Elements:[/color]\n"
			
			listing += "\n[color=#aaaaff]Streams (" + str(data_streams.size()) + "):[/color]\n"
			for stream in data_streams:
				listing += "- " + stream.id + " (" + stream.type + ", " + str(stream.size) + " bytes, " + str(stream.chunks.size()) + " chunks)\n"
			
			listing += "\n[color=#ffaaaa]Chunks (" + str(data_chunks.size()) + "):[/color]\n"
			var chunk_count = 0
			for chunk_id in data_chunks:
				listing += "- " + chunk_id + " (size: " + str(data_chunks[chunk_id].size) + ")\n"
				chunk_count += 1
				if chunk_count >= 10:
					listing += "  ... and " + str(data_chunks.size() - 10) + " more\n"
					break
			
			listing += "\n[color=#aaffaa]Splits (" + str(data_splits.size()) + "):[/color]\n"
			var split_count = 0
			for split_id in data_splits:
				listing += "- " + split_id + " (factor: " + str(data_splits[split_id].factor) + ")\n"
				split_count += 1
				if split_count >= 5:
					listing += "  ... and " + str(data_splits.size() - 5) + " more\n"
					break
			
			_log_message(listing)
			return {"success": true, "message": listing}
		
		"/help":
			# Display data splitter commands
			var help_text = "[color=#88ff99]Data Splitter Commands:[/color]\n"
			help_text += "/split [text] - Split text into data chunks\n"
			help_text += "/merge [chunk_id1] [chunk_id2] ... - Merge chunks\n"
			help_text += "/stream [id] [type] [size] - Create a new data stream\n"
			help_text += "/list - List all data elements\n"
			help_text += "/help - Display this help\n"
			
			_log_message(help_text)
			return {"success": true, "message": help_text}
		
		_:
			# Pass to notepad3d if available
			if notepad3d_integration and notepad3d_integration.has_method("process_command"):
				return notepad3d_integration.process_command(command)
			elif pitopia_main and pitopia_main.has_method("process_command"):
				return pitopia_main.process_command(command)
			else:
				return {"success": false, "message": "Unknown command. Try /help for available commands."}

# ----- SIGNAL HANDLERS -----
func _on_dimension_changed(new_dimension, old_dimension = 0):
	current_dimension = new_dimension
	
	if enable_debug_logs:
		print("DataSplitterController: Dimension changed to " + str(new_dimension) + "D")
	
	# Apply dimension effects to data elements
	_apply_dimension_effects(new_dimension)
	
	# Emit signal
	emit_signal("dimension_changed", new_dimension, old_dimension)

func _on_turn_advanced(turn_number):
	current_turn = turn_number
	
	if enable_debug_logs:
		print("DataSplitterController: Advanced to turn " + str(turn_number))
	
	# Process automatic data flows
	_process_data_flows()
	
	# Emit signal
	emit_signal("turn_advanced", turn_number)

func _on_reality_changed(new_reality, old_reality):
	current_reality = new_reality
	
	if enable_debug_logs:
		print("DataSplitterController: Reality changed to " + new_reality)
	
	# Apply reality effects to data elements
	_apply_reality_effects(new_reality)
	
	# Emit signal
	emit_signal("reality_changed", new_reality, old_reality)

func _on_moon_phase_changed(new_phase, old_phase, stability):
	current_moon_phase = new_phase
	
	if enable_debug_logs:
		print("DataSplitterController: Moon phase changed to " + str(new_phase) + " (stability: " + str(stability) + ")")
	
	# Adjust data flow and split stability based on moon phase
	_adjust_stability_by_moon_phase(new_phase, stability)

func _on_word_manifested(word, entity, reality_type = "", dimension = 0):
	if enable_debug_logs:
		print("DataSplitterController: Word '" + word + "' manifested")
	
	# Check for data splitter related words to trigger effects
	var data_related_words = ["data", "split", "stream", "flow", "chunk", "merge", "process"]
	for data_word in data_related_words:
		if word.to_lower().find(data_word) >= 0:
			_process_word_data_effects(word, entity)
			break

# ----- EFFECT FUNCTIONS -----
func _apply_dimension_effects(dimension: int):
	# Apply dimension-specific effects to data elements
	
	# Adjust stream properties
	for stream in data_streams:
		stream.dimension = dimension
		stream.properties.flow_rate = 1.0 + (dimension * 0.1)
		
		# Adjust visualization
		if stream_nodes.has(stream.id):
			var stream_node = stream_nodes[stream.id]
			
			# Scale based on dimension
			var scale_factor = 1.0 + ((dimension - 3) * 0.05)
			stream_node.scale = Vector3(scale_factor, scale_factor, scale_factor)
			
			# Adjust position
			var stream_index = data_streams.find(stream)
			var angle = (2 * PI / max_data_streams) * stream_index
			var radius = 3.0 + (dimension * 0.1)
			var height = 0.5 + (stream_index * 0.2)
			
			# Create tween for smooth transition
			var tween = get_tree().create_tween()
			tween.tween_property(stream_node, "position", Vector3(cos(angle) * radius, height, sin(angle) * radius), 1.0)
	
	# Adjust chunk properties
	for chunk_id in data_chunks:
		var chunk = data_chunks[chunk_id]
		chunk.dimension = dimension
		
		# Higher dimensions increase complexity and coherence
		chunk.properties.complexity = min(1.0, chunk.properties.complexity + (dimension * 0.02))
		
		# Adjust visualization
		if chunk_nodes.has(chunk_id):
			var chunk_node = chunk_nodes[chunk_id]
			
			# Scale and effects based on dimension
			var scale_factor = 1.0 + ((dimension - 3) * 0.03)
			chunk_node.scale = Vector3(scale_factor, scale_factor, scale_factor)
			
			# For dimensions 5+, add subtle glow effects
			if dimension >= 5:
				var mesh = chunk_node.get_child(0)
				if mesh is CSGBox3D:
					var material = mesh.material
					if material is StandardMaterial3D:
						material.emission_energy = 0.5 + ((dimension - 5) * 0.1)

func _apply_reality_effects(reality: String):
	# Apply reality-specific effects to data elements
	
	# Reality-specific properties for streams
	for stream in data_streams:
		stream.reality = reality
		
		match reality:
			"Physical":
				stream.properties.compression_ratio = 0.8
				stream.properties.stability = 0.9
			"Digital":
				stream.properties.compression_ratio = 0.5
				stream.properties.stability = 0.95
			"Astral":
				stream.properties.compression_ratio = 0.3
				stream.properties.stability = 0.7
			"Memory":
				stream.properties.compression_ratio = 0.4
				stream.properties.stability = 0.8
			"Dream":
				stream.properties.compression_ratio = 0.2
				stream.properties.stability = 0.6
		
		# Adjust visualization
		if stream_nodes.has(stream.id):
			var stream_node = stream_nodes[stream.id]
			var cylinder = stream_node.get_child(0)
			
			if cylinder is CSGCylinder3D and cylinder.material is StandardMaterial3D:
				var material = cylinder.material
				
				# Adjust colors based on reality
				match reality:
					"Physical":
						material.albedo_color = material.albedo_color.lerp(Color(0.2, 0.4, 0.9), 0.7)
						material.emission = material.emission.lerp(Color(0.3, 0.5, 1.0), 0.7)
					"Digital":
						material.albedo_color = material.albedo_color.lerp(Color(0.1, 0.8, 0.2), 0.7)
						material.emission = material.emission.lerp(Color(0.2, 0.9, 0.3), 0.7)
					"Astral":
						material.albedo_color = material.albedo_color.lerp(Color(0.9, 0.3, 0.9), 0.7)
						material.emission = material.emission.lerp(Color(1.0, 0.4, 1.0), 0.7)
					"Memory":
						material.albedo_color = material.albedo_color.lerp(Color(0.8, 0.8, 0.2), 0.7)
						material.emission = material.emission.lerp(Color(0.9, 0.9, 0.3), 0.7)
					"Dream":
						material.albedo_color = material.albedo_color.lerp(Color(0.5, 0.2, 0.8), 0.7)
						material.emission = material.emission.lerp(Color(0.6, 0.3, 0.9), 0.7)
	
	# Reality-specific properties for chunks
	for chunk_id in data_chunks:
		var chunk = data_chunks[chunk_id]
		chunk.reality = reality
		
		# Adjust visualization
		if chunk_nodes.has(chunk_id):
			var chunk_node = chunk_nodes[chunk_id]
			var box = chunk_node.get_child(0)
			
			if box is CSGBox3D and box.material is StandardMaterial3D:
				var material = box.material
				
				# Adjust material properties based on reality
				match reality:
					"Physical":
						material.metallic = 0.8
						material.roughness = 0.2
					"Digital":
						material.metallic = 0.2
						material.roughness = 0.1
					"Astral":
						material.metallic = 0.5
						material.roughness = 0.3
						material.emission_energy = 0.8
					"Memory":
						material.metallic = 0.3
						material.roughness = 0.5
					"Dream":
						material.metallic = 0.6
						material.roughness = 0.4
						material.emission_energy = 1.0

func _adjust_stability_by_moon_phase(phase: int, stability: float):
	# Adjust data processing based on moon phase
	
	# Modify stream flow rates
	for stream in data_streams:
		# Moon phase affects flow rate and stability
		var phase_factor = 0.5 + (stability * 0.5)
		stream.properties.flow_rate *= phase_factor
		stream.properties.stability = min(1.0, stream.properties.stability * phase_factor)
		
		# Visual adjustments
		if stream_nodes.has(stream.id):
			var stream_node = stream_nodes[stream.id]
			var cylinder = stream_node.get_child(0)
			
			if cylinder is CSGCylinder3D and cylinder.material is StandardMaterial3D:
				var material = cylinder.material
				material.emission_energy = 0.5 + (stability * 0.5)
	
	# Modify data chunk coherence
	for chunk_id in data_chunks:
		var chunk = data_chunks[chunk_id]
		
		# Moon phase affects data stability
		chunk.properties.coherence = min(1.0, chunk.properties.coherence * (0.7 + (stability * 0.3)))
		
		# Visual adjustments
		if chunk_nodes.has(chunk_id):
			var chunk_node = chunk_nodes[chunk_id]
			var box = chunk_node.get_child(0)
			
			if box is CSGBox3D and box.material is StandardMaterial3D:
				var material = box.material
				material.emission_energy = 0.4 + (stability * 0.6)

func _process_word_data_effects(word: String, entity):
	var word_lower = word.to_lower()
	
	if word_lower == "data" or word_lower == "stream":
		# Create a new data stream
		var stream_id = "word_stream_" + str(Time.get_unix_time_from_system())
		create_data_stream(stream_id, "text", 16 + word.length())
	
	elif word_lower == "split":
		# Split a random chunk if available
		if data_chunks.size() > 0:
			var chunk_id = data_chunks.keys()[randi() % data_chunks.size()]
			split_data_chunk(chunk_id)
	
	elif word_lower == "merge":
		# Merge random chunks if enough are available
		if data_chunks.size() >= 2:
			var all_chunks = data_chunks.keys()
			var to_merge = []
			
			# Pick 2-3 random chunks
			for i in range(min(data_chunks.size(), 2 + randi() % 2)):
				var idx = randi() % all_chunks.size()
				to_merge.append(all_chunks[idx])
				all_chunks.remove_at(idx)
			
			merge_data_chunks(to_merge)
	
	elif word_lower.find("flow") >= 0 or word_lower.find("process") >= 0:
		# Trigger data flows
		_process_data_flows()

func _process_data_flows():
	# Process automatic data flows between chunks and streams
	var flow_count = 0
	
	# For each stream, create flows between chunks
	for stream in data_streams:
		if stream.chunks.size() < 2:
			continue
		
		# Flow rate affects how many flows to create
		var flow_count_for_stream = int(max(1, stream.properties.flow_rate))
		
		for i in range(flow_count_for_stream):
			if stream.chunks.size() < 2:
				break
			
			# Pick random source and destination
			var source_idx = randi() % stream.chunks.size()
			var dest_idx = source_idx
			while dest_idx == source_idx:
				dest_idx = randi() % stream.chunks.size()
			
			var source_chunk = stream.chunks[source_idx]
			var dest_chunk = stream.chunks[dest_idx]
			
			# Create connection if doesn't exist
			_create_connection(source_chunk, dest_chunk, "flow")
			
			# Record flow
			var flow_id = "flow_" + str(Time.get_unix_time_from_system()) + "_" + str(flow_count)
			var flow_amount = 5 + randi() % 15
			
			var flow_data = {
				"id": flow_id,
				"source": source_chunk,
				"destination": dest_chunk,
				"amount": flow_amount,
				"timestamp": Time.get_unix_time_from_system(),
				"dimension": current_dimension,
				"reality": current_reality
			}
			
			data_flow_history.append(flow_data)
			emit_signal("data_flow_processed", flow_id, source_chunk, dest_chunk, flow_amount)
			
			flow_count += 1
			
			# Create visualization effect
			_create_flow_particle_effect(source_chunk, dest_chunk, flow_amount)
	
	if enable_debug_logs and flow_count > 0:
		print("DataSplitterController: Processed " + str(flow_count) + " data flows")
	
	# Update UI
	_update_ui_display()

func _create_flow_particle_effect(source_id: String, dest_id: String, amount: int):
	if not data_visualization_enabled:
		return
	
	if not chunk_nodes.has(source_id) or not chunk_nodes.has(dest_id):
		return
	
	var source_pos = chunk_nodes[source_id].global_position
	var dest_pos = chunk_nodes[dest_id].global_position
	
	# Create a simple particle effect
	var particles = CPUParticles3D.new()
	particles.emitting = true
	particles.amount = min(50, amount * 2)
	particles.lifetime = 1.0
	particles.one_shot = true
	particles.explosiveness = 0.0
	particles.direction = Vector3(0, 0, 0)
	particles.spread = 5.0
	particles.gravity = Vector3.ZERO
	
	# Set start and end positions
	particles.global_position = source_pos
	var dir = (dest_pos - source_pos).normalized()
	particles.velocity = dir * (source_pos.distance_to(dest_pos) / particles.lifetime)
	
	# Color based on dimension
	var base_color = Color(0.3, 0.7, 0.9)
	if current_dimension > 3:
		base_color = Color(0.9, 0.4, 0.8) # Higher dimensions more purple
	
	particles.color = base_color
	particles.color_ramp = Gradient.new()
	
	# Add to visualizer
	var visualizer_node = data_container.get_node("DataVisualizer")
	visualizer_node.add_child(particles)
	
	# Auto-remove when done
	var timer = Timer.new()
	timer.wait_time = particles.lifetime + 0.5
	timer.one_shot = true
	timer.connect("timeout", Callable(particles, "queue_free"))
	particles.add_child(timer)
	timer.start()

func _update_ui_display():
	# Update data splitter UI elements
	var ui = get_node_or_null("../UI")
	if not ui:
		return
	
	var data_panel = ui.get_node_or_null("DataSplitterPanel")
	if not data_panel:
		return
	
	# Update stream count
	var streams_label = data_panel.get_node_or_null("StreamsLabel")
	if streams_label:
		streams_label.text = "Active Streams: " + str(data_streams.size()) + "/" + str(max_data_streams)
	
	# Update chunk count
	var chunks_label = data_panel.get_node_or_null("ChunksLabel")
	if chunks_label:
		chunks_label.text = "Data Chunks: " + str(data_chunks.size())
	
	# Update splits count
	var splits_label = data_panel.get_node_or_null("SplitsLabel")
	if splits_label:
		splits_label.text = "Active Splits: " + str(data_splits.size())

func _log_message(message: String):
	# Log message to console output if available
	if console:
		var output = console.get_node_or_null("Panel/OutputLabel")
		if output and output is RichTextLabel:
			output.text += message + "\n"
			
			# Scroll to bottom
			output.scroll_to_line(output.get_line_count() - 1)
	
	if enable_debug_logs:
		print("DataSplitterController: " + message)

# ----- PHYSICS PROCESS -----
func _physics_process(delta):
	if not initialized or not data_visualization_enabled:
		return
	
	# Update connections - make sure they stay connected to moving chunks
	for connection_id in connection_nodes:
		var connection_data = active_connections.get(connection_id)
		if not connection_data:
			continue
		
		var source_id = connection_data.source
		var target_id = connection_data.target
		
		var source_node = null
		if chunk_nodes.has(source_id):
			source_node = chunk_nodes[source_id]
		elif stream_nodes.has(source_id):
			source_node = stream_nodes[source_id]
		
		var target_node = null
		if chunk_nodes.has(target_id):
			target_node = chunk_nodes[target_id]
		elif stream_nodes.has(target_id):
			target_node = stream_nodes[target_id]
		
		if source_node and target_node:
			_update_connection_line(connection_nodes[connection_id], source_node.global_position, target_node.global_position)
	
	# Apply dimension effects for 4D+ (temporal flows)
	if current_dimension >= 4:
		_process_temporal_effects(delta)

func _update_connection_line(connection_node, start_pos, end_pos):
	var line_container = connection_node.get_child(0)
	if not line_container or not line_container.get_child_count() > 0:
		return
	
	var mesh_instance = line_container.get_child(0)
	
	# Calculate midpoint and direction
	var midpoint = (start_pos + end_pos) / 2
	var direction = (end_pos - start_pos).normalized()
	var length = start_pos.distance_to(end_pos)
	
	# Update cylinder length
	if mesh_instance.mesh is CylinderMesh:
		mesh_instance.mesh.height = length
	
	# Position and orient cylinder to connect points
	mesh_instance.look_at_from_position(midpoint, end_pos, Vector3.UP)
	mesh_instance.rotate_object_local(Vector3.RIGHT, PI/2) # Rotate to align cylinder axis

func _process_temporal_effects(delta):
	# Apply temporal effects to data chunks (4D+)
	var time = Time.get_ticks_msec() / 1000.0
	var temporal_factor = (current_dimension - 3) * 0.05
	
	for chunk_id in chunk_nodes:
		var chunk_node = chunk_nodes[chunk_id]
		var original_pos = chunk_node.transform.origin
		
		# Create a unique oscillation for each chunk
		var chunk_hash = chunk_id.hash()
		var unique_offset = Vector3(
			sin(time + chunk_hash * 0.1) * temporal_factor,
			cos(time * 0.7 + chunk_hash * 0.05) * temporal_factor,
			sin(time * 0.5 + chunk_hash * 0.15) * temporal_factor
		)
		
		# Apply smooth movement
		chunk_node.global_position = chunk_node.global_position.lerp(original_pos + unique_offset, delta * 2.0)
		
		# Apply pulsing glow for dimensions 5+
		if current_dimension >= 5:
			var box = chunk_node.get_child(0)
			if box is CSGBox3D and box.material is StandardMaterial3D:
				var pulse = (sin(time + chunk_hash * 0.1) * 0.5 + 0.5) * temporal_factor * 2
				box.material.emission_energy = 0.6 + pulse
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/data_splitter_controller.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/data_splitter_terminal_bridge.gd
# SIZE: 43486 bytes
extends Node

class_name DataSplitterTerminalBridge

# ----- NODE PATHS -----
@export_node_path var data_splitter_controller_path: NodePath
@export_node_path var terminal_bridge_connector_path: NodePath
@export_node_path var console_path: NodePath

# ----- COMPONENT REFERENCES -----
var data_splitter_controller = null
var terminal_bridge_connector = null
var console = null

# ----- CONFIGURATION -----
@export var auto_initialize: bool = true
@export var enable_debug_logs: bool = true
@export var max_command_history: int = 50
@export var enable_color_output: bool = true
@export var attach_to_turn_system: bool = true

# ----- BRIDGE SETTINGS -----
@export var terminal_poll_interval: float = 0.5  # seconds
@export var data_sewer_path: String = "user://data_sewers"
@export var terminal_data_path: String = "user://terminal_data"
@export var terminal_file_extension: String = ".terminal"
@export var bridge_active: bool = false

# ----- COMMAND PREFIXES -----
const CMD_DATA_SPLIT = "/split"
const CMD_DATA_STREAM = "/stream"
const CMD_DATA_CHUNK = "/chunk"
const CMD_DATA_MERGE = "/merge"
const CMD_DATA_LIST = "/list"
const CMD_DATA_ANALYZE = "/analyze"
const CMD_DATA_VISUALIZE = "/visualize"
const CMD_DATA_HELP = "/help"

# ----- COMMUNICATION STATE -----
var last_poll_time = 0
var terminal_last_modified = {}
var command_history = []
var last_command_index = -1
var active_terminal_windows = []
var current_dimension: int = 3
var current_reality: String = "Digital"
var current_terminal_id: int = 0
var pending_data_operations = []

# ----- SIGNALS -----
signal terminal_bridge_ready
signal command_processed(command, result)
signal terminal_message_received(terminal_id, message)
signal data_operation_completed(operation_type, result)
signal terminal_bridge_error(error_message)
signal dimension_changed(new_dimension)
signal reality_changed(new_reality)

# ----- INITIALIZATION -----
func _ready():
	if auto_initialize:
		initialize()

func initialize():
	print("DataSplitterTerminalBridge: Initializing...")
	
	# Find components
	_resolve_component_paths()
	
	# Create required directories
	_create_directories()
	
	# Initialize terminal data
	_init_terminal_data()
	
	# Connect signals
	_connect_signals()
	
	# Start bridge
	bridge_active = true
	
	print("DataSplitterTerminalBridge: Initialization complete")
	emit_signal("terminal_bridge_ready")

func _resolve_component_paths():
	# Resolve DataSplitterController
	if data_splitter_controller_path:
		data_splitter_controller = get_node_or_null(data_splitter_controller_path)
		
	if not data_splitter_controller:
		data_splitter_controller = get_node_or_null("/root/DataSplitterController")
		if not data_splitter_controller:
			var nodes = get_tree().get_nodes_in_group("data_splitter")
			if nodes.size() > 0:
				data_splitter_controller = nodes[0]
	
	# Resolve TerminalBridgeConnector
	if terminal_bridge_connector_path:
		terminal_bridge_connector = get_node_or_null(terminal_bridge_connector_path)
		
	if not terminal_bridge_connector:
		terminal_bridge_connector = get_node_or_null("/root/TerminalBridgeConnector")
		if not terminal_bridge_connector:
			var nodes = get_tree().get_nodes_in_group("terminal_bridge")
			if nodes.size() > 0:
				terminal_bridge_connector = nodes[0]
	
	# Resolve Console
	if console_path:
		console = get_node_or_null(console_path)
		
	if not console and data_splitter_controller:
		console = data_splitter_controller.get_node_or_null("../Console")
		
	# Log results
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Component resolution:")
		print("- Data Splitter Controller: ", "Found" if data_splitter_controller else "Not found")
		print("- Terminal Bridge Connector: ", "Found" if terminal_bridge_connector else "Not found")
		print("- Console: ", "Found" if console else "Not found")

func _create_directories():
	# Create data sewer directory
	var dir = DirAccess.open("user://")
	if dir:
		if not dir.dir_exists(data_sewer_path):
			dir.make_dir_recursive(data_sewer_path)
		
		# Create terminal data directory
		if not dir.dir_exists(terminal_data_path):
			dir.make_dir_recursive(terminal_data_path)
			
		if enable_debug_logs:
			print("DataSplitterTerminalBridge: Directories created")
	else:
		print("DataSplitterTerminalBridge: Error accessing user directory")

func _init_terminal_data():
	# Create terminal data files for multiple terminals
	for i in range(6):  # Support 6 terminal windows
		var terminal_file = terminal_data_path + "/terminal_" + str(i) + terminal_file_extension
		
		if not FileAccess.file_exists(terminal_file):
			var file = FileAccess.open(terminal_file, FileAccess.WRITE)
			if file:
				var init_data = {
					"terminal_id": i,
					"last_update": Time.get_unix_time_from_system(),
					"messages": ["Terminal " + str(i) + " initialized for data splitting"],
					"data_operations": [],
					"data_results": []
				}
				file.store_string(JSON.stringify(init_data))
				
				if enable_debug_logs:
					print("DataSplitterTerminalBridge: Created terminal file for Terminal " + str(i))
		
		# Store last modified time
		terminal_last_modified[i] = Time.get_unix_time_from_system()
		
		# Add to active terminals
		active_terminal_windows.append(i)

func _connect_signals():
	# Connect to DataSplitterController signals
	if data_splitter_controller:
		# Connect to initialization_completed if available
		if data_splitter_controller.has_signal("initialization_completed"):
			data_splitter_controller.connect("initialization_completed", Callable(self, "_on_data_splitter_initialized"))
		
		# Connect to data operation signals
		if data_splitter_controller.has_signal("data_stream_created"):
			data_splitter_controller.connect("data_stream_created", Callable(self, "_on_data_stream_created"))
		
		if data_splitter_controller.has_signal("data_chunk_created"):
			data_splitter_controller.connect("data_chunk_created", Callable(self, "_on_data_chunk_created"))
		
		if data_splitter_controller.has_signal("data_split_created"):
			data_splitter_controller.connect("data_split_created", Callable(self, "_on_data_split_created"))
		
		if data_splitter_controller.has_signal("data_merged"):
			data_splitter_controller.connect("data_merged", Callable(self, "_on_data_merged"))
		
		if data_splitter_controller.has_signal("dimension_changed"):
			data_splitter_controller.connect("dimension_changed", Callable(self, "_on_dimension_changed"))
		
		if data_splitter_controller.has_signal("reality_changed"):
			data_splitter_controller.connect("reality_changed", Callable(self, "_on_reality_changed"))
	
	# Connect to TerminalBridgeConnector signals
	if terminal_bridge_connector:
		# Connect to terminal_connected if available
		if terminal_bridge_connector.has_signal("terminal_connected"):
			terminal_bridge_connector.connect("terminal_connected", Callable(self, "_on_terminal_connected"))
		
		# Connect to color shift signals
		if terminal_bridge_connector.has_signal("color_shift_detected"):
			terminal_bridge_connector.connect("color_shift_detected", Callable(self, "_on_color_shift_detected"))

# ----- PROCESSING -----
func _process(delta):
	if not bridge_active:
		return
	
	# Poll terminals at specified interval
	last_poll_time += delta
	if last_poll_time >= terminal_poll_interval:
		last_poll_time = 0
		_poll_terminal_files()
	
	# Process pending data operations
	_process_pending_data_operations()

func _poll_terminal_files():
	# Check terminal files for changes
	for terminal_id in active_terminal_windows:
		var terminal_file = terminal_data_path + "/terminal_" + str(terminal_id) + terminal_file_extension
		
		if FileAccess.file_exists(terminal_file):
			# Check if file has been modified
			var file_access = FileAccess.open(terminal_file, FileAccess.READ)
			if file_access:
				var modified_time = Time.get_unix_time_from_system()
				
				if not terminal_last_modified.has(terminal_id) or modified_time > terminal_last_modified[terminal_id]:
					terminal_last_modified[terminal_id] = modified_time
					
					# Read terminal data
					var json_text = file_access.get_as_text()
					
					var json = JSON.parse_string(json_text)
					if json:
						_process_terminal_data(json)
					else:
						print("DataSplitterTerminalBridge: Error parsing terminal JSON for Terminal " + str(terminal_id))

func _process_terminal_data(data):
	var terminal_id = data.terminal_id
	
	# Process messages
	if data.has("messages") and data.messages.size() > 0:
		var last_message = data.messages[data.messages.size() - 1]
		emit_signal("terminal_message_received", terminal_id, last_message)
		
		# Check if it's a data splitter command
		if last_message.begins_with("/"):
			_process_command(last_message, terminal_id)
	
	# Process data operations
	if data.has("data_operations") and data.operations.size() > 0:
		for operation in data.data_operations:
			# Check if operation is new
			var is_new = true
			
			for pending in pending_data_operations:
				if pending.id == operation.id:
					is_new = false
					break
			
			if is_new:
				pending_data_operations.append(operation)

func _process_command(command: String, terminal_id: int):
	# Store command in history
	_add_to_command_history(command)
	
	# Set current terminal ID
	current_terminal_id = terminal_id
	
	# Process command based on prefix
	var parts = command.split(" ", false, 1)
	var cmd = parts[0].to_lower()
	var params = ""
	if parts.size() > 1:
		params = parts[1]
	
	var result = {}
	
	match cmd:
		CMD_DATA_SPLIT:
			result = _handle_split_command(params)
		CMD_DATA_STREAM:
			result = _handle_stream_command(params)
		CMD_DATA_CHUNK:
			result = _handle_chunk_command(params)
		CMD_DATA_MERGE:
			result = _handle_merge_command(params)
		CMD_DATA_LIST:
			result = _handle_list_command(params)
		CMD_DATA_ANALYZE:
			result = _handle_analyze_command(params)
		CMD_DATA_VISUALIZE:
			result = _handle_visualize_command(params)
		CMD_DATA_HELP, "/data-help":
			result = _handle_help_command(params)
		_:
			# Check if command might be for data splitter
			if command.begins_with("/data-"):
				var custom_cmd = command.substr(6)
				result = _handle_custom_command(custom_cmd)
			else:
				# Not a data splitter command
				return
	
	# Send command result to terminal
	_send_result_to_terminal(result, terminal_id)
	
	# Emit signal
	emit_signal("command_processed", command, result)

func _process_pending_data_operations():
	# Process pending operations
	if pending_data_operations.size() > 0:
		var operation = pending_data_operations[0]
		
		match operation.type:
			"split":
				if data_splitter_controller:
					var result = data_splitter_controller.split_data_chunk(operation.chunk_id, operation.split_factor)
					_send_operation_result_to_terminal(operation.terminal_id, result)
					emit_signal("data_operation_completed", "split", result)
			"merge":
				if data_splitter_controller:
					var result = data_splitter_controller.merge_data_chunks(operation.chunk_ids, operation.merge_type)
					_send_operation_result_to_terminal(operation.terminal_id, result)
					emit_signal("data_operation_completed", "merge", result)
			"create_stream":
				if data_splitter_controller:
					var result = data_splitter_controller.create_data_stream(operation.stream_id, operation.data_type, operation.size)
					_send_operation_result_to_terminal(operation.terminal_id, result)
					emit_signal("data_operation_completed", "create_stream", result)
			"create_chunk":
				if data_splitter_controller:
					var result = data_splitter_controller.create_data_chunk(operation.chunk_id, operation.content, operation.parent_stream)
					_send_operation_result_to_terminal(operation.terminal_id, result)
					emit_signal("data_operation_completed", "create_chunk", result)
		
		# Remove processed operation
		pending_data_operations.pop_front()

# ----- COMMAND HANDLERS -----
func _handle_split_command(params: String) -> Dictionary:
	# Split command: /split [chunk_id] [split_factor]
	if params.strip_edges().is_empty():
		return {
			"success": false,
			"message": "Usage: " + CMD_DATA_SPLIT + " [chunk_id] [split_factor]"
		}
	
	var parts = params.split(" ", false)
	var chunk_id = parts[0]
	var split_factor = 3  # Default split factor
	
	if parts.size() >= 2 and parts[1].is_valid_integer():
		split_factor = parts[1].to_int()
	
	if data_splitter_controller:
		# Add operation to pending list
		_add_pending_operation({
			"id": "split_" + str(Time.get_unix_time_from_system()),
			"type": "split",
			"chunk_id": chunk_id,
			"split_factor": split_factor,
			"terminal_id": current_terminal_id
		})
		
		return {
			"success": true,
			"message": "Splitting chunk '" + chunk_id + "' with factor " + str(split_factor) + "...",
			"operation": "split",
			"chunk_id": chunk_id,
			"split_factor": split_factor
		}
	else:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}

func _handle_stream_command(params: String) -> Dictionary:
	# Stream command: /stream [stream_id] [data_type] [size]
	if params.strip_edges().is_empty():
		return {
			"success": false,
			"message": "Usage: " + CMD_DATA_STREAM + " [stream_id] [data_type] [size]"
		}
	
	var parts = params.split(" ", false)
	var stream_id = parts[0]
	var data_type = "binary"  # Default data type
	var size = 16  # Default size
	
	if parts.size() >= 2:
		data_type = parts[1]
	
	if parts.size() >= 3 and parts[2].is_valid_integer():
		size = parts[2].to_int()
	
	if data_splitter_controller:
		# Add operation to pending list
		_add_pending_operation({
			"id": "stream_" + str(Time.get_unix_time_from_system()),
			"type": "create_stream",
			"stream_id": stream_id,
			"data_type": data_type,
			"size": size,
			"terminal_id": current_terminal_id
		})
		
		return {
			"success": true,
			"message": "Creating data stream '" + stream_id + "' of type " + data_type + " with size " + str(size) + "...",
			"operation": "create_stream",
			"stream_id": stream_id,
			"data_type": data_type,
			"size": size
		}
	else:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}

func _handle_chunk_command(params: String) -> Dictionary:
	# Chunk command: /chunk [chunk_id] [parent_stream] [content]
	if params.strip_edges().is_empty():
		return {
			"success": false,
			"message": "Usage: " + CMD_DATA_CHUNK + " [chunk_id] [parent_stream] [content]"
		}
	
	var parts = params.split(" ", false, 2)
	
	if parts.size() < 3:
		return {
			"success": false,
			"message": "Usage: " + CMD_DATA_CHUNK + " [chunk_id] [parent_stream] [content]"
		}
	
	var chunk_id = parts[0]
	var parent_stream = parts[1]
	var content = parts[2]
	
	if data_splitter_controller:
		# Add operation to pending list
		_add_pending_operation({
			"id": "chunk_" + str(Time.get_unix_time_from_system()),
			"type": "create_chunk",
			"chunk_id": chunk_id,
			"parent_stream": parent_stream,
			"content": content,
			"terminal_id": current_terminal_id
		})
		
		return {
			"success": true,
			"message": "Creating data chunk '" + chunk_id + "' in stream '" + parent_stream + "'...",
			"operation": "create_chunk",
			"chunk_id": chunk_id,
			"parent_stream": parent_stream,
			"content_length": content.length()
		}
	else:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}

func _handle_merge_command(params: String) -> Dictionary:
	# Merge command: /merge [chunk_id1,chunk_id2,...] [merge_type]
	if params.strip_edges().is_empty():
		return {
			"success": false,
			"message": "Usage: " + CMD_DATA_MERGE + " [chunk_id1,chunk_id2,...] [merge_type]"
		}
	
	var parts = params.split(" ", false)
	
	if parts.size() < 1:
		return {
			"success": false,
			"message": "Usage: " + CMD_DATA_MERGE + " [chunk_id1,chunk_id2,...] [merge_type]"
		}
	
	var chunk_ids_str = parts[0]
	var chunk_ids = chunk_ids_str.split(",", false)
	
	if chunk_ids.size() < 2:
		return {
			"success": false,
			"message": "Need at least 2 chunks to merge. Usage: " + CMD_DATA_MERGE + " [chunk_id1,chunk_id2,...] [merge_type]"
		}
	
	var merge_type = "concatenate"  # Default merge type
	
	if parts.size() >= 2:
		merge_type = parts[1]
	
	if data_splitter_controller:
		# Add operation to pending list
		_add_pending_operation({
			"id": "merge_" + str(Time.get_unix_time_from_system()),
			"type": "merge",
			"chunk_ids": chunk_ids,
			"merge_type": merge_type,
			"terminal_id": current_terminal_id
		})
		
		return {
			"success": true,
			"message": "Merging " + str(chunk_ids.size()) + " chunks with merge type '" + merge_type + "'...",
			"operation": "merge",
			"chunk_ids": chunk_ids,
			"merge_type": merge_type
		}
	else:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}

func _handle_list_command(params: String) -> Dictionary:
	# List command: /list [streams|chunks|splits|all]
	var list_type = "all"
	
	if not params.strip_edges().is_empty():
		list_type = params.strip_edges().to_lower()
	
	if data_splitter_controller:
		var streams = []
		var chunks = {}
		var splits = {}
		var listing = "[color=#88ff99]Data Splitter Elements:[/color]\n"
		
		# Get data from controller
		if list_type == "all" or list_type == "streams":
			if data_splitter_controller.has_method("get_data_streams"):
				streams = data_splitter_controller.get_data_streams()
			elif data_splitter_controller.has("data_streams"):
				streams = data_splitter_controller.data_streams
		
		if list_type == "all" or list_type == "chunks":
			if data_splitter_controller.has_method("get_data_chunks"):
				chunks = data_splitter_controller.get_data_chunks()
			elif data_splitter_controller.has("data_chunks"):
				chunks = data_splitter_controller.data_chunks
		
		if list_type == "all" or list_type == "splits":
			if data_splitter_controller.has_method("get_data_splits"):
				splits = data_splitter_controller.get_data_splits()
			elif data_splitter_controller.has("data_splits"):
				splits = data_splitter_controller.data_splits
		
		# Generate listing
		if list_type == "all" or list_type == "streams":
			listing += "\n[color=#aaaaff]Streams (" + str(streams.size()) + "):[/color]\n"
			for stream in streams:
				listing += "- " + stream.id + " (" + stream.type + ", " + str(stream.size) + " bytes, " + str(stream.chunks.size()) + " chunks)\n"
		
		if list_type == "all" or list_type == "chunks":
			listing += "\n[color=#ffaaaa]Chunks (" + str(chunks.size()) + "):[/color]\n"
			var chunk_count = 0
			for chunk_id in chunks:
				listing += "- " + chunk_id + " (size: " + str(chunks[chunk_id].size) + ")\n"
				chunk_count += 1
				if chunk_count >= 10 and chunks.size() > 10:
					listing += "  ... and " + str(chunks.size() - 10) + " more\n"
					break
		
		if list_type == "all" or list_type == "splits":
			listing += "\n[color=#aaffaa]Splits (" + str(splits.size()) + "):[/color]\n"
			var split_count = 0
			for split_id in splits:
				listing += "- " + split_id + " (factor: " + str(splits[split_id].factor) + ")\n"
				split_count += 1
				if split_count >= 5 and splits.size() > 5:
					listing += "  ... and " + str(splits.size() - 5) + " more\n"
					break
		
		_log_message(listing)
		
		return {
			"success": true,
			"message": listing,
			"streams_count": streams.size(),
			"chunks_count": chunks.size(),
			"splits_count": splits.size()
		}
	else:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}

func _handle_analyze_command(params: String) -> Dictionary:
	# Analyze command: /analyze [text_to_analyze]
	if params.strip_edges().is_empty():
		return {
			"success": false,
			"message": "Usage: " + CMD_DATA_ANALYZE + " [text_to_analyze]"
		}
	
	# Perform basic analysis
	var analysis = {
		"total_chars": params.length(),
		"word_count": params.split(" ", false).size(),
		"line_count": params.split("\n", false).size(),
		"special_chars": {}
	}
	
	var special_chars = ["[", "]", "=", "|", "#", "@", "$", "%", "^", "&", "*"]
	
	for char in special_chars:
		var count = params.count(char)
		if count > 0:
			analysis.special_chars[char] = count
	
	# Check if there are potential natural split points
	var natural_splits = []
	
	if params.find("[") >= 0 and params.find("]") >= 0:
		natural_splits.append("brackets")
	
	if params.find("=") >= 0:
		natural_splits.append("equals")
	
	if params.find("|") >= 0:
		natural_splits.append("pipes")
	
	if params.find(",") >= 0:
		natural_splits.append("commas")
	
	analysis["natural_splits"] = natural_splits
	
	var message = "[color=#88ff99]Text Analysis:[/color]\n"
	message += "Characters: " + str(analysis.total_chars) + "\n"
	message += "Words: " + str(analysis.word_count) + "\n"
	message += "Lines: " + str(analysis.line_count) + "\n"
	
	if analysis.special_chars.size() > 0:
		message += "\n[color=#aaaaff]Special Characters:[/color]\n"
		for char in analysis.special_chars:
			message += "- '" + char + "': " + str(analysis.special_chars[char]) + "\n"
	
	if natural_splits.size() > 0:
		message += "\n[color=#aaffaa]Suggested Split Methods:[/color]\n"
		for split in natural_splits:
			message += "- " + split + "\n"
	
	_log_message(message)
	
	return {
		"success": true,
		"message": message,
		"analysis": analysis
	}

func _handle_visualize_command(params: String) -> Dictionary:
	# Visualize command: /visualize [chunk_id|stream_id] [dimension]
	if params.strip_edges().is_empty():
		return {
			"success": false,
			"message": "Usage: " + CMD_DATA_VISUALIZE + " [chunk_id|stream_id] [dimension]"
		}
	
	var parts = params.split(" ", false)
	var entity_id = parts[0]
	var dimension = current_dimension
	
	if parts.size() >= 2 and parts[1].is_valid_integer():
		dimension = parts[1].to_int()
	
	if data_splitter_controller:
		# Try to find entity
		var entity_type = "unknown"
		var found = false
		
		if data_splitter_controller.has_method("get_data_streams"):
			var streams = data_splitter_controller.get_data_streams()
			for stream in streams:
				if stream.id == entity_id:
					entity_type = "stream"
					found = true
					break
		elif data_splitter_controller.has("data_streams"):
			for stream in data_splitter_controller.data_streams:
				if stream.id == entity_id:
					entity_type = "stream"
					found = true
					break
		
		if not found and data_splitter_controller.has_method("get_data_chunks"):
			var chunks = data_splitter_controller.get_data_chunks()
			if chunks.has(entity_id):
				entity_type = "chunk"
				found = true
		elif not found and data_splitter_controller.has("data_chunks"):
			if data_splitter_controller.data_chunks.has(entity_id):
				entity_type = "chunk"
				found = true
		
		if found:
			var visualization_text = "[color=#88ff99]Visualizing " + entity_type + " '" + entity_id + "' in " + str(dimension) + "D:[/color]\n\n"
			
			if entity_type == "stream":
				visualization_text += _generate_stream_visualization(entity_id, dimension)
			else:
				visualization_text += _generate_chunk_visualization(entity_id, dimension)
			
			_log_message(visualization_text)
			
			return {
				"success": true,
				"message": visualization_text,
				"entity_type": entity_type,
				"entity_id": entity_id,
				"dimension": dimension
			}
		else:
			return {
				"success": false,
				"message": "Entity '" + entity_id + "' not found"
			}
	else:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}

func _handle_help_command(params: String) -> Dictionary:
	# Help command: /help
	var help_text = "[color=#88ff99]Data Splitter Terminal Bridge Commands:[/color]\n"
	help_text += "/split [chunk_id] [split_factor] - Split a data chunk\n"
	help_text += "/stream [stream_id] [data_type] [size] - Create a new data stream\n"
	help_text += "/chunk [chunk_id] [parent_stream] [content] - Create a new data chunk\n"
	help_text += "/merge [chunk_id1,chunk_id2,...] [merge_type] - Merge multiple chunks\n"
	help_text += "/list [streams|chunks|splits|all] - List data elements\n"
	help_text += "/analyze [text] - Analyze text for data splitting\n"
	help_text += "/visualize [chunk_id|stream_id] [dimension] - Visualize data in terminal\n"
	help_text += "/help - Display this help\n"
	
	_log_message(help_text)
	
	return {
		"success": true,
		"message": help_text
	}

func _handle_custom_command(command: String) -> Dictionary:
	# Handle custom commands passed to data splitter
	if data_splitter_controller and data_splitter_controller.has_method("process_command"):
		var result = data_splitter_controller.process_command(command)
		
		if not result.success:
			_log_message("Error: " + result.message)
		
		return result
	else:
		return {
			"success": false,
			"message": "Data Splitter Controller not available or does not support custom commands"
		}

# ----- HELPER FUNCTIONS -----
func _add_to_command_history(command: String):
	command_history.append(command)
	
	if command_history.size() > max_command_history:
		command_history.pop_front()
	
	last_command_index = command_history.size()

func _add_pending_operation(operation: Dictionary):
	pending_data_operations.append(operation)

func _send_result_to_terminal(result: Dictionary, terminal_id: int):
	var message = result.message if result.has("message") else ""
	
	if enable_color_output:
		if result.success:
			message = "[color=#88ff99]" + message + "[/color]"
		else:
			message = "[color=#ff7777]" + message + "[/color]"
	
	_send_message_to_terminal(terminal_id, message)

func _send_operation_result_to_terminal(terminal_id: int, result: Dictionary):
	var message = ""
	
	if result.success:
		message = "[color=#88ff99]Operation completed successfully![/color]\n"
		
		if result.has("message"):
			message += result.message
	else:
		message = "[color=#ff7777]Operation failed: " + result.message + "[/color]"
	
	_send_message_to_terminal(terminal_id, message)
	
	# Add result to terminal data file
	var terminal_file = terminal_data_path + "/terminal_" + str(terminal_id) + terminal_file_extension
	if FileAccess.file_exists(terminal_file):
		var file_access = FileAccess.open(terminal_file, FileAccess.READ)
		if file_access:
			var json_text = file_access.get_as_text()
			var json = JSON.parse_string(json_text)
			
			if json:
				if not json.has("data_results"):
					json.data_results = []
				
				json.data_results.append({
					"timestamp": Time.get_unix_time_from_system(),
					"result": result
				})
				
				file_access.close()
				
				# Save updated data
				file_access = FileAccess.open(terminal_file, FileAccess.WRITE)
				if file_access:
					file_access.store_string(JSON.stringify(json))

func _send_message_to_terminal(terminal_id: int, message: String):
	var terminal_file = terminal_data_path + "/terminal_" + str(terminal_id) + terminal_file_extension
	
	if FileAccess.file_exists(terminal_file):
		var file_access = FileAccess.open(terminal_file, FileAccess.READ)
		if file_access:
			var json_text = file_access.get_as_text()
			var json = JSON.parse_string(json_text)
			
			if json:
				if not json.has("messages"):
					json.messages = []
				
				json.messages.append(message)
				json.last_update = Time.get_unix_time_from_system()
				
				file_access.close()
				
				# Save updated data
				file_access = FileAccess.open(terminal_file, FileAccess.WRITE)
				if file_access:
					file_access.store_string(JSON.stringify(json))
					
					if enable_debug_logs:
						print("DataSplitterTerminalBridge: Message sent to Terminal " + str(terminal_id))
				else:
					print("DataSplitterTerminalBridge: Error opening terminal file for writing")
			else:
				print("DataSplitterTerminalBridge: Error parsing terminal JSON")
		else:
			print("DataSplitterTerminalBridge: Error opening terminal file for reading")
	else:
		print("DataSplitterTerminalBridge: Terminal file not found for Terminal " + str(terminal_id))

func _log_message(message: String):
	# Log to console if available
	if console:
		var output = console.get_node_or_null("Panel/OutputLabel")
		if output and output is RichTextLabel:
			output.text += message + "\n"
			
			# Scroll to bottom
			output.scroll_to_line(output.get_line_count() - 1)
	
	# Print to debug console if debug logs enabled
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: " + message.replace("[color=#88ff99]", "").replace("[/color]", "").replace("[color=#aaaaff]", "").replace("[color=#ffaaaa]", "").replace("[color=#aaffaa]", "").replace("[color=#ff7777]", ""))

func _generate_stream_visualization(stream_id: String, dimension: int) -> String:
	var visualization = ""
	var stream_data = null
	
	# Get stream data
	if data_splitter_controller.has_method("get_data_streams"):
		var streams = data_splitter_controller.get_data_streams()
		for stream in streams:
			if stream.id == stream_id:
				stream_data = stream
				break
	elif data_splitter_controller.has("data_streams"):
		for stream in data_splitter_controller.data_streams:
			if stream.id == stream_id:
				stream_data = stream
				break
	
	if not stream_data:
		return "Stream data not found"
	
	# Generate visualization based on dimension
	match dimension:
		1:
			# 1D visualization - simple line
			visualization += "[color=#aaaaff]" + "|" + "=" * (stream_data.size / 2) + stream_id + "=" * (stream_data.size / 2) + "|" + "[/color]\n"
			
			if stream_data.has("chunks") and stream_data.chunks.size() > 0:
				visualization += "-" * 40 + "\n"
				visualization += "Chunks: "
				
				for i in range(stream_data.chunks.size()):
					if i > 0:
						visualization += " - "
					visualization += stream_data.chunks[i]
		
		2:
			# 2D visualization - box
			var width = min(40, stream_data.size + 10)
			var top_bottom = "+" + "-" * (width - 2) + "+\n"
			
			visualization += "[color=#aaaaff]" + top_bottom
			
			# Create content lines
			var side = "|"
			
			# Stream ID line
			var padding = " " * ((width - 2 - stream_id.length()) / 2)
			visualization += side + padding + stream_id + padding
			if (width - 2 - stream_id.length()) % 2 != 0:
				visualization += " "
			visualization += side + "\n"
			
			// Stream type line
			var type_text = "Type: " + stream_data.type
			padding = " " * ((width - 2 - type_text.length()) / 2)
			visualization += side + padding + type_text + padding
			if (width - 2 - type_text.length()) % 2 != 0:
				visualization += " "
			visualization += side + "\n"
			
			// Stream size line
			var size_text = "Size: " + str(stream_data.size)
			padding = " " * ((width - 2 - size_text.length()) / 2)
			visualization += side + padding + size_text + padding
			if (width - 2 - size_text.length()) % 2 != 0:
				visualization += " "
			visualization += side + "\n"
			
			// Chunk count line
			var chunk_text = "Chunks: " + str(stream_data.chunks.size())
			padding = " " * ((width - 2 - chunk_text.length()) / 2)
			visualization += side + padding + chunk_text + padding
			if (width - 2 - chunk_text.length()) % 2 != 0:
				visualization += " "
			visualization += side + "\n"
			
			visualization += top_bottom + "[/color]"
			
			// If chunks exist, list them
			if stream_data.has("chunks") and stream_data.chunks.size() > 0:
				visualization += "\nChunks:\n"
				for chunk_id in stream_data.chunks:
					visualization += "- " + chunk_id + "\n"
		
		3, _:
			// 3D+ visualization - more detailed ASCII art
			var width = min(60, stream_data.size + 20)
			
			// Top
			visualization += "[color=#aaaaff]" + "    " + "_" * (width - 8) + "\n"
			visualization += "   /|" + " " * (width - 8) + "|\n"
			
			// Stream ID line
			var stream_id_padded = stream_id
			if stream_id.length() < width - 12:
				var padding = (width - 12 - stream_id.length()) / 2
				stream_id_padded = " " * padding + stream_id + " " * padding
			else:
				stream_id_padded = stream_id.substr(0, width - 15) + "..."
			
			visualization += "  / |  " + stream_id_padded + "  |\n"
			
			// Stream properties
			var type_text = "Type: " + stream_data.type
			var size_text = "Size: " + str(stream_data.size)
			var chunk_text = "Chunks: " + str(stream_data.chunks.size())
			
			visualization += " /__|" + "_" * (width - 8) + "|\n"
			visualization += "|   |" + " " * (width - 8) + "|\n"
			visualization += "|   |  " + type_text + " " * (width - 12 - type_text.length()) + "|\n"
			visualization += "|   |  " + size_text + " " * (width - 12 - size_text.length()) + "|\n"
			visualization += "|   |  " + chunk_text + " " * (width - 12 - chunk_text.length()) + "|\n"
			visualization += "|___|" + "_" * (width - 8) + "|[/color]\n"
			
			// Show dimensions based on dimension count
			if dimension >= 4:
				var dimension_text = "Dimensions: " + str(dimension) + "D"
				visualization += "\n[color=#ffaaaa]" + dimension_text + "[/color]\n"
				
				for d in range(4, dimension + 1):
					visualization += "  Dimension " + str(d) + ": " + _get_dimension_property(d) + "\n"
			
			// If chunks exist, list them with ASCII connection
			if stream_data.has("chunks") and stream_data.chunks.size() > 0:
				visualization += "\n[color=#aaffaa]Connected Chunks:[/color]\n"
				visualization += "    |\n"
				for i in range(stream_data.chunks.size()):
					if i < stream_data.chunks.size() - 1:
						visualization += "    ‚îú‚îÄ‚îÄ‚îÄ " + stream_data.chunks[i] + "\n"
					else:
						visualization += "    ‚îî‚îÄ‚îÄ‚îÄ " + stream_data.chunks[i] + "\n"
	
	return visualization

func _generate_chunk_visualization(chunk_id: String, dimension: int) -> String:
	var visualization = ""
	var chunk_data = null
	
	// Get chunk data
	if data_splitter_controller.has_method("get_data_chunks"):
		var chunks = data_splitter_controller.get_data_chunks()
		if chunks.has(chunk_id):
			chunk_data = chunks[chunk_id]
	elif data_splitter_controller.has("data_chunks"):
		if data_splitter_controller.data_chunks.has(chunk_id):
			chunk_data = data_splitter_controller.data_chunks[chunk_id]
	
	if not chunk_data:
		return "Chunk data not found"
	
	// Generate visualization based on dimension
	match dimension:
		1:
			// 1D visualization - simple representation
			visualization += "[color=#ffaaaa][" + chunk_id + ":" + str(chunk_data.size) + "][/color]\n"
			
			if chunk_data.has("content") and chunk_data.content.length() > 0:
				var content = chunk_data.content
				if content.length() > 40:
					content = content.substr(0, 37) + "..."
				visualization += "Content: " + content
		
		2:
			// 2D visualization - box
			var width = min(40, chunk_data.size + 10)
			var top_bottom = "+" + "-" * (width - 2) + "+\n"
			
			visualization += "[color=#ffaaaa]" + top_bottom
			
			// Create content lines
			var side = "|"
			
			// Chunk ID line
			var padding = " " * ((width - 2 - chunk_id.length()) / 2)
			visualization += side + padding + chunk_id + padding
			if (width - 2 - chunk_id.length()) % 2 != 0:
				visualization += " "
			visualization += side + "\n"
			
			// Parent stream line
			var stream_text = "Stream: " + chunk_data.parent_stream
			padding = " " * ((width - 2 - stream_text.length()) / 2)
			visualization += side + padding + stream_text + padding
			if (width - 2 - stream_text.length()) % 2 != 0:
				visualization += " "
			visualization += side + "\n"
			
			// Size line
			var size_text = "Size: " + str(chunk_data.size)
			padding = " " * ((width - 2 - size_text.length()) / 2)
			visualization += side + padding + size_text + padding
			if (width - 2 - size_text.length()) % 2 != 0:
				visualization += " "
			visualization += side + "\n"
			
			visualization += top_bottom + "[/color]"
			
			// Show content
			if chunk_data.has("content") and chunk_data.content.length() > 0:
				visualization += "\nContent:\n"
				var content = chunk_data.content
				if content.length() > 100:
					content = content.substr(0, 97) + "..."
				visualization += content + "\n"
		
		3, _:
			// 3D+ visualization - more detailed ASCII art
			var width = min(60, chunk_data.size + 20)
			
			// Top
			visualization += "[color=#ffaaaa]" + "    " + "_" * (width - 8) + "\n"
			visualization += "   /|" + " " * (width - 8) + "|\n"
			
			// Chunk ID line
			var chunk_id_padded = chunk_id
			if chunk_id.length() < width - 12:
				var padding = (width - 12 - chunk_id.length()) / 2
				chunk_id_padded = " " * padding + chunk_id + " " * padding
			else:
				chunk_id_padded = chunk_id.substr(0, width - 15) + "..."
			
			visualization += "  / |  " + chunk_id_padded + "  |\n"
			
			// Chunk properties
			var stream_text = "Stream: " + chunk_data.parent_stream
			var size_text = "Size: " + str(chunk_data.size)
			var created_text = "Created: " + _format_timestamp(chunk_data.created_at)
			
			visualization += " /__|" + "_" * (width - 8) + "|\n"
			visualization += "|   |" + " " * (width - 8) + "|\n"
			visualization += "|   |  " + stream_text + " " * (width - 12 - stream_text.length()) + "|\n"
			visualization += "|   |  " + size_text + " " * (width - 12 - size_text.length()) + "|\n"
			visualization += "|   |  " + created_text + " " * (width - 12 - created_text.length()) + "|\n"
			
			// Content preview
			if chunk_data.has("content") and chunk_data.content.length() > 0:
				var content = chunk_data.content
				if content.length() > width - 15:
					content = content.substr(0, width - 18) + "..."
				visualization += "|   |  " + content + " " * (width - 12 - content.length()) + "|\n"
			else:
				visualization += "|   |" + " " * (width - 8) + "|\n"
			
			visualization += "|___|" + "_" * (width - 8) + "|[/color]\n"
			
			// Show dimensions based on dimension count
			if dimension >= 4:
				var dimension_text = "Dimensions: " + str(dimension) + "D"
				visualization += "\n[color=#ffaaaa]" + dimension_text + "[/color]\n"
				
				for d in range(4, dimension + 1):
					visualization += "  Dimension " + str(d) + ": " + _get_dimension_property(d) + "\n"
			
			// Display properties
			if chunk_data.has("properties"):
				visualization += "\n[color=#aaffaa]Properties:[/color]\n"
				for prop in chunk_data.properties:
					visualization += "  " + prop + ": " + str(chunk_data.properties[prop]) + "\n"
	
	return visualization

func _get_dimension_property(dimension: int) -> String:
	match dimension:
		4:
			return "Time"
		5:
			return "Consciousness"
		6:
			return "Soul"
		7:
			return "Creation"
		8:
			return "Harmony"
		9:
			return "Unity"
		10:
			return "Infinite"
		11:
			return "Transcendence"
		12:
			return "Divine"
		_:
			return "Unknown"

func _format_timestamp(timestamp) -> String:
	var datetime = Time.get_datetime_dict_from_unix_time(timestamp)
	return "%04d-%02d-%02d %02d:%02d:%02d" % [
		datetime.year,
		datetime.month,
		datetime.day,
		datetime.hour,
		datetime.minute,
		datetime.second
	]

# ----- SIGNAL HANDLERS -----
func _on_data_splitter_initialized():
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Data Splitter Controller initialized")
	
	if data_splitter_controller:
		current_dimension = data_splitter_controller.current_dimension
		current_reality = data_splitter_controller.current_reality
		
		_send_message_to_all_terminals("Data Splitter initialized - Ready to process data in " + 
			str(current_dimension) + "D " + current_reality + " reality")

func _on_data_stream_created(stream_id, data_type, size):
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Stream created - " + stream_id)
	
	_send_message_to_all_terminals("[color=#aaaaff]New data stream created: " + stream_id + 
		" (Type: " + data_type + ", Size: " + str(size) + ")[/color]")

func _on_data_chunk_created(chunk_id, content, parent_stream):
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Chunk created - " + chunk_id)
	
	_send_message_to_all_terminals("[color=#ffaaaa]New data chunk created: " + chunk_id + 
		" in stream " + parent_stream + "[/color]")

func _on_data_split_created(split_id, original_chunk, resulting_chunks):
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Split created - " + split_id)
	
	_send_message_to_all_terminals("[color=#aaffaa]Data split performed: " + original_chunk + 
		" split into " + str(resulting_chunks.size()) + " chunks[/color]")

func _on_data_merged(merge_id, source_chunks, result_chunk):
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Merge performed - " + merge_id)
	
	_send_message_to_all_terminals("[color=#ffaaff]Data merge performed: " + 
		str(source_chunks.size()) + " chunks merged into " + result_chunk + "[/color]")

func _on_dimension_changed(new_dimension, old_dimension = 0):
	current_dimension = new_dimension
	
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Dimension changed to " + str(new_dimension) + "D")
	
	_send_message_to_all_terminals("[color=#88ffff]Dimension changed to " + str(new_dimension) + "D[/color]")
	
	emit_signal("dimension_changed", new_dimension)

func _on_reality_changed(new_reality, old_reality):
	current_reality = new_reality
	
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Reality changed to " + new_reality)
	
	_send_message_to_all_terminals("[color=#ffff88]Reality changed to " + new_reality + "[/color]")
	
	emit_signal("reality_changed", new_reality)

func _on_terminal_connected(details):
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Terminal connected")
	
	_send_message_to_all_terminals("[color=#88ff99]Terminal connected to Data Splitter[/color]")

func _on_color_shift_detected(from_color, to_color, temperature):
	if enable_debug_logs:
		print("DataSplitterTerminalBridge: Color shift detected")
	
	_send_message_to_all_terminals("[color=#" + to_color.to_html() + "]Color shift detected - Temperature: " + 
		str(temperature) + "[/color]")

# ----- PUBLIC API -----
func send_message_to_terminal(terminal_id: int, message: String) -> bool:
	if terminal_id < 0 or terminal_id >= 6:
		return false
	
	_send_message_to_terminal(terminal_id, message)
	return true

func _send_message_to_all_terminals(message: String):
	for terminal_id in active_terminal_windows:
		_send_message_to_terminal(terminal_id, message)

func process_direct_command(command: String) -> Dictionary:
	if command.begins_with("/"):
		return _process_command(command, current_terminal_id)
	else:
		# Not a command
		return {
			"success": false,
			"message": "Not a valid command. Commands should start with /"
		}

func create_data_stream(stream_id: String, data_type: String = "binary", size: int = 16) -> Dictionary:
	if not data_splitter_controller:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}
	
	var result = data_splitter_controller.create_data_stream(stream_id, data_type, size)
	return result

func split_data_chunk(chunk_id: String, split_factor: int = 3) -> Dictionary:
	if not data_splitter_controller:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}
	
	var result = data_splitter_controller.split_data_chunk(chunk_id, split_factor)
	return result

func merge_data_chunks(chunk_ids: Array, merge_type: String = "concatenate") -> Dictionary:
	if not data_splitter_controller:
		return {
			"success": false,
			"message": "Data Splitter Controller not available"
		}
	
	var result = data_splitter_controller.merge_data_chunks(chunk_ids, merge_type)
	return result

func get_current_dimension() -> int:
	return current_dimension

func get_current_reality() -> String:
	return current_reality

func set_current_terminal(terminal_id: int) -> bool:
	if terminal_id >= 0 and terminal_id < 6:
		current_terminal_id = terminal_id
		return true
	return false

func is_terminal_bridge_active() -> bool:
	return bridge_active

func start_bridge():
	bridge_active = true
	print("DataSplitterTerminalBridge: Bridge started")

func stop_bridge():
	bridge_active = false
	print("DataSplitterTerminalBridge: Bridge stopped")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/data_splitter_terminal_bridge.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/data_splitter_terminal_visualizer.gd
# SIZE: 22740 bytes
extends Node

class_name DataSplitterTerminalVisualizer

# ----- CONFIGURATION -----
@export var max_terminal_width: int = 80
@export var enable_colors: bool = true
@export var enable_ascii_art: bool = true
@export var enable_animations: bool = false
@export var detail_level: int = 2  # 1 = basic, 2 = normal, 3 = detailed

# ----- COLOR DEFINITIONS -----
const COLOR_RESET = "[/color]"
const COLOR_STREAM = "[color=#aaaaff]"  # Blue
const COLOR_CHUNK = "[color=#ffaaaa]"   # Red
const COLOR_SPLIT = "[color=#aaffaa]"   # Green
const COLOR_MERGE = "[color=#ffaaff]"   # Purple
const COLOR_SUCCESS = "[color=#88ff99]" # Light Green
const COLOR_ERROR = "[color=#ff7777]"   # Light Red
const COLOR_HEADER = "[color=#ffff88]"  # Yellow
const COLOR_DIMENSION = "[color=#88ffff]" # Cyan

# ----- ASCII TEMPLATES -----
# 3D Box template for stream/chunk visualization
const BOX_TEMPLATE_3D = [
    "    {top_line}",
    "   /|{top_content}|",
    "  / |{title_line}|",
    " /__|{mid_line}|",
    "|   |{content1}|",
    "|   |{content2}|",
    "|   |{content3}|",
    "|   |{content4}|",
    "|___|{bottom_line}|"
]

# 2D Box template for stream/chunk visualization
const BOX_TEMPLATE_2D = [
    "+{top_line}+",
    "|{title_line}|",
    "|{content1}|",
    "|{content2}|",
    "|{content3}|",
    "+{bottom_line}+"
]

# 1D Line template for stream/chunk visualization
const LINE_TEMPLATE_1D = "|{left_content}{title}{right_content}|"

# Tree template for connections
const TREE_TEMPLATE = [
    "    |",
    "{branches}"
]

# ----- INSTANCE VARIABLES -----
var current_dimension: int = 3
var current_reality: String = "Digital"

# ----- INITIALIZATION -----
func _ready():
    pass

# ----- PUBLIC VISUALIZATION METHODS -----
# Generate visualization for a data stream
func visualize_stream(stream_data: Dictionary, dimension: int = 3) -> String:
    match dimension:
        1:
            return _visualize_stream_1d(stream_data)
        2:
            return _visualize_stream_2d(stream_data)
        _:
            return _visualize_stream_3d(stream_data, dimension)

# Generate visualization for a data chunk
func visualize_chunk(chunk_data: Dictionary, dimension: int = 3) -> String:
    match dimension:
        1:
            return _visualize_chunk_1d(chunk_data)
        2:
            return _visualize_chunk_2d(chunk_data)
        _:
            return _visualize_chunk_3d(chunk_data, dimension)

# Generate visualization for a data split operation
func visualize_split(split_data: Dictionary) -> String:
    return _generate_split_visualization(split_data)

# Generate visualization for a data merge operation
func visualize_merge(merge_data: Dictionary) -> String:
    return _generate_merge_visualization(merge_data)

# Generate list visualization for streams
func visualize_stream_list(streams: Array) -> String:
    var result = COLOR_HEADER + "Streams (" + str(streams.size()) + "):" + COLOR_RESET + "\n"
    
    for stream in streams:
        result += "- " + stream.id + " (" + stream.type + ", " + str(stream.size) + " bytes, " + 
                 str(stream.chunks.size()) + " chunks)\n"
    
    return result

# Generate list visualization for chunks
func visualize_chunk_list(chunks: Dictionary) -> String:
    var result = COLOR_HEADER + "Chunks (" + str(chunks.size()) + "):" + COLOR_RESET + "\n"
    
    var count = 0
    for chunk_id in chunks:
        result += "- " + chunk_id + " (size: " + str(chunks[chunk_id].size) + ")\n"
        count += 1
        if count >= 10 and chunks.size() > 10:
            result += "  ... and " + str(chunks.size() - 10) + " more\n"
            break
    
    return result

# Generate list visualization for splits
func visualize_split_list(splits: Dictionary) -> String:
    var result = COLOR_HEADER + "Splits (" + str(splits.size()) + "):" + COLOR_RESET + "\n"
    
    var count = 0
    for split_id in splits:
        result += "- " + split_id + " (factor: " + str(splits[split_id].factor) + ")\n"
        count += 1
        if count >= 5 and splits.size() > 5:
            result += "  ... and " + str(splits.size() - 5) + " more\n"
            break
    
    return result

# Generate text analysis visualization
func visualize_text_analysis(text: String) -> String:
    # Basic analysis
    var analysis = {
        "total_chars": text.length(),
        "word_count": text.split(" ", false).size(),
        "line_count": text.split("\n", false).size(),
        "special_chars": {}
    }
    
    # Count special characters
    var special_chars = ["[", "]", "=", "|", "#", "@", "$", "%", "^", "&", "*"]
    for char in special_chars:
        var count = text.count(char)
        if count > 0:
            analysis.special_chars[char] = count
    
    # Check for natural split points
    var natural_splits = []
    if text.find("[") >= 0 and text.find("]") >= 0:
        natural_splits.append("brackets")
    if text.find("=") >= 0:
        natural_splits.append("equals")
    if text.find("|") >= 0:
        natural_splits.append("pipes")
    if text.find(",") >= 0:
        natural_splits.append("commas")
    
    analysis["natural_splits"] = natural_splits
    
    # Generate visualization
    var result = COLOR_SUCCESS + "Text Analysis:" + COLOR_RESET + "\n"
    result += "Characters: " + str(analysis.total_chars) + "\n"
    result += "Words: " + str(analysis.word_count) + "\n"
    result += "Lines: " + str(analysis.line_count) + "\n"
    
    if analysis.special_chars.size() > 0:
        result += "\n" + COLOR_STREAM + "Special Characters:" + COLOR_RESET + "\n"
        for char in analysis.special_chars:
            result += "- '" + char + "': " + str(analysis.special_chars[char]) + "\n"
    
    if natural_splits.size() > 0:
        result += "\n" + COLOR_SPLIT + "Suggested Split Methods:" + COLOR_RESET + "\n"
        for split in natural_splits:
            result += "- " + split + "\n"
    
    return result

# Generate help text visualization
func visualize_help() -> String:
    var help_text = COLOR_SUCCESS + "Data Splitter Terminal Bridge Commands:" + COLOR_RESET + "\n"
    help_text += "/split [chunk_id] [split_factor] - Split a data chunk\n"
    help_text += "/stream [stream_id] [data_type] [size] - Create a new data stream\n"
    help_text += "/chunk [chunk_id] [parent_stream] [content] - Create a new data chunk\n"
    help_text += "/merge [chunk_id1,chunk_id2,...] [merge_type] - Merge multiple chunks\n"
    help_text += "/list [streams|chunks|splits|all] - List data elements\n"
    help_text += "/analyze [text] - Analyze text for data splitting\n"
    help_text += "/visualize [chunk_id|stream_id] [dimension] - Visualize data in terminal\n"
    help_text += "/help - Display this help\n"
    
    return help_text

# ----- PRIVATE VISUALIZATION METHODS -----
# 1D Stream Visualization
func _visualize_stream_1d(stream_data: Dictionary) -> String:
    var stream_id = stream_data.id
    var line_length = max_terminal_width - 10  # Leave some margin
    
    # Calculate content length
    var total_length = line_length - stream_id.length()
    var left_content = "=" * (total_length / 2)
    var right_content = "=" * (total_length - left_content.length())
    
    var visualization = COLOR_STREAM
    visualization += LINE_TEMPLATE_1D.format({
        "left_content": left_content,
        "title": stream_id,
        "right_content": right_content
    })
    visualization += COLOR_RESET + "\n"
    
    # Add chunk information if present
    if stream_data.has("chunks") and stream_data.chunks.size() > 0:
        visualization += "-" * 40 + "\n"
        visualization += "Chunks: "
        
        for i in range(stream_data.chunks.size()):
            if i > 0:
                visualization += " - "
            visualization += stream_data.chunks[i]
    
    return visualization

# 2D Stream Visualization
func _visualize_stream_2d(stream_data: Dictionary) -> String:
    var stream_id = stream_data.id
    var width = min(max_terminal_width - 10, stream_data.size + 10)
    var top_bottom = "-" * (width - 2)
    
    # Calculate paddings for centered text
    var id_padding = " " * ((width - 2 - stream_id.length()) / 2)
    var id_extra = " " if (width - 2 - stream_id.length()) % 2 != 0 else ""
    
    var type_text = "Type: " + stream_data.type
    var type_padding = " " * ((width - 2 - type_text.length()) / 2)
    var type_extra = " " if (width - 2 - type_text.length()) % 2 != 0 else ""
    
    var size_text = "Size: " + str(stream_data.size)
    var size_padding = " " * ((width - 2 - size_text.length()) / 2)
    var size_extra = " " if (width - 2 - size_text.length()) % 2 != 0 else ""
    
    var chunk_text = "Chunks: " + str(stream_data.chunks.size())
    var chunk_padding = " " * ((width - 2 - chunk_text.length()) / 2)
    var chunk_extra = " " if (width - 2 - chunk_text.length()) % 2 != 0 else ""
    
    var visualization = COLOR_STREAM
    visualization += BOX_TEMPLATE_2D[0].format({"top_line": top_bottom}) + "\n"
    visualization += BOX_TEMPLATE_2D[1].format({"title_line": id_padding + stream_id + id_padding + id_extra}) + "\n"
    visualization += BOX_TEMPLATE_2D[2].format({"content1": type_padding + type_text + type_padding + type_extra}) + "\n"
    visualization += BOX_TEMPLATE_2D[3].format({"content2": size_padding + size_text + size_padding + size_extra}) + "\n"
    visualization += BOX_TEMPLATE_2D[4].format({"content3": chunk_padding + chunk_text + chunk_padding + chunk_extra}) + "\n"
    visualization += BOX_TEMPLATE_2D[5].format({"bottom_line": top_bottom}) + "\n"
    visualization += COLOR_RESET
    
    # Add chunk information if present
    if stream_data.has("chunks") and stream_data.chunks.size() > 0:
        visualization += "\nChunks:\n"
        for chunk_id in stream_data.chunks:
            visualization += "- " + chunk_id + "\n"
    
    return visualization

# 3D Stream Visualization
func _visualize_stream_3d(stream_data: Dictionary, dimension: int) -> String:
    var stream_id = stream_data.id
    var width = min(max_terminal_width - 15, stream_data.size + 20)
    
    # Create line templates
    var top_line = "_" * (width - 8)
    var mid_line = "_" * (width - 8)
    var bottom_line = "_" * (width - 8)
    
    # Prepare content lines
    var top_content = " " * (width - 8)
    
    # Stream ID line with padding
    var stream_id_padded = stream_id
    if stream_id.length() < width - 12:
        var padding = (width - 12 - stream_id.length()) / 2
        stream_id_padded = " " * padding + stream_id + " " * padding
    else:
        stream_id_padded = stream_id.substr(0, width - 15) + "..."
    var title_line = "  " + stream_id_padded + "  "
    
    # Stream properties
    var type_text = "  Type: " + stream_data.type
    var size_text = "  Size: " + str(stream_data.size)
    var chunk_text = "  Chunks: " + str(stream_data.chunks.size())
    
    # Pad properties to fit width
    type_text += " " * (width - 8 - type_text.length())
    size_text += " " * (width - 8 - size_text.length())
    chunk_text += " " * (width - 8 - chunk_text.length())
    
    var content4 = " " * (width - 8)
    
    # Create visualization
    var visualization = COLOR_STREAM
    visualization += BOX_TEMPLATE_3D[0].format({"top_line": top_line}) + "\n"
    visualization += BOX_TEMPLATE_3D[1].format({"top_content": top_content}) + "\n"
    visualization += BOX_TEMPLATE_3D[2].format({"title_line": title_line}) + "\n"
    visualization += BOX_TEMPLATE_3D[3].format({"mid_line": mid_line}) + "\n"
    visualization += BOX_TEMPLATE_3D[4].format({"content1": top_content}) + "\n"
    visualization += BOX_TEMPLATE_3D[5].format({"content2": type_text}) + "\n"
    visualization += BOX_TEMPLATE_3D[6].format({"content3": size_text}) + "\n"
    visualization += BOX_TEMPLATE_3D[7].format({"content4": chunk_text}) + "\n"
    visualization += BOX_TEMPLATE_3D[8].format({"bottom_line": bottom_line}) + "\n"
    visualization += COLOR_RESET
    
    # Show dimensions based on dimension count
    if dimension >= 4:
        visualization += "\n" + COLOR_DIMENSION + "Dimensions: " + str(dimension) + "D" + COLOR_RESET + "\n"
        
        for d in range(4, dimension + 1):
            visualization += "  Dimension " + str(d) + ": " + _get_dimension_property(d) + "\n"
    
    # If chunks exist, list them with ASCII connection
    if stream_data.has("chunks") and stream_data.chunks.size() > 0:
        visualization += "\n" + COLOR_SPLIT + "Connected Chunks:" + COLOR_RESET + "\n"
        visualization += "    |\n"
        
        var branches = ""
        for i in range(stream_data.chunks.size()):
            if i < stream_data.chunks.size() - 1:
                branches += "    ‚îú‚îÄ‚îÄ‚îÄ " + stream_data.chunks[i] + "\n"
            else:
                branches += "    ‚îî‚îÄ‚îÄ‚îÄ " + stream_data.chunks[i] + "\n"
        
        visualization += branches
    
    return visualization

# 1D Chunk Visualization
func _visualize_chunk_1d(chunk_data: Dictionary) -> String:
    var chunk_id = chunk_data.id
    var line_length = max_terminal_width - 10  # Leave some margin
    
    # Calculate content length
    var total_length = line_length - chunk_id.length()
    var left_content = "[" + "-" * ((total_length / 2) - 1)
    var right_content = "-" * ((total_length / 2) - 1) + "]"
    
    var visualization = COLOR_CHUNK
    visualization += left_content + chunk_id + right_content
    visualization += COLOR_RESET + "\n"
    
    # Add content preview if present
    if chunk_data.has("content") and chunk_data.content.length() > 0:
        var content = chunk_data.content
        if content.length() > 40:
            content = content.substr(0, 37) + "..."
        visualization += "Content: " + content
    
    return visualization

# 2D Chunk Visualization
func _visualize_chunk_2d(chunk_data: Dictionary) -> String:
    var chunk_id = chunk_data.id
    var width = min(max_terminal_width - 10, chunk_data.size + 10)
    var top_bottom = "-" * (width - 2)
    
    # Calculate paddings for centered text
    var id_padding = " " * ((width - 2 - chunk_id.length()) / 2)
    var id_extra = " " if (width - 2 - chunk_id.length()) % 2 != 0 else ""
    
    var stream_text = "Stream: " + chunk_data.parent_stream
    var stream_padding = " " * ((width - 2 - stream_text.length()) / 2)
    var stream_extra = " " if (width - 2 - stream_text.length()) % 2 != 0 else ""
    
    var size_text = "Size: " + str(chunk_data.size)
    var size_padding = " " * ((width - 2 - size_text.length()) / 2)
    var size_extra = " " if (width - 2 - size_text.length()) % 2 != 0 else ""
    
    var visualization = COLOR_CHUNK
    visualization += BOX_TEMPLATE_2D[0].format({"top_line": top_bottom}) + "\n"
    visualization += BOX_TEMPLATE_2D[1].format({"title_line": id_padding + chunk_id + id_padding + id_extra}) + "\n"
    visualization += BOX_TEMPLATE_2D[2].format({"content1": stream_padding + stream_text + stream_padding + stream_extra}) + "\n"
    visualization += BOX_TEMPLATE_2D[3].format({"content2": size_padding + size_text + size_padding + size_extra}) + "\n"
    
    # Content preview
    var content_line = ""
    if chunk_data.has("content") and chunk_data.content.length() > 0:
        var content = chunk_data.content
        if content.length() > width - 12:
            content = content.substr(0, width - 15) + "..."
        var content_padding = " " * ((width - 2 - content.length()) / 2)
        var content_extra = " " if (width - 2 - content.length()) % 2 != 0 else ""
        content_line = content_padding + content + content_padding + content_extra
    else:
        content_line = " " * (width - 2)
    
    visualization += BOX_TEMPLATE_2D[4].format({"content3": content_line}) + "\n"
    visualization += BOX_TEMPLATE_2D[5].format({"bottom_line": top_bottom}) + "\n"
    visualization += COLOR_RESET
    
    return visualization

# 3D Chunk Visualization
func _visualize_chunk_3d(chunk_data: Dictionary, dimension: int) -> String:
    var chunk_id = chunk_data.id
    var width = min(max_terminal_width - 15, chunk_data.size + 20)
    
    # Create line templates
    var top_line = "_" * (width - 8)
    var mid_line = "_" * (width - 8)
    var bottom_line = "_" * (width - 8)
    
    # Prepare content lines
    var top_content = " " * (width - 8)
    
    # Chunk ID line with padding
    var chunk_id_padded = chunk_id
    if chunk_id.length() < width - 12:
        var padding = (width - 12 - chunk_id.length()) / 2
        chunk_id_padded = " " * padding + chunk_id + " " * padding
    else:
        chunk_id_padded = chunk_id.substr(0, width - 15) + "..."
    var title_line = "  " + chunk_id_padded + "  "
    
    # Chunk properties
    var stream_text = "  Stream: " + chunk_data.parent_stream
    var size_text = "  Size: " + str(chunk_data.size)
    var created_text = "  Created: " + _format_timestamp(chunk_data.created_at)
    
    # Pad properties to fit width
    stream_text += " " * (width - 8 - stream_text.length())
    size_text += " " * (width - 8 - size_text.length())
    created_text += " " * (width - 8 - created_text.length())
    
    # Content preview
    var content_line = ""
    if chunk_data.has("content") and chunk_data.content.length() > 0:
        var content = chunk_data.content
        if content.length() > width - 12:
            content = content.substr(0, width - 15) + "..."
        content_line = "  " + content
        content_line += " " * (width - 8 - content_line.length())
    else:
        content_line = " " * (width - 8)
    
    # Create visualization
    var visualization = COLOR_CHUNK
    visualization += BOX_TEMPLATE_3D[0].format({"top_line": top_line}) + "\n"
    visualization += BOX_TEMPLATE_3D[1].format({"top_content": top_content}) + "\n"
    visualization += BOX_TEMPLATE_3D[2].format({"title_line": title_line}) + "\n"
    visualization += BOX_TEMPLATE_3D[3].format({"mid_line": mid_line}) + "\n"
    visualization += BOX_TEMPLATE_3D[4].format({"content1": top_content}) + "\n"
    visualization += BOX_TEMPLATE_3D[5].format({"content2": stream_text}) + "\n"
    visualization += BOX_TEMPLATE_3D[6].format({"content3": size_text}) + "\n"
    visualization += BOX_TEMPLATE_3D[7].format({"content4": created_text}) + "\n"
    visualization += BOX_TEMPLATE_3D[8].format({"bottom_line": bottom_line}) + "\n"
    visualization += COLOR_RESET
    
    # Show dimensions based on dimension count
    if dimension >= 4:
        visualization += "\n" + COLOR_DIMENSION + "Dimensions: " + str(dimension) + "D" + COLOR_RESET + "\n"
        
        for d in range(4, dimension + 1):
            visualization += "  Dimension " + str(d) + ": " + _get_dimension_property(d) + "\n"
    
    # Display properties if available
    if chunk_data.has("properties"):
        visualization += "\n" + COLOR_SPLIT + "Properties:" + COLOR_RESET + "\n"
        for prop in chunk_data.properties:
            visualization += "  " + prop + ": " + str(chunk_data.properties[prop]) + "\n"
    
    return visualization

# Generate split visualization
func _generate_split_visualization(split_data: Dictionary) -> String:
    var original_chunk = split_data.original_chunk
    var resulting_chunks = split_data.resulting_chunks
    var factor = split_data.factor
    
    var visualization = COLOR_SUCCESS + "Split Operation:" + COLOR_RESET + "\n"
    visualization += "Original Chunk: " + original_chunk + "\n"
    visualization += "Split Factor: " + str(factor) + "\n\n"
    
    # Generate ASCII art visualization
    visualization += COLOR_CHUNK + original_chunk + COLOR_RESET + "\n"
    visualization += "    |\n"
    visualization += "    ‚ñº\n"
    
    # Add arrows for each resulting chunk
    for i in range(resulting_chunks.size()):
        var spaces = " " * (4 + (i * 4))
        visualization += spaces + "‚Üì\n"
        visualization += spaces + COLOR_CHUNK + resulting_chunks[i] + COLOR_RESET + "\n"
    
    return visualization

# Generate merge visualization
func _generate_merge_visualization(merge_data: Dictionary) -> String:
    var source_chunks = merge_data.source_chunks
    var result_chunk = merge_data.result_chunk
    var merge_type = merge_data.merge_type
    
    var visualization = COLOR_SUCCESS + "Merge Operation:" + COLOR_RESET + "\n"
    visualization += "Merge Type: " + merge_type + "\n\n"
    
    # Generate ASCII art for source chunks
    for i in range(source_chunks.size()):
        var spaces = " " * (4 + (i * 4))
        visualization += spaces + COLOR_CHUNK + source_chunks[i] + COLOR_RESET + "\n"
        visualization += spaces + "‚Üì\n"
    
    // Add converging arrows
    var arrow_width = 4 + ((source_chunks.size() - 1) * 4)
    var arrows = ""
    for i in range(arrow_width):
        if i % 4 == 0:
            arrows += "‚Üì"
        else:
            arrows += " "
    visualization += arrows + "\n"
    
    // Center result chunk
    var center_space = " " * (arrow_width / 2)
    visualization += center_space + COLOR_CHUNK + result_chunk + COLOR_RESET + "\n"
    
    return visualization

# Get textual description for higher dimensions
func _get_dimension_property(dimension: int) -> String:
    match dimension:
        4:
            return "Time"
        5:
            return "Consciousness"
        6:
            return "Soul"
        7:
            return "Creation"
        8:
            return "Harmony"
        9:
            return "Unity"
        10:
            return "Infinite"
        11:
            return "Transcendence"
        12:
            return "Divine"
        _:
            return "Unknown"

# Format timestamp to human-readable date string
func _format_timestamp(timestamp) -> String:
    var datetime = Time.get_datetime_dict_from_unix_time(timestamp)
    return "%04d-%02d-%02d %02d:%02d:%02d" % [
        datetime.year,
        datetime.month,
        datetime.day,
        datetime.hour,
        datetime.minute,
        datetime.second
    ]

# ----- PUBLIC UTILITY METHODS -----
# Set current dimension for visualizations
func set_dimension(dimension: int) -> void:
    current_dimension = dimension

# Set current reality for visualizations
func set_reality(reality: String) -> void:
    current_reality = reality

# Set visualization configuration
func configure(config: Dictionary) -> void:
    if config.has("max_terminal_width"):
        max_terminal_width = config.max_terminal_width
    
    if config.has("enable_colors"):
        enable_colors = config.enable_colors
    
    if config.has("enable_ascii_art"):
        enable_ascii_art = config.enable_ascii_art
    
    if config.has("enable_animations"):
        enable_animations = config.enable_animations
    
    if config.has("detail_level"):
        detail_level = config.detail_level
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/data_splitter_terminal_visualizer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/digital_excavator.gd
# SIZE: 22151 bytes
extends Node

class_name DigitalExcavator

# Digital excavation configuration
const EXCAVATION_CONFIG = {
	"modes": {
		"surface": {
			"depth": 1,
			"energy_usage": 0.2,
			"stability_impact": 0.05,
			"discovery_rate": 0.4,
			"max_duration_minutes": 60
		},
		"intermediate": {
			"depth": 3,
			"energy_usage": 0.5,
			"stability_impact": 0.15,
			"discovery_rate": 0.6,
			"max_duration_minutes": 180
		},
		"deep": {
			"depth": 5,
			"energy_usage": 0.8,
			"stability_impact": 0.3,
			"discovery_rate": 0.8,
			"max_duration_minutes": 360
		},
		"quantum": {
			"depth": 7,
			"energy_usage": 1.0,
			"stability_impact": 0.5,
			"discovery_rate": 0.9,
			"max_duration_minutes": 720
		}
	},
	"algorithms": {
		"standard_hash": {
			"complexity": "low",
			"power_efficiency": 0.7,
			"reward_factor": 0.5,
			"stability_coefficient": 0.8
		},
		"advanced_hash": {
			"complexity": "medium",
			"power_efficiency": 0.5,
			"reward_factor": 0.8,
			"stability_coefficient": 0.6
		},
		"neural_hash": {
			"complexity": "high",
			"power_efficiency": 0.3,
			"reward_factor": 1.2,
			"stability_coefficient": 0.4
		},
		"quantum_hash": {
			"complexity": "extreme",
			"power_efficiency": 0.2,
			"reward_factor": 1.8,
			"stability_coefficient": 0.2
		}
	},
	"targets": {
		"numerical": {
			"type": "standard",
			"value_multiplier": 1.0,
			"difficulty": 0.5,
			"description": "Standard numerical sequences with verification"
		},
		"cryptographic": {
			"type": "advanced",
			"value_multiplier": 1.5,
			"difficulty": 0.7,
			"description": "Cryptographic puzzles with higher complexity"
		},
		"multidimensional": {
			"type": "complex",
			"value_multiplier": 2.0,
			"difficulty": 0.8,
			"description": "Multi-layered puzzles spanning dimensional barriers"
		},
		"reality": {
			"type": "quantum",
			"value_multiplier": 3.0,
			"difficulty": 0.95,
			"description": "Reality fragments with quantum uncertainty properties"
		}
	}
}

# Digital resources configuration
const RESOURCE_CONFIG = {
	"data_fragments": {
		"rarity": "common",
		"value": 1,
		"stability": 0.9,
		"description": "Basic data units found in digital excavation"
	},
	"code_crystals": {
		"rarity": "uncommon",
		"value": 5,
		"stability": 0.8,
		"description": "Crystallized code structures with algorithmic properties"
	},
	"pattern_matrices": {
		"rarity": "rare",
		"value": 20,
		"stability": 0.7,
		"description": "Matrix structures containing complex pattern information"
	},
	"reality_shards": {
		"rarity": "very_rare",
		"value": 100,
		"stability": 0.5,
		"description": "Fragments of digital reality with transformative properties"
	},
	"quantum_keys": {
		"rarity": "legendary",
		"value": 500,
		"stability": 0.3,
		"description": "Keys to fundamental quantum states of digital existence"
	}
}

# Excavation status
var excavation_status = {
	"active": false,
	"current_mode": "surface",
	"current_algorithm": "standard_hash",
	"current_target": "numerical",
	"current_depth": 0,
	"energy_consumption": 0.0,
	"stability_level": 1.0,
	"duration_minutes": 0,
	"last_start_time": 0,
	"progress": 0.0
}

# Resource inventory
var resource_inventory = {
	"data_fragments": 0,
	"code_crystals": 0,
	"pattern_matrices": 0,
	"reality_shards": 0,
	"quantum_keys": 0,
	"total_value": 0
}

# Discovery log
var discovery_log = []

# Excavation metrics
var metrics = {
	"total_excavation_time_minutes": 0,
	"total_energy_consumed": 0.0,
	"total_discoveries": 0,
	"total_value_discovered": 0,
	"stability_incidents": 0,
	"longest_excavation_minutes": 0
}

# Reality processor integration
var reality_processor = null
var current_turn = 1

# System timer and processor
var excavation_timer = null
var update_interval_seconds = 1.0

# Signals
signal excavation_started(config)
signal excavation_stopped(results)
signal resource_discovered(resource_type, amount, value)
signal stability_changed(old_level, new_level)
signal depth_reached(depth)
signal excavation_completed(summary)
signal error_occurred(error_info)

func _ready():
	# Initialize the excavator
	initialize_excavator()
	
	# Setup timer
	setup_timer()

func initialize_excavator():
	print("Initializing Digital Excavator...")
	
	# Connect to reality processor if available
	connect_to_reality_processor()
	
	# Load current turn
	load_current_turn()
	
	# Create storage directory
	create_storage_directory()
	
	print("Digital Excavator initialized")

func setup_timer():
	excavation_timer = Timer.new()
	add_child(excavation_timer)
	excavation_timer.wait_time = update_interval_seconds
	excavation_timer.connect("timeout", self, "_on_excavation_update")
	excavation_timer.set_paused(true)

func connect_to_reality_processor():
	# Try to find Reality Processor
	if ClassDB.class_exists("RealityDataProcessor"):
		reality_processor = RealityDataProcessor.new()
		add_child(reality_processor)
		print("Connected to Reality Data Processor")

func load_current_turn():
	var file = File.new()
	var turn_file = "/mnt/c/Users/Percision 15/12_turns_system/current_turn.txt"
	
	if file.file_exists(turn_file) and file.open(turn_file, File.READ) == OK:
		var content = file.get_as_text()
		file.close()
		
		var turn = int(content)
		if turn >= 1 and turn <= 12:
			current_turn = turn
	else:
		current_turn = 1

func create_storage_directory():
	var dir = Directory.new()
	var path = "/mnt/c/Users/Percision 15/12_turns_system/excavation_data"
	
	if not dir.dir_exists(path):
		var result = dir.make_dir_recursive(path)
		if result == OK:
			print("Created excavation data directory: " + path)
		else:
			push_error("Failed to create excavation data directory")

# Public API methods

# Start digital excavation
func start_excavation(mode = "surface", algorithm = "standard_hash", target = "numerical"):
	# Validate parameters
	if not EXCAVATION_CONFIG.modes.has(mode):
		push_error("Invalid excavation mode: " + mode)
		return false
	
	if not EXCAVATION_CONFIG.algorithms.has(algorithm):
		push_error("Invalid excavation algorithm: " + algorithm)
		return false
	
	if not EXCAVATION_CONFIG.targets.has(target):
		push_error("Invalid excavation target: " + target)
		return false
	
	# Check turn requirement
	var depth = EXCAVATION_CONFIG.modes[mode].depth
	if depth > current_turn:
		push_error("Excavation depth " + str(depth) + " exceeds current turn " + str(current_turn))
		emit_signal("error_occurred", {
			"type": "depth_restriction",
			"message": "Excavation depth exceeds current turn",
			"required_turn": depth,
			"current_turn": current_turn
		})
		return false
	
	# Check if excavation is already active
	if excavation_status.active:
		push_error("Excavation already active")
		return false
	
	# Configure excavation
	excavation_status.active = true
	excavation_status.current_mode = mode
	excavation_status.current_algorithm = algorithm
	excavation_status.current_target = target
	excavation_status.current_depth = EXCAVATION_CONFIG.modes[mode].depth
	excavation_status.energy_consumption = 0.0
	excavation_status.stability_level = 1.0
	excavation_status.duration_minutes = 0
	excavation_status.last_start_time = OS.get_unix_time()
	excavation_status.progress = 0.0
	
	# Start the timer
	excavation_timer.set_paused(false)
	
	# Emit signal
	emit_signal("excavation_started", {
		"mode": mode,
		"algorithm": algorithm,
		"target": target,
		"depth": EXCAVATION_CONFIG.modes[mode].depth,
		"start_time": excavation_status.last_start_time
	})
	
	print("Digital excavation started - Mode: " + mode + ", Algorithm: " + algorithm + ", Target: " + target)
	return true

# Stop digital excavation
func stop_excavation(reason = "user"):
	# Check if excavation is active
	if not excavation_status.active:
		return false
	
	# Stop the timer
	excavation_timer.set_paused(true)
	
	# Calculate duration
	var end_time = OS.get_unix_time()
	var duration_seconds = end_time - excavation_status.last_start_time
	excavation_status.duration_minutes = duration_seconds / 60.0
	
	# Update metrics
	metrics.total_excavation_time_minutes += excavation_status.duration_minutes
	metrics.total_energy_consumed += excavation_status.energy_consumption
	metrics.longest_excavation_minutes = max(metrics.longest_excavation_minutes, excavation_status.duration_minutes)
	
	# Prepare results
	var results = {
		"mode": excavation_status.current_mode,
		"algorithm": excavation_status.current_algorithm,
		"target": excavation_status.current_target,
		"depth": excavation_status.current_depth,
		"duration_minutes": excavation_status.duration_minutes,
		"energy_consumed": excavation_status.energy_consumption,
		"final_stability": excavation_status.stability_level,
		"resources_discovered": metrics.total_discoveries,
		"total_value": metrics.total_value_discovered,
		"stop_reason": reason
	}
	
	# Mark as inactive
	excavation_status.active = false
	
	# Emit signal
	emit_signal("excavation_stopped", results)
	
	# If completed (not stopped by user/error), emit completion signal
	if reason == "completed":
		emit_signal("excavation_completed", results)
	
	print("Digital excavation stopped - Reason: " + reason + ", Duration: " + 
		str(excavation_status.duration_minutes) + " minutes")
	
	return true

# Get excavation status
func get_excavation_status():
	var current_time = OS.get_unix_time()
	var current_duration = excavation_status.active ? 
		(current_time - excavation_status.last_start_time) / 60.0 : 
		excavation_status.duration_minutes
	
	return {
		"active": excavation_status.active,
		"mode": excavation_status.current_mode,
		"algorithm": excavation_status.current_algorithm,
		"target": excavation_status.current_target,
		"depth": excavation_status.current_depth,
		"duration_minutes": current_duration,
		"energy_consumption": excavation_status.energy_consumption,
		"stability_level": excavation_status.stability_level,
		"progress": excavation_status.progress,
		"estimated_completion": excavation_status.active ? 
			_estimate_completion_time() : 0
	}

# Get resource inventory
func get_resource_inventory():
	return {
		"data_fragments": resource_inventory.data_fragments,
		"code_crystals": resource_inventory.code_crystals,
		"pattern_matrices": resource_inventory.pattern_matrices,
		"reality_shards": resource_inventory.reality_shards,
		"quantum_keys": resource_inventory.quantum_keys,
		"total_value": resource_inventory.total_value
	}

# Get excavation metrics
func get_excavation_metrics():
	return {
		"total_excavation_time_minutes": metrics.total_excavation_time_minutes,
		"total_energy_consumed": metrics.total_energy_consumed,
		"total_discoveries": metrics.total_discoveries,
		"total_value_discovered": metrics.total_value_discovered,
		"stability_incidents": metrics.stability_incidents,
		"longest_excavation_minutes": metrics.longest_excavation_minutes,
		"current_turn": current_turn,
		"max_accessible_depth": current_turn
	}

# Get discovery log
func get_discovery_log(max_entries = 10):
	var entries = []
	
	var start_index = max(0, discovery_log.size() - max_entries)
	for i in range(start_index, discovery_log.size()):
		entries.append(discovery_log[i])
	
	return entries

# Process a single discovery attempt
func process_discovery_attempt():
	# Only process if excavation is active
	if not excavation_status.active:
		return null
	
	# Get current configuration
	var mode_config = EXCAVATION_CONFIG.modes[excavation_status.current_mode]
	var algo_config = EXCAVATION_CONFIG.algorithms[excavation_status.current_algorithm]
	var target_config = EXCAVATION_CONFIG.targets[excavation_status.current_target]
	
	# Calculate discovery chance
	var base_chance = mode_config.discovery_rate * algo_config.power_efficiency
	var difficulty_factor = 1.0 - target_config.difficulty
	var stability_factor = excavation_status.stability_level
	
	var discovery_chance = base_chance * difficulty_factor * stability_factor
	
	# Determine if discovery is made
	if randf() <= discovery_chance:
		# Determine which resource is discovered
		var resource_type = _determine_resource_type(
			excavation_status.current_depth,
			target_config.type
		)
		
		# Calculate amount
		var base_amount = 1 + randi() % 3
		var amount = base_amount * target_config.value_multiplier
		
		# Calculate value
		var resource_value = RESOURCE_CONFIG[resource_type].value
		var total_value = resource_value * amount
		
		# Add to inventory
		resource_inventory[resource_type] += amount
		resource_inventory.total_value += total_value
		
		# Update metrics
		metrics.total_discoveries += 1
		metrics.total_value_discovered += total_value
		
		# Add to discovery log
		var discovery = {
			"timestamp": OS.get_unix_time(),
			"resource_type": resource_type,
			"amount": amount,
			"value": total_value,
			"depth": excavation_status.current_depth,
			"stability": excavation_status.stability_level
		}
		
		discovery_log.append(discovery)
		
		# Emit signal
		emit_signal("resource_discovered", resource_type, amount, total_value)
		
		print("Resource discovered: " + str(amount) + " " + resource_type + " (Value: " + str(total_value) + ")")
		
		return discovery
	
	return null

# Store a digital artifact
func store_digital_artifact(artifact_data):
	if not excavation_status.active:
		push_error("Excavation not active")
		return false
	
	# Use Reality Processor if available
	if reality_processor:
		var dimension = _get_dimension_for_depth(excavation_status.current_depth)
		return reality_processor.store_artifact(artifact_data, dimension)
	
	# Fallback storage
	var file_path = "/mnt/c/Users/Percision 15/12_turns_system/excavation_data/artifact_" + 
		str(OS.get_unix_time()) + ".json"
	
	var file = File.new()
	if file.open(file_path, File.WRITE) == OK:
		file.store_string(JSON.print(artifact_data, "  "))
		file.close()
		return true
	else:
		push_error("Failed to store artifact")
		return false

# Use a resource to boost excavation
func use_resource(resource_type, amount = 1):
	if not RESOURCE_CONFIG.has(resource_type):
		push_error("Invalid resource type: " + resource_type)
		return false
	
	if resource_inventory[resource_type] < amount:
		push_error("Not enough resources: " + resource_type)
		return false
	
	# Apply resource effects
	var effect = _apply_resource_effect(resource_type, amount)
	
	if effect.success:
		# Subtract from inventory
		resource_inventory[resource_type] -= amount
		
		print("Used " + str(amount) + " " + resource_type + ": " + effect.description)
		return true
	
	return false

# Stabilize the excavation
func stabilize_excavation():
	if not excavation_status.active:
		push_error("Excavation not active")
		return false
	
	var old_stability = excavation_status.stability_level
	
	# Determine stabilization amount
	var base_stabilization = 0.15
	var mode_factor = 1.0 - (EXCAVATION_CONFIG.modes[excavation_status.current_mode].stability_impact * 0.5)
	var algo_factor = EXCAVATION_CONFIG.algorithms[excavation_status.current_algorithm].stability_coefficient
	
	var stabilization_amount = base_stabilization * mode_factor * algo_factor
	
	# Apply stabilization
	excavation_status.stability_level += stabilization_amount
	excavation_status.stability_level = min(excavation_status.stability_level, 1.0)
	
	emit_signal("stability_changed", old_stability, excavation_status.stability_level)
	
	print("Excavation stabilized: " + str(old_stability) + " -> " + str(excavation_status.stability_level))
	return true

# Timer update function
func _on_excavation_update():
	if not excavation_status.active:
		return
	
	# Get configs
	var mode_config = EXCAVATION_CONFIG.modes[excavation_status.current_mode]
	var algo_config = EXCAVATION_CONFIG.algorithms[excavation_status.current_algorithm]
	
	# Update duration
	var current_time = OS.get_unix_time()
	var elapsed_seconds = current_time - excavation_status.last_start_time
	excavation_status.duration_minutes = elapsed_seconds / 60.0
	
	# Check max duration
	if excavation_status.duration_minutes >= mode_config.max_duration_minutes:
		stop_excavation("completed")
		return
	
	# Update energy consumption
	var energy_rate = mode_config.energy_usage * (1.0 - algo_config.power_efficiency * 0.5)
	excavation_status.energy_consumption += energy_rate * update_interval_seconds / 60.0
	
	# Update progress
	excavation_status.progress = min(excavation_status.duration_minutes / mode_config.max_duration_minutes, 1.0) * 100.0
	
	# Affect stability
	_update_stability()
	
	# Check for discoveries
	process_discovery_attempt()

# Update stability
func _update_stability():
	# Get configs
	var mode_config = EXCAVATION_CONFIG.modes[excavation_status.current_mode]
	var algo_config = EXCAVATION_CONFIG.algorithms[excavation_status.current_algorithm]
	
	var old_stability = excavation_status.stability_level
	
	# Calculate stability impact
	var base_impact = mode_config.stability_impact * 0.01 # Small per-update impact
	var algo_factor = 1.0 - algo_config.stability_coefficient # Lower coefficient = higher impact
	
	var stability_impact = base_impact * (1.0 + algo_factor)
	
	# Apply stability impact
	excavation_status.stability_level -= stability_impact
	excavation_status.stability_level = max(excavation_status.stability_level, 0.1) # Prevent total collapse
	
	# Check for stability incident
	if old_stability >= 0.5 and excavation_status.stability_level < 0.5:
		metrics.stability_incidents += 1
		emit_signal("stability_changed", old_stability, excavation_status.stability_level)
		
		print("Stability incident: " + str(old_stability) + " -> " + str(excavation_status.stability_level))
	
	# Critical stability warning
	if excavation_status.stability_level < 0.2:
		emit_signal("error_occurred", {
			"type": "critical_stability",
			"message": "Excavation stability critically low",
			"stability": excavation_status.stability_level
		})

# Determine which resource is discovered
func _determine_resource_type(depth, target_type):
	# Weightings based on depth and target
	var weights = {
		"data_fragments": 0,
		"code_crystals": 0,
		"pattern_matrices": 0,
		"reality_shards": 0,
		"quantum_keys": 0
	}
	
	# Base weights by depth
	if depth <= 2:
		weights.data_fragments = 70
		weights.code_crystals = 25
		weights.pattern_matrices = 5
		weights.reality_shards = 0
		weights.quantum_keys = 0
	elif depth <= 4:
		weights.data_fragments = 40
		weights.code_crystals = 40
		weights.pattern_matrices = 15
		weights.reality_shards = 5
		weights.quantum_keys = 0
	elif depth <= 6:
		weights.data_fragments = 20
		weights.code_crystals = 30
		weights.pattern_matrices = 35
		weights.reality_shards = 15
		weights.quantum_keys = 0
	else: # depth > 6
		weights.data_fragments = 10
		weights.code_crystals = 20
		weights.pattern_matrices = 30
		weights.reality_shards = 30
		weights.quantum_keys = 10
	
	# Adjust based on target type
	match target_type:
		"standard":
			# No adjustment
			pass
		"advanced":
			weights.data_fragments = int(weights.data_fragments * 0.7)
			weights.code_crystals = int(weights.code_crystals * 1.2)
			weights.pattern_matrices = int(weights.pattern_matrices * 1.2)
		"complex":
			weights.data_fragments = int(weights.data_fragments * 0.5)
			weights.code_crystals = int(weights.code_crystals * 0.8)
			weights.pattern_matrices = int(weights.pattern_matrices * 1.5)
			weights.reality_shards = int(weights.reality_shards * 1.3)
			weights.quantum_keys = int(weights.quantum_keys * 1.5)
		"quantum":
			weights.data_fragments = int(weights.data_fragments * 0.3)
			weights.code_crystals = int(weights.code_crystals * 0.5)
			weights.pattern_matrices = int(weights.pattern_matrices * 0.8)
			weights.reality_shards = int(weights.reality_shards * 2.0)
			weights.quantum_keys = int(weights.quantum_keys * 4.0)
	
	# Calculate total weight
	var total_weight = 0
	for resource in weights:
		total_weight += weights[resource]
	
	# Generate random number
	var roll = randi() % total_weight
	
	# Determine result
	var cumulative = 0
	for resource in weights:
		cumulative += weights[resource]
		if roll < cumulative:
			return resource
	
	# Fallback
	return "data_fragments"

# Apply resource effect
func _apply_resource_effect(resource_type, amount):
	var effect = {
		"success": true,
		"description": ""
	}
	
	match resource_type:
		"data_fragments":
			# Slight stability boost
			var old_stability = excavation_status.stability_level
			excavation_status.stability_level += 0.05 * amount
			excavation_status.stability_level = min(excavation_status.stability_level, 1.0)
			effect.description = "Stability improved: " + str(old_stability) + " -> " + str(excavation_status.stability_level)
		
		"code_crystals":
			# Energy efficiency boost
			var energy_reduction = 0.1 * amount
			excavation_status.energy_consumption = max(excavation_status.energy_consumption * (1.0 - energy_reduction), 0)
			effect.description = "Energy consumption reduced by " + str(energy_reduction * 100) + "%"
		
		"pattern_matrices":
			# Discovery rate boost
			# This is handled implicitly in the next discovery attempt
			effect.description = "Discovery rate temporarily increased"
		
		"reality_shards":
			# Major stability restoration
			var old_stability = excavation_status.stability_level
			excavation_status.stability_level += 0.2 * amount
			excavation_status.stability_level = min(excavation_status.stability_level, 1.0)
			effect.description = "Stability significantly improved: " + str(old_stability) + " -> " + str(excavation_status.stability_level)
		
		"quantum_keys":
			# Dimensional shift - access higher depths temporarily
			excavation_status.current_depth += amount
			effect.description = "Excavation depth increased to " + str(excavation_status.current_depth)
			emit_signal("depth_reached", excavation_status.current_depth)
	
	return effect

# Estimate completion time
func _estimate_completion_time():
	if not excavation_status.active:
		return 0
	
	var mode_config = EXCAVATION_CONFIG.modes[excavation_status.current_mode]
	var remaining_minutes = mode_config.max_duration_minutes - excavation_status.duration_minutes
	
	return OS.get_unix_time() + (remaining_minutes * 60)

# Get dimension for depth
func _get_dimension_for_depth(depth):
	if depth <= 2:
		return "physical"
	elif depth <= 4:
		return "digital"
	elif depth <= 6:
		return "temporal"
	elif depth <= 8:
		return "conceptual"
	else:
		return "quantum"
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/digital_excavator.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/dimensional_bridge_visualizer.gd
# SIZE: 17175 bytes
extends Node2D
class_name DimensionalBridgeVisualizer

# Visualization system for the Claude-Ethereal Bridge
# Creates visual representations of dimensional connections, memory flows,
# and resonance patterns between Claude AI and Ethereal Engine

# Appearance settings
var color_palette = {
	"claude": Color(0.2, 0.4, 0.8),        # Blue
	"ethereal": Color(0.8, 0.3, 0.7),      # Purple
	"memory": Color(0.3, 0.7, 0.4),        # Green
	"command": Color(0.8, 0.6, 0.2),       # Orange
	"data": Color(0.7, 0.2, 0.3),          # Red
	"astral": Color(0.8, 0.8, 0.2),        # Yellow
	"temporal": Color(0.2, 0.6, 0.8),      # Cyan
	"resonance": Color(1.0, 1.0, 1.0),     # White
	"background": Color(0.05, 0.05, 0.1)   # Dark blue
}

# Animation settings
const FLOW_SPEED = 2.0
const PULSE_SPEED = 0.8
const ROTATION_SPEED = 0.1

# Visualization elements
var dimensions = {}
var connections = {}
var memory_flows = {}
var resonances = {}

# References to required components
var claude_ethereal_bridge
var ethereal_engine_integration

# Dimensional layout
var center_position = Vector2(512, 300)
var radius = 200
var inner_radius = 100

# Signal declarations
signal dimension_clicked(dimension_name, dimension_type)
signal connection_clicked(source_name, target_name)
signal flow_completed(flow_id, source, target)

func _ready():
	print("üé® Initializing Dimensional Bridge Visualizer")
	
	# Set background
	VisualServer.set_default_clear_color(color_palette.background)
	
	# Connect to required components
	_connect_to_systems()
	
	# Set up dimensions
	_setup_dimensions()
	
	# Set up initial connections
	_setup_connections()
	
	# Set up signal handlers
	_connect_signals()
	
	print("‚ú® Dimensional Bridge Visualizer ready")

func _connect_to_systems():
	# Find Claude Ethereal Bridge
	if has_node("/root/ClaudeEtherealBridge"):
		claude_ethereal_bridge = get_node("/root/ClaudeEtherealBridge")
		print("‚úì Connected to Claude Ethereal Bridge")
	else:
		print("‚ö† Claude Ethereal Bridge not found")
	
	# Find Ethereal Engine Integration
	if has_node("/root/EtherealEngineIntegration"):
		ethereal_engine_integration = get_node("/root/EtherealEngineIntegration")
		print("‚úì Connected to Ethereal Engine Integration")
	else:
		print("‚ö† Ethereal Engine Integration not found")

func _setup_dimensions():
	# Claude dimensions (inner circle)
	var claude_dimensions = ["short_term", "conversation", "long_term", "intuition", "imagination"]
	var claude_angle_step = 2 * PI / claude_dimensions.size()
	
	for i in range(claude_dimensions.size()):
		var angle = i * claude_angle_step
		var pos = center_position + Vector2(cos(angle), sin(angle)) * inner_radius
		
		dimensions[claude_dimensions[i]] = {
			"position": pos,
			"type": "claude",
			"color": color_palette.claude.lightened(0.2 * (i % 3)),
			"size": 30,
			"active": true,
			"pulse_phase": randf() * PI * 2,
			"angle": angle
		}
	
	# Ethereal dimensions (outer circle)
	var ethereal_dimensions = ["Memory", "Command", "Visual", "Data", "Temporal", "Astral", "Ethereal"]
	var ethereal_angle_step = 2 * PI / ethereal_dimensions.size()
	
	for i in range(ethereal_dimensions.size()):
		var angle = i * ethereal_angle_step
		var pos = center_position + Vector2(cos(angle), sin(angle)) * radius
		
		dimensions[ethereal_dimensions[i]] = {
			"position": pos,
			"type": "ethereal",
			"color": color_palette.ethereal.lightened(0.15 * (i % 5)),
			"size": 40,
			"active": true,
			"pulse_phase": randf() * PI * 2,
			"angle": angle
		}
	
	print("üîµ Initialized " + str(dimensions.size()) + " dimensions")

func _setup_connections():
	# Setup initial connections based on memory mapping
	if claude_ethereal_bridge:
		var mapping = claude_ethereal_bridge.memory_mapping
		
		# Connect Claude dimensions to Ethereal dimensions
		for claude_dim in mapping.claude:
			var ethereal_dim = mapping.claude[claude_dim]
			_add_connection(claude_dim, ethereal_dim)
	else:
		# Manual default mapping if bridge not available
		_add_connection("short_term", "Command")
		_add_connection("conversation", "Memory")
		_add_connection("long_term", "Data")
		_add_connection("intuition", "Astral")
		_add_connection("imagination", "Ethereal")
	
	print("üîó Initialized " + str(connections.size()) + " connections")

func _connect_signals():
	if claude_ethereal_bridge:
		claude_ethereal_bridge.connect("claude_message_sent", _on_claude_message_sent)
		claude_ethereal_bridge.connect("claude_response_received", _on_claude_response_received)
		claude_ethereal_bridge.connect("memory_synchronized", _on_memory_synchronized)
		claude_ethereal_bridge.connect("dimension_resonance_detected", _on_dimension_resonance_detected)
	
	if ethereal_engine_integration:
		ethereal_engine_integration.connect("pathway_established", _on_pathway_established)
		ethereal_engine_integration.connect("luno_cycle_changed", _on_luno_cycle_changed)
		ethereal_engine_integration.connect("token_usage_updated", _on_token_usage_updated)

# Adding visual elements
func _add_connection(source: String, target: String):
	if source not in dimensions or target not in dimensions:
		print("‚ö† Cannot add connection: dimensions not found")
		return null
	
	var connection_id = source + "_to_" + target
	
	if connection_id in connections:
		return connections[connection_id]
	
	connections[connection_id] = {
		"source": source,
		"target": target,
		"color": dimensions[source].color.linear_interpolate(dimensions[target].color, 0.5),
		"width": 2.0,
		"active": true,
		"flow_particles": [],
		"resonance": 0.0
	}
	
	print("üîó Added connection: " + connection_id)
	return connections[connection_id]

func create_memory_flow(source: String, target: String, size: float = 1.0):
	if source not in dimensions or target not in dimensions:
		print("‚ö† Cannot create memory flow: dimensions not found")
		return null
	
	var connection_id = source + "_to_" + target
	if connection_id not in connections:
		_add_connection(source, target)
	
	var flow_id = "flow_" + str(memory_flows.size())
	
	memory_flows[flow_id] = {
		"source": source,
		"target": target,
		"position": dimensions[source].position,
		"progress": 0.0,
		"size": size * 10, # Visual size of the memory particle
		"color": color_palette.memory,
		"speed": FLOW_SPEED * (0.8 + randf() * 0.4), # Randomize speed slightly
		"active": true,
		"completion_callback": null
	}
	
	print("üí´ Created memory flow: " + flow_id)
	return flow_id

func create_resonance(source: String, target: String, strength: float = 0.8):
	if source not in dimensions or target not in dimensions:
		print("‚ö† Cannot create resonance: dimensions not found")
		return null
	
	var connection_id = source + "_to_" + target
	if connection_id not in connections:
		_add_connection(source, target)
	
	var resonance_id = "resonance_" + str(resonances.size())
	
	resonances[resonance_id] = {
		"source": source,
		"target": target,
		"strength": strength,
		"pulse_speed": PULSE_SPEED * (1.0 + strength),
		"pulse_phase": randf() * PI * 2,
		"color": color_palette.resonance,
		"lifetime": 10.0, # Seconds until resonance fades
		"remaining_time": 10.0,
		"active": true
	}
	
	# Update connection resonance
	connections[connection_id].resonance = strength
	connections[connection_id].width = 2.0 + (strength * 6.0)
	
	print("‚ú® Created resonance: " + resonance_id + " (strength: " + str(strength) + ")")
	return resonance_id

func set_dimension_active(dimension: String, active: bool):
	if dimension not in dimensions:
		return
	
	dimensions[dimension].active = active
	
	print("üîµ Dimension " + dimension + " set to " + ("active" if active else "inactive"))

func set_connection_active(source: String, target: String, active: bool):
	var connection_id = source + "_to_" + target
	if connection_id not in connections:
		return
	
	connections[connection_id].active = active
	
	print("üîó Connection " + connection_id + " set to " + ("active" if active else "inactive"))

func highlight_dimension(dimension: String, duration: float = 1.0):
	if dimension not in dimensions:
		return
	
	var original_size = dimensions[dimension].size
	dimensions[dimension].size *= 1.5
	
	# Revert after duration
	var timer = Timer.new()
	add_child(timer)
	timer.wait_time = duration
	timer.one_shot = true
	timer.connect("timeout", _on_highlight_timeout.bind(dimension, original_size))
	timer.start()
	
	print("üîÜ Highlighting dimension: " + dimension)

func _on_highlight_timeout(dimension: String, original_size: float):
	if dimension in dimensions:
		dimensions[dimension].size = original_size

# Update and drawing
func _process(delta):
	# Update flow particles
	_update_flows(delta)
	
	# Update resonances
	_update_resonances(delta)
	
	# Update dimension pulses
	_update_dimensions(delta)
	
	# Request redraw
	queue_redraw()

func _update_flows(delta):
	var flows_to_remove = []
	
	for flow_id in memory_flows:
		var flow = memory_flows[flow_id]
		
		if not flow.active:
			continue
		
		# Update progress
		flow.progress += flow.speed * delta
		
		if flow.progress >= 1.0:
			# Flow completed, mark for removal
			emit_signal("flow_completed", flow_id, flow.source, flow.target)
			flows_to_remove.append(flow_id)
			continue
		
		# Update position
		var source_pos = dimensions[flow.source].position
		var target_pos = dimensions[flow.target].position
		flow.position = source_pos.linear_interpolate(target_pos, flow.progress)
	
	# Remove completed flows
	for flow_id in flows_to_remove:
		memory_flows.erase(flow_id)

func _update_resonances(delta):
	var resonances_to_remove = []
	
	for resonance_id in resonances:
		var resonance = resonances[resonance_id]
		
		if not resonance.active:
			continue
		
		# Update phase
		resonance.pulse_phase += resonance.pulse_speed * delta
		
		# Update lifetime
		resonance.remaining_time -= delta
		if resonance.remaining_time <= 0:
			resonances_to_remove.append(resonance_id)
			
			# Reset connection width
			var connection_id = resonance.source + "_to_" + resonance.target
			if connection_id in connections:
				connections[connection_id].resonance = 0.0
				connections[connection_id].width = 2.0
	
	# Remove expired resonances
	for resonance_id in resonances_to_remove:
		resonances.erase(resonance_id)

func _update_dimensions(delta):
	for dimension in dimensions.values():
		dimension.pulse_phase += PULSE_SPEED * delta
		
		# Slowly rotate dimensions
		dimension.angle += ROTATION_SPEED * delta
		var new_pos
		
		if dimension.type == "claude":
			new_pos = center_position + Vector2(cos(dimension.angle), sin(dimension.angle)) * inner_radius
		else:
			new_pos = center_position + Vector2(cos(dimension.angle), sin(dimension.angle)) * radius
			
		dimension.position = dimension.position.linear_interpolate(new_pos, delta * 0.5)

func _draw():
	# Draw connections
	for connection in connections.values():
		if not connection.active:
			continue
		
		var source_pos = dimensions[connection.source].position
		var target_pos = dimensions[connection.target].position
		
		# Calculate connection width with pulsing based on resonance
		var width = connection.width
		if connection.resonance > 0:
			var pulse_effect = sin(OS.get_ticks_msec() / 100.0) * 0.2 * connection.resonance
			width = max(1.0, width * (1.0 + pulse_effect))
		
		draw_line(source_pos, target_pos, connection.color, width, true)
	
	# Draw resonances
	for resonance in resonances.values():
		if not resonance.active:
			continue
		
		var source_pos = dimensions[resonance.source].position
		var target_pos = dimensions[resonance.target].position
		
		# Get the middle point for the resonance glow
		var mid_point = source_pos.linear_interpolate(target_pos, 0.5)
		
		# Calculate size based on phase
		var pulse = (sin(resonance.pulse_phase) * 0.5 + 0.5) * resonance.strength
		var size = 20 + (pulse * 40)
		
		# Draw glow
		var color = resonance.color
		color.a = resonance.strength * (resonance.remaining_time / 10.0) * 0.7
		
		draw_circle(mid_point, size, color)
	
	# Draw dimensions
	for dim_name in dimensions:
		var dimension = dimensions[dim_name]
		
		if not dimension.active:
			continue
		
		# Calculate pulse effect for size
		var pulse = sin(dimension.pulse_phase) * 0.1 + 0.9
		var size = dimension.size * pulse
		
		# Draw dimension circle
		draw_circle(dimension.position, size, dimension.color)
		
		# Draw dimension name
		var font_color = Color(1, 1, 1, 0.9)
		draw_string(default_font, dimension.position + Vector2(-dim_name.length() * 3, -size - 5), 
			dim_name, font_color)
	
	# Draw memory flows
	for flow in memory_flows.values():
		if not flow.active:
			continue
		
		# Draw particle with trail effect
		draw_circle(flow.position, flow.size, flow.color)
		
		# Optional: Draw trail
		var source_pos = dimensions[flow.source].position
		var current_pos = flow.position
		var trail_progress = flow.progress * 0.8  # Trail length as percentage of progress
		var trail_start = source_pos.linear_interpolate(current_pos, max(0, flow.progress - trail_progress))
		
		var trail_color = flow.color
		trail_color.a = 0.4
		draw_line(trail_start, current_pos, trail_color, flow.size * 0.7, true)

# Input handling
func _input(event):
	if event is InputEventMouseButton and event.button_index == BUTTON_LEFT and event.pressed:
		# Check if clicked on a dimension
		for dim_name in dimensions:
			var dimension = dimensions[dim_name]
			var distance = dimension.position.distance_to(event.position)
			
			if distance <= dimension.size:
				print("üñ±Ô∏è Dimension clicked: " + dim_name)
				emit_signal("dimension_clicked", dim_name, dimension.type)
				highlight_dimension(dim_name)
				return
		
		# Check if clicked on a connection (simplified)
		for connection_id in connections:
			var connection = connections[connection_id]
			var source_pos = dimensions[connection.source].position
			var target_pos = dimensions[connection.target].position
			
			# Check if click is near the line
			var closest_point = Geometry.get_closest_point_to_segment_2d(event.position, source_pos, target_pos)
			var distance = closest_point.distance_to(event.position)
			
			if distance <= 10:  # 10px threshold for clicking connections
				print("üñ±Ô∏è Connection clicked: " + connection_id)
				emit_signal("connection_clicked", connection.source, connection.target)
				return

# Signal handlers
func _on_claude_message_sent(message, tokens_used):
	# Create memory flow from Command to Ethereal
	create_memory_flow("conversation", "Command", 1.0 + (tokens_used / 1000.0))
	highlight_dimension("conversation")

func _on_claude_response_received(response, tokens_used):
	# Create memory flow from Ethereal to Memory
	create_memory_flow("Command", "Memory", 1.0 + (tokens_used / 1000.0))
	highlight_dimension("Memory")

func _on_memory_synchronized(source_type, target_type, memory_count):
	if source_type in dimensions and target_type in dimensions:
		create_memory_flow(source_type, target_type, 0.5 + (memory_count / 20.0))
		highlight_dimension(target_type)

func _on_dimension_resonance_detected(claude_dimension, ethereal_dimension, strength):
	if claude_dimension in dimensions and ethereal_dimension in dimensions:
		create_resonance(claude_dimension, ethereal_dimension, strength)
		highlight_dimension(claude_dimension)
		highlight_dimension(ethereal_dimension)

func _on_pathway_established(from_dimension, to_dimension, pathway_id):
	if from_dimension in dimensions and to_dimension in dimensions:
		_add_connection(from_dimension, to_dimension)
		create_memory_flow(from_dimension, to_dimension, 1.5)

func _on_luno_cycle_changed(cycle, name):
	# Update visualization to reflect LUNO cycle
	var cycle_colors = [
		Color(0.7, 0.3, 0.3),  # Genesis (Red)
		Color(0.8, 0.4, 0.2),  # Formation (Orange)
		Color(0.8, 0.7, 0.2),  # Complexity (Yellow)
		Color(0.5, 0.8, 0.3),  # Consciousness (Green)
		Color(0.3, 0.8, 0.6),  # Awakening (Teal)
		Color(0.2, 0.6, 0.8),  # Enlightenment (Blue)
		Color(0.4, 0.4, 0.8),  # Manifestation (Indigo)
		Color(0.6, 0.3, 0.8),  # Connection (Purple)
		Color(0.8, 0.3, 0.7),  # Harmony (Pink)
		Color(0.8, 0.2, 0.4),  # Transcendence (Rose)
		Color(0.9, 0.9, 0.9),  # Unity (White)
		Color(0.3, 0.3, 0.3)   # Beyond (Gray)
	]
	
	# Update ethereal dimensions color
	for dim_name in dimensions:
		var dimension = dimensions[dim_name]
		if dimension.type == "ethereal":
			dimension.color = cycle_colors[(cycle - 1) % 12].lightened(0.1 * (dim_name.length() % 3))
	
	# Create resonance pulses in all dimensions
	var ethereal_dimensions = []
	for dim_name in dimensions:
		if dimensions[dim_name].type == "ethereal":
			ethereal_dimensions.append(dim_name)
	
	for i in range(ethereal_dimensions.size()):
		var dim1 = ethereal_dimensions[i]
		var dim2 = ethereal_dimensions[(i + 1) % ethereal_dimensions.size()]
		create_resonance(dim1, dim2, 0.5)

func _on_token_usage_updated(used, total, percentage):
	# Visualize token usage by adjusting dimension sizes
	for dim_name in dimensions:
		var dimension = dimensions[dim_name]
		if dimension.type == "claude":
			dimension.size = 30 * (1.0 - (percentage * 0.3))  # Shrink as tokens are used up
	
	# If usage is high, create memory flows to visualize
	if percentage > 0.7:
		create_memory_flow("short_term", "Command", percentage)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/dimensional_bridge_visualizer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/dimensional_color_system.gd
# SIZE: 31755 bytes
class_name DimensionalColorSystem
extends Node

# ----- COLOR FREQUENCY CONSTANTS -----
const COLOR_HARMONICS = {
    "PRIMARY": {
        "frequencies": [99, 333, 555, 777, 999],
        "colors": [
            Color(0.1, 0.4, 0.9, 1.0),  # 99: Deep blue
            Color(0.0, 0.9, 0.6, 1.0),  # 333: Teal
            Color(0.9, 0.4, 0.7, 1.0),  # 555: Pink
            Color(0.9, 0.8, 0.1, 1.0),  # 777: Gold
            Color(1.0, 1.0, 1.0, 1.0)   # 999: Pure white
        ]
    },
    "SECONDARY": {
        "frequencies": [120, 240, 360, 480, 600, 720, 840, 960],
        "colors": [
            Color(0.5, 0.0, 0.9, 1.0),  # 120: Purple
            Color(0.0, 0.7, 0.9, 1.0),  # 240: Cyan 
            Color(0.0, 0.9, 0.0, 1.0),  # 360: Green
            Color(0.9, 0.9, 0.0, 1.0),  # 480: Yellow
            Color(0.9, 0.5, 0.0, 1.0),  # 600: Orange
            Color(0.9, 0.0, 0.0, 1.0),  # 720: Red
            Color(0.9, 0.0, 0.9, 1.0),  # 840: Magenta
            Color(0.3, 0.6, 0.9, 1.0)   # 960: Blue
        ]
    },
    "TERITARY": {
        "frequencies": [33, 66, 166, 233, 266, 299, 399, 466, 499, 533, 599, 633, 666, 699, 833, 866, 899, 933, 966],
        "colors": []  # Generated in _ready()
    }
}

# ----- MESH CONSTANTS -----
const MESH_HARMONIC_POINTS = {
    "CENTERS": [333, 666, 999],
    "EDGES": [120, 240, 480, 720, 960],
    "CORNERS": [99, 555, 777]
}

# ----- COLOR ANIMATION SETTINGS -----
const MIN_FREQUENCY = 1
const MAX_FREQUENCY = 999
const DEFAULT_ANIMATION_DURATION = 1.0 # seconds
const DEFAULT_PULSE_FREQUENCY = 4.0 # Hz
const DEFAULT_AMPLITUDE = 0.2

# ----- FREQUENCY MAPPINGS -----
var frequency_color_map = {}
var mesh_point_map = {}
var animation_timers = {}
var active_animations = {}

# ----- COLOR PALETTES -----
var color_palettes = {
    "default": [],
    "ethereal": [],
    "akashic": [],
    "dimensional": [],
    "turn_based": []
}

# ----- SYSTEM REFERENCES -----
var ethereal_bridge = null
var akashic_system = null

# ----- SIGNALS -----
signal color_frequency_updated(frequency, color)
signal animation_started(animation_id, frequency)
signal animation_completed(animation_id, frequency)
signal mesh_point_activated(point_type, frequency)

# ----- INITIALIZATION -----
func _ready():
    # Generate tertiary colors
    _generate_tertiary_colors()
    
    # Initialize frequency color map
    _initialize_frequency_color_map()
    
    # Initialize mesh point map
    _initialize_mesh_point_map()
    
    # Generate color palettes
    _generate_color_palettes()
    
    # Find system references
    _find_systems()
    
    print("Dimensional Color System initialized with " + str(frequency_color_map.size()) + " color frequencies")

func _generate_tertiary_colors():
    # Generate colors for tertiary frequencies by interpolating between primaries and secondaries
    var tertiary_frequencies = COLOR_HARMONICS.TERITARY.frequencies
    var tertiary_colors = []
    
    for freq in tertiary_frequencies:
        # Find surrounding reference frequencies
        var lower_freq = 0
        var lower_color = Color(0, 0, 0, 1)
        var upper_freq = MAX_FREQUENCY
        var upper_color = Color(1, 1, 1, 1)
        
        # Check primary frequencies
        for i in range(COLOR_HARMONICS.PRIMARY.frequencies.size()):
            var primary_freq = COLOR_HARMONICS.PRIMARY.frequencies[i]
            if primary_freq < freq and primary_freq > lower_freq:
                lower_freq = primary_freq
                lower_color = COLOR_HARMONICS.PRIMARY.colors[i]
            elif primary_freq > freq and primary_freq < upper_freq:
                upper_freq = primary_freq
                upper_color = COLOR_HARMONICS.PRIMARY.colors[i]
        
        # Check secondary frequencies
        for i in range(COLOR_HARMONICS.SECONDARY.frequencies.size()):
            var secondary_freq = COLOR_HARMONICS.SECONDARY.frequencies[i]
            if secondary_freq < freq and secondary_freq > lower_freq:
                lower_freq = secondary_freq
                lower_color = COLOR_HARMONICS.SECONDARY.colors[i]
            elif secondary_freq > freq and secondary_freq < upper_freq:
                upper_freq = secondary_freq
                upper_color = COLOR_HARMONICS.SECONDARY.colors[i]
        
        # Calculate interpolation factor
        var factor = 0.5
        if upper_freq != lower_freq:
            factor = float(freq - lower_freq) / (upper_freq - lower_freq)
        
        # Interpolate color
        var color = lower_color.lerp(upper_color, factor)
        
        # Add to tertiary colors
        tertiary_colors.append(color)
    
    COLOR_HARMONICS.TERITARY.colors = tertiary_colors

func _initialize_frequency_color_map():
    # Initialize map with base (black) color
    for freq in range(MIN_FREQUENCY, MAX_FREQUENCY + 1):
        var base_color = Color(0.1, 0.1, 0.1, 1.0)
        frequency_color_map[freq] = base_color
    
    # Add primary frequencies
    for i in range(COLOR_HARMONICS.PRIMARY.frequencies.size()):
        var freq = COLOR_HARMONICS.PRIMARY.frequencies[i]
        var color = COLOR_HARMONICS.PRIMARY.colors[i]
        frequency_color_map[freq] = color
    
    # Add secondary frequencies
    for i in range(COLOR_HARMONICS.SECONDARY.frequencies.size()):
        var freq = COLOR_HARMONICS.SECONDARY.frequencies[i]
        var color = COLOR_HARMONICS.SECONDARY.colors[i]
        frequency_color_map[freq] = color
    
    # Add tertiary frequencies
    for i in range(COLOR_HARMONICS.TERITARY.frequencies.size()):
        var freq = COLOR_HARMONICS.TERITARY.frequencies[i]
        var color = COLOR_HARMONICS.TERITARY.colors[i]
        frequency_color_map[freq] = color
    
    # Fill all other frequencies by interpolation
    for freq in range(MIN_FREQUENCY, MAX_FREQUENCY + 1):
        if frequency_color_map[freq].r == 0.1 and frequency_color_map[freq].g == 0.1 and frequency_color_map[freq].b == 0.1:
            # Find surrounding reference frequencies
            var lower_freq = MIN_FREQUENCY - 1
            var upper_freq = MAX_FREQUENCY + 1
            
            # Find closest lower frequency with defined color
            for ref_freq in range(freq-1, MIN_FREQUENCY-1, -1):
                if frequency_color_map.has(ref_freq) and frequency_color_map[ref_freq].r != 0.1 or frequency_color_map[ref_freq].g != 0.1 or frequency_color_map[ref_freq].b != 0.1:
                    lower_freq = ref_freq
                    break
            
            # Find closest upper frequency with defined color
            for ref_freq in range(freq+1, MAX_FREQUENCY+2):
                if frequency_color_map.has(ref_freq) and frequency_color_map[ref_freq].r != 0.1 or frequency_color_map[ref_freq].g != 0.1 or frequency_color_map[ref_freq].b != 0.1:
                    upper_freq = ref_freq
                    break
            
            # Interpolate color
            if lower_freq >= MIN_FREQUENCY and upper_freq <= MAX_FREQUENCY:
                var lower_color = frequency_color_map[lower_freq]
                var upper_color = frequency_color_map[upper_freq]
                var factor = float(freq - lower_freq) / (upper_freq - lower_freq)
                frequency_color_map[freq] = lower_color.lerp(upper_color, factor)

func _initialize_mesh_point_map():
    # Map mesh points to their frequencies
    for freq in range(MIN_FREQUENCY, MAX_FREQUENCY + 1):
        var point_types = []
        
        # Check if frequency is a center point
        if MESH_HARMONIC_POINTS.CENTERS.has(freq):
            point_types.append("center")
        
        # Check if frequency is an edge point
        if MESH_HARMONIC_POINTS.EDGES.has(freq):
            point_types.append("edge")
        
        # Check if frequency is a corner point
        if MESH_HARMONIC_POINTS.CORNERS.has(freq):
            point_types.append("corner")
        
        if point_types.size() > 0:
            mesh_point_map[freq] = point_types

func _generate_color_palettes():
    # Generate different color palettes for different systems
    
    # Default palette (full spectrum)
    color_palettes.default = [
        frequency_color_map[99],
        frequency_color_map[240],
        frequency_color_map[333],
        frequency_color_map[480],
        frequency_color_map[555],
        frequency_color_map[720],
        frequency_color_map[777],
        frequency_color_map[999]
    ]
    
    # Ethereal palette (blues and cyans)
    color_palettes.ethereal = [
        frequency_color_map[99],    # Deep blue
        frequency_color_map[240],   # Cyan
        frequency_color_map[333],   # Teal
        Color(0.2, 0.5, 0.8, 1.0),  # Sky blue
        Color(0.0, 0.3, 0.7, 1.0),  # Ocean blue
        Color(0.1, 0.6, 0.8, 1.0),  # Aqua
        Color(0.4, 0.7, 0.9, 1.0),  # Light blue
        Color(0.7, 0.9, 1.0, 1.0)   # Pale blue
    ]
    
    # Akashic palette (purples and magentas)
    color_palettes.akashic = [
        Color(0.3, 0.0, 0.5, 1.0),  # Deep purple
        Color(0.5, 0.0, 0.5, 1.0),  # Purple
        Color(0.7, 0.0, 0.7, 1.0),  # Magenta
        Color(0.8, 0.2, 0.8, 1.0),  # Bright magenta
        Color(0.4, 0.0, 0.8, 1.0),  # Violet
        Color(0.6, 0.3, 0.9, 1.0),  # Lavender
        Color(0.8, 0.4, 1.0, 1.0),  # Light purple
        Color(0.9, 0.7, 1.0, 1.0)   # Pale lavender
    ]
    
    # Dimensional palette (greens and golds)
    color_palettes.dimensional = [
        Color(0.0, 0.5, 0.3, 1.0),  # Deep green
        Color(0.0, 0.7, 0.4, 1.0),  # Emerald
        Color(0.3, 0.8, 0.2, 1.0),  # Lime green
        Color(0.5, 0.9, 0.3, 1.0),  # Bright green
        Color(0.7, 0.8, 0.2, 1.0),  # Yellow-green
        Color(0.8, 0.7, 0.2, 1.0),  # Gold
        frequency_color_map[777],   # Gold from harmonics
        Color(1.0, 0.9, 0.5, 1.0)   # Pale gold
    ]
    
    # Turn-based palette (reds and oranges)
    color_palettes.turn_based = [
        Color(0.5, 0.0, 0.0, 1.0),  # Deep red
        Color(0.7, 0.0, 0.0, 1.0),  # Red
        Color(0.9, 0.2, 0.0, 1.0),  # Bright red
        Color(0.9, 0.4, 0.0, 1.0),  # Orange-red
        Color(0.9, 0.6, 0.0, 1.0),  # Orange
        Color(1.0, 0.7, 0.2, 1.0),  # Bright orange
        Color(1.0, 0.8, 0.4, 1.0),  # Light orange
        Color(1.0, 0.9, 0.7, 1.0)   # Pale orange
    ]

func _find_systems():
    # Find Ethereal Bridge
    ethereal_bridge = get_node_or_null("/root/EtherealAkashicBridge")
    if not ethereal_bridge:
        ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealAkashicBridge")
    
    # Find Akashic System
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    print("Systems found - Ethereal Bridge: %s, Akashic System: %s" % [
        "Yes" if ethereal_bridge else "No",
        "Yes" if akashic_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

# ----- PROCESS -----
func _process(delta):
    # Update animations
    _update_animations(delta)

func _update_animations(delta):
    var completed_animations = []
    
    for animation_id in active_animations:
        var animation = active_animations[animation_id]
        animation.elapsed_time += delta
        
        # Check if animation is complete
        if animation.elapsed_time >= animation.duration:
            completed_animations.append(animation_id)
            emit_signal("animation_completed", animation_id, animation.frequency)
        else:
            # Update animation
            var progress = animation.elapsed_time / animation.duration
            
            match animation.type:
                "pulse":
                    _update_pulse_animation(animation, progress)
                "fade":
                    _update_fade_animation(animation, progress)
                "cycle":
                    _update_cycle_animation(animation, progress)
                "rainbow":
                    _update_rainbow_animation(animation, progress)
                "mesh_point":
                    _update_mesh_point_animation(animation, progress)
    
    # Remove completed animations
    for animation_id in completed_animations:
        active_animations.erase(animation_id)

func _update_pulse_animation(animation, progress):
    var base_color = animation.base_color
    var target_color = animation.target_color
    var frequency = animation.pulse_frequency
    var amplitude = animation.amplitude
    
    # Calculate pulse factor (0 to 1 to 0)
    var pulse_progress = sin(progress * TAU * frequency) * 0.5 + 0.5
    pulse_progress = pulse_progress * amplitude
    
    # Interpolate color
    var current_color = base_color.lerp(target_color, pulse_progress)
    
    # Update color in map
    animation.current_color = current_color
    frequency_color_map[animation.frequency] = current_color
    
    emit_signal("color_frequency_updated", animation.frequency, current_color)

func _update_fade_animation(animation, progress):
    var start_color = animation.start_color
    var end_color = animation.end_color
    
    # Interpolate color
    var current_color = start_color.lerp(end_color, progress)
    
    # Update color in map
    animation.current_color = current_color
    frequency_color_map[animation.frequency] = current_color
    
    emit_signal("color_frequency_updated", animation.frequency, current_color)

func _update_cycle_animation(animation, progress):
    var palette = animation.palette
    
    # Calculate which color in the palette to use
    var palette_size = palette.size()
    var cycle_position = fmod(progress * palette_size * animation.cycle_speed, palette_size)
    var index1 = int(cycle_position)
    var index2 = (index1 + 1) % palette_size
    var blend_factor = cycle_position - index1
    
    # Interpolate between the two colors
    var color1 = palette[index1]
    var color2 = palette[index2]
    var current_color = color1.lerp(color2, blend_factor)
    
    # Update color in map
    animation.current_color = current_color
    frequency_color_map[animation.frequency] = current_color
    
    emit_signal("color_frequency_updated", animation.frequency, current_color)

func _update_rainbow_animation(animation, progress):
    # Create a rainbow cycling effect
    var hue = fmod(progress * animation.rainbow_speed, 1.0)
    var sat = animation.saturation
    var val = animation.brightness
    
    # Convert HSV to RGB
    var current_color = Color.from_hsv(hue, sat, val)
    
    # Update color in map
    animation.current_color = current_color
    frequency_color_map[animation.frequency] = current_color
    
    emit_signal("color_frequency_updated", animation.frequency, current_color)

func _update_mesh_point_animation(animation, progress):
    var point_type = animation.point_type
    var base_color = animation.base_color
    var highlight_color = animation.highlight_color
    
    # Calculate highlight intensity (0 to 1 to 0)
    var frequency = animation.pulse_frequency
    var intensity = sin(progress * TAU * frequency) * 0.5 + 0.5
    
    # Scale intensity by point type importance
    match point_type:
        "center":
            intensity = intensity * 1.0 # Full intensity
        "corner":
            intensity = intensity * 0.8 # 80% intensity
        "edge":
            intensity = intensity * 0.6 # 60% intensity
    
    # Interpolate color
    var current_color = base_color.lerp(highlight_color, intensity)
    
    # Update color in map
    animation.current_color = current_color
    frequency_color_map[animation.frequency] = current_color
    
    emit_signal("color_frequency_updated", animation.frequency, current_color)
    
    # Emit mesh point signal periodically
    if fmod(progress * frequency * 10, 1.0) < 0.1:
        emit_signal("mesh_point_activated", point_type, animation.frequency)

# ----- COLOR MAPPING -----
func get_color_for_frequency(frequency: int) -> Color:
    # Clamp frequency to valid range
    frequency = clamp(frequency, MIN_FREQUENCY, MAX_FREQUENCY)
    
    if frequency_color_map.has(frequency):
        return frequency_color_map[frequency]
    
    # Color not found, return default
    return Color(0.5, 0.5, 0.5, 1.0)

func get_mesh_point_type(frequency: int) -> Array:
    if mesh_point_map.has(frequency):
        return mesh_point_map[frequency]
    
    return []

func get_closest_harmonic_frequency(frequency: int) -> int:
    # Find the closest frequency in the harmonics
    var all_harmonics = []
    all_harmonics.append_array(COLOR_HARMONICS.PRIMARY.frequencies)
    all_harmonics.append_array(COLOR_HARMONICS.SECONDARY.frequencies)
    all_harmonics.append_array(COLOR_HARMONICS.TERITARY.frequencies)
    
    var closest_freq = all_harmonics[0]
    var closest_dist = abs(frequency - closest_freq)
    
    for freq in all_harmonics:
        var dist = abs(frequency - freq)
        if dist < closest_dist:
            closest_dist = dist
            closest_freq = freq
    
    return closest_freq

func get_color_palette(palette_name: String = "default") -> Array:
    if color_palettes.has(palette_name):
        return color_palettes[palette_name]
    
    return color_palettes.default

# ----- ANIMATION FUNCTIONS -----
func start_pulse_animation(frequency: int, duration: float = DEFAULT_ANIMATION_DURATION, pulse_freq: float = DEFAULT_PULSE_FREQUENCY, amplitude: float = DEFAULT_AMPLITUDE) -> String:
    # Create a pulsing animation for a frequency
    var base_color = get_color_for_frequency(frequency)
    var harmonic_freq = get_closest_harmonic_frequency(frequency)
    var target_color = get_color_for_frequency(harmonic_freq)
    
    # Create animation ID
    var animation_id = "pulse_" + str(frequency) + "_" + str(Time.get_unix_time_from_system())
    
    # Create animation data
    active_animations[animation_id] = {
        "type": "pulse",
        "frequency": frequency,
        "duration": duration,
        "pulse_frequency": pulse_freq,
        "amplitude": amplitude,
        "base_color": base_color,
        "target_color": target_color,
        "current_color": base_color,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, frequency)
    
    return animation_id

func start_fade_animation(frequency: int, target_color: Color, duration: float = DEFAULT_ANIMATION_DURATION) -> String:
    # Create a fading animation from current color to target color
    var start_color = get_color_for_frequency(frequency)
    
    # Create animation ID
    var animation_id = "fade_" + str(frequency) + "_" + str(Time.get_unix_time_from_system())
    
    # Create animation data
    active_animations[animation_id] = {
        "type": "fade",
        "frequency": frequency,
        "duration": duration,
        "start_color": start_color,
        "end_color": target_color,
        "current_color": start_color,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, frequency)
    
    return animation_id

func start_cycle_animation(frequency: int, palette_name: String = "default", duration: float = DEFAULT_ANIMATION_DURATION, cycle_speed: float = 1.0) -> String:
    # Create a cycling animation through a color palette
    var palette = get_color_palette(palette_name)
    var start_color = get_color_for_frequency(frequency)
    
    # Create animation ID
    var animation_id = "cycle_" + str(frequency) + "_" + str(Time.get_unix_time_from_system())
    
    # Create animation data
    active_animations[animation_id] = {
        "type": "cycle",
        "frequency": frequency,
        "duration": duration,
        "palette": palette,
        "cycle_speed": cycle_speed,
        "current_color": start_color,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, frequency)
    
    return animation_id

func start_rainbow_animation(frequency: int, duration: float = DEFAULT_ANIMATION_DURATION, rainbow_speed: float = 1.0, saturation: float = 1.0, brightness: float = 1.0) -> String:
    # Create a rainbow cycling animation
    var start_color = get_color_for_frequency(frequency)
    
    # Create animation ID
    var animation_id = "rainbow_" + str(frequency) + "_" + str(Time.get_unix_time_from_system())
    
    # Create animation data
    active_animations[animation_id] = {
        "type": "rainbow",
        "frequency": frequency,
        "duration": duration,
        "rainbow_speed": rainbow_speed,
        "saturation": saturation,
        "brightness": brightness,
        "current_color": start_color,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, frequency)
    
    return animation_id

func start_mesh_point_animation(frequency: int, duration: float = DEFAULT_ANIMATION_DURATION, pulse_freq: float = DEFAULT_PULSE_FREQUENCY) -> String:
    # Create an animation for mesh points (centers, edges, corners)
    var point_types = get_mesh_point_type(frequency)
    
    if point_types.size() == 0:
        return ""
    
    var point_type = point_types[0] # Use first type if multiple
    var base_color = get_color_for_frequency(frequency)
    var highlight_color = Color(1.0, 1.0, 1.0, 1.0) # White highlight
    
    # Adjust highlight color based on point type
    match point_type:
        "center":
            highlight_color = Color(1.0, 1.0, 1.0, 1.0) # White
        "corner":
            highlight_color = Color(1.0, 0.9, 0.1, 1.0) # Gold
        "edge":
            highlight_color = Color(0.1, 0.9, 1.0, 1.0) # Cyan
    
    # Create animation ID
    var animation_id = "mesh_" + str(frequency) + "_" + str(Time.get_unix_time_from_system())
    
    # Create animation data
    active_animations[animation_id] = {
        "type": "mesh_point",
        "frequency": frequency,
        "duration": duration,
        "pulse_frequency": pulse_freq,
        "point_type": point_type,
        "base_color": base_color,
        "highlight_color": highlight_color,
        "current_color": base_color,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, frequency)
    emit_signal("mesh_point_activated", point_type, frequency)
    
    return animation_id

func stop_animation(animation_id: String) -> bool:
    if active_animations.has(animation_id):
        var animation = active_animations[animation_id]
        var frequency = animation.frequency
        
        # Reset color to harmonic color
        var harmonic_freq = get_closest_harmonic_frequency(frequency)
        frequency_color_map[frequency] = get_color_for_frequency(harmonic_freq)
        
        active_animations.erase(animation_id)
        return true
    
    return false

func stop_all_animations() -> void:
    # Reset all colors to their harmonic values
    for animation_id in active_animations:
        var animation = active_animations[animation_id]
        var frequency = animation.frequency
        var harmonic_freq = get_closest_harmonic_frequency(frequency)
        frequency_color_map[frequency] = get_color_for_frequency(harmonic_freq)
    
    active_animations.clear()

# ----- TEXT COLOR FUNCTIONS -----
func get_colored_text(text: String, frequency: int) -> String:
    var color = get_color_for_frequency(frequency)
    
    # Convert color to hex
    var hex_color = color.to_html(false)
    
    # Return BBCode colored text
    return "[color=#" + hex_color + "]" + text + "[/color]"

func get_gradient_text(text: String, start_freq: int, end_freq: int) -> String:
    var start_color = get_color_for_frequency(start_freq)
    var end_color = get_color_for_frequency(end_freq)
    
    # Return BBCode gradient text
    var start_hex = start_color.to_html(false)
    var end_hex = end_color.to_html(false)
    
    return "[gradient start=#" + start_hex + " end=#" + end_hex + "]" + text + "[/gradient]"

func colorize_line(line: String, base_frequency: int, symbol_boost: int = 10) -> String:
    # Colorize an entire line, with special handling for symbols
    var result = ""
    var current_freq = base_frequency
    
    for i in range(line.length()):
        var char = line[i]
        
        # Adjust frequency based on character
        match char:
            "#":
                current_freq = min(MAX_FREQUENCY, current_freq + symbol_boost)
            "_":
                current_freq = min(MAX_FREQUENCY, current_freq + symbol_boost / 2)
            "@":
                current_freq = min(MAX_FREQUENCY, current_freq + symbol_boost * 2)
            "$":
                current_freq = min(MAX_FREQUENCY, current_freq + symbol_boost * 3)
            "%":
                current_freq = min(MAX_FREQUENCY, current_freq + symbol_boost * 1.5)
            "&":
                current_freq = min(MAX_FREQUENCY, current_freq + symbol_boost * 2.5)
            "*":
                current_freq = min(MAX_FREQUENCY, current_freq + symbol_boost * 3.5)
            ".":
                current_freq = max(MIN_FREQUENCY, current_freq - symbol_boost / 2)
            ",":
                current_freq = max(MIN_FREQUENCY, current_freq - symbol_boost / 4)
            " ":
                current_freq = base_frequency # Reset to base
        
        # Apply color to character
        var color = get_color_for_frequency(current_freq)
        var hex_color = color.to_html(false)
        
        result += "[color=#" + hex_color + "]" + char + "[/color]"
    
    return result

func colorize_mesh_points(text: String) -> String:
    # Apply special coloring to mesh point frequencies
    var result = text
    
    # Check for numbers in text that match mesh point frequencies
    for freq in mesh_point_map.keys():
        var freq_str = str(freq)
        
        # Replace occurrences of the frequency with colored version
        var color = get_color_for_frequency(freq)
        var hex_color = color.to_html(false)
        
        # Create replacement with proper coloring
        var replacement = "[color=#" + hex_color + "]" + freq_str + "[/color]"
        
        # Replace in text (using regex to match whole words only)
        var regex = RegEx.new()
        regex.compile("\\b" + freq_str + "\\b")
        result = regex.sub(result, replacement, true)
    
    return result

# ----- LINE ANIMATION FUNCTIONS -----
func start_line_animation(line_index: int, frequency: int = 120, animation_type: String = "pulse", duration: float = DEFAULT_ANIMATION_DURATION) -> String:
    # Create an animation for a specific line
    var animation_id = ""
    
    match animation_type:
        "pulse":
            animation_id = start_pulse_animation(frequency, duration, DEFAULT_PULSE_FREQUENCY, DEFAULT_AMPLITUDE)
        "rainbow":
            animation_id = start_rainbow_animation(frequency, duration)
        "cycle":
            animation_id = start_cycle_animation(frequency, "default", duration)
        "mesh_point":
            animation_id = start_mesh_point_animation(frequency, duration)
    
    if animation_id != "":
        active_animations[animation_id].line_index = line_index
    
    return animation_id

func animate_text_typing(text: String, base_freq: int = 120, duration: float = 2.0, delay_per_char: float = 0.05) -> void:
    # Animate text appearing character by character with changing colors
    # This would typically be implemented by the rendering system
    # Here we just create the animation data
    
    var animation_id = "typing_" + str(Time.get_unix_time_from_system())
    
    active_animations[animation_id] = {
        "type": "typing",
        "text": text,
        "base_frequency": base_freq,
        "duration": duration,
        "delay_per_char": delay_per_char,
        "current_char": 0,
        "elapsed_time": 0.0
    }
    
    emit_signal("animation_started", animation_id, base_freq)

# ----- MESH VISUALIZATION HELPERS -----
func highlight_mesh_points(frequencies: Array, duration: float = 5.0) -> void:
    # Start animations for all the specified frequencies
    for freq in frequencies:
        if mesh_point_map.has(freq):
            start_mesh_point_animation(freq, duration)

func highlight_mesh_centers(duration: float = 5.0) -> void:
    highlight_mesh_points(MESH_HARMONIC_POINTS.CENTERS, duration)

func highlight_mesh_edges(duration: float = 5.0) -> void:
    highlight_mesh_points(MESH_HARMONIC_POINTS.EDGES, duration)

func highlight_mesh_corners(duration: float = 5.0) -> void:
    highlight_mesh_points(MESH_HARMONIC_POINTS.CORNERS, duration)

func get_mesh_visualization_colors() -> Dictionary:
    # Return colors for mesh visualization
    return {
        "centers": [
            get_color_for_frequency(MESH_HARMONIC_POINTS.CENTERS[0]),
            get_color_for_frequency(MESH_HARMONIC_POINTS.CENTERS[1]),
            get_color_for_frequency(MESH_HARMONIC_POINTS.CENTERS[2])
        ],
        "edges": [
            get_color_for_frequency(MESH_HARMONIC_POINTS.EDGES[0]),
            get_color_for_frequency(MESH_HARMONIC_POINTS.EDGES[1]),
            get_color_for_frequency(MESH_HARMONIC_POINTS.EDGES[2]),
            get_color_for_frequency(MESH_HARMONIC_POINTS.EDGES[3]),
            get_color_for_frequency(MESH_HARMONIC_POINTS.EDGES[4])
        ],
        "corners": [
            get_color_for_frequency(MESH_HARMONIC_POINTS.CORNERS[0]),
            get_color_for_frequency(MESH_HARMONIC_POINTS.CORNERS[1]),
            get_color_for_frequency(MESH_HARMONIC_POINTS.CORNERS[2])
        ]
    }

# ----- ETHEREAL INTEGRATION -----
func sync_with_ethereal_bridge() -> bool:
    if not ethereal_bridge:
        return false
    
    # Get dimensional data from ethereal bridge
    if ethereal_bridge.has_method("get_active_dimensions"):
        var active_dimensions = ethereal_bridge.get_active_dimensions()
        
        for dim_data in active_dimensions:
            if dim_data.has("frequency"):
                var freq = int(dim_data.frequency * 1000) # Convert 0-1 to 0-1000
                freq = clamp(freq, MIN_FREQUENCY, MAX_FREQUENCY)
                
                # Start pulse animation for this dimension
                start_pulse_animation(freq, 10.0, 0.5, 0.3)
        
        return true
    
    return false

# ----- PUBLIC API -----
func get_frequency_info(frequency: int) -> Dictionary:
    frequency = clamp(frequency, MIN_FREQUENCY, MAX_FREQUENCY)
    
    var color = get_color_for_frequency(frequency)
    var point_types = get_mesh_point_type(frequency)
    var is_harmonic = false
    var harmonic_type = ""
    
    # Check if frequency is a harmonic
    if COLOR_HARMONICS.PRIMARY.frequencies.has(frequency):
        is_harmonic = true
        harmonic_type = "primary"
    elif COLOR_HARMONICS.SECONDARY.frequencies.has(frequency):
        is_harmonic = true
        harmonic_type = "secondary"
    elif COLOR_HARMONICS.TERITARY.frequencies.has(frequency):
        is_harmonic = true
        harmonic_type = "tertiary"
    
    return {
        "frequency": frequency,
        "color": color,
        "mesh_point_types": point_types,
        "is_harmonic": is_harmonic,
        "harmonic_type": harmonic_type,
        "has_active_animation": _frequency_has_animation(frequency)
    }

func _frequency_has_animation(frequency: int) -> bool:
    for animation_id in active_animations:
        if active_animations[animation_id].frequency == frequency:
            return true
    
    return false
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/dimensional_color_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/dimensional_window_transformer.gd
# SIZE: 25783 bytes
class_name DimensionalWindowTransformer
extends Node

# ----- WINDOW SETTINGS -----
@export_category("Window Configuration")
@export var ethereal_bridge_path: String = "res://12_turns_system/ethereal_akashic_bridge.gd"
@export var akashic_system_path: String = "res://12_turns_system/akashic_number_system.gd"
@export var base_window_size: Vector2 = Vector2(1280, 720)
@export var window_transform_speed: float = 0.5
@export var window_transition_duration: float = 0.5
@export var enable_experimental_features: bool = true
@export var max_window_instances: int = 5
@export var dimension_color_mode: String = "frequential" # frequential, stability, hybrid

# ----- WINDOW STATES -----
enum WindowState {
    NORMAL,
    TRANSITIONING,
    MAXIMIZED,
    MINIMIZED,
    ETHEREAL,
    FRACTALIZED,
    DIMENSIONAL_SHIFT
}

# ----- WINDOW TRANSFORMS -----
var window_references: Array = []
var window_states: Dictionary = {}
var window_transforms: Dictionary = {}
var window_positions: Dictionary = {}
var window_dimensions: Dictionary = {}
var active_transitions: Dictionary = {}
var window_colors: Dictionary = {}

# ----- DIMENSIONAL DATA -----
var current_dimension: String = "0-0-0"
var dimension_stack: Array = []
var fractal_points: Array = []
var dimension_properties: Dictionary = {}

# ----- COMPONENT REFERENCES -----
var ethereal_bridge: Node = null
var akashic_system: Node = null
var symbol_system: Node = null

# ----- TRANSFORMATION MATRICES -----
var transform_matrices: Dictionary = {
    "identity": Transform2D.IDENTITY,
    "rotate_90": Transform2D(Vector2(0, -1), Vector2(1, 0), Vector2.ZERO),
    "rotate_180": Transform2D(Vector2(-1, 0), Vector2(0, -1), Vector2.ZERO),
    "rotate_270": Transform2D(Vector2(0, 1), Vector2(-1, 0), Vector2.ZERO),
    "mirror_x": Transform2D(Vector2(-1, 0), Vector2(0, 1), Vector2.ZERO),
    "mirror_y": Transform2D(Vector2(1, 0), Vector2(0, -1), Vector2.ZERO),
    "scale_up": Transform2D(Vector2(1.2, 0), Vector2(0, 1.2), Vector2.ZERO),
    "scale_down": Transform2D(Vector2(0.8, 0), Vector2(0, 0.8), Vector2.ZERO),
    "shear_x": Transform2D(Vector2(1, 0.2), Vector2(0, 1), Vector2.ZERO),
    "shear_y": Transform2D(Vector2(1, 0), Vector2(0.2, 1), Vector2.ZERO)
}

# ----- WINDOW PATTERNS -----
var window_patterns: Dictionary = {
    "triangle": { 
        "points": [Vector2(0, 0), Vector2(1, 0), Vector2(0.5, 0.866)],
        "transform_sequence": ["identity", "rotate_120", "rotate_240"]
    },
    "square": {
        "points": [Vector2(0, 0), Vector2(1, 0), Vector2(1, 1), Vector2(0, 1)],
        "transform_sequence": ["identity", "rotate_90", "rotate_180", "rotate_270"]
    },
    "pentagon": {
        "points": [
            Vector2(0.5, 0), 
            Vector2(1, 0.363), 
            Vector2(0.809, 0.951), 
            Vector2(0.191, 0.951),
            Vector2(0, 0.363)
        ],
        "transform_sequence": ["identity", "rotate_72", "rotate_144", "rotate_216", "rotate_288"]
    },
    "hexagon": {
        "points": [
            Vector2(0.5, 0),
            Vector2(1, 0.25),
            Vector2(1, 0.75),
            Vector2(0.5, 1),
            Vector2(0, 0.75),
            Vector2(0, 0.25)
        ],
        "transform_sequence": ["identity", "rotate_60", "rotate_120", "rotate_180", "rotate_240", "rotate_300"]
    },
    "cube": {
        "points": [
            Vector2(0, 0), Vector2(1, 0), Vector2(1, 1), Vector2(0, 1),  # Front face
            Vector2(0.2, 0.2), Vector2(1.2, 0.2), Vector2(1.2, 1.2), Vector2(0.2, 1.2)  # Back face
        ],
        "transform_sequence": ["identity", "rotate_90", "rotate_180", "rotate_270", "mirror_x", "mirror_y", "shear_x", "shear_y"]
    }
}

# ----- SIGNALS -----
signal window_transformed(window_id, transform_type)
signal window_state_changed(window_id, old_state, new_state)
signal window_dimension_changed(window_id, old_dimension, new_dimension)
signal windows_synchronized()
signal fractal_data_updated(points)

# ----- INITIALIZATION -----
func _ready():
    _find_components()
    _initialize_window_references()
    
    # Connect to ethereal bridge if available
    if ethereal_bridge:
        if ethereal_bridge.has_signal("fractal_data_updated"):
            ethereal_bridge.connect("fractal_data_updated", _on_fractal_data_updated)
        
        if ethereal_bridge.has_signal("dimension_changed"):
            ethereal_bridge.connect("dimension_changed", _on_dimension_changed)
        
        # Get initial dimension data
        _update_dimension_data()

func _find_components():
    # Find Ethereal Bridge
    var bridge_script = load(ethereal_bridge_path) if ResourceLoader.exists(ethereal_bridge_path) else null
    if bridge_script:
        ethereal_bridge = get_node_or_null("/root/EtherealAkashicBridge")
        if not ethereal_bridge:
            ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealAkashicBridge")
    
    # Find Akashic System
    var akashic_script = load(akashic_system_path) if ResourceLoader.exists(akashic_system_path) else null
    if akashic_script:
        akashic_system = get_node_or_null("/root/AkashicNumberSystem")
        if not akashic_system:
            akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    print("Components found - Ethereal Bridge: %s, Akashic System: %s" % [
        "Yes" if ethereal_bridge else "No",
        "Yes" if akashic_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_window_references():
    # Add main window
    var main_window = {
        "id": "main",
        "viewport": get_viewport(),
        "size": base_window_size,
        "position": Vector2.ZERO,
        "state": WindowState.NORMAL,
        "dimension": current_dimension,
        "transform": Transform2D.IDENTITY
    }
    
    window_references.append(main_window)
    window_states["main"] = WindowState.NORMAL
    window_transforms["main"] = Transform2D.IDENTITY
    window_positions["main"] = Vector2.ZERO
    window_dimensions["main"] = current_dimension
    
    # Set initial window properties
    if OS.has_feature("windows") or OS.has_feature("X11") or OS.has_feature("OSX"):
        OS.window_size = base_window_size
        OS.window_position = Vector2i(100, 100)
        window_positions["main"] = Vector2(100, 100)

# ----- UPDATE LOOP -----
func _process(delta):
    # Update active transitions
    _update_transitions(delta)
    
    # Handle periodic window synchronization
    _sync_window_transforms()

# ----- WINDOW MANAGEMENT -----
func create_window(window_id: String, size: Vector2 = Vector2.ZERO, position: Vector2 = Vector2.ZERO):
    if window_references.size() >= max_window_instances:
        print("Cannot create more windows: maximum instances reached")
        return null
    
    if OS.has_feature("windows") or OS.has_feature("X11") or OS.has_feature("OSX"):
        if size == Vector2.ZERO:
            size = base_window_size
        
        if position == Vector2.ZERO:
            position = Vector2(200, 200)
        
        var window = Window.new()
        window.size = Vector2i(size)
        window.position = Vector2i(position)
        window.title = "Dimensional Window: " + window_id
        
        var new_window = {
            "id": window_id,
            "window": window,
            "size": size,
            "position": position,
            "state": WindowState.NORMAL,
            "dimension": current_dimension,
            "transform": Transform2D.IDENTITY
        }
        
        window_references.append(new_window)
        window_states[window_id] = WindowState.NORMAL
        window_transforms[window_id] = Transform2D.IDENTITY
        window_positions[window_id] = position
        window_dimensions[window_id] = current_dimension
        
        add_child(window)
        return window
    
    print("Window creation not supported on this platform")
    return null

func close_window(window_id: String):
    for i in range(window_references.size()):
        if window_references[i].id == window_id and window_id != "main":
            var window_ref = window_references[i]
            
            if window_ref.has("window") and is_instance_valid(window_ref.window):
                window_ref.window.queue_free()
            
            window_references.remove_at(i)
            window_states.erase(window_id)
            window_transforms.erase(window_id)
            window_positions.erase(window_id)
            window_dimensions.erase(window_id)
            active_transitions.erase(window_id)
            
            return true
    
    return false

func transform_window(window_id: String, transform_type: String):
    if not window_transforms.has(window_id):
        print("Window not found: " + window_id)
        return false
    
    if not transform_matrices.has(transform_type):
        print("Transform type not found: " + transform_type)
        return false
    
    # Start transition to new transform
    var current_transform = window_transforms[window_id]
    var target_transform = transform_matrices[transform_type]
    
    active_transitions[window_id] = {
        "start_transform": current_transform,
        "target_transform": target_transform,
        "progress": 0.0,
        "duration": window_transition_duration,
        "transform_type": transform_type
    }
    
    return true

func transform_window_to_pattern(window_id: String, pattern_name: String, point_index: int = 0):
    if not window_patterns.has(pattern_name):
        print("Pattern not found: " + pattern_name)
        return false
    
    var pattern = window_patterns[pattern_name]
    
    if point_index < 0 or point_index >= pattern.transform_sequence.size():
        print("Invalid point index for pattern: " + str(point_index))
        return false
    
    var transform_type = pattern.transform_sequence[point_index]
    return transform_window(window_id, transform_type)

func set_window_position(window_id: String, position: Vector2):
    if not window_positions.has(window_id):
        print("Window not found: " + window_id)
        return false
    
    window_positions[window_id] = position
    
    for window_ref in window_references:
        if window_ref.id == window_id:
            if window_id == "main":
                OS.window_position = Vector2i(position)
            elif window_ref.has("window") and is_instance_valid(window_ref.window):
                window_ref.window.position = Vector2i(position)
            
            return true
    
    return false

func set_window_size(window_id: String, size: Vector2):
    for window_ref in window_references:
        if window_ref.id == window_id:
            window_ref.size = size
            
            if window_id == "main":
                OS.window_size = Vector2i(size)
            elif window_ref.has("window") and is_instance_valid(window_ref.window):
                window_ref.window.size = Vector2i(size)
            
            return true
    
    return false

func set_window_state(window_id: String, state: int):
    if not window_states.has(window_id):
        print("Window not found: " + window_id)
        return false
    
    var old_state = window_states[window_id]
    window_states[window_id] = state
    
    # Apply state-specific transformations
    match state:
        WindowState.MAXIMIZED:
            if window_id == "main":
                OS.window_maximized = true
            # For other windows, use custom maximization
        
        WindowState.MINIMIZED:
            if window_id == "main":
                OS.window_minimized = true
            # For other windows, use custom minimization
        
        WindowState.NORMAL:
            if window_id == "main":
                OS.window_maximized = false
                OS.window_minimized = false
            # For other windows, restore normal state
        
        WindowState.ETHEREAL:
            # Apply ethereal effect - pulsing transparency
            _apply_ethereal_effect(window_id)
        
        WindowState.FRACTALIZED:
            # Apply fractal transformation
            _apply_fractal_transformation(window_id)
        
        WindowState.DIMENSIONAL_SHIFT:
            # Prepare for dimension shift
            _prepare_dimensional_shift(window_id)
    
    emit_signal("window_state_changed", window_id, old_state, state)
    return true

func change_window_dimension(window_id: String, dimension_key: String):
    if not window_dimensions.has(window_id):
        print("Window not found: " + window_id)
        return false
    
    # Check if dimension exists in ethereal bridge
    if ethereal_bridge and ethereal_bridge.has_method("get_dimension_fractal"):
        var dim_fractal = ethereal_bridge.get_dimension_fractal(dimension_key)
        if dim_fractal == null:
            print("Dimension not found: " + dimension_key)
            return false
    
    var old_dimension = window_dimensions[window_id]
    window_dimensions[window_id] = dimension_key
    
    # Update window color based on dimension
    _update_window_color(window_id, dimension_key)
    
    emit_signal("window_dimension_changed", window_id, old_dimension, dimension_key)
    return true

# ----- TRANSITION HANDLING -----
func _update_transitions(delta):
    var completed_transitions = []
    
    for window_id in active_transitions:
        var transition = active_transitions[window_id]
        transition.progress += delta / transition.duration
        
        if transition.progress >= 1.0:
            # Transition complete
            window_transforms[window_id] = transition.target_transform
            completed_transitions.append(window_id)
            
            emit_signal("window_transformed", window_id, transition.transform_type)
        else:
            # Update in-progress transition
            window_transforms[window_id] = transition.start_transform.interpolate_with(
                transition.target_transform,
                transition.progress
            )
    
    # Remove completed transitions
    for window_id in completed_transitions:
        active_transitions.erase(window_id)

func _sync_window_transforms():
    for window_ref in window_references:
        var window_id = window_ref.id
        
        if window_transforms.has(window_id):
            var transform = window_transforms[window_id]
            
            # Apply transform to window shader or canvas item
            if window_id == "main":
                # Apply to main window via shader or canvas
                if get_viewport().has_method("set_canvas_transform"):
                    get_viewport().set_canvas_transform(transform)
            elif window_ref.has("window") and is_instance_valid(window_ref.window):
                # Apply to sub-window
                if window_ref.window.has_method("set_canvas_transform"):
                    window_ref.window.set_canvas_transform(transform)
    
    emit_signal("windows_synchronized")

# ----- SPECIAL WINDOW EFFECTS -----
func _apply_ethereal_effect(window_id: String):
    # This would typically use shaders for the ethereal effect
    # Simplified version just applies a scale transform
    transform_window(window_id, "scale_up")
    
    # In a real implementation, you would apply a shader with pulsing transparency

func _apply_fractal_transformation(window_id: String):
    # Apply a fractal-based transformation
    # This effect would be based on the current dimension's fractal points
    
    # For now, just apply a random transform from the available matrices
    var transform_keys = transform_matrices.keys()
    var random_transform = transform_keys[randi() % transform_keys.size()]
    
    transform_window(window_id, random_transform)

func _prepare_dimensional_shift(window_id: String):
    # Set up the window for dimension shifting
    # This effect would prepare a smooth transition between dimensions
    
    # For now, just apply a sequence of transforms
    transform_window(window_id, "rotate_90")
    # In a real implementation, this would be a more elaborate sequence

func _update_window_color(window_id: String, dimension_key: String):
    # Generate color based on dimension properties
    var color = Color.WHITE
    
    if ethereal_bridge and dimension_properties.has(dimension_key):
        var properties = dimension_properties[dimension_key]
        
        match dimension_color_mode:
            "frequential":
                # Higher frequency = more blue
                var freq = properties.frequency
                color = Color(1.0 - freq, 1.0 - freq/2.0, freq)
            
            "stability":
                # Higher stability = more green
                var stability = properties.stability
                color = Color(1.0 - stability, stability, 1.0 - stability/2.0)
            
            "hybrid":
                # Combine frequency and stability
                var freq = properties.frequency
                var stability = properties.stability
                color = Color(
                    1.0 - (freq + stability)/2.0,
                    stability,
                    freq
                )
    
    window_colors[window_id] = color
    
    # Apply color to window
    # This would typically be done via a shader or other visual effect
    # For now, just store the color for reference

# ----- DIMENSION DATA HANDLERS -----
func _update_dimension_data():
    if not ethereal_bridge:
        return
    
    # Get current dimension
    if ethereal_bridge.has_method("get_dimension_fractal"):
        current_dimension = ethereal_bridge.get_property("current_dimension") if ethereal_bridge.has_method("get_property") else "0-0-0"
        
        # Update dimension stack
        if ethereal_bridge.has_property("dimension_stack"):
            dimension_stack = ethereal_bridge.dimension_stack.duplicate()
    
    # Get fractal data
    if ethereal_bridge.has_method("get_fractal_visualization_data"):
        var fractal_data = ethereal_bridge.get_fractal_visualization_data()
        
        if fractal_data.has("points"):
            fractal_points = fractal_data.points.duplicate()
            
            # Update dimension properties dictionary
            for point in fractal_points:
                if point.has("key"):
                    dimension_properties[point.key] = {
                        "frequency": point.frequency,
                        "stability": point.stability,
                        "position": point.position
                    }

func _on_fractal_data_updated(points):
    fractal_points = points.duplicate()
    
    # Update dimension properties
    for point in fractal_points:
        if point.has("key"):
            dimension_properties[point.key] = {
                "frequency": point.frequency,
                "stability": point.stability,
                "position": point.position
            }
    
    emit_signal("fractal_data_updated", fractal_points)

func _on_dimension_changed(previous, current):
    # Update current dimension
    current_dimension = current
    
    # Add to dimension stack
    dimension_stack.append(previous)
    if dimension_stack.size() > 12:
        dimension_stack.remove_at(0)
    
    # Update main window dimension
    window_dimensions["main"] = current
    _update_window_color("main", current)

# ----- PUBLIC API -----
func get_window_list():
    var result = []
    for window_ref in window_references:
        result.append({
            "id": window_ref.id,
            "state": window_states.get(window_ref.id, WindowState.NORMAL),
            "dimension": window_dimensions.get(window_ref.id, current_dimension),
            "position": window_positions.get(window_ref.id, Vector2.ZERO),
            "size": window_ref.size if window_ref.has("size") else base_window_size
        })
    return result

func arrange_windows_in_pattern(pattern_name: String):
    if not window_patterns.has(pattern_name):
        print("Pattern not found: " + pattern_name)
        return false
    
    var pattern = window_patterns[pattern_name]
    var points = pattern.points
    var transforms = pattern.transform_sequence
    
    # Ensure we have enough windows
    var window_count = min(window_references.size(), points.size())
    
    # Position windows according to pattern
    for i in range(window_count):
        var window_ref = window_references[i]
        var point = points[i]
        var transform_type = transforms[i % transforms.size()]
        
        # Set window position based on pattern point
        var screen_size = DisplayServer.screen_get_size()
        var position = Vector2(
            point.x * (screen_size.x - window_ref.size.x),
            point.y * (screen_size.y - window_ref.size.y)
        )
        
        set_window_position(window_ref.id, position)
        transform_window(window_ref.id, transform_type)
    
    return true

func create_dimensional_window_set(dimension_keys: Array):
    # Create a window for each dimension
    var created_windows = []
    
    for i in range(min(dimension_keys.size(), max_window_instances - window_references.size())):
        var dimension = dimension_keys[i]
        var window_id = "dim_" + dimension
        
        var window = create_window(window_id)
        if window:
            change_window_dimension(window_id, dimension)
            created_windows.append(window_id)
    
    return created_windows

func set_window_transform_speed(speed: float):
    window_transform_speed = max(0.1, speed)
    window_transition_duration = 1.0 / window_transform_speed
    return window_transform_speed

func generate_window_from_coordinates(x: int, y: int, z: int):
    if not ethereal_bridge or not ethereal_bridge.has_method("get_dimension_at_coordinates"):
        return null
    
    var dimension_key = ethereal_bridge.get_dimension_at_coordinates(x, y, z)
    if not dimension_key:
        return null
    
    var window_id = "dim_" + dimension_key
    var window = create_window(window_id)
    
    if window:
        change_window_dimension(window_id, dimension_key)
        
        # Position based on coordinates
        var position = Vector2(
            (x + dimensional_depth) * 100,
            (y + dimensional_depth) * 100
        )
        set_window_position(window_id, position)
        
        # Scale based on z coordinate
        var scale_factor = 1.0 + (z / float(dimensional_depth) * 0.5)
        set_window_size(window_id, base_window_size * scale_factor)
    
    return window

func combine_windows(window_ids: Array, pattern_name: String = ""):
    if window_ids.size() < 2:
        return false
    
    # If pattern provided, arrange windows in that pattern first
    if pattern_name != "" and window_patterns.has(pattern_name):
        var pattern = window_patterns[pattern_name]
        var points = pattern.points
        var transforms = pattern.transform_sequence
        
        for i in range(min(window_ids.size(), points.size())):
            var window_id = window_ids[i]
            if window_transforms.has(window_id):
                # Set position based on pattern
                var screen_size = DisplayServer.screen_get_size()
                var position = Vector2(
                    points[i].x * screen_size.x / 2,
                    points[i].y * screen_size.y / 2
                )
                
                set_window_position(window_id, position)
                
                # Apply transform
                var transform_type = transforms[i % transforms.size()]
                transform_window(window_id, transform_type)
    
    # In a real implementation, this would do more to visually combine the windows
    return true

func split_window(window_id: String, split_count: int = 2):
    if not window_dimensions.has(window_id):
        return []
    
    # Get original window's dimension and size
    var original_dimension = window_dimensions[window_id]
    var original_size = null
    var original_position = null
    
    for window_ref in window_references:
        if window_ref.id == window_id:
            original_size = window_ref.size if window_ref.has("size") else base_window_size
            original_position = window_positions.get(window_id, Vector2.ZERO)
            break
    
    if not original_size or not original_position:
        return []
    
    # Create new windows
    var new_windows = []
    for i in range(split_count):
        var new_id = window_id + "_split_" + str(i)
        
        # Calculate new position with offset
        var offset = Vector2(
            (i % 2) * original_size.x * 0.6,
            (i / 2) * original_size.y * 0.6
        )
        var new_position = original_position + offset
        
        # Calculate new size (smaller than original)
        var new_size = original_size * (0.7 / sqrt(split_count))
        
        # Create new window
        var window = create_window(new_id, new_size, new_position)
        if window:
            # Inherit dimension
            change_window_dimension(new_id, original_dimension)
            
            # Apply a transform
            var transform_keys = transform_matrices.keys()
            var random_transform = transform_keys[i % transform_keys.size()]
            transform_window(new_id, random_transform)
            
            new_windows.append(new_id)
    
    return new_windows
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/dimensional_window_transformer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/dimension_visualizer.gd
# SIZE: 21864 bytes
extends Spatial

class_name DimensionVisualizer

# Constants - Advanced color system with ghostly gradients and 3D effects
const DIMENSION_COLORS = [
    Color(0.2, 0.4, 0.8, 0.9), # Dimension 1 - Ethereal blue
    Color(0.3, 0.6, 0.9, 0.9), # Dimension 2 - Deeper azure
    Color(0.4, 0.7, 0.8, 0.9), # Dimension 3 - Teal essence
    Color(0.5, 0.8, 0.7, 0.9), # Dimension 4 - Seafoam spirit
    Color(0.6, 0.9, 0.6, 0.9), # Dimension 5 - Ghostly green
    Color(0.7, 0.9, 0.5, 0.9), # Dimension 6 - Spectral lime
    Color(0.8, 0.9, 0.4, 0.9), # Dimension 7 - Phantom yellow
    Color(0.9, 0.8, 0.3, 0.9), # Dimension 8 - Amber vision
    Color(0.9, 0.7, 0.2, 0.9), # Dimension 9 - Golden apparition
    Color(0.9, 0.6, 0.1, 0.9), # Dimension 10 - Ghostfire orange
    Color(0.9, 0.5, 0.0, 0.9), # Dimension 11 - Ember specter
    Color(1.0, 0.4, 0.0, 0.9)  # Dimension 12 - Flamecore phantom
]

# Secondary gradient colors for each dimension
const DIMENSION_GRADIENT_COLORS = [
    Color(0.1, 0.2, 0.6, 0.7), # Dimension 1 - Secondary
    Color(0.2, 0.3, 0.7, 0.7), # Dimension 2 - Secondary
    Color(0.3, 0.5, 0.6, 0.7), # Dimension 3 - Secondary
    Color(0.4, 0.6, 0.5, 0.7), # Dimension 4 - Secondary
    Color(0.5, 0.7, 0.4, 0.7), # Dimension 5 - Secondary
    Color(0.6, 0.7, 0.3, 0.7), # Dimension 6 - Secondary
    Color(0.7, 0.7, 0.2, 0.7), # Dimension 7 - Secondary
    Color(0.7, 0.6, 0.1, 0.7), # Dimension 8 - Secondary
    Color(0.7, 0.5, 0.1, 0.7), # Dimension 9 - Secondary
    Color(0.7, 0.4, 0.0, 0.7), # Dimension 10 - Secondary
    Color(0.7, 0.3, 0.0, 0.7), # Dimension 11 - Secondary
    Color(0.8, 0.2, 0.0, 0.7)  # Dimension 12 - Secondary
]

# Ghostly glow intensity for each dimension
const DIMENSION_GLOW = [
    0.3,  # Dimension 1
    0.35, # Dimension 2
    0.4,  # Dimension 3
    0.45, # Dimension 4
    0.5,  # Dimension 5
    0.55, # Dimension 6
    0.6,  # Dimension 7
    0.65, # Dimension 8
    0.7,  # Dimension 9
    0.75, # Dimension 10
    0.8,  # Dimension 11
    0.85  # Dimension 12
]

const POINTS_SHAPES = {
    "creation": "sphere",
    "exploration": "cube",
    "interaction": "cylinder",
    "challenge": "pyramid",
    "mastery": "star"
}

# Visualization options
export(bool) var auto_rotate = true
export(float) var rotation_speed = 0.5
export(float) var point_scale = 1.0
export(bool) var use_physics = false
export(String, "flat", "spiral", "cloud", "neural", "custom") var layout_mode = "spiral"
export(bool) var show_connections = true
export(int, 5, 100) var max_visible_points = 50
export(float, 0.1, 5.0) var animation_speed = 1.0

# Internal state
var current_dimension = 1
var dimension_progress = 0.0
var visualized_points = []
var visualized_categories = {}
var visualized_total = 0
var materials = {}
var meshes = {}
var point_instances = []
var camera_target = Vector3.ZERO
var noise = OpenSimplexNoise.new()
var animation_offset = 0.0

# References
var _account_manager = null

# 3D objects
var dimension_container
var point_container
var connection_container
var camera

func _ready():
    # Set up 3D scene
    setup_scene()
    
    # Connect to systems
    connect_to_systems()
    
    # Initialize noise for procedural motion
    noise.seed = randi()
    noise.octaves = 4
    noise.period = 20.0
    
    # Initial update
    update_visualization()

func _process(delta):
    # Auto-rotate if enabled
    if auto_rotate:
        dimension_container.rotate_y(delta * rotation_speed * 0.2)
    
    # Animate points if physics is not used
    if not use_physics:
        animate_points(delta)
    
    # Update animation offset
    animation_offset += delta * animation_speed

func setup_scene():
    # Create dimension container
    dimension_container = Spatial.new()
    add_child(dimension_container)
    
    # Create point container
    point_container = Spatial.new()
    dimension_container.add_child(point_container)
    
    # Create connection container
    connection_container = Spatial.new()
    dimension_container.add_child(connection_container)
    
    # Create camera
    var camera_pivot = Spatial.new()
    add_child(camera_pivot)
    
    camera = Camera.new()
    camera.translation = Vector3(0, 5, 10)
    camera.look_at(Vector3.ZERO, Vector3.UP)
    camera_pivot.add_child(camera)
    
    # Create materials for each dimension
    for i in range(DIMENSION_COLORS.size()):
        var material = SpatialMaterial.new()
        material.albedo_color = DIMENSION_COLORS[i]
        material.metallic = 0.7
        material.roughness = 0.2
        material.emission_enabled = true
        material.emission = DIMENSION_COLORS[i]
        material.emission_energy = 0.3
        materials[i + 1] = material
    
    # Create meshes for each point type
    create_point_meshes()

func create_point_meshes():
    # Sphere for creation points - ghostly flowing shape
    var sphere_mesh = SphereMesh.new()
    sphere_mesh.radius = 0.3
    sphere_mesh.height = 0.6
    sphere_mesh.radial_segments = 16
    sphere_mesh.rings = 8
    meshes["sphere"] = sphere_mesh

    # Cube for exploration points - spectral geometric form
    var cube_mesh = CubeMesh.new()
    cube_mesh.size = Vector3(0.5, 0.5, 0.5)
    meshes["cube"] = cube_mesh

    # Cylinder for interaction points - ethereal connection symbol
    var cylinder_mesh = CylinderMesh.new()
    cylinder_mesh.top_radius = 0.25
    cylinder_mesh.bottom_radius = 0.25
    cylinder_mesh.height = 0.6
    cylinder_mesh.radial_segments = 12
    cylinder_mesh.rings = 6
    meshes["cylinder"] = cylinder_mesh

    # Pyramid (prism) for challenge points - ascension form
    var prism_mesh = PrismMesh.new()
    prism_mesh.size = Vector3(0.5, 0.5, 0.5)
    meshes["pyramid"] = prism_mesh

    # Custom mesh for star (mastery) points - radiant achievement marker
    # In a real implementation, this would be a custom star mesh
    # For now, we'll use a specialized sphere with emissive material
    var star_mesh = SphereMesh.new()
    star_mesh.radius = 0.2
    star_mesh.height = 0.4
    star_mesh.radial_segments = 12
    star_mesh.rings = 6
    meshes["star"] = star_mesh

func connect_to_systems():
    # Connect to account manager
    if has_node("/root/SmartAccountManager") or get_node_or_null("/root/SmartAccountManager"):
        _account_manager = get_node("/root/SmartAccountManager")
        _account_manager.connect("points_updated", self, "_on_points_updated")
        _account_manager.connect("dimension_changed", self, "_on_dimension_changed")
        print("Connected to SmartAccountManager")
        
        # Initial values
        current_dimension = _account_manager.current_dimension
        dimension_progress = _account_manager.get_progress_to_next_dimension()
        
        # Load category points
        if _account_manager.points_categories:
            visualized_categories = _account_manager.points_categories.duplicate()
            
            for category in visualized_categories:
                visualized_total += visualized_categories[category]

func update_visualization():
    # Clear existing visualization
    clear_visualization()
    
    # Create new points based on current data
    create_points()
    
    # Update background/environment based on dimension
    update_environment()
    
    # Update camera position based on layout
    update_camera()

func clear_visualization():
    # Remove existing point instances
    for point in point_instances:
        if is_instance_valid(point):
            point.queue_free()
    
    # Clear arrays
    point_instances = []
    visualized_points = []
    
    # Clear connection lines
    for child in connection_container.get_children():
        child.queue_free()

func create_points():
    # Calculate total point count based on categories
    var total_points = min(max_visible_points, int(visualized_total / 100))
    total_points = max(total_points, 10) # Minimum 10 points
    
    # Create points for each category
    for category in visualized_categories:
        var category_points = int((visualized_categories[category] / visualized_total) * total_points)
        var shape = POINTS_SHAPES[category] if category in POINTS_SHAPES else "sphere"
        
        for i in range(category_points):
            create_point_instance(category, shape)
    
    # Calculate point positions based on layout
    position_points()
    
    # Create connections if enabled
    if show_connections:
        create_connections()

func create_point_instance(category, shape):
    # Create mesh instance with ghostly 3D gradient effect
    var mesh_instance = MeshInstance.new()
    mesh_instance.mesh = meshes[shape]

    # Create advanced material with ghostly effects
    var material = SpatialMaterial.new()

    # Get primary and secondary gradient colors
    var primary_color = DIMENSION_COLORS[current_dimension - 1]
    var secondary_color = DIMENSION_GRADIENT_COLORS[current_dimension - 1]
    var glow_intensity = DIMENSION_GLOW[current_dimension - 1]

    # Set material properties for ghostly appearance
    material.flags_transparent = true
    material.albedo_color = primary_color
    material.emission_enabled = true
    material.emission = primary_color
    material.emission_energy = glow_intensity
    material.rim_enabled = true
    material.rim = 0.5
    material.rim_tint = 0.5
    material.metallic = 0.7
    material.roughness = 0.2

    # Add vertex color support for gradient effect
    material.vertex_color_use_as_albedo = true

    # Adjust properties based on category for varied appearances
    match category:
        "creation":
            material.emission_energy = glow_intensity * 1.2
            material.roughness = 0.1
        "exploration":
            material.metallic = 0.5
            material.rim_tint = 0.7
        "interaction":
            material.emission_energy = glow_intensity * 0.9
            material.rim = 0.7
        "challenge":
            material.roughness = 0.4
            material.metallic = 0.9
        "mastery":
            material.emission_energy = glow_intensity * 1.5
            material.roughness = 0.0
            material.metallic = 1.0

    mesh_instance.material_override = material
    mesh_instance.scale = Vector3.ONE * point_scale

    # Apply a slight rotation for more visual interest
    mesh_instance.rotation_degrees = Vector3(
        randf() * 360.0,
        randf() * 360.0,
        randf() * 360.0
    )

    # Add to containers
    point_container.add_child(mesh_instance)
    point_instances.append(mesh_instance)

    # Add metadata
    mesh_instance.set_meta("category", category)
    mesh_instance.set_meta("primary_color", primary_color)
    mesh_instance.set_meta("secondary_color", secondary_color)
    mesh_instance.set_meta("glow_intensity", glow_intensity)

    # Add to visualization data
    visualized_points.append({
        "instance": mesh_instance,
        "category": category,
        "shape": shape,
        "position": Vector3.ZERO,
        "velocity": Vector3.ZERO,
        "created_at": OS.get_unix_time(),
        "primary_color": primary_color,
        "secondary_color": secondary_color,
        "glow_pulse_offset": randf() * TAU # Random offset for glow pulsing
    })

func position_points():
    match layout_mode:
        "flat":
            position_points_flat()
        "spiral":
            position_points_spiral()
        "cloud":
            position_points_cloud()
        "neural":
            position_points_neural()
        "custom":
            position_points_custom()
        _:
            position_points_spiral() # Default

func position_points_flat():
    var point_count = visualized_points.size()
    var radius = 5.0
    
    for i in range(point_count):
        var angle = (i / float(point_count)) * TAU
        var pos = Vector3(cos(angle) * radius, 0, sin(angle) * radius)
        
        visualized_points[i]["position"] = pos
        visualized_points[i]["instance"].translation = pos

func position_points_spiral():
    var point_count = visualized_points.size()
    var height_scale = 2.0
    var radius_scale = 5.0
    var rotations = 2.0
    
    for i in range(point_count):
        var t = i / float(point_count)
        var angle = t * TAU * rotations
        var radius = radius_scale * (0.2 + 0.8 * t)
        var height = height_scale * (t - 0.5)
        
        var pos = Vector3(cos(angle) * radius, height, sin(angle) * radius)
        
        visualized_points[i]["position"] = pos
        visualized_points[i]["instance"].translation = pos

func position_points_cloud():
    var point_count = visualized_points.size()
    var radius = 5.0
    
    for i in range(point_count):
        var phi = acos(1 - 2 * (i / float(point_count)))
        var theta = TAU * ((1 + sqrt(5)) / 2) * i
        
        var pos = Vector3(
            radius * sin(phi) * cos(theta),
            radius * sin(phi) * sin(theta),
            radius * cos(phi)
        )
        
        visualized_points[i]["position"] = pos
        visualized_points[i]["instance"].translation = pos

func position_points_neural():
    # Group points by category
    var points_by_category = {}
    
    for point in visualized_points:
        var category = point["category"]
        if not category in points_by_category:
            points_by_category[category] = []
        
        points_by_category[category].append(point)
    
    # Position each category in its own cluster
    var angle_offset = 0
    var category_count = points_by_category.size()
    
    for category in points_by_category:
        var points = points_by_category[category]
        var point_count = points.size()
        
        var cluster_angle = angle_offset * TAU / category_count
        var cluster_center = Vector3(
            cos(cluster_angle) * 4.0,
            0,
            sin(cluster_angle) * 4.0
        )
        
        # Position points around cluster center
        for i in range(point_count):
            var radius = 2.0
            var point_angle = (i / float(point_count)) * TAU
            
            var offset = Vector3(
                cos(point_angle) * radius * 0.5,
                (i % 3) - 1.0,
                sin(point_angle) * radius * 0.5
            )
            
            var pos = cluster_center + offset
            
            points[i]["position"] = pos
            points[i]["instance"].translation = pos
        
        angle_offset += 1

func position_points_custom():
    # This would implement a custom layout algorithm
    # For now, we'll just use a variation of the spiral
    
    var point_count = visualized_points.size()
    
    for i in range(point_count):
        var t = i / float(point_count)
        var angle = t * TAU * 3.0
        
        var category = visualized_points[i]["category"]
        var category_offset = 0.0
        
        if category == "creation":
            category_offset = 2.0
        elif category == "exploration":
            category_offset = 1.0
        elif category == "interaction":
            category_offset = 0.0
        elif category == "challenge":
            category_offset = -1.0
        elif category == "mastery":
            category_offset = -2.0
        
        var pos = Vector3(
            cos(angle) * (3.0 + t * 2.0),
            category_offset + sin(angle * 2.0),
            sin(angle) * (3.0 + t * 2.0)
        )
        
        visualized_points[i]["position"] = pos
        visualized_points[i]["instance"].translation = pos

func create_connections():
    # Create connections between points of the same category
    var points_by_category = {}
    
    for i in range(visualized_points.size()):
        var point = visualized_points[i]
        var category = point["category"]
        
        if not category in points_by_category:
            points_by_category[category] = []
        
        points_by_category[category].append(i)
    
    # Create connections for each category
    for category in points_by_category:
        var indices = points_by_category[category]
        
        if indices.size() <= 1:
            continue
        
        # Connect points in sequence
        for i in range(indices.size() - 1):
            var from_idx = indices[i]
            var to_idx = indices[i + 1]
            
            create_connection_line(
                visualized_points[from_idx]["position"],
                visualized_points[to_idx]["position"],
                DIMENSION_COLORS[current_dimension - 1]
            )

func create_connection_line(from_pos, to_pos, color):
    # In a real implementation, this would create a 3D line
    # This is a simplified version using an immediate geometry node
    
    var immediate = ImmediateGeometry.new()
    connection_container.add_child(immediate)
    
    var material = SpatialMaterial.new()
    material.albedo_color = color
    material.flags_unshaded = true
    material.flags_transparent = true
    material.params_blend_mode = SpatialMaterial.BLEND_MODE_ADD
    
    immediate.material_override = material
    
    immediate.begin(Mesh.PRIMITIVE_LINE_STRIP)
    immediate.add_vertex(from_pos)
    immediate.add_vertex(to_pos)
    immediate.end()

func update_environment():
    # In a real implementation, this would update the environment
    # based on the current dimension
    pass

func update_camera():
    # Calculate camera target position based on visualization
    calculate_camera_target()
    
    # In a real implementation, this would smoothly update the camera position
    # For now, we'll just print the target
    print("Camera target: " + str(camera_target))

func calculate_camera_target():
    # Calculate the centroid of all points
    var sum = Vector3.ZERO
    var count = visualized_points.size()
    
    if count == 0:
        camera_target = Vector3.ZERO
        return
    
    for point in visualized_points:
        sum += point["position"]
    
    camera_target = sum / count

func animate_points(delta):
    # Animate each point with ghostly gradient and 3D effects
    for i in range(visualized_points.size()):
        var point = visualized_points[i]
        var pos = point["position"]
        var instance = point["instance"]

        # Get noise values for organic movement
        var noise_val = noise.get_noise_3d(
            pos.x * 0.1,
            pos.y * 0.1 + animation_offset,
            pos.z * 0.1
        )

        var noise_val2 = noise.get_noise_3d(
            pos.z * 0.12,
            pos.x * 0.12 + animation_offset * 0.7,
            pos.y * 0.12
        )

        # Create ghostly motion effect
        var offset = Vector3(
            noise_val * 0.2,
            sin(animation_offset * 2.0 + pos.x * 0.3) * 0.1,
            noise_val2 * 0.2
        )

        # Apply position with ethereal movement
        instance.translation = pos + offset

        # Animate material properties for ghostly gradient effect
        if instance.material_override:
            var material = instance.material_override
            var primary_color = point["primary_color"]
            var secondary_color = point["secondary_color"]
            var glow_intensity = instance.get_meta("glow_intensity")
            var glow_pulse = sin(animation_offset * 1.5 + point["glow_pulse_offset"]) * 0.3 + 0.7

            # Create color gradients and ghostly pulsing
            material.emission_energy = glow_intensity * glow_pulse

            # Add slight rotation for ethereal floating effect
            instance.rotate_y(delta * 0.2 * noise_val)
            instance.rotate_x(delta * 0.1 * noise_val2)

            # Scale pulsing for a breathing effect
            var scale_pulse = 1.0 + sin(animation_offset + point["glow_pulse_offset"]) * 0.05
            instance.scale = Vector3.ONE * point_scale * scale_pulse

        # Add trail effect for mastery and creation categories
        if point["category"] == "mastery" or point["category"] == "creation":
            # In a real implementation, would create ghost trail particles here
            pass

func _on_points_updated(total, category, amount):
    # Update category values
    if _account_manager:
        visualized_categories = _account_manager.points_categories.duplicate()
        
        visualized_total = 0
        for cat in visualized_categories:
            visualized_total += visualized_categories[cat]
    
    # Update visualization if significant change
    if amount > 100 or visualized_points.size() < 10:
        update_visualization()

func _on_dimension_changed(new_dimension):
    # Update dimension
    current_dimension = new_dimension
    
    # Update dimension progress
    if _account_manager:
        dimension_progress = _account_manager.get_progress_to_next_dimension()
    
    # Update visualization
    update_visualization()
    
    # Play dimension transition effect
    play_dimension_transition_effect()

func play_dimension_transition_effect():
    # In a real implementation, this would play a visual/sound effect
    # For now, just print a message
    print("VISUAL EFFECT: Dimension transition to " + str(current_dimension))

func set_layout_mode(mode):
    if mode in ["flat", "spiral", "cloud", "neural", "custom"]:
        layout_mode = mode
        update_visualization()
        return true
    
    return false

func set_auto_rotate(enabled):
    auto_rotate = enabled
    return true

func set_point_scale(scale):
    point_scale = clamp(scale, 0.1, 3.0)
    
    # Update existing points
    for point in point_instances:
        if is_instance_valid(point):
            point.scale = Vector3.ONE * point_scale
    
    return true

func set_use_physics(enabled):
    use_physics = enabled
    return true

func set_max_visible_points(max_points):
    max_visible_points = clamp(max_points, 5, 100)
    update_visualization()
    return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/dimension_visualizer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/divine_game_controller.gd
# SIZE: 6715 bytes
extends Node

# Divine Game Controller
# Initializes and integrates all systems for the 12 turns word game
# Terminal 1: Divine Word Genesis

# Integration with existing main.gd system
var main_controller = null

func _ready():
	# Create the 12-turns system core components
	initialize_systems()
	initialize_ui()
	
	# Try to connect to existing main controller
	main_controller = get_node_or_null("/root/main")
	if main_controller:
		connect_to_main_controller()
	
	print("Divine Word Genesis System Initialized")
	print("Terminal 1: Divine Word Genesis is ready")
	print("12 turns system active - 9-second sacred interval enabled")

func initialize_systems():
	# Check if the new systems already exist
	if get_node_or_null("/root/DivineWordGame") == null:
		var word_game = DivineWordGame.new()
		word_game.name = "DivineWordGame"
		get_tree().root.add_child(word_game)
	
	if get_node_or_null("/root/WordCommentSystem") == null:
		var comment_system = WordCommentSystem.new()
		comment_system.name = "WordCommentSystem"
		get_tree().root.add_child(comment_system)
	
	if get_node_or_null("/root/WordDreamStorage") == null:
		var dream_storage = WordDreamStorage.new()
		dream_storage.name = "WordDreamStorage"
		get_tree().root.add_child(dream_storage)
	
	if get_node_or_null("/root/WordSalemGameController") == null:
		var salem_controller = WordSalemGameController.new()
		salem_controller.name = "WordSalemGameController"
		get_tree().root.add_child(salem_controller)
	
	if get_node_or_null("/root/WordCrimesAnalysis") == null:
		var crimes_analysis = WordCrimesAnalysis.new()
		crimes_analysis.name = "WordCrimesAnalysis" 
		get_tree().root.add_child(crimes_analysis)

func initialize_ui():
	# Create the main UI container
	var ui_container = Control.new()
	ui_container.name = "UIContainer"
	ui_container.set_anchors_preset(Control.PRESET_WIDE)
	add_child(ui_container)
	
	# Create the Divine Word UI
	var main_ui = DivineWordUI.new()
	main_ui.name = "DivineWordUI"
	main_ui.set_anchors_preset(Control.PRESET_WIDE)
	ui_container.add_child(main_ui)
	
	# Create the Word Comment UI
	var comment_ui = WordCommentUI.new()
	comment_ui.name = "WordCommentUI"
	comment_ui.set_anchors_preset(Control.PRESET_WIDE)
	comment_ui.visible = false  # Start hidden
	ui_container.add_child(comment_ui)
	
	# Create the Salem Game UI
	var salem_ui = WordSalemUI.new()
	salem_ui.name = "WordSalemUI"
	salem_ui.set_anchors_preset(Control.PRESET_WIDE)
	salem_ui.visible = false  # Start hidden
	ui_container.add_child(salem_ui)

func connect_to_main_controller():
	if main_controller:
		# Connect signals from main controller to our systems
		main_controller.connect("turn_advanced", self, "_on_main_turn_advanced")
		main_controller.connect("note_created", self, "_on_main_note_created")
		main_controller.connect("word_manifested", self, "_on_main_word_manifested")
		
		# Connect our divine word processor to the existing one
		var divine_word_processor = get_node_or_null("/root/DivineWordProcessor")
		var word_salem_controller = get_node_or_null("/root/WordSalemGameController")
		
		if divine_word_processor and word_salem_controller:
			# Connect signals for word processing
			if main_controller.word_processor:
				main_controller.word_processor.connect("word_processed", divine_word_processor, "_on_word_processed_external")
				
				# Also connect to Salem controller
				main_controller.word_processor.connect("word_processed", word_salem_controller, "_on_word_processed_external")
		
		print("Connected to existing main controller")

func _input(event):
	# Handle UI toggling with Tab key
	if event is InputEventKey and event.pressed:
		if event.scancode == KEY_TAB:
			toggle_ui()
		elif event.scancode == KEY_QUOTELEFT:  # Backtick key
			toggle_comment_mode()

func toggle_ui():
	# Toggle between different UI screens
	var ui_container = get_node("UIContainer")
	var main_ui = ui_container.get_node("DivineWordUI")
	var comment_ui = ui_container.get_node("WordCommentUI")
	var salem_ui = ui_container.get_node("WordSalemUI")
	
	if main_ui.visible:
		main_ui.visible = false
		comment_ui.visible = true
		salem_ui.visible = false
	elif comment_ui.visible:
		main_ui.visible = false
		comment_ui.visible = false
		salem_ui.visible = true
	else:
		main_ui.visible = true
		comment_ui.visible = false
		salem_ui.visible = false

func toggle_comment_mode():
	# Toggle dream mode in the comment UI
	var ui_container = get_node("UIContainer")
	var comment_ui = ui_container.get_node("WordCommentUI")
	
	# Make sure Comment UI is visible
	if !comment_ui.visible:
		ui_container.get_node("DivineWordUI").visible = false
		ui_container.get_node("WordSalemUI").visible = false
		comment_ui.visible = true
	
	# Toggle dream mode
	comment_ui._on_dream_toggle(!comment_ui.dream_mode)

# Event handlers for main controller signals

func _on_main_turn_advanced(turn_number, symbol, dimension):
	# Sync with our turn system
	var turn_system = get_node_or_null("/root/TurnSystem")
	if turn_system:
		turn_system.set_dimension(turn_number)
		print("Synchronized with main controller: Turn " + str(turn_number) + " - Dimension " + dimension)
		
		# Add comment about dimension change
		var word_comment_system = get_node_or_null("/root/WordCommentSystem")
		if word_comment_system:
			word_comment_system.add_comment("dimension_change", 
				"SYNCHRONIZED: Main controller advanced to " + dimension,
				word_comment_system.CommentType.OBSERVATION)

func _on_main_note_created(note_data):
	# Process the note in our systems
	var divine_word_processor = get_node_or_null("/root/DivineWordProcessor")
	var word_comment_system = get_node_or_null("/root/WordCommentSystem")
	
	if divine_word_processor and word_comment_system:
		var power = divine_word_processor.process_word(note_data.text, "Main_" + str(note_data.id))
		
		# Add as comment
		word_comment_system.add_comment("note_" + str(note_data.id),
			"NOTE: \"" + note_data.text + "\" from main controller (Power: " + str(power) + ")",
			word_comment_system.CommentType.OBSERVATION)
		
		print("Processed note from main controller: " + note_data.text)

func _on_main_word_manifested(word, position, power):
	# Process the manifested word in our systems
	var divine_word_game = get_node_or_null("/root/DivineWordGame")
	var word_comment_system = get_node_or_null("/root/WordCommentSystem")
	
	if divine_word_game and word_comment_system:
		# Process in game
		divine_word_game.process_word(word)
		
		# Add as divine comment
		word_comment_system.add_comment(word,
			"MANIFESTED: Word manifested from main controller at position " + str(position) + " with power " + str(power),
			word_comment_system.CommentType.DIVINE)
		
		print("Word manifested from main controller: " + word)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/divine_game_controller.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/divine_word_game.gd
# SIZE: 17004 bytes
extends Node

# Divine Word Game - Main Game Controller
# Integrates all systems for the 12 turns word game
# Terminal 1: Divine Word Genesis

class_name DivineWordGame

# Game state
enum GameState {
	MENU,
	PLAYING,
	PAUSED,
	GAME_OVER
}

var current_state = GameState.MENU
var current_level = 1
var player_name = "Divine Judge"
var score = 0
var turn_count = 0
var dimension_unlocked = 1  # Start with 1D unlocked

# References to other systems
var turn_system = null
var divine_word_processor = null
var word_salem_controller = null
var word_crimes_analysis = null
var word_comment_system = null
var word_dream_storage = null

# Game configuration
var config = {
	"turn_duration": 9.0,  # Sacred 9-second interval
	"dimensions": 12,
	"min_power_for_level_up": 100,
	"players": [],
	"word_targets": {},
	"banned_words": [],
	"sacred_words": [],
	"dimension_challenges": {}
}

# Signals
signal game_started
signal game_paused
signal game_resumed
signal game_over(final_score)
signal level_up(new_level)
signal dimension_unlocked(dimension)
signal word_target_completed(word, power)
signal turn_cycle_completed(cycle_number)

func _ready():
	initialize_game()
	connect_signals()
	setup_config()

func initialize_game():
	# Get references to all required systems
	turn_system = get_node_or_null("/root/TurnSystem")
	divine_word_processor = get_node_or_null("/root/DivineWordProcessor")
	word_salem_controller = get_node_or_null("/root/WordSalemGameController")
	word_crimes_analysis = get_node_or_null("/root/WordCrimesAnalysis")
	word_comment_system = get_node_or_null("/root/WordCommentSystem")
	word_dream_storage = get_node_or_null("/root/WordDreamStorage")
	
	# Create any missing systems
	if not turn_system:
		turn_system = TurnSystem.new()
		turn_system.name = "TurnSystem"
		get_tree().root.add_child(turn_system)
	
	if not divine_word_processor:
		divine_word_processor = DivineWordProcessor.new()
		divine_word_processor.name = "DivineWordProcessor"
		get_tree().root.add_child(divine_word_processor)
	
	if not word_salem_controller:
		word_salem_controller = WordSalemGameController.new()
		word_salem_controller.name = "WordSalemGameController"
		get_tree().root.add_child(word_salem_controller)
	
	if not word_crimes_analysis:
		word_crimes_analysis = WordCrimesAnalysis.new()
		word_crimes_analysis.name = "WordCrimesAnalysis"
		get_tree().root.add_child(word_crimes_analysis)
	
	if not word_comment_system:
		word_comment_system = WordCommentSystem.new()
		word_comment_system.name = "WordCommentSystem"
		get_tree().root.add_child(word_comment_system)
	
	if not word_dream_storage:
		word_dream_storage = WordDreamStorage.new()
		word_dream_storage.name = "WordDreamStorage"
		get_tree().root.add_child(word_dream_storage)

func connect_signals():
	if turn_system:
		turn_system.connect("turn_completed", self, "_on_turn_completed")
		turn_system.connect("dimension_changed", self, "_on_dimension_changed")
	
	if divine_word_processor:
		divine_word_processor.connect("word_processed", self, "_on_word_processed")
	
	if word_salem_controller:
		word_salem_controller.connect("game_over", self, "_on_salem_game_over")
		word_salem_controller.connect("word_crime_detected", self, "_on_word_crime_detected")
	
	if word_crimes_analysis:
		word_crimes_analysis.connect("dangerous_pattern_detected", self, "_on_dangerous_pattern_detected")
		word_crimes_analysis.connect("cosmic_power_threshold_reached", self, "_on_cosmic_power_threshold_reached")
	
	if word_comment_system:
		word_comment_system.connect("dream_recorded", self, "_on_dream_recorded")

func setup_config():
	# Set up initial game configuration
	
	# Add sample players for the Salem game
	config.players = [
		player_name,
		"Wordsmith",
		"Etymologist",
		"Word Sheriff",
		"Scribe",
		"Linguist",
		"Word Witch",
		"Mafia Godfather",
		"Mafia Silencer"
	]
	
	# Set up dimension challenges
	config.dimension_challenges = {
		1: {
			"name": "Linear Expression",
			"description": "Create words with at least 7 letters",
			"target_words": ["dimension", "linearly", "sequence", "oneness"],
			"min_power": 15,
			"reward": 100
		},
		2: {
			"name": "Planar Reflection",
			"description": "Create palindromes (words that read the same backward)",
			"target_words": ["level", "radar", "kayak", "deified"],
			"min_power": 20,
			"reward": 200
		},
		3: {
			"name": "Spatial Construction",
			"description": "Create words related to 3D space",
			"target_words": ["cube", "volume", "sphere", "depth", "breadth"],
			"min_power": 25,
			"reward": 300
		},
		4: {
			"name": "Temporal Flow",
			"description": "Create words related to time",
			"target_words": ["moment", "eternity", "chronos", "temporal"],
			"min_power": 30,
			"reward": 400
		},
		5: {
			"name": "Probability Waves",
			"description": "Create words containing 'qu' (quantum notation)",
			"target_words": ["quantum", "quark", "qubit", "liquid"],
			"min_power": 35,
			"reward": 500
		},
		6: {
			"name": "Phase Resonance",
			"description": "Create words with repeating letters",
			"target_words": ["bubble", "summer", "coffee", "llama"],
			"min_power": 40,
			"reward": 600
		},
		7: {
			"name": "Dream Weaving",
			"description": "Create words related to dreams or sleep",
			"target_words": ["dream", "sleep", "unconscious", "astral"],
			"min_power": 45,
			"reward": 700
		},
		8: {
			"name": "Interconnection",
			"description": "Create compound words",
			"target_words": ["starlight", "moonbeam", "sunflower", "rainfall"],
			"min_power": 50,
			"reward": 800
		},
		9: {
			"name": "Divine Judgment",
			"description": "Create words related to judgment or decision",
			"target_words": ["verdict", "justice", "balance", "decision"],
			"min_power": 55,
			"reward": 900
		},
		10: {
			"name": "Harmonic Convergence",
			"description": "Create words with vowel harmony",
			"target_words": ["banana", "elegant", "harmony", "symphony"],
			"min_power": 60,
			"reward": 1000
		},
		11: {
			"name": "Conscious Reflection",
			"description": "Create words related to thought and consciousness",
			"target_words": ["awareness", "cognition", "thought", "sentient"],
			"min_power": 65,
			"reward": 1100
		},
		12: {
			"name": "Divine Manifestation",
			"description": "Create words of spiritual or divine significance",
			"target_words": ["divine", "sacred", "eternal", "transcend"],
			"min_power": 70,
			"reward": 1200
		}
	}
	
	# Set up banned words
	config.banned_words = [
		"delete",
		"crash",
		"error",
		"terminate",
		"kill",
		"destroy",
		"corrupt"
	]
	
	# Set up sacred words
	config.sacred_words = [
		"divine",
		"transcend",
		"genesis",
		"creation",
		"harmony",
		"balance",
		"eternity"
	]
	
	# Set up word targets for current level
	update_word_targets()

func update_word_targets():
	config.word_targets = {}
	
	# Add dimension-specific targets based on current dimension
	var dimension = turn_system.current_dimension if turn_system else 1
	
	if config.dimension_challenges.has(dimension):
		var challenge = config.dimension_challenges[dimension]
		for word in challenge.target_words:
			config.word_targets[word] = {
				"completed": false,
				"min_power": challenge.min_power,
				"reward": challenge.reward / challenge.target_words.size()
			}
	
	# Add level-specific targets
	var level_words = []
	match current_level:
		1: level_words = ["start", "begin", "create"]
		2: level_words = ["expand", "develop", "grow"]
		3: level_words = ["transform", "evolve", "change"]
		4: level_words = ["master", "perfect", "complete"]
		5: level_words = ["transcend", "ascend", "divine"]
	
	for word in level_words:
		config.word_targets[word] = {
			"completed": false,
			"min_power": 20 * current_level,
			"reward": 50 * current_level
		}

func start_game():
	if current_state != GameState.MENU:
		return false
	
	current_state = GameState.PLAYING
	score = 0
	turn_count = 0
	current_level = 1
	dimension_unlocked = 1
	
	# Start the turn system
	if turn_system:
		turn_system.start_turns()
	
	# Start the Salem game
	if word_salem_controller:
		word_salem_controller.start_game(config.players)
	
	emit_signal("game_started")
	return true

func pause_game():
	if current_state != GameState.PLAYING:
		return false
	
	current_state = GameState.PAUSED
	
	# Pause the turn system
	if turn_system:
		turn_system.pause_turns()
	
	emit_signal("game_paused")
	return true

func resume_game():
	if current_state != GameState.PAUSED:
		return false
	
	current_state = GameState.PLAYING
	
	# Resume the turn system
	if turn_system:
		turn_system.resume_turns()
	
	emit_signal("game_resumed")
	return true

func end_game():
	if current_state != GameState.PLAYING and current_state != GameState.PAUSED:
		return false
	
	current_state = GameState.GAME_OVER
	
	# Stop the turn system
	if turn_system:
		turn_system.stop_turns()
	
	emit_signal("game_over", score)
	return true

func process_word(word):
	if current_state != GameState.PLAYING:
		return 0
	
	var power = 0
	
	# Check for banned words
	if word.to_lower() in config.banned_words:
		# Penalty for using banned words
		score -= 50
		if word_comment_system:
			word_comment_system.add_comment(word, "BANNED WORD: Penalty applied", 
				word_comment_system.CommentType.WARNING)
		return -1
	
	# Process the word
	if divine_word_processor:
		power = divine_word_processor.process_word(word, player_name)
	
	# Check for word targets
	check_word_targets(word, power)
	
	# Check for sacred words
	if word.to_lower() in config.sacred_words:
		# Bonus for using sacred words
		var bonus = power * 2
		score += bonus
		if word_comment_system:
			word_comment_system.add_comment(word, "SACRED WORD: Bonus applied +" + str(bonus), 
				word_comment_system.CommentType.DIVINE)
	
	return power

func check_word_targets(word, power):
	if not config.word_targets.has(word.to_lower()):
		return
	
	var target = config.word_targets[word.to_lower()]
	
	if not target.completed and power >= target.min_power:
		target.completed = true
		score += target.reward
		emit_signal("word_target_completed", word, power)
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment(word, "TARGET COMPLETED: +" + str(target.reward) + " points", 
				word_comment_system.CommentType.DIVINE)
		
		# Check if all targets for this dimension are completed
		check_dimension_completion()

func check_dimension_completion():
	var all_completed = true
	var dimension = turn_system.current_dimension if turn_system else 1
	
	if not config.dimension_challenges.has(dimension):
		return
	
	var challenge = config.dimension_challenges[dimension]
	
	for word in challenge.target_words:
		if config.word_targets.has(word) and not config.word_targets[word].completed:
			all_completed = false
			break
	
	if all_completed:
		# Unlock the next dimension
		unlock_dimension(dimension + 1)
		
		# Add bonus points
		score += challenge.reward
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment("dimension_" + str(dimension), 
				"DIMENSION MASTERED: All targets completed! +" + str(challenge.reward) + " bonus points", 
				word_comment_system.CommentType.DIVINE)

func unlock_dimension(dimension):
	if dimension > 12 or dimension <= dimension_unlocked:
		return
	
	dimension_unlocked = dimension
	emit_signal("dimension_unlocked", dimension)
	
	# Add comment
	if word_comment_system:
		word_comment_system.add_comment("dimension_unlock", 
			"DIMENSION " + str(dimension) + " UNLOCKED: New challenges await!", 
			word_comment_system.CommentType.DIVINE)
	
	# Update targets to include new dimension challenges
	update_word_targets()

func check_level_up():
	var target_score = current_level * config.min_power_for_level_up
	
	if score >= target_score:
		current_level += 1
		emit_signal("level_up", current_level)
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment("level_up", 
				"LEVEL UP: You have reached level " + str(current_level) + "!", 
				word_comment_system.CommentType.DIVINE)
		
		# Update targets for new level
		update_word_targets()
		
		return true
	
	return false

func _on_turn_completed(turn_number):
	turn_count = turn_number
	
	# Every 12 turns, a full cycle is completed
	if turn_number % 12 == 0:
		var cycle_number = turn_number / 12
		emit_signal("turn_cycle_completed", cycle_number)
		
		# Add cycle completion bonus
		score += cycle_number * 100
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment("cycle_" + str(cycle_number), 
				"CYCLE COMPLETED: +" + str(cycle_number * 100) + " points", 
				word_comment_system.CommentType.OBSERVATION)
		
		# Check for level up
		check_level_up()

func _on_dimension_changed(new_dimension, old_dimension):
	# Update word targets when dimension changes
	update_word_targets()
	
	# Add comment
	if word_comment_system:
		word_comment_system.add_comment("dimension_change", 
			"DIMENSION CHANGED: From " + str(old_dimension) + "D to " + str(new_dimension) + "D", 
			word_comment_system.CommentType.OBSERVATION)

func _on_word_processed(word, power, source_player):
	# Only handle words from the player
	if source_player != player_name:
		return
	
	# Add points based on word power
	score += power
	
	# Special handling for dimension 9 (judgment dimension)
	if turn_system and turn_system.current_dimension == 9:
		# In dimension 9, words have special judgment powers
		if power >= 50:
			# High power words in dimension 9 can influence Salem game judgment
			if word_salem_controller and word_salem_controller.current_state == word_salem_controller.GameState.JUDGMENT:
				word_salem_controller.influence_judgment(word, power)
	
	# Special handling for dimension 7 (dream dimension)
	if turn_system and turn_system.current_dimension == 7:
		# In dimension 7, words can generate dreams
		if power >= 30 and word_comment_system:
			word_comment_system.generate_dream_for_word(word, power)

func _on_salem_game_over(winning_faction):
	# Add points based on winning faction
	if winning_faction == "Town":
		score += 1000
	elif winning_faction == "Mafia":
		score += 500
	
	# Add comment
	if word_comment_system:
		word_comment_system.add_comment("salem_game", 
			"SALEM GAME OVER: " + winning_faction + " wins!", 
			word_comment_system.CommentType.OBSERVATION)

func _on_word_crime_detected(criminal, crime_type, word_power):
	# If the player commits crimes, apply penalties
	if criminal == player_name:
		var penalty = 0
		match crime_type:
			"minor": penalty = 10
			"moderate": penalty = 25
			"major": penalty = 50
			"cosmic": penalty = 100
		
		score -= penalty
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment("crime_penalty", 
				"CRIME PENALTY: -" + str(penalty) + " points for " + crime_type + " crime", 
				word_comment_system.CommentType.WARNING)

func _on_dangerous_pattern_detected(pattern, word, power):
	# Apply penalty for dangerous patterns
	if current_state == GameState.PLAYING:
		score -= 30
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment(word, 
				"DANGEROUS PATTERN: -30 points for using pattern '" + pattern + "'", 
				word_comment_system.CommentType.WARNING)

func _on_cosmic_power_threshold_reached(word, power):
	# Apply bonus for cosmic power words
	if current_state == GameState.PLAYING:
		var bonus = power * 3
		score += bonus
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment(word, 
				"COSMIC POWER: +" + str(bonus) + " points for reaching cosmic power", 
				word_comment_system.CommentType.DIVINE)
		
		# Cosmic power words automatically unlock the next dimension if not already unlocked
		if turn_system:
			unlock_dimension(turn_system.current_dimension + 1)

func _on_dream_recorded(dream_text, power_level):
	# Apply bonus for recording dreams
	if current_state == GameState.PLAYING:
		var bonus = power_level
		score += bonus
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment("dream_bonus", 
				"DREAM RECORDED: +" + str(bonus) + " points", 
				word_comment_system.CommentType.DREAM)

# Public API for game interaction

func submit_word(word):
	if current_state != GameState.PLAYING:
		return 0
	
	return process_word(word)

func get_dimension_challenge():
	var dimension = turn_system.current_dimension if turn_system else 1
	
	if config.dimension_challenges.has(dimension):
		return config.dimension_challenges[dimension]
	
	return null

func get_current_targets():
	var targets = []
	
	for word in config.word_targets.keys():
		targets.append({
			"word": word,
			"completed": config.word_targets[word].completed,
			"min_power": config.word_targets[word].min_power,
			"reward": config.word_targets[word].reward
		})
	
	return targets

func get_game_stats():
	return {
		"player_name": player_name,
		"score": score,
		"level": current_level,
		"turn_count": turn_count,
		"dimension": turn_system.current_dimension if turn_system else 1,
		"dimension_unlocked": dimension_unlocked,
		"state": current_state
	}

func restart_game():
	end_game()
	start_game()
	return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/divine_word_game.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/divine_word_processor.gd
# SIZE: 9863 bytes
extends Node

class_name DivineWordProcessor

# ----- WORD POWER SYSTEM -----
const POWER_THRESHOLD = 50  # Words with power > 50 create reality impacts
const REALITY_THRESHOLD = 200  # Combined power for persistent reality
const GOD_WORD_MULTIPLIER = 2.0  # Multiplier for divine words

# ----- WORD DICTIONARIES -----
var word_power_dictionary = {
    "god": 100,
    "divine": 75,
    "eternal": 50,
    "infinite": 50, 
    "creation": 40,
    "reality": 35,
    "universe": 30,
    "perfect": 25,
    "absolute": 20,
    "supreme": 15,
    "transcendent": 18,
    "omniscient": 45,
    "omnipotent": 48,
    "celestial": 28,
    "sovereign": 22,
    "immortal": 33,
    "timeless": 30,
    "limitless": 29,
    "almighty": 43,
    "sacred": 19
}

var typo_corrections = {
    "tiyr": "tier",
    "n==": "new",
    "t": "it",
    "orf": "of",
    "fo": "of",
    "teh": "the",
    "adn": "and",
    "taht": "that",
    "wiht": "with",
    "hte": "the",
    "trun": "turn",
    "si": "is",
    "jsut": "just",
    "becuase": "because",
    "thsi": "this",
    "waht": "what",
    "suer": "sure",
    "thign": "thing",
    "togehter": "together",
    "goign": "going",
    "tiem": "time",
    "liek": "like",
    "eahc": "each",
    "rigth": "right",
    "worht": "worth",
    "differnet": "different",
    "creat": "create",
    "divin": "divine",
    "eternl": "eternal"
}

# ----- MEMORY STORAGE -----
var memories = {
    1: [], # Tier 1 - recent and vivid
    2: [], # Tier 2 - important but older
    3: []  # Tier 3 - archived foundational
}

# ----- REALITY STORAGE -----
var realities = []
var active_manifestations = []
var divine_account = {
    "id": "JSH_DIVINE_" + str(randi()),
    "creation_date": OS.get_datetime(),
    "divine_level": 1,
    "word_count": 0,
    "reality_count": 0
}

# ----- SIGNALS -----
signal word_processed(word, power)
signal reality_created(reality_data)
signal memory_stored(memory_data)
signal divine_level_changed(new_level)

# ----- INITIALIZATION -----
func _ready():
    print("Divine Word Processor initialized")
    print("Word dictionary loaded with %d divine words" % word_power_dictionary.size())

# ----- WORD PROCESSING -----
func process_text(text, source="manual", tier=1):
    # Apply autocorrect
    var corrected_text = apply_autocorrect(text)
    
    # Only record if text changed
    if corrected_text != text:
        print("Divine autocorrect applied: '%s' ‚Üí '%s'" % [text, corrected_text])
    
    # Split into words
    var words = extract_words(corrected_text)
    
    # Track powerful words
    var powerful_words = []
    var total_power = 0
    
    # Process each word
    for word in words:
        var power = check_word_power(word.to_lower())
        if power > 0:
            total_power += power
            divine_account.word_count += 1
            
            if power > POWER_THRESHOLD:
                powerful_words.append({"word": word, "power": power})
        
        # Emit signal for each processed word
        emit_signal("word_processed", word, power)
    
    # Create memory if text is substantial
    if words.size() > 0:
        create_memory(corrected_text, tier, powerful_words, total_power)
    
    # Check for reality impacts
    if total_power > POWER_THRESHOLD:
        create_reality_impact(corrected_text, powerful_words, total_power)
    
    # Increase divine level based on word power
    var level_increase = int(total_power / 100)
    if level_increase > 0:
        divine_account.divine_level += level_increase
        emit_signal("divine_level_changed", divine_account.divine_level)
    
    return {
        "original": text,
        "corrected": corrected_text,
        "word_count": words.size(),
        "powerful_words": powerful_words,
        "total_power": total_power
    }

# Extract words from text
func extract_words(text):
    # Simple word extraction - split by spaces and remove punctuation
    var words_with_punctuation = text.split(" ", false)
    var words = []
    
    for word in words_with_punctuation:
        var cleaned_word = word.strip_edges()
        # Remove common punctuation
        cleaned_word = cleaned_word.replace(",", "").replace(".", "").replace("!", "").replace("?", "")
        if cleaned_word.length() > 0:
            words.append(cleaned_word)
    
    return words

# Apply autocorrect to text
func apply_autocorrect(text):
    var corrected = text
    
    for typo in typo_corrections:
        corrected = corrected.replace(typo, typo_corrections[typo])
    
    return corrected

# Check power level of a word
func check_word_power(word):
    if word_power_dictionary.has(word):
        return word_power_dictionary[word]
    
    # Unknown words have minimal power
    return 1

# ----- MEMORY FUNCTIONS -----
func create_memory(text, tier, powerful_words, power):
    var timestamp = OS.get_unix_time()
    
    var memory = {
        "id": "memory_" + str(timestamp) + "_" + str(randi() % 10000),
        "text": text,
        "tier": tier,
        "timestamp": timestamp,
        "date": OS.get_datetime(),
        "powerful_words": powerful_words,
        "power": power,
        "linked_realities": []
    }
    
    # Store in appropriate tier
    if tier >= 1 and tier <= 3:
        memories[tier].append(memory)
    else:
        # Default to tier 1 for invalid tiers
        memories[1].append(memory)
    
    emit_signal("memory_stored", memory)
    
    # Very powerful memories automatically promote to higher tier
    if power > REALITY_THRESHOLD and tier < 3:
        var promoted_memory = memory.duplicate()
        promoted_memory.tier = 3
        promoted_memory.id = "memory_promoted_" + promoted_memory.id
        memories[3].append(promoted_memory)
        
        print("Memory automatically promoted to Tier 3 due to high power (%d)" % power)
    
    return memory

# Get all memories at a specific tier
func get_memories_by_tier(tier):
    if tier >= 1 and tier <= 3 and memories.has(tier):
        return memories[tier]
    return []

# Get all memories
func get_all_memories():
    var all_memories = []
    for tier in memories:
        all_memories.append_array(memories[tier])
    return all_memories

# ----- REALITY FUNCTIONS -----
func create_reality_impact(source_text, powerful_words, total_power):
    var timestamp = OS.get_unix_time()
    var reality_id = "reality_" + str(timestamp) + "_" + str(randi() % 10000)
    
    # Calculate persistence based on power
    var is_persistent = total_power > REALITY_THRESHOLD
    var duration = is_persistent ? -1 : int(total_power * 60) # -1 means permanent
    
    var reality = {
        "id": reality_id,
        "source_text": source_text,
        "powerful_words": powerful_words,
        "total_power": total_power,
        "timestamp": timestamp,
        "date": OS.get_datetime(),
        "is_persistent": is_persistent,
        "duration": duration,
        "active": true
    }
    
    # Add to realities list
    realities.append(reality)
    active_manifestations.append(reality)
    divine_account.reality_count += 1
    
    print("Reality impact created with power %d" % total_power)
    if is_persistent:
        print("This reality is PERSISTENT due to high power level!")
    else:
        var duration_mins = duration / 60
        print("This reality will last for approximately %d minutes" % duration_mins)
    
    emit_signal("reality_created", reality)
    
    return reality

# Save the current reality state with a name
func save_reality_state(name):
    var timestamp = OS.get_unix_time()
    var save_id = "divine_save_" + str(timestamp)
    
    var save_data = {
        "id": save_id,
        "name": name,
        "timestamp": timestamp,
        "date": OS.get_datetime(),
        "memories": get_all_memories(),
        "realities": realities.duplicate(),
        "active_manifestations": active_manifestations.duplicate(),
        "divine_account": divine_account.duplicate()
    }
    
    # Save to a JSON file
    var file = File.new()
    var save_path = "user://divine_saves/" + name + "_" + str(timestamp) + ".json"
    
    # Ensure directory exists
    var dir = Directory.new()
    if !dir.dir_exists("user://divine_saves"):
        dir.make_dir_recursive("user://divine_saves")
    
    # Save file
    file.open(save_path, File.WRITE)
    file.store_string(JSON.print(save_data, "  "))
    file.close()
    
    print("Divine reality state saved as '%s'" % name)
    print("Save location: %s" % save_path)
    
    return save_data

# ----- UTILITY FUNCTIONS -----
func get_divine_status():
    var level = divine_account.divine_level
    var status = "Novice Creator"
    
    if level > 1000:
        status = "Supreme Deity"
    elif level > 500:
        status = "Greater God"
    elif level > 200:
        status = "Lesser God"
    elif level > 100:
        status = "Demigod"
    elif level > 50:
        status = "Divine Aspirant"
    
    return {
        "level": level,
        "status": status,
        "words_processed": divine_account.word_count,
        "realities_created": divine_account.reality_count,
        "memory_count": get_all_memories().size()
    }

# Print divine status to console
func print_divine_status():
    var status = get_divine_status()
    
    print("=== DIVINE ACCOUNT STATUS ===")
    print("Divine Level: %d (%s)" % [status.level, status.status])
    print("Words Processed: %d" % status.words_processed)
    print("Realities Created: %d" % status.realities_created)
    print("Memories Stored: %d" % status.memory_count)
    
    # Print memory breakdown
    print("\nMemory Tiers:")
    for tier in memories:
        print("- Tier %d: %d memories" % [tier, memories[tier].size()])
    
    # Print active manifestations
    print("\nActive Reality Manifestations: %d" % active_manifestations.size())
    
    return status
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/divine_word_processor.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/divine_word_ui.gd
# SIZE: 14544 bytes
extends Control

# Divine Word UI
# Main user interface for the Divine Word Game
# Terminal 1: Divine Word Genesis

class_name DivineWordUI

# UI Components
var word_input
var submit_button
var score_label
var level_label
var dimension_label
var turn_label
var message_log
var targets_panel
var challenge_panel
var dimension_indicator

# Game references
var divine_word_game = null
var turn_system = null
var divine_word_processor = null

# Visual elements
var dimension_colors = [
	Color(1, 0, 0),      # 1D - Red
	Color(1, 0.5, 0),    # 2D - Orange
	Color(1, 1, 0),      # 3D - Yellow
	Color(0, 1, 0),      # 4D - Green
	Color(0, 1, 1),      # 5D - Cyan
	Color(0, 0, 1),      # 6D - Blue
	Color(0.5, 0, 1),    # 7D - Purple
	Color(1, 0, 1),      # 8D - Magenta
	Color(1, 0.5, 0.5),  # 9D - Pink (significant)
	Color(0.5, 1, 0.5),  # 10D - Light Green
	Color(0.5, 0.5, 1),  # 11D - Light Blue
	Color(1, 1, 1)       # 12D - White
]

# Nine-second timer
var nine_second_timer = 9.0
var timer_bar

func _ready():
	initialize_ui()
	connect_systems()

func initialize_ui():
	# Set up the main layout
	set_anchors_preset(Control.PRESET_WIDE)
	
	var main_container = VBoxContainer.new()
	main_container.set_anchors_preset(Control.PRESET_WIDE)
	add_child(main_container)
	
	# Header with game info
	var header = HBoxContainer.new()
	main_container.add_child(header)
	
	var title_label = Label.new()
	title_label.text = "DIVINE WORD GENESIS"
	title_label.size_flags_horizontal = SIZE_EXPAND_FILL
	header.add_child(title_label)
	
	score_label = Label.new()
	score_label.text = "Score: 0"
	score_label.size_flags_horizontal = SIZE_EXPAND_FILL
	header.add_child(score_label)
	
	level_label = Label.new()
	level_label.text = "Level: 1"
	level_label.size_flags_horizontal = SIZE_EXPAND_FILL
	header.add_child(level_label)
	
	turn_label = Label.new()
	turn_label.text = "Turn: 0"
	turn_label.size_flags_horizontal = SIZE_EXPAND_FILL
	header.add_child(turn_label)
	
	dimension_label = Label.new()
	dimension_label.text = "Dimension: 1D"
	dimension_label.size_flags_horizontal = SIZE_EXPAND_FILL
	header.add_child(dimension_label)
	
	# Timer bar for the 9-second interval
	timer_bar = ProgressBar.new()
	timer_bar.max_value = 9.0
	timer_bar.min_value = 0.0
	timer_bar.value = 9.0
	timer_bar.size_flags_horizontal = SIZE_EXPAND_FILL
	main_container.add_child(timer_bar)
	
	# Main content area
	var content_container = HBoxContainer.new()
	content_container.size_flags_vertical = SIZE_EXPAND_FILL
	main_container.add_child(content_container)
	
	# Left panel - Dimension visualization
	var left_panel = VBoxContainer.new()
	left_panel.size_flags_horizontal = SIZE_EXPAND_FILL
	left_panel.size_flags_stretch_ratio = 0.3
	content_container.add_child(left_panel)
	
	var dimension_label = Label.new()
	dimension_label.text = "DIMENSIONS"
	left_panel.add_child(dimension_label)
	
	dimension_indicator = ColorRect.new()
	dimension_indicator.color = dimension_colors[0]
	dimension_indicator.size_flags_vertical = SIZE_EXPAND_FILL
	left_panel.add_child(dimension_indicator)
	
	var dimension_grid = GridContainer.new()
	dimension_grid.columns = 4
	left_panel.add_child(dimension_grid)
	
	for i in range(12):
		var dim_button = Button.new()
		dim_button.text = str(i + 1) + "D"
		dim_button.set_h_size_flags(SIZE_EXPAND_FILL)
		dim_button.connect("pressed", self, "_on_dimension_button_pressed", [i + 1])
		dimension_grid.add_child(dim_button)
	
	# Center panel - Message log and word input
	var center_panel = VBoxContainer.new()
	center_panel.size_flags_horizontal = SIZE_EXPAND_FILL
	center_panel.size_flags_stretch_ratio = 0.4
	content_container.add_child(center_panel)
	
	var log_label = Label.new()
	log_label.text = "MESSAGE LOG"
	center_panel.add_child(log_label)
	
	message_log = RichTextLabel.new()
	message_log.bbcode_enabled = true
	message_log.size_flags_vertical = SIZE_EXPAND_FILL
	center_panel.add_child(message_log)
	
	var input_container = HBoxContainer.new()
	center_panel.add_child(input_container)
	
	word_input = LineEdit.new()
	word_input.placeholder_text = "Enter a word..."
	word_input.size_flags_horizontal = SIZE_EXPAND_FILL
	word_input.connect("text_entered", self, "_on_word_submitted")
	input_container.add_child(word_input)
	
	submit_button = Button.new()
	submit_button.text = "Submit"
	submit_button.connect("pressed", self, "_on_submit_pressed")
	input_container.add_child(submit_button)
	
	# Right panel - Challenge and targets
	var right_panel = VBoxContainer.new()
	right_panel.size_flags_horizontal = SIZE_EXPAND_FILL
	right_panel.size_flags_stretch_ratio = 0.3
	content_container.add_child(right_panel)
	
	var challenge_label = Label.new()
	challenge_label.text = "DIMENSION CHALLENGE"
	right_panel.add_child(challenge_label)
	
	challenge_panel = RichTextLabel.new()
	challenge_panel.bbcode_enabled = true
	challenge_panel.size_flags_vertical = SIZE_EXPAND_FILL
	challenge_panel.size_flags_stretch_ratio = 0.4
	right_panel.add_child(challenge_panel)
	
	var targets_label = Label.new()
	targets_label.text = "WORD TARGETS"
	right_panel.add_child(targets_label)
	
	targets_panel = RichTextLabel.new()
	targets_panel.bbcode_enabled = true
	targets_panel.size_flags_vertical = SIZE_EXPAND_FILL
	targets_panel.size_flags_stretch_ratio = 0.6
	right_panel.add_child(targets_panel)
	
	# Game buttons
	var game_buttons = HBoxContainer.new()
	main_container.add_child(game_buttons)
	
	var start_button = Button.new()
	start_button.text = "Start Game"
	start_button.connect("pressed", self, "_on_start_button_pressed")
	game_buttons.add_child(start_button)
	
	var pause_button = Button.new()
	pause_button.text = "Pause"
	pause_button.connect("pressed", self, "_on_pause_button_pressed")
	game_buttons.add_child(pause_button)
	
	var help_button = Button.new()
	help_button.text = "Help"
	help_button.connect("pressed", self, "_on_help_button_pressed")
	game_buttons.add_child(help_button)

func connect_systems():
	divine_word_game = get_node("/root/DivineWordGame")
	turn_system = get_node("/root/TurnSystem")
	divine_word_processor = get_node("/root/DivineWordProcessor")
	
	if divine_word_game:
		divine_word_game.connect("game_started", self, "_on_game_started")
		divine_word_game.connect("game_paused", self, "_on_game_paused")
		divine_word_game.connect("game_resumed", self, "_on_game_resumed")
		divine_word_game.connect("game_over", self, "_on_game_over")
		divine_word_game.connect("level_up", self, "_on_level_up")
		divine_word_game.connect("dimension_unlocked", self, "_on_dimension_unlocked")
		divine_word_game.connect("word_target_completed", self, "_on_word_target_completed")
	
	if turn_system:
		turn_system.connect("turn_completed", self, "_on_turn_completed")
		turn_system.connect("dimension_changed", self, "_on_dimension_changed")
	
	if divine_word_processor:
		divine_word_processor.connect("word_processed", self, "_on_word_processed")

func _process(delta):
	if turn_system and turn_system.is_running:
		# Update the 9-second timer
		nine_second_timer -= delta
		
		if nine_second_timer <= 0:
			nine_second_timer = 9.0  # Reset to the sacred 9-second interval
		
		timer_bar.value = nine_second_timer
		
		# Update timer bar color based on urgency
		if nine_second_timer < 3.0:
			timer_bar.modulate = Color(1, 0, 0)  # Red
		elif nine_second_timer < 6.0:
			timer_bar.modulate = Color(1, 1, 0)  # Yellow
		else:
			timer_bar.modulate = Color(0, 1, 0)  # Green
	
	# Update game stats
	if divine_word_game:
		var stats = divine_word_game.get_game_stats()
		score_label.text = "Score: " + str(stats.score)
		level_label.text = "Level: " + str(stats.level)
		
		if stats.state == divine_word_game.GameState.PAUSED:
			timer_bar.modulate = Color(0.5, 0.5, 0.5)  # Gray when paused

func _on_start_button_pressed():
	if divine_word_game:
		if divine_word_game.start_game():
			add_message("Game started!", Color(0, 1, 0))
			update_challenge_panel()
			update_targets_panel()

func _on_pause_button_pressed():
	if divine_word_game:
		var stats = divine_word_game.get_game_stats()
		
		if stats.state == divine_word_game.GameState.PLAYING:
			if divine_word_game.pause_game():
				add_message("Game paused", Color(1, 1, 0))
		elif stats.state == divine_word_game.GameState.PAUSED:
			if divine_word_game.resume_game():
				add_message("Game resumed", Color(0, 1, 0))

func _on_help_button_pressed():
	show_help()

func _on_dimension_button_pressed(dimension):
	if turn_system and divine_word_game:
		var stats = divine_word_game.get_game_stats()
		
		if stats.state == divine_word_game.GameState.PLAYING and dimension <= stats.dimension_unlocked:
			turn_system.set_dimension(dimension)
			add_message("Manually switching to dimension " + str(dimension) + "D", Color(0.5, 0.5, 1))

func _on_word_submitted(text):
	submit_word(text)

func _on_submit_pressed():
	submit_word(word_input.text)

func submit_word(text):
	if text.empty():
		return
	
	if divine_word_game:
		var power = divine_word_game.submit_word(text)
		
		if power > 0:
			add_message("Word submitted: " + text + " (Power: " + str(power) + ")", Color(0, 1, 0))
		elif power < 0:
			add_message("BANNED WORD: " + text + " - Penalty applied!", Color(1, 0, 0))
		else:
			add_message("Cannot process word right now", Color(0.5, 0.5, 0.5))
	
	# Clear the input field
	word_input.text = ""

func add_message(text, color=Color(1, 1, 1)):
	var time_str = OS.get_time()
	var timestamp = "%02d:%02d:%02d" % [time_str.hour, time_str.minute, time_str.second]
	
	message_log.bbcode_text += "[color=#888888][" + timestamp + "][/color] "
	message_log.bbcode_text += "[color=#" + color.to_html(false) + "]" + text + "[/color]\n"
	
	# Scroll to bottom
	message_log.scroll_to_line(message_log.get_line_count())

func update_challenge_panel():
	if divine_word_game:
		var challenge = divine_word_game.get_dimension_challenge()
		
		if challenge:
			challenge_panel.bbcode_text = "[b]" + challenge.name + "[/b]\n"
			challenge_panel.bbcode_text += challenge.description + "\n\n"
			challenge_panel.bbcode_text += "[u]Required Power:[/u] " + str(challenge.min_power) + "\n"
			challenge_panel.bbcode_text += "[u]Reward:[/u] " + str(challenge.reward) + " points\n"
		else:
			challenge_panel.bbcode_text = "No challenge available for this dimension."

func update_targets_panel():
	if divine_word_game:
		var targets = divine_word_game.get_current_targets()
		
		if targets.size() > 0:
			targets_panel.bbcode_text = "[b]Current Word Targets:[/b]\n"
			
			for target in targets:
				var status = target.completed ? "[color=green]‚úì[/color]" : "[color=yellow]‚óØ[/color]"
				var color = target.completed ? "#88FF88" : "#FFFFFF"
				
				targets_panel.bbcode_text += status + " [color=" + color + "]" + target.word
				targets_panel.bbcode_text += " (Min Power: " + str(target.min_power) + ")[/color]\n"
		else:
			targets_panel.bbcode_text = "No word targets available."

func show_help():
	var help_text = """
[b]DIVINE WORD GENESIS - HELP[/b]

[u]Game Objective:[/u]
Create words to gain power and progress through 12 dimensions.

[u]How to Play:[/u]
1. Type words in the input field and submit them
2. Complete dimension challenges to unlock new dimensions
3. Meet word targets to gain bonus points
4. Progress through levels by earning points
5. Avoid banned words to prevent penalties

[u]Special Rules:[/u]
- The sacred 9-second interval governs turn progression
- Each dimension has unique challenges and word targets
- Sacred words provide bonus points
- Reach cosmic power levels for special rewards
- Dreams in dimension 7 have special significance
- Judgments in dimension 9 affect the Town of Salem game

[u]Dimensions:[/u]
- 1D: Linear words (one-dimensional thinking)
- 2D: Planar words (two-dimensional concepts)
- 3D: Spatial words (physical manifestation)
- 4D: Temporal words (time-related concepts)
- 5D: Probability words (quantum concepts)
- 6D: Resonance words (pattern and repetition)
- 7D: Dream words (subconscious manifestation)
- 8D: Network words (interconnected concepts)
- 9D: Judgment words (ethical evaluation)
- 10D: Harmonic words (balanced structures)
- 11D: Conscious words (awareness concepts)
- 12D: Divine words (transcendent concepts)
"""
	
	message_log.bbcode_text += help_text

func _on_game_started():
	add_message("Game started!", Color(0, 1, 0))
	update_challenge_panel()
	update_targets_panel()

func _on_game_paused():
	add_message("Game paused", Color(1, 1, 0))

func _on_game_resumed():
	add_message("Game resumed", Color(0, 1, 0))

func _on_game_over(final_score):
	add_message("Game over! Final score: " + str(final_score), Color(1, 0.5, 0))
	
	# Show game over summary
	message_log.bbcode_text += "\n[color=#FFAA00][b]GAME OVER SUMMARY[/b][/color]\n"
	
	if divine_word_game:
		var stats = divine_word_game.get_game_stats()
		message_log.bbcode_text += "Final Level: " + str(stats.level) + "\n"
		message_log.bbcode_text += "Turns Played: " + str(stats.turn_count) + "\n"
		message_log.bbcode_text += "Highest Dimension: " + str(stats.dimension_unlocked) + "D\n"
	
	message_log.bbcode_text += "\nStart a new game to play again.\n"

func _on_level_up(new_level):
	add_message("LEVEL UP! You are now level " + str(new_level), Color(1, 1, 0))
	update_targets_panel()

func _on_dimension_unlocked(dimension):
	add_message("DIMENSION UNLOCKED: You can now access " + str(dimension) + "D", Color(1, 0, 1))
	update_challenge_panel()
	update_targets_panel()

func _on_word_target_completed(word, power):
	add_message("TARGET COMPLETED: " + word + " (Power: " + str(power) + ")", Color(0, 1, 0.5))
	update_targets_panel()

func _on_turn_completed(turn_number):
	turn_label.text = "Turn: " + str(turn_number)
	
	# Every 12 turns, add a cycle completion message
	if turn_number % 12 == 0:
		var cycle_number = turn_number / 12
		add_message("CYCLE " + str(cycle_number) + " COMPLETED", Color(0.5, 0.5, 1))

func _on_dimension_changed(new_dimension, old_dimension):
	dimension_label.text = "Dimension: " + str(new_dimension) + "D"
	
	# Update dimension visualization
	if new_dimension >= 1 and new_dimension <= 12:
		dimension_indicator.color = dimension_colors[new_dimension - 1]
	
	# Update challenge and targets panels
	update_challenge_panel()
	update_targets_panel()
	
	# Add dimension change message
	add_message("Dimension changed: " + str(old_dimension) + "D ‚Üí " + str(new_dimension) + "D", Color(0.5, 1, 1))

func _on_word_processed(word, power, source_player):
	# Only display messages for significant power levels
	if power >= 50:
		add_message("High power word detected: " + word + " (" + str(power) + ")", Color(1, 0.5, 0))
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/divine_word_ui.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/dream_api_interface.gd
# SIZE: 25880 bytes
extends Node

# Dream API Interface
# Connects to external APIs for dream processing and game data exchange
# Reads and parses main game data, dreams, and memory structures

class_name DreamAPIInterface

# ----- API CONFIGURATION -----
const API_TIMEOUT = 30.0
const MAX_RETRY_COUNT = 3
const DREAM_CACHE_SIZE = 50
const DEFAULT_PORT = 4000
const DEFAULT_HOST = "localhost"

# ----- AUTHENTICATION -----
var api_key = ""
var api_secret = ""
var session_token = ""

# ----- CONNECTIONS -----
var active_connections = {}
var dream_cache = []
var memory_tier_cache = {}
var request_queue = []
var response_callbacks = {}

# ----- INTEGRATION -----
var dual_core_terminal = null
var divine_word_game = null
var word_comment_system = null
var word_dream_storage = null
var turn_system = null

# ----- DREAM STATE -----
enum DreamState {
    DORMANT,
    ACTIVE,
    LUCID,
    NIGHTMARE,
    PROPHETIC,
    DIVINE
}

var current_dream_state = DreamState.DORMANT
var dream_intensity = 0.0  # 0.0 to 1.0
var dream_sync_interval = 9.0  # Sacred 9-second interval

# ----- SIGNALS -----
signal dream_received(dream_id, dream_data)
signal dream_sent(dream_id)
signal api_connected(api_name)
signal api_disconnected(api_name)
signal memory_tier_accessed(tier, data)
signal main_data_read(data_type, data)
signal dream_state_changed(old_state, new_state)

# ----- INITIALIZATION -----
func _ready():
    print("Dream API Interface initializing...")
    
    # Connect to required systems
    _connect_to_systems()
    
    # Initialize dream cache
    _initialize_dream_cache()
    
    # Set up sync timer
    var sync_timer = Timer.new()
    sync_timer.wait_time = dream_sync_interval
    sync_timer.one_shot = false
    sync_timer.autostart = true
    sync_timer.connect("timeout", self, "_on_dream_sync_timer")
    add_child(sync_timer)
    
    print("Dream API Interface initialized")
    print("Current dream state: " + DreamState.keys()[current_dream_state])

func _connect_to_systems():
    # Connect to dual core terminal
    dual_core_terminal = get_node_or_null("/root/DualCoreTerminal")
    if dual_core_terminal:
        dual_core_terminal.connect("miracle_triggered", self, "_on_miracle_triggered")
        dual_core_terminal.connect("time_state_changed", self, "_on_time_state_changed")
        dual_core_terminal.connect("snake_case_detected", self, "_on_snake_case_detected")
    
    # Connect to divine word game
    divine_word_game = get_node_or_null("/root/DivineWordGame")
    if divine_word_game:
        # Check if this is a connection to the actual game
        if divine_word_game.has_method("get_game_stats"):
            var stats = divine_word_game.get_game_stats()
            print("Connected to Divine Word Game (Level: " + str(stats.level) + ")")
    
    # Connect to word comment system
    word_comment_system = get_node_or_null("/root/WordCommentSystem")
    if word_comment_system:
        word_comment_system.connect("dream_recorded", self, "_on_dream_recorded")
    
    # Connect to word dream storage
    word_dream_storage = get_node_or_null("/root/WordDreamStorage")
    
    # Connect to turn system
    turn_system = get_node_or_null("/root/TurnSystem")
    if turn_system:
        turn_system.connect("dimension_changed", self, "_on_dimension_changed")

func _initialize_dream_cache():
    dream_cache = []
    
    # Initialize memory tier cache
    for tier in range(1, 4):
        memory_tier_cache[tier] = []
    
    # If word dream storage exists, try to load some initial dreams
    if word_dream_storage and word_dream_storage.has_method("get_all_dreams"):
        var dreams = word_dream_storage.get_all_dreams()
        for dream in dreams:
            if dream_cache.size() < DREAM_CACHE_SIZE:
                dream_cache.append(dream)
            else:
                break
    
    print("Dream cache initialized with " + str(dream_cache.size()) + " dreams")

# ----- API CONNECTION -----
func connect_to_api(api_name, host=DEFAULT_HOST, port=DEFAULT_PORT):
    # Create HTTP client
    var http = HTTPClient.new()
    var err = http.connect_to_host(host, port)
    
    if err != OK:
        print("Error connecting to API: " + str(err))
        return false
    
    # Add to active connections
    active_connections[api_name] = {
        "client": http,
        "host": host,
        "port": port,
        "status": HTTPClient.STATUS_CONNECTING,
        "last_request": 0,
        "last_response": 0,
        "retry_count": 0
    }
    
    print("Connecting to API: " + api_name + " at " + host + ":" + str(port))
    return true

func disconnect_from_api(api_name):
    if not active_connections.has(api_name):
        return false
    
    var connection = active_connections[api_name]
    
    if connection.has("client"):
        connection.client.close()
    
    active_connections.erase(api_name)
    
    emit_signal("api_disconnected", api_name)
    print("Disconnected from API: " + api_name)
    
    return true

func set_api_credentials(key, secret):
    api_key = key
    api_secret = secret
    return true

func authenticate_api(api_name):
    if not active_connections.has(api_name):
        return false
    
    var connection = active_connections[api_name]
    
    if connection.status != HTTPClient.STATUS_CONNECTED:
        return false
    
    # Create authentication request
    var headers = [
        "Content-Type: application/json",
        "Authorization: Bearer " + api_key
    ]
    
    var data = {
        "key": api_key,
        "secret": api_secret
    }
    
    var json_data = JSON.print(data)
    
    # Send request
    var err = connection.client.request("POST", "/auth", headers, json_data)
    
    if err != OK:
        print("Error sending authentication request: " + str(err))
        return false
    
    connection.last_request = OS.get_unix_time()
    
    # Add callback for response
    response_callbacks[api_name] = {
        "type": "auth",
        "timestamp": OS.get_unix_time()
    }
    
    return true

# ----- DREAM PROCESSING -----
func send_dream(dream_data, api_name):
    if not active_connections.has(api_name):
        return false
    
    var connection = active_connections[api_name]
    
    if connection.status != HTTPClient.STATUS_CONNECTED:
        return false
    
    # Create dream sending request
    var headers = [
        "Content-Type: application/json",
        "Authorization: Bearer " + api_key
    ]
    
    var json_data = JSON.print(dream_data)
    
    # Send request
    var err = connection.client.request("POST", "/dreams", headers, json_data)
    
    if err != OK:
        print("Error sending dream: " + str(err))
        return false
    
    connection.last_request = OS.get_unix_time()
    
    # Add to request queue
    request_queue.append({
        "api_name": api_name,
        "endpoint": "/dreams",
        "method": "POST",
        "data": dream_data,
        "timestamp": OS.get_unix_time(),
        "retry_count": 0
    })
    
    # Generate dream ID
    var dream_id = "dream_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
    
    emit_signal("dream_sent", dream_id)
    return dream_id

func fetch_dreams(api_name, count=10):
    if not active_connections.has(api_name):
        return false
    
    var connection = active_connections[api_name]
    
    if connection.status != HTTPClient.STATUS_CONNECTED:
        return false
    
    # Create dream fetching request
    var headers = [
        "Content-Type: application/json",
        "Authorization: Bearer " + api_key
    ]
    
    # Send request
    var err = connection.client.request("GET", "/dreams?count=" + str(count), headers, "")
    
    if err != OK:
        print("Error fetching dreams: " + str(err))
        return false
    
    connection.last_request = OS.get_unix_time()
    
    # Add callback for response
    response_callbacks[api_name] = {
        "type": "fetch_dreams",
        "timestamp": OS.get_unix_time()
    }
    
    return true

func process_dream(dream_text, source="api", state=DreamState.ACTIVE):
    # Process a dream text and add it to storage
    var dream_id = "dream_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
    
    var dream_data = {
        "id": dream_id,
        "text": dream_text,
        "source": source,
        "state": state,
        "timestamp": OS.get_unix_time(),
        "processed": false
    }
    
    # Add to cache
    if dream_cache.size() >= DREAM_CACHE_SIZE:
        dream_cache.pop_front()  # Remove oldest dream
    
    dream_cache.append(dream_data)
    
    # If word dream storage exists, store the dream
    if word_dream_storage and word_dream_storage.has_method("save_dream"):
        var tier = 1
        
        # Higher tier for more important dreams
        if state == DreamState.PROPHETIC or state == DreamState.DIVINE:
            tier = 3
        elif state == DreamState.LUCID:
            tier = 2
        
        word_dream_storage.save_dream(dream_data, tier)
        
        # Keep tier cache updated
        if memory_tier_cache.has(tier):
            memory_tier_cache[tier].append(dream_data)
    
    # If word comment system exists, add comment about the dream
    if word_comment_system:
        var comment_type = word_comment_system.CommentType.DREAM
        if state == DreamState.DIVINE:
            comment_type = word_comment_system.CommentType.DIVINE
        
        word_comment_system.add_comment("dream_" + dream_id, 
            "DREAM: " + dream_text, 
            comment_type, "Dream_API")
    
    emit_signal("dream_received", dream_id, dream_data)
    return dream_id

func change_dream_state(new_state):
    var old_state = current_dream_state
    current_dream_state = new_state
    
    # Update dream intensity based on state
    match new_state:
        DreamState.DORMANT:
            dream_intensity = 0.0
        DreamState.ACTIVE:
            dream_intensity = 0.3
        DreamState.LUCID:
            dream_intensity = 0.6
        DreamState.NIGHTMARE:
            dream_intensity = 0.8
        DreamState.PROPHETIC:
            dream_intensity = 0.9
        DreamState.DIVINE:
            dream_intensity = 1.0
    
    # Update dream sync interval based on intensity
    dream_sync_interval = 9.0 / (1.0 + dream_intensity)  # Faster sync for higher intensity
    
    emit_signal("dream_state_changed", old_state, new_state)
    print("Dream state changed from " + DreamState.keys()[old_state] + " to " + DreamState.keys()[new_state])
    
    # If word comment system exists, add comment about state change
    if word_comment_system:
        var comment_type = word_comment_system.CommentType.DREAM
        if new_state == DreamState.DIVINE:
            comment_type = word_comment_system.CommentType.DIVINE
        
        word_comment_system.add_comment("dream_state", 
            "Dream state changed to " + DreamState.keys()[new_state], 
            comment_type, "Dream_API")
    
    return true

# ----- MEMORY TIER ACCESS -----
func access_memory_tier(tier, read_only=true):
    if tier < 1 or tier > 3:
        return null
    
    # Check if cached data exists
    if memory_tier_cache.has(tier) and memory_tier_cache[tier].size() > 0:
        emit_signal("memory_tier_accessed", tier, memory_tier_cache[tier])
        return memory_tier_cache[tier]
    
    # Try to fetch from word dream storage
    if word_dream_storage and word_dream_storage.has_method("get_memories_by_tier"):
        var memories = word_dream_storage.get_memories_by_tier(tier)
        
        # Cache the results
        memory_tier_cache[tier] = memories
        
        emit_signal("memory_tier_accessed", tier, memories)
        return memories
    
    # If divine word game exists, try its memory access method
    if divine_word_game and divine_word_game.has_method("get_memory_by_tier"):
        var memories = divine_word_game.get_memory_by_tier(tier)
        
        # Cache the results
        memory_tier_cache[tier] = memories
        
        emit_signal("memory_tier_accessed", tier, memories)
        return memories
    
    return []

func store_in_memory_tier(data, tier):
    if tier < 1 or tier > 3:
        return false
    
    # If word dream storage exists, store the data
    if word_dream_storage and word_dream_storage.has_method("save_memory"):
        word_dream_storage.save_memory(data, tier)
        
        # Update cache
        if not memory_tier_cache.has(tier):
            memory_tier_cache[tier] = []
        
        memory_tier_cache[tier].append(data)
        
        emit_signal("memory_tier_accessed", tier, memory_tier_cache[tier])
        return true
    
    # If divine word game exists, try its memory storage method
    if divine_word_game and divine_word_game.has_method("save_to_tier"):
        divine_word_game.save_to_tier(data, tier)
        
        # Update cache
        if not memory_tier_cache.has(tier):
            memory_tier_cache[tier] = []
        
        memory_tier_cache[tier].append(data)
        
        emit_signal("memory_tier_accessed", tier, memory_tier_cache[tier])
        return true
    
    return false

# ----- MAIN DATA READING -----
func read_main_data(data_type):
    var data = null
    
    match data_type:
        "game_stats":
            if divine_word_game and divine_word_game.has_method("get_game_stats"):
                data = divine_word_game.get_game_stats()
        
        "terminal_cores":
            if dual_core_terminal and dual_core_terminal.has_method("get_all_cores"):
                data = dual_core_terminal.get_all_cores()
        
        "dream_cache":
            data = dream_cache
        
        "turn_info":
            if turn_system and turn_system.has_method("get_turn_info"):
                data = turn_system.get_turn_info()
        
        "current_dimension":
            if turn_system:
                data = turn_system.current_dimension
        
        "memory_tiers":
            var tiers = {}
            for tier in range(1, 4):
                tiers[tier] = access_memory_tier(tier)
            data = tiers
        
        "dream_state":
            data = {
                "state": current_dream_state,
                "intensity": dream_intensity,
                "sync_interval": dream_sync_interval,
                "cache_size": dream_cache.size()
            }
    
    if data != null:
        emit_signal("main_data_read", data_type, data)
    
    return data

func read_all_main_data():
    var all_data = {}
    
    var data_types = [
        "game_stats",
        "terminal_cores",
        "dream_cache",
        "turn_info",
        "current_dimension",
        "memory_tiers",
        "dream_state"
    ]
    
    for data_type in data_types:
        all_data[data_type] = read_main_data(data_type)
    
    return all_data

# ----- SNAKE CASE DATA FORMATTING -----
func format_snake_case(text):
    # Convert text to snake_case format
    var result = ""
    var prev_char_was_uppercase = false
    
    for i in range(text.length()):
        var c = text[i]
        
        if c == " ":
            # Replace spaces with underscores
            result += "_"
            prev_char_was_uppercase = false
        elif c >= "A" and c <= "Z":
            # Convert uppercase to lowercase, possibly add underscore
            if i > 0 and not prev_char_was_uppercase and result[result.length() - 1] != "_":
                result += "_"
            
            result += c.to_lower()
            prev_char_was_uppercase = true
        else:
            result += c
            prev_char_was_uppercase = false
    
    return result

func clean_data_with_snake_case(data):
    # Convert all keys in a dictionary to snake_case
    if typeof(data) != TYPE_DICTIONARY:
        return data
    
    var result = {}
    
    for key in data:
        var snake_key = format_snake_case(key)
        
        if typeof(data[key]) == TYPE_DICTIONARY:
            result[snake_key] = clean_data_with_snake_case(data[key])
        elif typeof(data[key]) == TYPE_ARRAY:
            var cleaned_array = []
            for item in data[key]:
                if typeof(item) == TYPE_DICTIONARY:
                    cleaned_array.append(clean_data_with_snake_case(item))
                else:
                    cleaned_array.append(item)
            result[snake_key] = cleaned_array
        else:
            result[snake_key] = data[key]
    
    return result

# ----- EVENT HANDLERS -----
func _on_dream_sync_timer():
    # Called at the sacred interval for dream synchronization
    
    # Check dream state
    if current_dream_state == DreamState.DORMANT:
        return
    
    # Generate a dream based on current state
    if randf() < dream_intensity:
        _generate_dream()
    
    # Check if any API connections need refreshing
    for api_name in active_connections:
        var connection = active_connections[api_name]
        
        if OS.get_unix_time() - connection.last_request > 60:
            # Refresh connection by fetching dreams
            fetch_dreams(api_name, 1)

func _generate_dream():
    # Generate a dream based on current state
    var templates = []
    
    match current_dream_state:
        DreamState.ACTIVE:
            templates = [
                "Walking through a misty forest, the trees whisper secrets.",
                "Flying over an endless ocean, feeling weightless and free.",
                "Exploring an ancient library filled with glowing books.",
                "Climbing a staircase that seems to reach into the clouds."
            ]
        
        DreamState.LUCID:
            templates = [
                "I realize I'm dreaming as the sky turns purple with geometric patterns.",
                "As I become aware this is a dream, I begin to shape the environment around me.",
                "The dream landscape responds to my thoughts, shifting and changing at will.",
                "I can feel the boundaries between reality and dream becoming thin and permeable."
            ]
        
        DreamState.NIGHTMARE:
            templates = [
                "Shadows with glowing eyes chase me through endless corridors.",
                "I'm falling endlessly into a dark abyss with no bottom.",
                "The walls are closing in slowly, and I can't find an exit.",
                "Everyone I meet has no face, just smooth skin where features should be."
            ]
        
        DreamState.PROPHETIC:
            templates = [
                "I see fragments of future events, like pieces of a shattered mirror.",
                "Numbers and symbols float in the air, forming patterns that reveal coming changes.",
                "A voice speaks from everywhere and nowhere, telling me what is to come.",
                "Time splits into multiple streams, showing different possible futures."
            ]
        
        DreamState.DIVINE:
            templates = [
                "Surrounded by light beyond description, I receive knowledge beyond words.",
                "The universe unfolds before me, revealing its sacred patterns and purpose.",
                "Divine beings of pure energy communicate with me through music and color.",
                "The boundaries between all things dissolve, and I experience complete unity."
            ]
    
    if templates.size() > 0:
        var template = templates[randi() % templates.size()]
        process_dream(template, "generated", current_dream_state)

func _on_miracle_triggered(core_id):
    # Miracles elevate dream state
    var new_state = min(current_dream_state + 2, DreamState.DIVINE)
    change_dream_state(new_state)
    
    # Generate a divine dream
    process_dream(
        "A miracle ripples through reality, revealing glimpses of divine patterns.",
        "miracle",
        DreamState.DIVINE
    )

func _on_time_state_changed(old_state, new_state):
    # Time shifts affect dreams
    if new_state == dual_core_terminal.TimeState.PAST:
        change_dream_state(DreamState.ACTIVE)
    elif new_state == dual_core_terminal.TimeState.FUTURE:
        change_dream_state(DreamState.PROPHETIC)
    elif new_state == dual_core_terminal.TimeState.TIMELESS:
        change_dream_state(DreamState.DIVINE)
    else: # PRESENT
        change_dream_state(DreamState.LUCID)

func _on_snake_case_detected(text, cleaned_text):
    # Snake case triggers affect dreams
    if cleaned_text == "i_might_see":
        change_dream_state(DreamState.DIVINE)
        
        # Generate a special dream
        process_dream(
            "I_Might_See reveals a glimpse beyond the veil, where all knowledge is accessible.",
            "snake_case",
            DreamState.DIVINE
        )
    elif cleaned_text == "dream_state":
        # Cycle dream state
        var next_state = (current_dream_state + 1) % DreamState.size()
        change_dream_state(next_state)
    elif cleaned_text == "access_tier_3":
        # Access highest memory tier
        access_memory_tier(3, false)

func _on_dream_recorded(dream_text, power_level):
    # When a dream is recorded in the comment system, process it
    var state = DreamState.ACTIVE
    
    if power_level > 80:
        state = DreamState.DIVINE
    elif power_level > 60:
        state = DreamState.PROPHETIC
    elif power_level > 40:
        state = DreamState.LUCID
    elif power_level > 20:
        state = DreamState.ACTIVE
    else:
        state = DreamState.DORMANT
    
    process_dream(dream_text, "comment_system", state)

func _on_dimension_changed(new_dimension, old_dimension):
    # Dimension 7 is the dream dimension
    if new_dimension == 7:
        change_dream_state(DreamState.DIVINE)
        
        # Generate a dimension 7 dream
        process_dream(
            "Entering Dimension 7, the realm of dreams and collective consciousness.",
            "dimension_7",
            DreamState.DIVINE
        )
    elif old_dimension == 7:
        # Leaving dream dimension
        change_dream_state(DreamState.LUCID)

# ----- PUBLIC API -----
func get_dream_cache():
    return dream_cache

func get_dream_by_id(dream_id):
    for dream in dream_cache:
        if dream.id == dream_id:
            return dream
    
    return null

func get_dreams_by_state(state):
    var result = []
    
    for dream in dream_cache:
        if dream.state == state:
            result.append(dream)
    
    return result

func get_current_dream_state():
    return {
        "state": current_dream_state,
        "intensity": dream_intensity,
        "name": DreamState.keys()[current_dream_state]
    }

func get_memory_tier_info():
    var result = {}
    
    for tier in range(1, 4):
        var count = 0
        if memory_tier_cache.has(tier):
            count = memory_tier_cache[tier].size()
        
        result[tier] = {
            "count": count,
            "name": "Tier " + str(tier)
        }
    
    return result

func create_dream_from_text(text, state=null):
    # Determine dream state based on text content if not provided
    if state == null:
        if "divine" in text.to_lower() or "god" in text.to_lower():
            state = DreamState.DIVINE
        elif "future" in text.to_lower() or "prophec" in text.to_lower():
            state = DreamState.PROPHETIC
        elif "nightmare" in text.to_lower() or "terror" in text.to_lower():
            state = DreamState.NIGHTMARE
        elif "lucid" in text.to_lower() or "aware" in text.to_lower():
            state = DreamState.LUCID
        else:
            state = DreamState.ACTIVE
    
    return process_dream(text, "api_create", state)

func search_dreams(query):
    var results = []
    
    for dream in dream_cache:
        if dream.text.to_lower().find(query.to_lower()) >= 0:
            results.append(dream)
    
    return results

func find_patterns_in_dreams(pattern_regex):
    var results = []
    var regex = RegEx.new()
    var err = regex.compile(pattern_regex)
    
    if err != OK:
        print("Error compiling regex: " + str(err))
        return results
    
    for dream in dream_cache:
        var matches = regex.search_all(dream.text)
        if matches.size() > 0:
            results.append({
                "dream": dream,
                "matches": matches
            })
    
    return results

func connect_to_chat_api(api_key=""):
    # Configure connection to external chat API (e.g., OpenAI)
    if api_key != "":
        set_api_credentials(api_key, "")
    
    # Try to connect
    return connect_to_api("chat_api", "api.openai.com", 443)

func process_chat_response(response_text):
    # Process a response from a chat API and extract dream content
    if response_text.find("DREAM:") >= 0:
        var parts = response_text.split("DREAM:", true, 1)
        if parts.size() > 1:
            var dream_text = parts[1].strip_edges()
            return create_dream_from_text(dream_text)
    elif response_text.find("MEMORY:") >= 0:
        var parts = response_text.split("MEMORY:", true, 1)
        if parts.size() > 1:
            var memory_text = parts[1].strip_edges()
            var data = {
                "text": memory_text,
                "source": "chat_api",
                "timestamp": OS.get_unix_time()
            }
            
            // Determine which tier to store in
            var tier = 1
            if memory_text.to_lower().find("important") >= 0 or memory_text.to_lower().find("crucial") >= 0:
                tier = 2
            elif memory_text.to_lower().find("divine") >= 0 or memory_text.to_lower().find("fundamental") >= 0:
                tier = 3
            
            store_in_memory_tier(data, tier)
            return "memory_" + str(OS.get_unix_time())
    
    return null

func set_openai_key(key):
    api_key = key
    return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/dream_api_interface.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/drive_connector.gd
# SIZE: 29877 bytes
extends Node

# Drive Connector System
# Connects and synchronizes multiple storage drives (Local, iCloud, Google Drive)
# Integrates with Terminal Memory System and Concurrent Processor

class_name DriveConnector

# Drive types
enum DriveType { LOCAL, ICLOUD, GOOGLE_DRIVE, REMOTE }

# Connection status
enum ConnectionStatus { DISCONNECTED, CONNECTING, CONNECTED, ERROR }

# Drive Configuration
class DriveConfig:
	var name: String
	var type: int
	var path: String
	var connection_status: int = ConnectionStatus.DISCONNECTED
	var last_sync: int = 0
	var quota_total: int = 0
	var quota_used: int = 0
	var sync_enabled: bool = true
	var emoji: String = "üíæ"
	
	func _init(p_name: String, p_type: int, p_path: String, p_emoji: String = "üíæ"):
		name = p_name
		type = p_type
		path = p_path
		emoji = p_emoji
		
	func get_status_emoji():
		match connection_status:
			ConnectionStatus.CONNECTED: return "üü¢"
			ConnectionStatus.CONNECTING: return "üü°"
			ConnectionStatus.ERROR: return "üî¥"
			_: return "‚ö™"
			
	func get_type_string():
		match type:
			DriveType.LOCAL: return "Local"
			DriveType.ICLOUD: return "iCloud"
			DriveType.GOOGLE_DRIVE: return "Google Drive"
			DriveType.REMOTE: return "Remote"
			_: return "Unknown"
			
	func get_summary():
		return "%s %s %s - %s (%s)" % [
			get_status_emoji(),
			emoji,
			name,
			get_type_string(),
			_format_size(quota_used) + "/" + _format_size(quota_total) if quota_total > 0 else "Unlimited"
		]
	
	func _format_size(bytes: int) -> String:
		if bytes < 1024:
			return str(bytes) + " B"
		elif bytes < 1024 * 1024:
			return str(bytes / 1024) + " KB"
		elif bytes < 1024 * 1024 * 1024:
			return str(bytes / (1024 * 1024)) + " MB"
		else:
			return str(bytes / (1024 * 1024 * 1024)) + " GB"

# Drive storage
var drives = {}
var active_drive: String = "local"
var terminal_memory = null
var processor = null

# Signals
signal drive_connected(drive_name)
signal drive_disconnected(drive_name)
signal sync_completed(drive_name)
signal sync_failed(drive_name, error)

func _ready():
	# Configure default local drive
	add_drive("local", DriveType.LOCAL, "user://", "üíª")
	
	# Look for terminal memory system
	terminal_memory = get_node_or_null("/root/TerminalMemorySystem")
	
	if terminal_memory and terminal_memory.has_method("add_memory_text"):
		terminal_memory.add_memory_text("Drive Connector initialized with local drive.", "system")
		if terminal_memory.has_node("processor"):
			processor = terminal_memory.get_node("processor")

# Add a new drive to the system
func add_drive(name: String, type: int, path: String, emoji: String = "üíæ") -> bool:
	if drives.has(name):
		_log("Drive with name '%s' already exists." % name)
		return false
		
	drives[name] = DriveConfig.new(name, type, path, emoji)
	_log("Added new drive: %s" % drives[name].get_summary())
	return true

# Connect to a drive
func connect_drive(name: String) -> bool:
	if not drives.has(name):
		_log("Drive '%s' does not exist." % name)
		return false
		
	var drive = drives[name]
	_log("Connecting to drive: %s" % drive.get_summary())
	
	drive.connection_status = ConnectionStatus.CONNECTING
	
	match drive.type:
		DriveType.LOCAL:
			return _connect_local_drive(drive)
		DriveType.ICLOUD:
			return _connect_icloud_drive(drive)
		DriveType.GOOGLE_DRIVE:
			return _connect_google_drive(drive)
		DriveType.REMOTE:
			return _connect_remote_drive(drive)
		_:
			_log("Unknown drive type: %d" % drive.type)
			drive.connection_status = ConnectionStatus.ERROR
			return false

# Connect to all drives
func connect_all_drives() -> void:
	_log("Connecting to all drives...")
	
	# If we have a processor, connect drives concurrently
	if processor:
		var drive_names = []
		for name in drives.keys():
			drive_names.append(name)
			
		processor.create_parallel_tasks(
			"connect_drives",
			self,
			["connect_drive"] * drive_names.size(),
			[[name] for name in drive_names]
		)
	else:
		# Otherwise connect in sequence
		for name in drives.keys():
			connect_drive(name)

# Disconnect from a drive
func disconnect_drive(name: String) -> bool:
	if not drives.has(name):
		_log("Drive '%s' does not exist." % name)
		return false
		
	var drive = drives[name]
	_log("Disconnecting from drive: %s" % drive.name)
	
	# Save any pending data before disconnecting
	if drive.connection_status == ConnectionStatus.CONNECTED:
		sync_drive(name)
		
	drive.connection_status = ConnectionStatus.DISCONNECTED
	emit_signal("drive_disconnected", name)
	_log("Disconnected from drive: %s" % drive.name)
	return true

# Set active drive
func set_active_drive(name: String) -> bool:
	if not drives.has(name):
		_log("Drive '%s' does not exist." % name)
		return false
		
	if drives[name].connection_status != ConnectionStatus.CONNECTED:
		_log("Drive '%s' is not connected." % name)
		return false
		
	active_drive = name
	_log("Active drive set to: %s" % drives[name].get_summary())
	return true

# Get list of available drives
func get_drives() -> Dictionary:
	return drives

# Synchronize a specific drive
func sync_drive(name: String) -> bool:
	if not drives.has(name):
		_log("Drive '%s' does not exist." % name)
		return false
		
	var drive = drives[name]
	if drive.connection_status != ConnectionStatus.CONNECTED:
		_log("Drive '%s' is not connected." % name)
		return false
		
	_log("Synchronizing drive: %s" % drive.name)
	
	match drive.type:
		DriveType.LOCAL:
			return _sync_local_drive(drive)
		DriveType.ICLOUD:
			return _sync_icloud_drive(drive)
		DriveType.GOOGLE_DRIVE:
			return _sync_google_drive(drive)
		DriveType.REMOTE:
			return _sync_remote_drive(drive)
		_:
			_log("Unknown drive type: %d" % drive.type)
			return false

# Synchronize all drives
func sync_all_drives() -> void:
	_log("Synchronizing all drives...")
	
	# If we have a processor, sync drives concurrently
	if processor:
		var drive_names = []
		for name in drives.keys():
			if drives[name].connection_status == ConnectionStatus.CONNECTED:
				drive_names.append(name)
				
		processor.create_parallel_tasks(
			"sync_drives",
			self,
			["sync_drive"] * drive_names.size(),
			[[name] for name in drive_names]
		)
	else:
		# Otherwise sync in sequence
		for name in drives.keys():
			if drives[name].connection_status == ConnectionStatus.CONNECTED:
				sync_drive(name)

# Get drive summary
func get_drive_summary(name: String) -> String:
	if not drives.has(name):
		return "Drive '%s' does not exist." % name
		
	return drives[name].get_summary()

# Get all drives summary
func get_all_drives_summary() -> String:
	var summary = "Connected Drives Summary:\n"
	
	for name in drives.keys():
		summary += "- " + drives[name].get_summary() + "\n"
		
	return summary

# Save memory data to drive
func save_memory_to_drive(memory_data, drive_name: String = "") -> bool:
	var target_drive_name = drive_name if drive_name else active_drive
	
	if not drives.has(target_drive_name):
		_log("Drive '%s' does not exist." % target_drive_name)
		return false
		
	var drive = drives[target_drive_name]
	if drive.connection_status != ConnectionStatus.CONNECTED:
		_log("Drive '%s' is not connected." % target_drive_name)
		return false
		
	_log("Saving memory data to drive: %s" % drive.name)
	
	match drive.type:
		DriveType.LOCAL:
			return _save_to_local_drive(memory_data, drive)
		DriveType.ICLOUD:
			return _save_to_icloud_drive(memory_data, drive)
		DriveType.GOOGLE_DRIVE:
			return _save_to_google_drive(memory_data, drive)
		DriveType.REMOTE:
			return _save_to_remote_drive(memory_data, drive)
		_:
			_log("Unknown drive type: %d" % drive.type)
			return false

# Load memory data from drive
func load_memory_from_drive(drive_name: String = "") -> Dictionary:
	var target_drive_name = drive_name if drive_name else active_drive
	
	if not drives.has(target_drive_name):
		_log("Drive '%s' does not exist." % target_drive_name)
		return {}
		
	var drive = drives[target_drive_name]
	if drive.connection_status != ConnectionStatus.CONNECTED:
		_log("Drive '%s' is not connected." % target_drive_name)
		return {}
		
	_log("Loading memory data from drive: %s" % drive.name)
	
	match drive.type:
		DriveType.LOCAL:
			return _load_from_local_drive(drive)
		DriveType.ICLOUD:
			return _load_from_icloud_drive(drive)
		DriveType.GOOGLE_DRIVE:
			return _load_from_google_drive(drive)
		DriveType.REMOTE:
			return _load_from_remote_drive(drive)
		_:
			_log("Unknown drive type: %d" % drive.type)
			return {}

# Process command with the connector
func process_command(command: String) -> void:
	var parts = command.split(" ", true, 2)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"#connect":
			if args.empty():
				connect_all_drives()
			else:
				connect_drive(args)
		"#disconnect":
			if args.empty():
				_log("Please specify a drive to disconnect.")
			else:
				disconnect_drive(args)
		"#sync":
			if args.empty():
				sync_all_drives()
			else:
				sync_drive(args)
		"#active":
			if args.empty():
				_log("Current active drive: %s" % get_drive_summary(active_drive))
			else:
				set_active_drive(args)
		"#list":
			_log(get_all_drives_summary())
		"#add":
			_process_add_command(args)
		"##drive":
			_process_advanced_drive_command(args)
		"###drive":
			_process_system_drive_command(args)
		_:
			_log("Unknown drive command: %s" % cmd)

# Configure iCloud drive
func configure_icloud(size_gb: int = 5) -> bool:
	var name = "icloud"
	var path = "user://icloud/"
	var emoji = "‚òÅÔ∏è"
	
	if add_drive(name, DriveType.ICLOUD, path, emoji):
		drives[name].quota_total = size_gb * 1024 * 1024 * 1024
		drives[name].quota_used = 0
		_log("Configured iCloud drive with %dGB quota" % size_gb)
		return true
	
	return false

# Configure Google Drive
func configure_google_drive(size_gb: int = 15) -> bool:
	var name = "gdrive" 
	var path = "user://gdrive/"
	var emoji = "üìù"
	
	if add_drive(name, DriveType.GOOGLE_DRIVE, path, emoji):
		drives[name].quota_total = size_gb * 1024 * 1024 * 1024
		drives[name].quota_used = 0
		_log("Configured Google Drive with %dGB quota" % size_gb)
		return true
	
	return false

# Create directory structure for a drive
func create_drive_directories(drive_name: String) -> bool:
	if not drives.has(drive_name):
		_log("Drive '%s' does not exist." % drive_name)
		return false
		
	var drive = drives[drive_name]
	if drive.connection_status != ConnectionStatus.CONNECTED:
		_log("Drive '%s' is not connected." % drive_name)
		return false
		
	_log("Creating directory structure for drive: %s" % drive.name)
	
	var dir = Directory.new()
	var base_path = drive.path
	
	# Create base directory
	if not dir.dir_exists(base_path):
		dir.make_dir_recursive(base_path)
	
	# Create subdirectories
	var subdirs = ["memories", "tdic", "projects", "words", "dimensions", "sync"]
	
	for subdir in subdirs:
		var path = base_path + subdir
		if not dir.dir_exists(path):
			dir.make_dir(path)
	
	_log("Directory structure created for drive: %s" % drive.name)
	return true

# IMPLEMENTATION OF PRIVATE METHODS

# Process commands to add new drives
func _process_add_command(args: String) -> void:
	var parts = args.split(" ", true, 2)
	
	if parts.size() < 2:
		_log("Usage: #add <drive_type> <name> [<path>]")
		return
		
	var drive_type_str = parts[0].to_lower()
	var name = parts[1]
	var path = parts[2] if parts.size() > 2 else "user://" + name + "/"
	
	var drive_type = DriveType.LOCAL
	var emoji = "üíæ"
	
	match drive_type_str:
		"local":
			drive_type = DriveType.LOCAL
			emoji = "üíª"
		"icloud":
			drive_type = DriveType.ICLOUD
			emoji = "‚òÅÔ∏è"
		"gdrive", "google":
			drive_type = DriveType.GOOGLE_DRIVE
			emoji = "üìù"
		"remote":
			drive_type = DriveType.REMOTE
			emoji = "üåê"
		_:
			_log("Unknown drive type: %s" % drive_type_str)
			return
			
	if add_drive(name, drive_type, path, emoji):
		_log("Drive added successfully. Connect with: #connect %s" % name)
	else:
		_log("Failed to add drive.")

# Process advanced drive commands
func _process_advanced_drive_command(args: String) -> void:
	var parts = args.split(" ", true, 2)
	
	if parts.size() < 1:
		_log("Usage: ##drive <command> [<args>]")
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"quota":
			_set_drive_quota(subargs)
		"emoji":
			_set_drive_emoji(subargs)
		"path":
			_set_drive_path(subargs)
		"status":
			_log(get_all_drives_summary())
		"mkdir":
			_create_drive_directory(subargs)
		_:
			_log("Unknown advanced drive command: %s" % subcmd)

# Process system drive commands
func _process_system_drive_command(args: String) -> void:
	var parts = args.split(" ", true, 2)
	
	if parts.size() < 1:
		_log("Usage: ###drive <command> [<args>]")
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"reset":
			_reset_drive(subargs)
		"configure":
			_configure_all_drives()
		"makedirs":
			_create_all_directories()
		"pokemonsync":
			_pokemon_themed_sync()
		"emojimap":
			_show_emoji_map()
		_:
			_log("Unknown system drive command: %s" % subcmd)

# Reset a drive or all drives
func _reset_drive(drive_name: String) -> void:
	if drive_name.empty() or drive_name == "all":
		_log("Resetting all drives...")
		drives.clear()
		add_drive("local", DriveType.LOCAL, "user://", "üíª")
		_log("All drives have been reset.")
	elif drives.has(drive_name):
		drives.erase(drive_name)
		_log("Drive '%s' has been reset." % drive_name)
	else:
		_log("Drive '%s' does not exist." % drive_name)

# Configure all standard drives
func _configure_all_drives() -> void:
	_log("Configuring all standard drives...")
	
	# Make sure local drive exists
	if not drives.has("local"):
		add_drive("local", DriveType.LOCAL, "user://", "üíª")
		
	# Configure iCloud (5GB free tier)
	configure_icloud(5)
	
	# Configure Google Drive (15GB free tier)
	configure_google_drive(15)
	
	# Add a remote drive as example
	add_drive("remote", DriveType.REMOTE, "http://example.com/api/storage", "üåê")
	
	_log("All standard drives configured.")

# Create directories for all drives
func _create_all_directories() -> void:
	_log("Creating directories for all connected drives...")
	
	for name in drives.keys():
		if drives[name].connection_status == ConnectionStatus.CONNECTED:
			create_drive_directories(name)
			
	_log("Directory creation completed.")

# Set quota for a drive
func _set_drive_quota(args: String) -> void:
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		_log("Usage: ##drive quota <drive_name> <size_gb>")
		return
		
	var drive_name = parts[0]
	var size_gb = int(parts[1])
	
	if not drives.has(drive_name):
		_log("Drive '%s' does not exist." % drive_name)
		return
		
	drives[drive_name].quota_total = size_gb * 1024 * 1024 * 1024
	_log("Set quota for drive '%s' to %dGB" % [drive_name, size_gb])

# Set emoji for a drive
func _set_drive_emoji(args: String) -> void:
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		_log("Usage: ##drive emoji <drive_name> <emoji>")
		return
		
	var drive_name = parts[0]
	var emoji = parts[1]
	
	if not drives.has(drive_name):
		_log("Drive '%s' does not exist." % drive_name)
		return
		
	drives[drive_name].emoji = emoji
	_log("Set emoji for drive '%s' to %s" % [drive_name, emoji])

# Set path for a drive
func _set_drive_path(args: String) -> void:
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		_log("Usage: ##drive path <drive_name> <path>")
		return
		
	var drive_name = parts[0]
	var path = parts[1]
	
	if not drives.has(drive_name):
		_log("Drive '%s' does not exist." % drive_name)
		return
		
	drives[drive_name].path = path
	_log("Set path for drive '%s' to %s" % [drive_name, path])

# Create directory in a drive
func _create_drive_directory(args: String) -> void:
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 2:
		_log("Usage: ##drive mkdir <drive_name> <directory>")
		return
		
	var drive_name = parts[0]
	var directory = parts[1]
	
	if not drives.has(drive_name):
		_log("Drive '%s' does not exist." % drive_name)
		return
		
	if drives[drive_name].connection_status != ConnectionStatus.CONNECTED:
		_log("Drive '%s' is not connected." % drive_name)
		return
		
	var dir = Directory.new()
	var path = drives[drive_name].path + directory
	
	if not dir.dir_exists(path):
		dir.make_dir_recursive(path)
		_log("Created directory '%s' on drive '%s'" % [directory, drive_name])
	else:
		_log("Directory '%s' already exists on drive '%s'" % [directory, drive_name])

# Pokemon themed sync operation
func _pokemon_themed_sync() -> void:
	_log("Starting Pok√©mon-themed drive synchronization! üêæ")
	
	var pokemon_emojis = ["üê¢", "üî•", "üíß", "‚ö°", "üåø", "ü¶é", "ü¶ä", "üêâ", "üåü", "üåà"]
	var pokemon_names = ["Squirtle", "Charmander", "Vaporeon", "Pikachu", "Bulbasaur", "Sceptile", "Vulpix", "Dragonite", "Jirachi", "Ho-Oh"]
	
	var i = 0
	for drive_name in drives.keys():
		if drives[drive_name].connection_status == ConnectionStatus.CONNECTED:
			var pokemon_idx = i % pokemon_emojis.size()
			var pokemon_emoji = pokemon_emojis[pokemon_idx]
			var pokemon_name = pokemon_names[pokemon_idx]
			
			_log("%s %s is synchronizing drive '%s'!" % [pokemon_emoji, pokemon_name, drive_name])
			sync_drive(drive_name)
			i += 1
			
	_log("Pok√©mon-themed synchronization complete! Gotta sync 'em all! üéÆ")

# Show emoji map for drives
func _show_emoji_map() -> void:
	_log("Drive Emoji Map:")
	_log("- Local Drive: üíª")
	_log("- iCloud: ‚òÅÔ∏è")
	_log("- Google Drive: üìù")
	_log("- Remote/Network: üåê")
	_log("- Backup Drive: üìº")
	_log("- Encrypted Drive: üîí")
	_log("- Shared Drive: üë•")
	_log("- Archive: üì¶")
	_log("- System: ‚öôÔ∏è")
	_log("- External Drive: üìÄ")

# Connect implementations
func _connect_local_drive(drive: DriveConfig) -> bool:
	# For local drives, just check if the directory exists or try to create it
	var dir = Directory.new()
	
	if not dir.dir_exists(drive.path):
		var err = dir.make_dir_recursive(drive.path)
		if err != OK:
			_log("Failed to create directory: %s (Error: %d)" % [drive.path, err])
			drive.connection_status = ConnectionStatus.ERROR
			return false
	
	# Update drive info
	var stats = _get_directory_stats(drive.path)
	drive.quota_used = stats.size
	
	drive.connection_status = ConnectionStatus.CONNECTED
	drive.last_sync = OS.get_unix_time()
	
	emit_signal("drive_connected", drive.name)
	_log("Connected to local drive: %s" % drive.name)
	return true

func _connect_icloud_drive(drive: DriveConfig) -> bool:
	# Simulate connection to iCloud
	_log("Connecting to iCloud Drive: %s" % drive.name)
	yield(get_tree().create_timer(0.5), "timeout")
	
	# Create the directory for our simulated iCloud
	var dir = Directory.new()
	if not dir.dir_exists(drive.path):
		var err = dir.make_dir_recursive(drive.path)
		if err != OK:
			_log("Failed to create iCloud directory: %s (Error: %d)" % [drive.path, err])
			drive.connection_status = ConnectionStatus.ERROR
			return false
	
	# In a real implementation, this would connect to the iCloud API
	drive.connection_status = ConnectionStatus.CONNECTED
	drive.last_sync = OS.get_unix_time()
	drive.quota_used = int(drive.quota_total * 0.3) # Simulate 30% used
	
	emit_signal("drive_connected", drive.name)
	_log("Connected to iCloud Drive: %s" % drive.name)
	return true

func _connect_google_drive(drive: DriveConfig) -> bool:
	# Simulate connection to Google Drive
	_log("Connecting to Google Drive: %s" % drive.name)
	yield(get_tree().create_timer(0.7), "timeout")
	
	# Create the directory for our simulated Google Drive
	var dir = Directory.new()
	if not dir.dir_exists(drive.path):
		var err = dir.make_dir_recursive(drive.path)
		if err != OK:
			_log("Failed to create Google Drive directory: %s (Error: %d)" % [drive.path, err])
			drive.connection_status = ConnectionStatus.ERROR
			return false
	
	# In a real implementation, this would connect to the Google Drive API
	drive.connection_status = ConnectionStatus.CONNECTED
	drive.last_sync = OS.get_unix_time()
	drive.quota_used = int(drive.quota_total * 0.25) # Simulate 25% used
	
	emit_signal("drive_connected", drive.name)
	_log("Connected to Google Drive: %s" % drive.name)
	return true

func _connect_remote_drive(drive: DriveConfig) -> bool:
	# Simulate connection to a remote drive
	_log("Connecting to Remote Drive: %s" % drive.name)
	yield(get_tree().create_timer(1.0), "timeout")
	
	# Simulate random connection failure (20% chance)
	if randf() < 0.2:
		_log("Failed to connect to Remote Drive: %s" % drive.name)
		drive.connection_status = ConnectionStatus.ERROR
		return false
	
	# In a real implementation, this would connect to a remote API
	drive.connection_status = ConnectionStatus.CONNECTED
	drive.last_sync = OS.get_unix_time()
	drive.quota_used = int(drive.quota_total * 0.5) # Simulate 50% used
	
	emit_signal("drive_connected", drive.name)
	_log("Connected to Remote Drive: %s" % drive.name)
	return true

# Sync implementations
func _sync_local_drive(drive: DriveConfig) -> bool:
	_log("Synchronizing local drive: %s" % drive.name)
	
	# Update stats
	var stats = _get_directory_stats(drive.path)
	drive.quota_used = stats.size
	drive.last_sync = OS.get_unix_time()
	
	emit_signal("sync_completed", drive.name)
	_log("Synchronized local drive: %s" % drive.name)
	return true

func _sync_icloud_drive(drive: DriveConfig) -> bool:
	_log("Synchronizing iCloud Drive: %s" % drive.name)
	yield(get_tree().create_timer(0.5), "timeout")
	
	# In a real implementation, this would sync with the iCloud API
	drive.last_sync = OS.get_unix_time()
	
	emit_signal("sync_completed", drive.name)
	_log("Synchronized iCloud Drive: %s" % drive.name)
	return true

func _sync_google_drive(drive: DriveConfig) -> bool:
	_log("Synchronizing Google Drive: %s" % drive.name)
	yield(get_tree().create_timer(0.7), "timeout")
	
	# In a real implementation, this would sync with the Google Drive API
	drive.last_sync = OS.get_unix_time()
	
	emit_signal("sync_completed", drive.name)
	_log("Synchronized Google Drive: %s" % drive.name)
	return true

func _sync_remote_drive(drive: DriveConfig) -> bool:
	_log("Synchronizing Remote Drive: %s" % drive.name)
	yield(get_tree().create_timer(1.0), "timeout")
	
	# Simulate random sync failure (10% chance)
	if randf() < 0.1:
		_log("Failed to synchronize Remote Drive: %s" % drive.name)
		emit_signal("sync_failed", drive.name, "Connection timeout")
		return false
	
	# In a real implementation, this would sync with a remote API
	drive.last_sync = OS.get_unix_time()
	
	emit_signal("sync_completed", drive.name)
	_log("Synchronized Remote Drive: %s" % drive.name)
	return true

# Save implementations
func _save_to_local_drive(data, drive: DriveConfig) -> bool:
	_log("Saving data to local drive: %s" % drive.name)
	
	var file = File.new()
	var file_path = drive.path + "memories/memory_data.dat"
	
	# Make sure the directory exists
	var dir = Directory.new()
	if not dir.dir_exists(drive.path + "memories"):
		dir.make_dir_recursive(drive.path + "memories")
	
	var err = file.open(file_path, File.WRITE)
	if err != OK:
		_log("Failed to open file for writing: %s (Error: %d)" % [file_path, err])
		return false
	
	file.store_var(data)
	file.close()
	
	# Update stats
	var stats = _get_directory_stats(drive.path)
	drive.quota_used = stats.size
	
	_log("Data saved to local drive: %s" % drive.name)
	return true

func _save_to_icloud_drive(data, drive: DriveConfig) -> bool:
	_log("Saving data to iCloud Drive: %s" % drive.name)
	
	# Simulate iCloud save
	yield(get_tree().create_timer(0.5), "timeout")
	
	# Actually save to our simulated iCloud directory
	var file = File.new()
	var file_path = drive.path + "memories/memory_data.dat"
	
	# Make sure the directory exists
	var dir = Directory.new()
	if not dir.dir_exists(drive.path + "memories"):
		dir.make_dir_recursive(drive.path + "memories")
	
	var err = file.open(file_path, File.WRITE)
	if err != OK:
		_log("Failed to open file for writing: %s (Error: %d)" % [file_path, err])
		return false
	
	file.store_var(data)
	file.close()
	
	# Simulate usage update
	drive.quota_used += 1024 * 1024 # Add 1MB
	
	_log("Data saved to iCloud Drive: %s" % drive.name)
	return true

func _save_to_google_drive(data, drive: DriveConfig) -> bool:
	_log("Saving data to Google Drive: %s" % drive.name)
	
	# Simulate Google Drive save
	yield(get_tree().create_timer(0.7), "timeout")
	
	# Actually save to our simulated Google Drive directory
	var file = File.new()
	var file_path = drive.path + "memories/memory_data.dat"
	
	# Make sure the directory exists
	var dir = Directory.new()
	if not dir.dir_exists(drive.path + "memories"):
		dir.make_dir_recursive(drive.path + "memories")
	
	var err = file.open(file_path, File.WRITE)
	if err != OK:
		_log("Failed to open file for writing: %s (Error: %d)" % [file_path, err])
		return false
	
	file.store_var(data)
	file.close()
	
	# Simulate usage update
	drive.quota_used += 1024 * 1024 # Add 1MB
	
	_log("Data saved to Google Drive: %s" % drive.name)
	return true

func _save_to_remote_drive(data, drive: DriveConfig) -> bool:
	_log("Saving data to Remote Drive: %s" % drive.name)
	
	# Simulate remote save
	yield(get_tree().create_timer(1.0), "timeout")
	
	# Simulate random save failure (15% chance)
	if randf() < 0.15:
		_log("Failed to save data to Remote Drive: %s" % drive.name)
		return false
	
	# Actually save to our simulated remote directory
	var file = File.new()
	var file_path = drive.path + "memories/memory_data.dat"
	
	# Make sure the directory exists
	var dir = Directory.new()
	if not dir.dir_exists(drive.path + "memories"):
		dir.make_dir_recursive(drive.path + "memories")
	
	var err = file.open(file_path, File.WRITE)
	if err != OK:
		_log("Failed to open file for writing: %s (Error: %d)" % [file_path, err])
		return false
	
	file.store_var(data)
	file.close()
	
	# Simulate usage update
	drive.quota_used += 2 * 1024 * 1024 # Add 2MB
	
	_log("Data saved to Remote Drive: %s" % drive.name)
	return true

# Load implementations
func _load_from_local_drive(drive: DriveConfig) -> Dictionary:
	_log("Loading data from local drive: %s" % drive.name)
	
	var file = File.new()
	var file_path = drive.path + "memories/memory_data.dat"
	
	if not file.file_exists(file_path):
		_log("File does not exist: %s" % file_path)
		return {}
	
	var err = file.open(file_path, File.READ)
	if err != OK:
		_log("Failed to open file for reading: %s (Error: %d)" % [file_path, err])
		return {}
	
	var data = file.get_var()
	file.close()
	
	_log("Data loaded from local drive: %s" % drive.name)
	return data if data is Dictionary else {}

func _load_from_icloud_drive(drive: DriveConfig) -> Dictionary:
	_log("Loading data from iCloud Drive: %s" % drive.name)
	
	# Simulate iCloud load
	yield(get_tree().create_timer(0.5), "timeout")
	
	# Actually load from our simulated iCloud directory
	var file = File.new()
	var file_path = drive.path + "memories/memory_data.dat"
	
	if not file.file_exists(file_path):
		_log("File does not exist: %s" % file_path)
		return {}
	
	var err = file.open(file_path, File.READ)
	if err != OK:
		_log("Failed to open file for reading: %s (Error: %d)" % [file_path, err])
		return {}
	
	var data = file.get_var()
	file.close()
	
	_log("Data loaded from iCloud Drive: %s" % drive.name)
	return data if data is Dictionary else {}

func _load_from_google_drive(drive: DriveConfig) -> Dictionary:
	_log("Loading data from Google Drive: %s" % drive.name)
	
	# Simulate Google Drive load
	yield(get_tree().create_timer(0.7), "timeout")
	
	# Actually load from our simulated Google Drive directory
	var file = File.new()
	var file_path = drive.path + "memories/memory_data.dat"
	
	if not file.file_exists(file_path):
		_log("File does not exist: %s" % file_path)
		return {}
	
	var err = file.open(file_path, File.READ)
	if err != OK:
		_log("Failed to open file for reading: %s (Error: %d)" % [file_path, err])
		return {}
	
	var data = file.get_var()
	file.close()
	
	_log("Data loaded from Google Drive: %s" % drive.name)
	return data if data is Dictionary else {}

func _load_from_remote_drive(drive: DriveConfig) -> Dictionary:
	_log("Loading data from Remote Drive: %s" % drive.name)
	
	# Simulate remote load
	yield(get_tree().create_timer(1.0), "timeout")
	
	# Simulate random load failure (15% chance)
	if randf() < 0.15:
		_log("Failed to load data from Remote Drive: %s" % drive.name)
		return {}
	
	# Actually load from our simulated remote directory
	var file = File.new()
	var file_path = drive.path + "memories/memory_data.dat"
	
	if not file.file_exists(file_path):
		_log("File does not exist: %s" % file_path)
		return {}
	
	var err = file.open(file_path, File.READ)
	if err != OK:
		_log("Failed to open file for reading: %s (Error: %d)" % [file_path, err])
		return {}
	
	var data = file.get_var()
	file.close()
	
	_log("Data loaded from Remote Drive: %s" % drive.name)
	return data if data is Dictionary else {}

# Helper: Get directory stats
func _get_directory_stats(path: String) -> Dictionary:
	var result = {
		"size": 0,
		"files": 0,
		"dirs": 0
	}
	
	var dir = Directory.new()
	if dir.open(path) != OK:
		return result
		
	dir.list_dir_begin(true, true)
	
	var file_name = dir.get_next()
	while file_name != "":
		if dir.current_is_dir():
			result.dirs += 1
			var subdir_stats = _get_directory_stats(path.plus_file(file_name))
			result.size += subdir_stats.size
			result.files += subdir_stats.files
			result.dirs += subdir_stats.dirs
		else:
			var file = File.new()
			if file.open(path.plus_file(file_name), File.READ) == OK:
				result.size += file.get_len()
				file.close()
			result.files += 1
			
		file_name = dir.get_next()
		
	dir.list_dir_end()
	
	return result

# Log message to terminal if available
func _log(message: String) -> void:
	print(message)
	if terminal_memory and terminal_memory.has_method("add_memory_text"):
		terminal_memory.add_memory_text(message, "drive")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/drive_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/drive_memory_connector.gd
# SIZE: 11643 bytes
extends Node

# Drive Memory Connector
# Connects the memory investment system to local and external drives
# Enables cross-system memory persistence and synchronization

signal drive_connected(drive_name)
signal memory_fragment_found(fragment_data)
signal sync_complete(stats)

# Drive connection types
enum DriveType {
    LOCAL,
    NETWORK,
    CLOUD,
    VIRTUAL,
    ETHEREAL
}

# Connection state
var connected_drives = {}
var active_memory_paths = []
var memory_fragments = []
var sync_in_progress = false

# Constants
const FRAGMENT_EXTENSION = ".mem.json"
const DRIVE_CONFIG_PATH = "res://12_turns_system/drive_config.json"
const DEFAULT_PATHS = [
    "/mnt/c/Users/Percision 15/12_turns_system/",
    "/mnt/c/Users/Percision 15/world_of_words/",
    "/mnt/c/Users/Percision 15/notepad3d/",
    "/mnt/c/Users/Percision 15/Eden_OS/",
    "/mnt/c/Users/Percision 15/LuminusOS/"
]

# File system access
var file = FileAccess
var dir = DirAccess

# Configuration
var config = {
    "auto_sync": true,
    "sync_interval": 300,  # seconds
    "fragment_threshold": 5,
    "ethereal_enabled": true,
    "directional_scanning": true
}

func _ready():
    # Load configuration
    _load_config()
    
    # Setup timer for auto-sync
    var timer = Timer.new()
    timer.wait_time = config.sync_interval
    timer.autostart = true
    timer.timeout.connect(_auto_sync)
    add_child(timer)
    
    # Connect to default drives
    for path in DEFAULT_PATHS:
        connect_drive(path, DriveType.LOCAL)
    
    # Initial scan
    scan_for_memory_fragments()

func _load_config():
    if file.file_exists(DRIVE_CONFIG_PATH):
        var config_file = file.open(DRIVE_CONFIG_PATH, file.READ)
        var json = JSON.parse_string(config_file.get_as_text())
        if json:
            # Update config with loaded values
            for key in json:
                if config.has(key):
                    config[key] = json[key]

func _save_config():
    var config_file = file.open(DRIVE_CONFIG_PATH, file.WRITE)
    config_file.store_string(JSON.stringify(config, "  "))

func connect_drive(path, type = DriveType.LOCAL):
    # Skip if already connected
    if connected_drives.has(path):
        return false
    
    # Validate path exists
    if not dir.dir_exists(path):
        if type == DriveType.ETHEREAL:
            # Ethereal drives don't need to physically exist
            pass
        else:
            print("Drive path does not exist: ", path)
            return false
    
    # Register drive
    connected_drives[path] = {
        "type": type,
        "connected_at": Time.get_unix_time_from_system(),
        "fragments_found": 0,
        "last_sync": 0
    }
    
    # Add to active paths
    active_memory_paths.append(path)
    
    # Emit signal
    emit_signal("drive_connected", path)
    
    return true

func disconnect_drive(path):
    if connected_drives.has(path):
        active_memory_paths.erase(path)
        connected_drives.erase(path)
        return true
    return false

func scan_for_memory_fragments():
    memory_fragments.clear()
    var fragments_found = 0
    
    for path in active_memory_paths:
        var drive_type = connected_drives[path].type
        
        if drive_type == DriveType.ETHEREAL:
            # Ethereal drives use a different scanning method
            var ethereal_fragments = _scan_ethereal_drive(path)
            memory_fragments.append_array(ethereal_fragments)
            fragments_found += ethereal_fragments.size()
        else:
            # Physical drive scanning
            fragments_found += _scan_physical_drive(path)
    
    print("Memory scan complete. Found ", fragments_found, " fragments.")
    return fragments_found

func _scan_physical_drive(path):
    var fragments_found = 0
    var d = dir.open(path)
    
    if d:
        d.list_dir_begin()
        var file_name = d.get_next()
        
        while file_name != "":
            if not d.current_is_dir():
                # Check if it's a memory fragment
                if file_name.ends_with(FRAGMENT_EXTENSION):
                    var full_path = path.path_join(file_name)
                    var fragment = _load_fragment(full_path)
                    
                    if fragment:
                        memory_fragments.append(fragment)
                        fragments_found += 1
                        emit_signal("memory_fragment_found", fragment)
            else:
                # Recursively scan subdirectories if not . or ..
                if file_name != "." and file_name != ".." and config.directional_scanning:
                    var subdir_path = path.path_join(file_name)
                    fragments_found += _scan_physical_drive(subdir_path)
            
            file_name = d.get_next()
    
    # Update drive stats
    if connected_drives.has(path):
        connected_drives[path].fragments_found = fragments_found
        connected_drives[path].last_sync = Time.get_unix_time_from_system()
    
    return fragments_found

func _scan_ethereal_drive(path):
    # Ethereal drives don't physically exist
    # They're procedurally generated based on memory investment patterns
    var ethereal_fragments = []
    
    # Generate ethereal fragments based on existing memory patterns
    for i in range(memory_fragments.size()):
        var source_fragment = memory_fragments[i]
        
        # Only create ethereal variations if we have enough physical fragments
        if i % config.fragment_threshold == 0 and i > 0:
            var ethereal_fragment = _generate_ethereal_fragment(source_fragment)
            ethereal_fragments.append(ethereal_fragment)
    
    return ethereal_fragments

func _generate_ethereal_fragment(source):
    # Create an ethereal variation of a physical fragment
    var ethereal = source.duplicate(true)
    
    # Modify with ethereal properties
    ethereal.is_ethereal = true
    ethereal.origin_path = source.path
    ethereal.path = "ethereal://" + str(randi() % 1000000) + "/" + source.name
    
    # Add dimensional shift
    if ethereal.has("dimensions"):
        for d in ethereal.dimensions:
            # Shift dimension value slightly
            ethereal.dimensions[d] += randf_range(-0.1, 0.2)
    
    # Add blue tint to color if present
    if ethereal.has("color"):
        var color = Color(ethereal.color)
        color = color.lerp(Color(0.5, 0.7, 0.9), 0.3)
        ethereal.color = color.to_html()
    
    return ethereal

func _load_fragment(path):
    if not file.file_exists(path):
        return null
    
    var fragment_file = file.open(path, file.READ)
    var json = JSON.parse_string(fragment_file.get_as_text())
    
    if json:
        # Add metadata
        json.path = path
        json.name = path.get_file().trim_suffix(FRAGMENT_EXTENSION)
        json.is_ethereal = false
        
        return json
    
    return null

func save_memory_fragment(fragment_data, target_path = ""):
    if target_path.is_empty():
        # Use the first connected drive by default
        if active_memory_paths.size() > 0:
            target_path = active_memory_paths[0]
        else:
            print("No connected drives to save fragment")
            return false
    
    # Ensure path ends with separator
    if not target_path.ends_with("/"):
        target_path += "/"
    
    # Generate a name if none provided
    if not fragment_data.has("name") or fragment_data.name.is_empty():
        fragment_data.name = "memory_" + str(randi() % 1000000)
    
    # Create the file path
    var file_path = target_path + fragment_data.name + FRAGMENT_EXTENSION
    
    # Save to file
    var fragment_file = file.open(file_path, file.WRITE)
    if fragment_file:
        # Remove path info before saving (to avoid circular references)
        var save_data = fragment_data.duplicate(true)
        if save_data.has("path"):
            save_data.erase("path")
        
        fragment_file.store_string(JSON.stringify(save_data, "  "))
        return true
    
    return false

func get_memory_fragment(name_or_path):
    # Try to find by path
    for fragment in memory_fragments:
        if fragment.path == name_or_path:
            return fragment
    
    # Try to find by name
    for fragment in memory_fragments:
        if fragment.name == name_or_path:
            return fragment
    
    return null

func _auto_sync():
    if config.auto_sync and not sync_in_progress:
        sync_memory_fragments()

func sync_memory_fragments():
    if sync_in_progress:
        return false
    
    sync_in_progress = true
    
    # Scan all drives
    var found = scan_for_memory_fragments()
    
    # Cross-reference fragments and sync unique ones to all drives
    var unique_fragments = _identify_unique_fragments()
    var sync_stats = {
        "found": found,
        "unique": unique_fragments.size(),
        "synced": 0
    }
    
    # Sync to all drives
    for fragment in unique_fragments:
        # Skip ethereal fragments, they don't get saved to disk
        if fragment.has("is_ethereal") and fragment.is_ethereal:
            continue
        
        for path in active_memory_paths:
            var drive_type = connected_drives[path].type
            
            # Only sync to physical drives
            if drive_type != DriveType.ETHEREAL:
                if save_memory_fragment(fragment, path):
                    sync_stats.synced += 1
    
    sync_in_progress = false
    emit_signal("sync_complete", sync_stats)
    return true

func _identify_unique_fragments():
    var unique = []
    var fragment_hashes = {}
    
    for fragment in memory_fragments:
        # Create a simplified version for hashing
        var simplified = fragment.duplicate(true)
        if simplified.has("path"):
            simplified.erase("path")
        if simplified.has("name"):
            simplified.erase("name")
        if simplified.has("is_ethereal"):
            simplified.erase("is_ethereal")
        
        # Generate a hash
        var hash_text = JSON.stringify(simplified)
        var fragment_hash = hash_text.hash()
        
        # Add if unique
        if not fragment_hashes.has(fragment_hash):
            fragment_hashes[fragment_hash] = true
            unique.append(fragment)
    
    return unique

func get_drive_stats():
    var stats = {
        "drives": connected_drives.size(),
        "fragments": memory_fragments.size(),
        "paths": active_memory_paths
    }
    return stats

func create_fragment_from_investment(word, category, value, directional_data):
    var fragment = {
        "name": "investment_" + word,
        "type": "investment",
        "word": word,
        "category": category,
        "value": value,
        "timestamp": Time.get_unix_time_from_system(),
        "directions": directional_data,
        "dimensions": {
            "x": directional_data.get("right", 0) - directional_data.get("left", 0),
            "y": directional_data.get("up", 0) - directional_data.get("down", 0),
            "z": directional_data.get("forward", 0) - directional_data.get("backward", 0),
            "w": directional_data.get("inward", 0) - directional_data.get("outward", 0)
        },
        "color": _get_category_color(category)
    }
    
    return fragment

func _get_category_color(category):
    match category:
        "Knowledge": return "#3388ff"
        "Insight": return "#cc66ff"
        "Creation": return "#33cc66"
        "Connection": return "#ff9933"
        "Memory": return "#99ccff"
        "Dream": return "#7755cc"
        "Ethereal": return "#eeeeff"
        _: return "#aaaaaa"
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/drive_memory_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/dual_core_terminal.gd
# SIZE: 26332 bytes
extends Node

# Dual Core Terminal System for 12 Turns Game
# Manages multiple terminal cores and their interactions with the Divine Word Game
# Implements hash-based bracket coloring and special pattern detection

class_name DualCoreTerminal

# ----- CORE CONFIGURATION -----
const MAX_CORES = 9
const CORE_0_PRIORITY = 100
const HASH_SYMBOL = "#"
const MAX_ACCOUNT_VALUE = 19

# ----- TERMINAL WINDOW STATES -----
enum WindowState {
    ACTIVE,
    PROCESSING,
    WAITING,
    BACKGROUND,
    API_CONNECTED,
    MAX_ACCOUNT,
    CALIBRATION,
    GAME_MODE,
    TETRIS_MODE,
    MINECRAFT_MODE
}

# ----- MIRACLE PATTERN DETECTION -----
const MIRACLE_PATTERN = "#$%$#@@"
const SPECIAL_PATTERNS = {
    "####": "solid_wall",
    "~~~~": "water_area",
    "^^^^": "lava_pit",
    "...+...": "door_corridor",
    "@@@": "entity_spawn",
    "$$$": "treasure_room",
    "###\n#+#\n###": "enclosed_room",
    "[@]": "player_start",
    "<->": "teleporter",
    "/*\\": "time_rune",
    "|/\\|": "dimension_gate"
}

# ----- TIME STATES -----
enum TimeState {
    PAST,
    PRESENT,
    FUTURE,
    TIMELESS
}

# ----- BRACKET STYLES -----
var bracket_styles = {
    "default": {
        "color": Color(1, 1, 1),
        "bold": false,
        "symbol_pairs": [["(", ")"], ["[", "]"], ["{", "}"], ["<", ">"]]
    },
    "red": {
        "color": Color(1, 0, 0),
        "bold": true,
        "symbol_pairs": [["(", ")"], ["[", "]"], ["{", "}"], ["<", ">"]]
    },
    "green": {
        "color": Color(0, 1, 0),
        "bold": true,
        "symbol_pairs": [["(", ")"], ["[", "]"], ["{", "}"], ["<", ">"]]
    },
    "blue": {
        "color": Color(0, 0, 1),
        "bold": true,
        "symbol_pairs": [["(", ")"], ["[", "]"], ["{", "}"], ["<", ">"]]
    },
    "purple": {
        "color": Color(0.5, 0, 0.5),
        "bold": true,
        "symbol_pairs": [["(", ")"], ["[", "]"], ["{", "}"], ["<", ">"]]
    },
    "gold": {
        "color": Color(1, 0.84, 0),
        "bold": true,
        "symbol_pairs": [["(", ")"], ["[", "]"], ["{", "}"], ["<", ">"]]
    },
    "rainbow": {
        "color": Color(1, 1, 1),  # Base color, actual colors cycle
        "bold": true,
        "symbol_pairs": [["(", ")"], ["[", "]"], ["{", "}"], ["<", ">"]],
        "rainbow": true
    }
}

# ----- TERMINAL CORE STORAGE -----
var cores = {}
var active_core_id = 0
var current_time_state = TimeState.PRESENT
var rainbow_colors = [
    Color(1, 0, 0),      # Red
    Color(1, 0.5, 0),    # Orange
    Color(1, 1, 0),      # Yellow
    Color(0, 1, 0),      # Green
    Color(0, 0.5, 1),    # Blue
    Color(0.3, 0, 0.8)   # Purple
]
var rainbow_index = 0
var rainbow_timer = 0

# ----- GAME INTEGRATION -----
var divine_word_game = null
var divine_word_processor = null
var turn_system = null
var word_comment_system = null

# ----- SIGNALS -----
signal core_switched(from_core, to_core)
signal input_processed(core_id, text, result)
signal special_pattern_detected(pattern, effect)
signal miracle_triggered(core_id)
signal time_state_changed(old_state, new_state)
signal snake_case_detected(text, cleaned_text)

# ----- INITIALIZATION -----
func _ready():
    print("Dual Core Terminal System initializing...")
    
    # Initialize core 0 (always exists)
    cores[0] = {
        "id": 0,
        "state": WindowState.ACTIVE,
        "name": "Core 0",
        "priority": CORE_0_PRIORITY,
        "buffer": "",
        "history": [],
        "bracket_style": "default",
        "account_value": 0,
        "special_patterns": {},
        "last_input": "",
        "creation_time": OS.get_unix_time(),
        "miracle_count": 0
    }
    
    # Connect to game systems
    _connect_to_game_systems()
    
    # Initialize additional cores based on current dimension
    _initialize_dimension_cores()
    
    print("Dual Core Terminal System initialized")
    print("Active cores: " + str(cores.size()))
    print("Current time state: " + TimeState.keys()[current_time_state])

func _connect_to_game_systems():
    # Connect to divine word game
    divine_word_game = get_node_or_null("/root/DivineWordGame")
    
    # Connect to divine word processor
    divine_word_processor = get_node_or_null("/root/DivineWordProcessor")
    
    # Connect to turn system
    turn_system = get_node_or_null("/root/TurnSystem")
    if turn_system:
        turn_system.connect("dimension_changed", self, "_on_dimension_changed")
    
    # Connect to word comment system
    word_comment_system = get_node_or_null("/root/WordCommentSystem")

func _initialize_dimension_cores():
    # Create additional cores based on current dimension
    var dimension = 3 # Default dimension if turn system not found
    
    if turn_system:
        dimension = turn_system.current_dimension
    
    # Create cores based on dimension
    for i in range(1, min(dimension + 1, MAX_CORES)):
        # Each dimension unlocks a new core
        if not cores.has(i):
            cores[i] = {
                "id": i,
                "state": WindowState.WAITING,
                "name": "Core " + str(i),
                "priority": i * 10,
                "buffer": "",
                "history": [],
                "bracket_style": "default",
                "account_value": 0,
                "special_patterns": {},
                "last_input": "",
                "creation_time": OS.get_unix_time(),
                "miracle_count": 0
            }

# ----- PROCESSING -----
func _process(delta):
    # Update rainbow colors if any cores use rainbow style
    rainbow_timer += delta
    if rainbow_timer >= 0.2: # Update every 0.2 seconds
        rainbow_timer = 0
        rainbow_index = (rainbow_index + 1) % rainbow_colors.size()
        
        # Check if any cores use rainbow brackets
        for core_id in cores:
            if cores[core_id].bracket_style == "rainbow":
                # This will trigger a redraw on any UI components displaying this core
                pass

# ----- CORE MANAGEMENT -----
func switch_core(core_id):
    if not cores.has(core_id):
        print("ERROR: Cannot switch to non-existent core: " + str(core_id))
        return false
    
    var old_core = active_core_id
    active_core_id = core_id
    
    # Mark old core as background, new core as active
    if cores.has(old_core):
        cores[old_core].state = WindowState.BACKGROUND
    
    cores[active_core_id].state = WindowState.ACTIVE
    
    emit_signal("core_switched", old_core, active_core_id)
    print("Switched from Core " + str(old_core) + " to Core " + str(core_id))
    
    return true

func create_core(core_id, name=""):
    if cores.has(core_id):
        print("WARNING: Core " + str(core_id) + " already exists!")
        return false
    
    if core_id < 0 or core_id >= MAX_CORES:
        print("ERROR: Core ID must be between 0 and " + str(MAX_CORES-1))
        return false
    
    var core_name = name if name else "Core " + str(core_id)
    
    cores[core_id] = {
        "id": core_id,
        "state": WindowState.WAITING,
        "name": core_name,
        "priority": core_id * 10,
        "buffer": "",
        "history": [],
        "bracket_style": "default",
        "account_value": 0,
        "special_patterns": {},
        "last_input": "",
        "creation_time": OS.get_unix_time(),
        "miracle_count": 0
    }
    
    print("Created new core: " + core_name + " (ID: " + str(core_id) + ")")
    return true

func get_core_info(core_id):
    if not cores.has(core_id):
        return null
    
    # Return a copy of core info without history (can be large)
    var info = cores[core_id].duplicate()
    info.erase("history")
    return info

func get_all_cores():
    var core_ids = []
    for core_id in cores:
        core_ids.append(core_id)
    return core_ids

# ----- INPUT PROCESSING -----
func process_input(core_id, input_text):
    if not cores.has(core_id):
        print("ERROR: Cannot process input for non-existent core: " + str(core_id))
        return null
    
    # Store raw input in core history
    cores[core_id].history.append({
        "type": "input",
        "text": input_text,
        "timestamp": OS.get_unix_time()
    })
    
    cores[core_id].last_input = input_text
    
    var result = {
        "original": input_text,
        "processed": input_text,
        "special_patterns": [],
        "hash_commands": [],
        "miracle_triggered": false,
        "time_shift": false,
        "snake_case_detected": false
    }
    
    # Process special hash commands
    if input_text.find(HASH_SYMBOL) >= 0:
        result.hash_commands = _process_hash_commands(core_id, input_text)
    
    # Check for special patterns
    var patterns = _detect_special_patterns(input_text)
    result.special_patterns = patterns
    
    # Check for miracle pattern
    if input_text.find(MIRACLE_PATTERN) >= 0:
        result.miracle_triggered = true
        _trigger_miracle(core_id)
    
    # Check for time state commands
    var time_shift = _check_time_shift_commands(input_text)
    if time_shift:
        result.time_shift = true
    
    # Check for snake_case formatting
    if "_" in input_text:
        var snake_case = _process_snake_case(input_text)
        if snake_case.detected:
            result.snake_case_detected = true
            result.snake_case = snake_case.cleaned
            
            emit_signal("snake_case_detected", input_text, snake_case.cleaned)
            
            # Special case for "I_Might_See"
            if snake_case.cleaned == "i_might_see":
                result.i_might_see_secret = true
                _handle_i_might_see_secret(core_id)
    
    # Process words with divine word processor
    if divine_word_processor:
        var word_result = divine_word_processor.process_text(input_text, "Terminal_Core_" + str(core_id))
        result.word_power = word_result.total_power
        result.powerful_words = word_result.powerful_words
    
    # Send result to game if available
    if divine_word_game:
        divine_word_game.process_word(input_text)
    
    # Add output to core history
    cores[core_id].history.append({
        "type": "output",
        "text": str(result),
        "timestamp": OS.get_unix_time()
    })
    
    emit_signal("input_processed", core_id, input_text, result)
    return result

func _process_hash_commands(core_id, text):
    var commands = []
    var parts = text.split(HASH_SYMBOL)
    
    # Skip the first part (before any hash)
    for i in range(1, parts.size()):
        var command_text = parts[i].strip_edges()
        
        # Extract first word as command
        var command = ""
        var param = ""
        
        var space_pos = command_text.find(" ")
        if space_pos >= 0:
            command = command_text.substr(0, space_pos).to_lower()
            param = command_text.substr(space_pos + 1).strip_edges()
        else:
            command = command_text.to_lower()
        
        if command:
            commands.append({
                "command": command,
                "param": param
            })
            
            # Process command
            _process_command(core_id, command, param)
    
    return commands

func _process_command(core_id, command, param):
    match command:
        "red", "green", "blue", "purple", "gold", "rainbow", "default":
            # Change bracket style
            cores[core_id].bracket_style = command
            print("Core " + str(core_id) + " bracket style set to: " + command)
        
        "switch":
            # Switch core if param is a valid core ID
            if param.is_valid_integer():
                var target_core = int(param)
                if cores.has(target_core):
                    switch_core(target_core)
        
        "account":
            # Set account value if param is a valid integer
            if param.is_valid_integer():
                var value = int(param)
                if value >= 0 and value <= MAX_ACCOUNT_VALUE:
                    cores[core_id].account_value = value
                    print("Core " + str(core_id) + " account value set to: " + str(value))
                    
                    # If account value reached max, set special state
                    if value == MAX_ACCOUNT_VALUE:
                        cores[core_id].state = WindowState.MAX_ACCOUNT
                        print("Core " + str(core_id) + " reached MAX_ACCOUNT state!")
        
        "calibrate":
            # Enter calibration mode
            cores[core_id].state = WindowState.CALIBRATION
            print("Core " + str(core_id) + " entered CALIBRATION state")
        
        "game":
            # Enter game mode
            cores[core_id].state = WindowState.GAME_MODE
            print("Core " + str(core_id) + " entered GAME_MODE state")
        
        "name":
            # Set core name
            if param:
                cores[core_id].name = param
                print("Core " + str(core_id) + " renamed to: " + param)
        
        "comment":
            # Add comment to word comment system
            if word_comment_system and param:
                var parts = param.split(" ", true, 1)
                if parts.size() >= 2:
                    var word = parts[0]
                    var comment = parts[1]
                    word_comment_system.add_comment(word, comment, word_comment_system.CommentType.OBSERVATION, 
                        "Core_" + str(core_id))
                    print("Comment added for word: " + word)

func _detect_special_patterns(text):
    var found_patterns = []
    
    # Check for each special pattern
    for pattern in SPECIAL_PATTERNS:
        if text.find(pattern) >= 0:
            found_patterns.append({
                "pattern": pattern,
                "effect": SPECIAL_PATTERNS[pattern]
            })
            
            emit_signal("special_pattern_detected", pattern, SPECIAL_PATTERNS[pattern])
    
    return found_patterns

func _trigger_miracle(core_id):
    # Increment miracle count for this core
    cores[core_id].miracle_count += 1
    
    # Add special output to core history
    cores[core_id].history.append({
        "type": "miracle",
        "text": "MIRACLE PATTERN DETECTED: Reality manifests!",
        "timestamp": OS.get_unix_time()
    })
    
    # Change bracket style to rainbow for this core
    cores[core_id].bracket_style = "rainbow"
    
    emit_signal("miracle_triggered", core_id)
    print("MIRACLE triggered on Core " + str(core_id) + "!")
    
    # Notify divine word game if available
    if divine_word_game:
        divine_word_game.process_word("miracle")
    
    # Add comment to word comment system if available
    if word_comment_system:
        word_comment_system.add_comment("miracle", 
            "MIRACLE PATTERN DETECTED on Core " + str(core_id) + "!",
            word_comment_system.CommentType.DIVINE, "Miracle_System")

func _check_time_shift_commands(text):
    var lower_text = text.to_lower()
    var old_state = current_time_state
    var changed = false
    
    if "past" in lower_text and (text.begins_with("past") or " past" in lower_text):
        current_time_state = TimeState.PAST
        changed = true
    elif "future" in lower_text and (text.begins_with("future") or " future" in lower_text):
        current_time_state = TimeState.FUTURE
        changed = true
    elif "present" in lower_text and (text.begins_with("present") or " present" in lower_text):
        current_time_state = TimeState.PRESENT
        changed = true
    elif "timeless" in lower_text and (text.begins_with("timeless") or " timeless" in lower_text):
        current_time_state = TimeState.TIMELESS
        changed = true
    
    if changed and old_state != current_time_state:
        emit_signal("time_state_changed", old_state, current_time_state)
        print("Time state changed from " + TimeState.keys()[old_state] + " to " + TimeState.keys()[current_time_state])
        
        # Add comment to word comment system if available
        if word_comment_system:
            word_comment_system.add_comment("time_shift",
                "Time state shifted to " + TimeState.keys()[current_time_state],
                word_comment_system.CommentType.OBSERVATION, "Time_System")
        
        return true
    
    return false

func _process_snake_case(text):
    var result = {
        "detected": false,
        "cleaned": ""
    }
    
    # Check if text has underscores and follows snake_case pattern
    if "_" in text:
        var words = text.split("_")
        var valid_snake_case = true
        
        # Verify that all parts are valid words
        for word in words:
            if word.strip_edges().empty():
                valid_snake_case = false
                break
        
        if valid_snake_case:
            result.detected = true
            result.cleaned = text.to_lower().strip_edges()
            
            # Add comment to word comment system if available
            if word_comment_system:
                word_comment_system.add_comment("snake_case",
                    "Snake case detected: " + result.cleaned,
                    word_comment_system.CommentType.OBSERVATION, "Snake_Case_System")
    
    return result

func _handle_i_might_see_secret(core_id):
    # Special functionality for the I_Might_See secret
    print("I_Might_See secret detected on Core " + str(core_id) + "!")
    
    # Add special output to core history
    cores[core_id].history.append({
        "type": "secret",
        "text": "I_MIGHT_SEE: The hidden truth reveals itself!",
        "timestamp": OS.get_unix_time()
    })
    
    # Change bracket style to gold for this core
    cores[core_id].bracket_style = "gold"
    
    # Add comment to word comment system if available
    if word_comment_system:
        word_comment_system.add_comment("i_might_see",
            "SECRET DISCOVERED: I_Might_See reveals the hidden reality!",
            word_comment_system.CommentType.DIVINE, "Secret_System")
    
    # If turn system is available, advance to the next dimension
    if turn_system and turn_system.current_dimension < turn_system.max_turns:
        turn_system.set_dimension(turn_system.current_dimension + 1)

# ----- TEXT FORMATTING -----
func format_text_with_brackets(core_id, text):
    if not cores.has(core_id):
        return text
    
    var style_name = cores[core_id].bracket_style
    
    if not bracket_styles.has(style_name):
        style_name = "default"
    
    var style = bracket_styles[style_name]
    var formatted_text = text
    
    # Handle rainbow style specially
    if style_name == "rainbow":
        # Choose color based on current rainbow index
        var color = rainbow_colors[rainbow_index]
        
        # Format each bracket pair with the current rainbow color
        for pair in style.symbol_pairs:
            var open_bracket = pair[0]
            var close_bracket = pair[1]
            
            # Replace with colored versions
            formatted_text = formatted_text.replace(open_bracket, "[color=#" + color.to_html(false) + "]" + open_bracket + "[/color]")
            formatted_text = formatted_text.replace(close_bracket, "[color=#" + color.to_html(false) + "]" + close_bracket + "[/color]")
    else:
        # Standard styling
        var color = style.color
        var is_bold = style.bold
        
        for pair in style.symbol_pairs:
            var open_bracket = pair[0]
            var close_bracket = pair[1]
            
            # Replace with colored/bold versions
            var open_tag = "[color=#" + color.to_html(false) + "]"
            var close_tag = "[/color]"
            
            if is_bold:
                open_tag += "[b]"
                close_tag = "[/b]" + close_tag
            
            formatted_text = formatted_text.replace(open_bracket, open_tag + open_bracket + close_tag)
            formatted_text = formatted_text.replace(close_bracket, open_tag + close_bracket + close_tag)
    
    return formatted_text

func format_output_for_time_state(text):
    # Modify text based on current time state
    match current_time_state:
        TimeState.PAST:
            return "[i][color=#aaaaaa]" + text + "[/color][/i]"
        
        TimeState.FUTURE:
            return "[color=#7777ff]" + text + "[/color]"
        
        TimeState.TIMELESS:
            return "[color=#aa77dd][wave amp=20 freq=2 connected=true]" + text + "[/wave][/color]"
        
        _: # PRESENT or default
            return text

# ----- EVENT HANDLERS -----
func _on_dimension_changed(new_dimension, old_dimension):
    print("Dimension changed from " + str(old_dimension) + "D to " + str(new_dimension) + "D")
    
    # Create new cores for the new dimension
    for i in range(old_dimension + 1, new_dimension + 1):
        if i < MAX_CORES and not cores.has(i):
            create_core(i)
    
    # Update all cores with dimension-specific behavior
    _update_cores_for_dimension(new_dimension)

func _update_cores_for_dimension(dimension):
    # Apply dimension-specific effects to all cores
    match dimension:
        1: # Genesis - core 0 only
            # Reset all cores except core 0
            for core_id in cores:
                if core_id != 0:
                    cores[core_id].buffer = ""
                    cores[core_id].state = WindowState.WAITING
            
            # Focus on core 0
            switch_core(0)
        
        4: # 4D - Time dimension
            # Enable time shifting commands
            print("Time dimension activated - Time shifting enabled")
        
        7: # 7D - Dream dimension
            # Change bracket style of core 7 to purple (dream color)
            if cores.has(7):
                cores[7].bracket_style = "purple"
                
                # Add comment about special state
                if word_comment_system:
                    word_comment_system.add_comment("core_7", 
                        "Core 7 activated in Dream Dimension - Unlock your subconscious!",
                        word_comment_system.CommentType.DREAM, "Core_System")
        
        9: # 9D - Judgment dimension
            # Change bracket style of core 0 to gold (judgment color)
            cores[0].bracket_style = "gold"
            
            # Add comment about this special dimension
            if word_comment_system:
                word_comment_system.add_comment("dimension_9", 
                    "Judgment dimension activated - Words will be judged!",
                    word_comment_system.CommentType.DIVINE, "Core_System")
        
        12: # 12D - Divine dimension
            # All cores get rainbow brackets
            for core_id in cores:
                cores[core_id].bracket_style = "rainbow"
            
            # Add comment about ultimate dimension
            if word_comment_system:
                word_comment_system.add_comment("dimension_12", 
                    "Divine dimension activated - All cores at maximum power!",
                    word_comment_system.CommentType.DIVINE, "Core_System")

# ----- PUBLIC API -----
func get_current_core_id():
    return active_core_id

func get_core_history(core_id, limit=10):
    if not cores.has(core_id):
        return []
    
    # Return most recent entries
    var history = cores[core_id].history
    
    if history.size() <= limit:
        return history
    
    return history.slice(history.size() - limit, history.size() - 1)

func get_formatted_core_output(core_id, text):
    # Apply bracket formatting and time state formatting
    var bracketed = format_text_with_brackets(core_id, text)
    return format_output_for_time_state(bracketed)

func clear_core_history(core_id):
    if cores.has(core_id):
        cores[core_id].history = []
        return true
    return false

func get_time_state():
    return current_time_state

func set_time_state(state):
    if state >= 0 and state < TimeState.size():
        var old_state = current_time_state
        current_time_state = state
        
        if old_state != current_time_state:
            emit_signal("time_state_changed", old_state, current_time_state)
            return true
    
    return false

func get_miracle_count(core_id):
    if cores.has(core_id):
        return cores[core_id].miracle_count
    return 0

func get_total_miracle_count():
    var total = 0
    for core_id in cores:
        total += cores[core_id].miracle_count
    return total

# Creates a multicolor bracket pattern based on the current core
func get_multicolor_pattern(core_id, text, pattern_type="standard"):
    var result = text
    
    # Different pattern types
    match pattern_type:
        "rainbow":
            # Rainbow pattern with gradient across text
            var colors = rainbow_colors
            var sections = min(6, text.length())
            var section_length = text.length() / sections
            
            for i in range(sections):
                var start_pos = i * section_length
                var end_pos = (i + 1) * section_length
                if i == sections - 1:
                    end_pos = text.length()
                
                var color = colors[i % colors.size()]
                var section = text.substr(start_pos, end_pos - start_pos)
                
                result = result.replace(section, "[color=#" + color.to_html(false) + "]" + section + "[/color]")
        
        "miracle":
            # Special miracle pattern with flashing effect
            result = "[rainbow freq=0.2 sat=10 val=20]" + result + "[/rainbow]"
        
        "snake_case":
            # Pattern for snake_case words
            var words = text.split("_")
            result = ""
            
            for i in range(words.size()):
                var word = words[i]
                var color = rainbow_colors[i % rainbow_colors.size()]
                
                result += "[color=#" + color.to_html(false) + "]" + word + "[/color]"
                if i < words.size() - 1:
                    result += "[color=#ffffff]_[/color]"
        
        _: # standard or default
            # Just apply the core's bracket style
            result = format_text_with_brackets(core_id, text)
    
    return result
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/dual_core_terminal.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/eden_pitopia_integration.gd
# SIZE: 43648 bytes
extends Node

# Eden Pitopia Integration
# Integrates Eden Harmony and Pitopia systems with the Akashic Notepad3D game
# Connects the word manifestation and dimensional systems across projects

class_name EdenPitopiaIntegration

# ----- COMPONENT REFERENCES -----
var akashic_controller = null
var system_integrator = null 
var universal_connector = null
var integrated_game_system = null
var harmony_connector = null
var pitopia_main = null

# ----- EDEN COMPONENTS -----
var word_manifestor = null
var ethereal_engine = null
var dimension_controller = null
var turn_system = null
var entity_manager = null
var color_system = null

# ----- CONFIGURATION -----
export var auto_initialize = true
export var default_dimension = 3
export var auto_sync_dimensions = true
export var record_words_to_akashic = true
export var enable_dimension_effects = true
export var enable_turn_system_integration = true
export var debug_mode = false

# ----- STATE VARIABLES -----
var initialized = false
var active_dimension = 3
var pitopia_dimension = 3
var harmony_dimension = 3
var manifested_words = {}
var entity_mappings = {}
var dimension_sync_active = true
var akashic_record_cache = {}
var turn_callbacks = {}
var dimensional_transition_active = false

# ----- SIGNALS -----
signal integration_initialized
signal word_manifested(word, entity_id, system_name)
signal entity_created(entity_id, entity_data, system_name)
signal dimension_synchronized(dimension_number, source_system)
signal turn_advanced(turn_number)
signal akashic_record_created(record_id, content, tags)

# ----- INITIALIZATION -----
func _ready():
    if auto_initialize:
        initialize()

func initialize():
    print("Initializing Eden Pitopia Integration...")
    
    # Find system integrator
    system_integrator = find_system_integrator()
    
    # Find akashic controller through system integrator
    if system_integrator and system_integrator.has_method("get_akashic_controller"):
        akashic_controller = system_integrator.get_akashic_controller()
    else:
        akashic_controller = find_node_by_class("AkashicNotepadController")
    
    # Find integrated game system
    integrated_game_system = find_node_by_class("IntegratedGameSystem")
    
    # Find universal connector
    universal_connector = find_node_by_class("UniversalAkashicConnector")
    
    # Connect to Harmony and Pitopia systems
    connect_to_eden_harmony()
    connect_to_pitopia()
    
    # Set initial dimension
    active_dimension = default_dimension
    
    # Connect signals
    connect_signals()
    
    # Mark as initialized
    initialized = true
    print("Eden Pitopia Integration initialized")
    emit_signal("integration_initialized")
    
    # Synchronize dimensions
    if auto_sync_dimensions:
        synchronize_dimensions(active_dimension)

# ----- COMPONENT DISCOVERY -----
func find_system_integrator():
    # First try to find it in the scene
    var integrator = find_node_by_class("SystemIntegrator")
    
    # If not found, try to find it globally
    if not integrator:
        if has_node("/root/SystemIntegrator"):
            integrator = get_node("/root/SystemIntegrator")
    
    return integrator

func find_node_by_class(class_name):
    # First check if it's a child of this node
    for child in get_children():
        if child.get_class() == class_name:
            return child
    
    # Try to find it in the scene tree
    var root = get_tree().get_root()
    
    for child in root.get_children():
        var found = find_node_recursive(child, class_name)
        if found:
            return found
    
    return null

func find_node_recursive(node, class_name):
    if node.get_class() == class_name:
        return node
    
    for child in node.get_children():
        var found = find_node_recursive(child, class_name)
        if found:
            return found
    
    return null

# ----- EDEN HARMONY CONNECTION -----
func connect_to_eden_harmony():
    # Try to find EdenHarmonyConnector
    harmony_connector = find_node_by_class("EdenHarmonyConnector")
    
    if not harmony_connector:
        # Try to load the script and create an instance
        var harmony_script = load_script_file("eden_harmony_connector.gd")
        if harmony_script:
            harmony_connector = Node.new()
            harmony_connector.set_script(harmony_script)
            harmony_connector.name = "EdenHarmonyConnector"
            add_child(harmony_connector)
            print("Created new Eden Harmony Connector instance")
    
    if harmony_connector:
        # Get references to Eden components
        word_manifestor = harmony_connector.get_word_manifestor()
        turn_system = harmony_connector.get_turn_system()
        ethereal_engine = harmony_connector.get_ethereal_engine()
        dimension_controller = harmony_connector.get_dimension_controller()
        entity_manager = harmony_connector.get_entity_manager()
        color_system = harmony_connector.get_color_system()
        
        print("Connected to Eden Harmony system")
        return true
    
    print("Failed to connect to Eden Harmony system")
    return false

# ----- PITOPIA CONNECTION -----
func connect_to_pitopia():
    # Try to find PitopiaMain
    pitopia_main = find_node_by_class("PitopiaMain")
    
    if not pitopia_main:
        # Try to load the script and create an instance
        var pitopia_script = load_script_file("pitopia_main.gd")
        if pitopia_script:
            pitopia_main = Node.new()
            pitopia_main.set_script(pitopia_script)
            pitopia_main.name = "PitopiaMain"
            add_child(pitopia_main)
            print("Created new Pitopia Main instance")
    
    if pitopia_main:
        # If we have a Pitopia main instance but no Eden components, get them from Pitopia
        if not word_manifestor and pitopia_main.has_method("get_word_manifestor"):
            word_manifestor = pitopia_main.get_word_manifestor()
        
        if not turn_system and pitopia_main.has_method("get_turn_system"):
            turn_system = pitopia_main.get_turn_system()
        
        if not ethereal_engine and pitopia_main.has_method("get_ethereal_engine"):
            ethereal_engine = pitopia_main.get_ethereal_engine()
        
        if not dimension_controller and pitopia_main.has_method("get_dimension_controller"):
            dimension_controller = pitopia_main.get_dimension_controller()
        
        if not color_system and pitopia_main.has_method("get_color_system"):
            color_system = pitopia_main.get_color_system()
        
        print("Connected to Pitopia system")
        return true
    
    print("Failed to connect to Pitopia system")
    return false

func load_script_file(script_name):
    # Check in several locations for the script
    var potential_paths = [
        "/mnt/c/Users/Percision 15/Godot_Eden/Eden_May/" + script_name,
        "/mnt/c/Users/Percision 15/Godot_Eden/Eden_May/the_palace_pf/code/gdscript/scripts/" + script_name,
        "/mnt/c/Users/Percision 15/12_turns_system/" + script_name,
        "/mnt/c/Users/Percision 15/Eden_OS/scripts/" + script_name,
        "res://" + script_name,
        "res://scripts/" + script_name,
        "res://addons/" + script_name
    ]
    
    for path in potential_paths:
        if File.new().file_exists(path):
            if debug_mode:
                print("Found script at: " + path)
            return load(path)
    
    # If not found, try to search for it
    for base_dir in ["/mnt/c/Users/Percision 15/12_turns_system", "/mnt/c/Users/Percision 15/Godot_Eden/Eden_May", "/mnt/c/Users/Percision 15/Eden_OS"]:
        var script_path = search_for_script(base_dir, script_name)
        if script_path:
            if debug_mode:
                print("Found script by searching at: " + script_path)
            return load(script_path)
    
    if debug_mode:
        print("Failed to find script: " + script_name)
    return null

func search_for_script(base_dir, script_name):
    var dir = Directory.new()
    
    if not dir.dir_exists(base_dir):
        return null
    
    if dir.open(base_dir) == OK:
        dir.list_dir_begin(true, true)
        
        var file_name = dir.get_next()
        while file_name != "":
            var full_path = base_dir + "/" + file_name
            
            if dir.current_is_dir():
                # Recursively search subdirectories
                var found_in_subdir = search_for_script(full_path, script_name)
                if found_in_subdir:
                    return found_in_subdir
            else:
                # Check if this is the script we're looking for
                if file_name == script_name:
                    return full_path
            
            file_name = dir.get_next()
        
        dir.list_dir_end()
    
    return null

# ----- SIGNAL CONNECTIONS -----
func connect_signals():
    # Connect signals from Eden Harmony
    if harmony_connector:
        if harmony_connector.has_signal("word_manifested"):
            harmony_connector.connect("word_manifested", self, "_on_harmony_word_manifested")
        
        if harmony_connector.has_signal("dimension_changed"):
            harmony_connector.connect("dimension_changed", self, "_on_harmony_dimension_changed")
        
        if harmony_connector.has_signal("turn_advanced"):
            harmony_connector.connect("turn_advanced", self, "_on_harmony_turn_advanced")
        
        if harmony_connector.has_signal("entity_created"):
            harmony_connector.connect("entity_created", self, "_on_harmony_entity_created")
    
    # Connect signals from Pitopia
    if pitopia_main:
        if pitopia_main.has_signal("word_manifested"):
            pitopia_main.connect("word_manifested", self, "_on_pitopia_word_manifested")
        
        if pitopia_main.has_signal("dimension_changed"):
            pitopia_main.connect("dimension_changed", self, "_on_pitopia_dimension_changed")
        
        if pitopia_main.has_signal("turn_advanced"):
            pitopia_main.connect("turn_advanced", self, "_on_pitopia_turn_advanced")
    
    # Connect signals from integrated game system
    if integrated_game_system:
        if integrated_game_system.has_signal("dimension_changed"):
            integrated_game_system.connect("dimension_changed", self, "_on_integrated_dimension_changed")
        
        if integrated_game_system.has_signal("entity_created"):
            integrated_game_system.connect("entity_created", self, "_on_integrated_entity_created")
    
    # Connect signals from akashic controller
    if akashic_controller:
        if akashic_controller.has_signal("record_created"):
            akashic_controller.connect("record_created", self, "_on_akashic_record_created")

# ----- DIMENSION MANAGEMENT -----
func synchronize_dimensions(dimension_number):
    if not dimension_sync_active or dimensional_transition_active:
        return false
    
    dimensional_transition_active = true
    active_dimension = dimension_number
    
    # Update Eden Harmony dimension
    if harmony_connector and harmony_connector.has_method("set_dimension"):
        harmony_connector.set_dimension(dimension_number)
        harmony_dimension = dimension_number
    elif dimension_controller and dimension_controller.has_method("change_dimension"):
        dimension_controller.change_dimension(dimension_number)
        harmony_dimension = dimension_number
    
    # Update Pitopia dimension
    if pitopia_main and pitopia_main.has_method("set_dimension"):
        pitopia_main.set_dimension(dimension_number)
        pitopia_dimension = dimension_number
    
    # Update integrated game system
    if integrated_game_system and integrated_game_system.has_method("set_current_dimension"):
        integrated_game_system.set_current_dimension(dimension_number)
    
    # Update akashic controller
    if akashic_controller and akashic_controller.has_method("visualize_akashic_record"):
        akashic_controller.visualize_akashic_record(dimension_number)
    
    # Apply dimensional effects
    if enable_dimension_effects:
        apply_dimensional_effects(dimension_number)
    
    # Emit signal
    emit_signal("dimension_synchronized", dimension_number, "integration")
    
    dimensional_transition_active = false
    return true

func apply_dimensional_effects(dimension_number):
    # Apply different visual effects based on dimension
    var dimension_props = get_dimension_properties(dimension_number)
    
    # Apply color effects
    if color_system and color_system.has_method("set_dimension_color"):
        color_system.set_dimension_color(dimension_number)
    
    # Update environment if needed
    var environment = null
    
    if pitopia_main and pitopia_main.has_method("get_environment"):
        environment = pitopia_main.get_environment()
    elif has_node("/root/WorldEnvironment"):
        environment = get_node("/root/WorldEnvironment").environment
    
    if environment:
        # Update fog color
        if dimension_props.has("fog_color"):
            environment.fog_color = dimension_props.fog_color
        
        # Update fog density
        if dimension_props.has("fog_density"):
            environment.fog_depth_begin = dimension_props.fog_density.begin
            environment.fog_depth_end = dimension_props.fog_density.end
        
        # Update ambient light
        if dimension_props.has("ambient_color"):
            environment.ambient_light_color = dimension_props.ambient_color
            environment.ambient_light_energy = dimension_props.ambient_energy
        
        # Update background color
        if dimension_props.has("background_color"):
            environment.background_color = dimension_props.background_color
    
    # Activate dimension-specific effects if entity manager exists
    if entity_manager and entity_manager.has_method("apply_dimension_effect"):
        entity_manager.apply_dimension_effect(dimension_number)

func get_dimension_properties(dimension_number):
    var dimension_data = {
        "name": "",
        "symbol": "",
        "fog_color": Color(0.05, 0.05, 0.1),
        "fog_density": {"begin": 20.0, "end": 100.0},
        "ambient_color": Color(0.1, 0.1, 0.2),
        "ambient_energy": 0.3,
        "background_color": Color(0.01, 0.01, 0.05)
    }
    
    # Set dimension-specific properties
    match dimension_number:
        1: # Linear Expression (1D)
            dimension_data.name = "Linear Expression"
            dimension_data.symbol = "Œ±"
            dimension_data.fog_color = Color(0.1, 0.05, 0.05)
            dimension_data.fog_density = {"begin": 10.0, "end": 30.0}
            dimension_data.ambient_color = Color(0.2, 0.1, 0.1)
            dimension_data.ambient_energy = 0.2
            dimension_data.background_color = Color(0.05, 0.01, 0.01)
            
        2: # Planar Reflection (2D)
            dimension_data.name = "Planar Reflection"
            dimension_data.symbol = "Œ≤"
            dimension_data.fog_color = Color(0.1, 0.1, 0.05)
            dimension_data.fog_density = {"begin": 15.0, "end": 40.0}
            dimension_data.ambient_color = Color(0.2, 0.2, 0.1)
            dimension_data.ambient_energy = 0.25
            dimension_data.background_color = Color(0.05, 0.05, 0.01)
            
        3: # Spatial Manifestation (3D)
            dimension_data.name = "Spatial Manifestation"
            dimension_data.symbol = "Œ≥"
            dimension_data.fog_color = Color(0.05, 0.1, 0.05)
            dimension_data.fog_density = {"begin": 20.0, "end": 60.0}
            dimension_data.ambient_color = Color(0.1, 0.2, 0.1)
            dimension_data.ambient_energy = 0.3
            dimension_data.background_color = Color(0.01, 0.05, 0.01)
            
        4: # Temporal Flow (4D)
            dimension_data.name = "Temporal Flow"
            dimension_data.symbol = "Œ¥"
            dimension_data.fog_color = Color(0.05, 0.05, 0.1)
            dimension_data.fog_density = {"begin": 25.0, "end": 70.0}
            dimension_data.ambient_color = Color(0.1, 0.1, 0.2)
            dimension_data.ambient_energy = 0.35
            dimension_data.background_color = Color(0.01, 0.01, 0.05)
            
        5: # Probability Waves (5D)
            dimension_data.name = "Probability Waves"
            dimension_data.symbol = "Œµ"
            dimension_data.fog_color = Color(0.1, 0.05, 0.1)
            dimension_data.fog_density = {"begin": 30.0, "end": 80.0}
            dimension_data.ambient_color = Color(0.2, 0.1, 0.2)
            dimension_data.ambient_energy = 0.4
            dimension_data.background_color = Color(0.05, 0.01, 0.05)
            
        6: # Phase Resonance (6D)
            dimension_data.name = "Phase Resonance"
            dimension_data.symbol = "Œ∂"
            dimension_data.fog_color = Color(0.05, 0.1, 0.1)
            dimension_data.fog_density = {"begin": 30.0, "end": 100.0}
            dimension_data.ambient_color = Color(0.1, 0.2, 0.2)
            dimension_data.ambient_energy = 0.45
            dimension_data.background_color = Color(0.01, 0.05, 0.05)
            
        7: # Dream Weaving (7D)
            dimension_data.name = "Dream Weaving"
            dimension_data.symbol = "Œ∑"
            dimension_data.fog_color = Color(0.1, 0.05, 0.15)
            dimension_data.fog_density = {"begin": 40.0, "end": 120.0}
            dimension_data.ambient_color = Color(0.2, 0.1, 0.3)
            dimension_data.ambient_energy = 0.5
            dimension_data.background_color = Color(0.05, 0.01, 0.1)
            
        8: # Interconnection (8D)
            dimension_data.name = "Interconnection"
            dimension_data.symbol = "Œ∏"
            dimension_data.fog_color = Color(0.05, 0.15, 0.1)
            dimension_data.fog_density = {"begin": 50.0, "end": 150.0}
            dimension_data.ambient_color = Color(0.1, 0.3, 0.2)
            dimension_data.ambient_energy = 0.55
            dimension_data.background_color = Color(0.01, 0.1, 0.05)
            
        9: # Divine Judgment (9D)
            dimension_data.name = "Divine Judgment"
            dimension_data.symbol = "Œπ"
            dimension_data.fog_color = Color(0.15, 0.15, 0.05)
            dimension_data.fog_density = {"begin": 70.0, "end": 200.0}
            dimension_data.ambient_color = Color(0.3, 0.3, 0.1)
            dimension_data.ambient_energy = 0.6
            dimension_data.background_color = Color(0.1, 0.1, 0.01)
            
        10: # Harmonic Convergence (10D)
            dimension_data.name = "Harmonic Convergence"
            dimension_data.symbol = "Œ∫"
            dimension_data.fog_color = Color(0.15, 0.05, 0.15)
            dimension_data.fog_density = {"begin": 100.0, "end": 300.0}
            dimension_data.ambient_color = Color(0.3, 0.1, 0.3)
            dimension_data.ambient_energy = 0.7
            dimension_data.background_color = Color(0.1, 0.01, 0.1)
            
        11: # Conscious Reflection (11D)
            dimension_data.name = "Conscious Reflection"
            dimension_data.symbol = "Œª"
            dimension_data.fog_color = Color(0.05, 0.15, 0.15)
            dimension_data.fog_density = {"begin": 150.0, "end": 400.0}
            dimension_data.ambient_color = Color(0.1, 0.3, 0.3)
            dimension_data.ambient_energy = 0.8
            dimension_data.background_color = Color(0.01, 0.1, 0.1)
            
        12: # Divine Manifestation (12D)
            dimension_data.name = "Divine Manifestation"
            dimension_data.symbol = "Œº"
            dimension_data.fog_color = Color(0.15, 0.15, 0.15)
            dimension_data.fog_density = {"begin": 200.0, "end": 500.0}
            dimension_data.ambient_color = Color(0.3, 0.3, 0.3)
            dimension_data.ambient_energy = 1.0
            dimension_data.background_color = Color(0.1, 0.1, 0.1)
    
    return dimension_data

# ----- WORD MANIFESTATION -----
func manifest_word(word, system_name = "integration", dimension = 0):
    if word.empty():
        return null
    
    if dimension == 0:
        dimension = active_dimension
    
    var entity_id = null
    
    # Track the word
    if not manifested_words.has(word):
        manifested_words[word] = {
            "entity_ids": {},
            "power": 50,
            "dimension": dimension,
            "timestamp": OS.get_unix_time()
        }
    
    # Try to manifest using the appropriate system
    match system_name:
        "harmony":
            if harmony_connector and harmony_connector.has_method("manifest_word"):
                entity_id = harmony_connector.manifest_word(word)
            elif word_manifestor and word_manifestor.has_method("manifest_word"):
                entity_id = word_manifestor.manifest_word(word)
                
        "pitopia":
            if pitopia_main and pitopia_main.has_method("manifest_word"):
                entity_id = pitopia_main.manifest_word(word)
                
        "integrated":
            if integrated_game_system and integrated_game_system.has_method("create_entity"):
                entity_id = integrated_game_system.create_entity("word", {
                    "text": word,
                    "power": manifested_words[word].power,
                    "dimension": dimension
                })
                
        "akashic":
            if akashic_controller and akashic_controller.has_method("create_akashic_entry"):
                var position = Vector3(
                    randf() * 10 - 5,
                    randf() * 5,
                    randf() * 10 - 5
                )
                
                entity_id = akashic_controller.create_akashic_entry(
                    word,
                    position,
                    dimension,
                    ["word", "manifested"]
                )
                
        _: # Use best available system
            # Try integrated system first
            if integrated_game_system and integrated_game_system.has_method("create_entity"):
                entity_id = integrated_game_system.create_entity("word", {
                    "text": word,
                    "power": manifested_words[word].power,
                    "dimension": dimension
                })
            # Then try Eden Harmony
            elif harmony_connector and harmony_connector.has_method("manifest_word"):
                entity_id = harmony_connector.manifest_word(word)
            # Then try Pitopia
            elif pitopia_main and pitopia_main.has_method("manifest_word"):
                entity_id = pitopia_main.manifest_word(word)
            # Fallback to akashic records
            elif akashic_controller and akashic_controller.has_method("create_akashic_entry"):
                var position = Vector3(
                    randf() * 10 - 5,
                    randf() * 5,
                    randf() * 10 - 5
                )
                
                entity_id = akashic_controller.create_akashic_entry(
                    word,
                    position,
                    dimension,
                    ["word", "manifested"]
                )
    
    # Record the entity ID if successful
    if entity_id:
        manifested_words[word].entity_ids[system_name] = entity_id
        
        # Record in entity mappings for cross-system reference
        entity_mappings[entity_id] = {
            "word": word,
            "system": system_name,
            "dimension": dimension,
            "created_at": OS.get_unix_time()
        }
        
        # Create akashic record if enabled
        if record_words_to_akashic and akashic_controller and system_name != "akashic":
            var position = Vector3(
                randf() * 10 - 5,
                randf() * 5,
                randf() * 10 - 5
            )
            
            var akashic_id = akashic_controller.create_akashic_entry(
                word,
                position,
                dimension,
                ["word", "manifested", system_name]
            )
            
            # Record this mapping
            if akashic_id:
                entity_mappings[akashic_id] = {
                    "word": word,
                    "system": "akashic",
                    "original_system": system_name,
                    "original_id": entity_id,
                    "dimension": dimension,
                    "created_at": OS.get_unix_time()
                }
        
        # Emit signal
        emit_signal("word_manifested", word, entity_id, system_name)
    
    return entity_id

func connect_entities(entity1_id, entity2_id, connection_type = "default"):
    # Verify both entities exist
    if not entity_mappings.has(entity1_id) or not entity_mappings.has(entity2_id):
        return false
    
    var entity1 = entity_mappings[entity1_id]
    var entity2 = entity_mappings[entity2_id]
    
    # Try to connect in the appropriate systems
    var connected = false
    
    # Try connecting in Eden Harmony if both entities are from there
    if entity1.system == "harmony" and entity2.system == "harmony":
        if harmony_connector and harmony_connector.has_method("connect_entities"):
            connected = harmony_connector.connect_entities(entity1_id, entity2_id, connection_type)
    
    # Try connecting in Pitopia if both entities are from there
    elif entity1.system == "pitopia" and entity2.system == "pitopia":
        if pitopia_main and pitopia_main.has_method("connect_entities"):
            connected = pitopia_main.connect_entities(entity1_id, entity2_id, connection_type)
    
    # Try connecting in integrated system
    elif entity1.system == "integrated" and entity2.system == "integrated":
        if integrated_game_system and integrated_game_system.has_method("connect_entities"):
            connected = integrated_game_system.connect_entities(entity1_id, entity2_id, connection_type)
    
    # Try connecting in akashic system
    elif entity1.system == "akashic" and entity2.system == "akashic":
        if akashic_controller and akashic_controller.has_method("connect_akashic_entries"):
            connected = akashic_controller.connect_akashic_entries(entity1_id, entity2_id)
    
    # Cross-system connection - create a record of the connection in akashic records
    else:
        if akashic_controller and akashic_controller.has_method("create_akashic_entry"):
            var word1 = entity1.word
            var word2 = entity2.word
            var dimension = max(entity1.dimension, entity2.dimension)
            
            var position = Vector3(
                randf() * 10 - 5,
                randf() * 5,
                randf() * 10 - 5
            )
            
            var connection_text = "Connection between '%s' and '%s' (%s)" % [word1, word2, connection_type]
            
            var akashic_id = akashic_controller.create_akashic_entry(
                connection_text,
                position,
                dimension,
                ["connection", entity1.system, entity2.system]
            )
            
            if akashic_id:
                connected = true
                
                # Connect the entities in their original systems if possible
                var original_entity1 = entity1.get("original_id", entity1_id)
                var original_entity2 = entity2.get("original_id", entity2_id)
                
                var original_system1 = entity1.get("original_system", entity1.system)
                var original_system2 = entity2.get("original_system", entity2.system)
                
                # Create connection in universal connector if available
                if universal_connector and universal_connector.has_method("connect_systems"):
                    if original_system1 != original_system2:
                        universal_connector.connect_systems(original_system1, original_system2, "entity_connection")
    
    return connected

func evolve_entity(entity_id):
    # Verify entity exists
    if not entity_mappings.has(entity_id):
        return false
    
    var entity = entity_mappings[entity_id]
    var evolved = false
    
    # Try to evolve in the appropriate system
    match entity.system:
        "harmony":
            if harmony_connector and harmony_connector.has_method("evolve_entity"):
                evolved = harmony_connector.evolve_entity(entity_id)
            elif entity_manager and entity_manager.has_method("evolve_entity"):
                evolved = entity_manager.evolve_entity(entity_id)
                
        "pitopia":
            if pitopia_main and pitopia_main.has_method("evolve_entity"):
                evolved = pitopia_main.evolve_entity(entity_id)
                
        "integrated":
            if integrated_game_system and integrated_game_system.has_method("evolve_entity"):
                evolved = integrated_game_system.evolve_entity(entity_id)
                
        "akashic":
            # Can't directly evolve akashic entities, but can create a new evolved version
            if akashic_controller and akashic_controller.has_method("create_akashic_entry"):
                var position = Vector3(
                    randf() * 10 - 5,
                    randf() * 5 + 2,  # Slightly higher to represent evolution
                    randf() * 10 - 5
                )
                
                var word = entity.word
                var dimension = entity.dimension
                
                var evolved_id = akashic_controller.create_akashic_entry(
                    "Evolved: " + word,
                    position,
                    dimension,
                    ["evolved", "word", "manifested"]
                )
                
                if evolved_id:
                    evolved = true
                    
                    # Connect the original and evolved entities
                    if akashic_controller.has_method("connect_akashic_entries"):
                        akashic_controller.connect_akashic_entries(entity_id, evolved_id)
    
    return evolved

# ----- TURN SYSTEM INTEGRATION -----
func advance_turn():
    # Try to advance turn in the appropriate systems
    var advanced = false
    
    // Try integrated system first
    if integrated_game_system and integrated_game_system.has_method("set_current_dimension"):
        var next_turn = (active_dimension % 12) + 1
        advanced = integrated_game_system.set_current_dimension(next_turn)
        active_dimension = next_turn
    
    // Try Eden Harmony
    elif harmony_connector and harmony_connector.has_method("advance_turn"):
        advanced = harmony_connector.advance_turn()
        if harmony_connector.has_method("get_current_turn"):
            harmony_dimension = harmony_connector.get_current_turn()
            active_dimension = harmony_dimension
    
    // Try turn system directly
    elif turn_system and turn_system.has_method("advance_turn"):
        advanced = turn_system.advance_turn()
        if turn_system.has_method("get_current_turn"):
            active_dimension = turn_system.get_current_turn()
    
    // Try Pitopia
    elif pitopia_main and pitopia_main.has_method("advance_turn"):
        advanced = pitopia_main.advance_turn()
        if pitopia_main.has_method("get_current_turn"):
            pitopia_dimension = pitopia_main.get_current_turn()
            active_dimension = pitopia_dimension
    
    // Synchronize dimensions
    if advanced and auto_sync_dimensions:
        synchronize_dimensions(active_dimension)
    
    // Emit signal
    emit_signal("turn_advanced", active_dimension)
    
    return advanced

func register_turn_callback(turn_number, callback_object, callback_method, callback_args = []):
    if not turn_callbacks.has(turn_number):
        turn_callbacks[turn_number] = []
    
    turn_callbacks[turn_number].append({
        "object": callback_object,
        "method": callback_method,
        "args": callback_args
    })
    
    return true

func process_turn_callbacks(turn_number):
    if not turn_callbacks.has(turn_number):
        return false
    
    var callbacks = turn_callbacks[turn_number]
    var processed_count = 0
    
    for callback in callbacks:
        var object = callback.object
        var method = callback.method
        var args = callback.args
        
        if is_instance_valid(object) and object.has_method(method):
            object.callv(method, args)
            processed_count += 1
    
    return processed_count > 0

# ----- EVENT HANDLERS -----
func _on_harmony_word_manifested(word, entity_id):
    if debug_mode:
        print("Eden Harmony word manifested: %s (Entity ID: %s)" % [word, entity_id])
    
    # Record the mapping
    entity_mappings[entity_id] = {
        "word": word,
        "system": "harmony",
        "dimension": harmony_dimension,
        "created_at": OS.get_unix_time()
    }
    
    # Create akashic record if enabled
    if record_words_to_akashic and akashic_controller:
        manifest_word(word, "akashic", harmony_dimension)
    
    # Emit signal
    emit_signal("word_manifested", word, entity_id, "harmony")

func _on_harmony_dimension_changed(new_dimension, old_dimension):
    if debug_mode:
        print("Eden Harmony dimension changed: %d -> %d" % [old_dimension, new_dimension])
    
    harmony_dimension = new_dimension
    
    # Synchronize dimensions if enabled
    if auto_sync_dimensions and not dimensional_transition_active:
        synchronize_dimensions(new_dimension)

func _on_harmony_turn_advanced(turn_number):
    if debug_mode:
        print("Eden Harmony turn advanced: %d" % turn_number)
    
    # Process turn callbacks
    process_turn_callbacks(turn_number)
    
    # Emit signal
    emit_signal("turn_advanced", turn_number)

func _on_harmony_entity_created(entity_id, entity_data):
    if debug_mode:
        print("Eden Harmony entity created: %s" % entity_id)
    
    # Record the mapping
    entity_mappings[entity_id] = {
        "word": entity_data.get("word", "unknown"),
        "system": "harmony",
        "dimension": harmony_dimension,
        "data": entity_data,
        "created_at": OS.get_unix_time()
    }
    
    # Emit signal
    emit_signal("entity_created", entity_id, entity_data, "harmony")

func _on_pitopia_word_manifested(word, entity_id):
    if debug_mode:
        print("Pitopia word manifested: %s (Entity ID: %s)" % [word, entity_id])
    
    # Record the mapping
    entity_mappings[entity_id] = {
        "word": word,
        "system": "pitopia",
        "dimension": pitopia_dimension,
        "created_at": OS.get_unix_time()
    }
    
    # Create akashic record if enabled
    if record_words_to_akashic and akashic_controller:
        manifest_word(word, "akashic", pitopia_dimension)
    
    # Emit signal
    emit_signal("word_manifested", word, entity_id, "pitopia")

func _on_pitopia_dimension_changed(new_dimension, old_dimension):
    if debug_mode:
        print("Pitopia dimension changed: %d -> %d" % [old_dimension, new_dimension])
    
    pitopia_dimension = new_dimension
    
    # Synchronize dimensions if enabled
    if auto_sync_dimensions and not dimensional_transition_active:
        synchronize_dimensions(new_dimension)

func _on_pitopia_turn_advanced(turn_number):
    if debug_mode:
        print("Pitopia turn advanced: %d" % turn_number)
    
    # Process turn callbacks
    process_turn_callbacks(turn_number)
    
    # Emit signal
    emit_signal("turn_advanced", turn_number)

func _on_integrated_dimension_changed(turn_number, symbol, dimension_name):
    if debug_mode:
        print("Integrated system dimension changed: %d (%s - %s)" % [turn_number, symbol, dimension_name])
    
    # Synchronize dimensions if enabled
    if auto_sync_dimensions and not dimensional_transition_active:
        synchronize_dimensions(turn_number)

func _on_integrated_entity_created(entity_id, entity_type, entity_data):
    if debug_mode:
        print("Integrated system entity created: %s (Type: %s)" % [entity_id, entity_type])
    
    # Record the mapping
    entity_mappings[entity_id] = {
        "word": entity_data.get("text", entity_type),
        "system": "integrated",
        "type": entity_type,
        "dimension": active_dimension,
        "data": entity_data,
        "created_at": OS.get_unix_time()
    }
    
    # Create akashic record if enabled and entity type is word
    if record_words_to_akashic and akashic_controller and entity_type == "word":
        var word = entity_data.get("text", "")
        if not word.empty():
            manifest_word(word, "akashic", active_dimension)
    
    # Emit signal
    emit_signal("entity_created", entity_id, entity_data, "integrated")

func _on_akashic_record_created(record_id):
    if debug_mode:
        print("Akashic record created: %s" % record_id)
    
    # Get the record
    if akashic_controller and akashic_controller.has_method("get_akashic_entry"):
        var record = akashic_controller.get_akashic_entry(record_id)
        
        if record:
            # Add to cache
            akashic_record_cache[record_id] = {
                "content": record.content,
                "position": record.position.coordinate,
                "dimension": record.position.dimension,
                "power": record.position.power,
                "tags": record.tags,
                "created_at": OS.get_unix_time()
            }
            
            # Emit signal
            emit_signal("akashic_record_created", record_id, record.content, record.tags)

# ----- PUBLIC API -----
func get_manifested_words():
    return manifested_words

func get_entity_mappings():
    return entity_mappings

func get_akashic_record_cache():
    return akashic_record_cache

func get_current_dimension():
    return active_dimension

func get_turn_callbacks():
    return turn_callbacks

func toggle_dimension_sync(active = true):
    dimension_sync_active = active
    return dimension_sync_active

func get_dimension_symbols():
    return ["Œ±", "Œ≤", "Œ≥", "Œ¥", "Œµ", "Œ∂", "Œ∑", "Œ∏", "Œπ", "Œ∫", "Œª", "Œº"]

func get_dimension_names():
    return [
        "Linear Expression",
        "Planar Reflection",
        "Spatial Manifestation",
        "Temporal Flow",
        "Probability Waves",
        "Phase Resonance",
        "Dream Weaving",
        "Interconnection",
        "Divine Judgment",
        "Harmonic Convergence",
        "Conscious Reflection",
        "Divine Manifestation"
    ]

# ----- COMMAND PROCESSING -----
func process_command(command_text):
    if command_text.empty():
        return "Please enter a command"
    
    # Split command and arguments
    var parts = command_text.split(" ", false, 1)
    var cmd = parts[0].to_lower()
    var args = parts[1] if parts.size() > 1 else ""
    
    # Process command
    match cmd:
        "manifest":
            return process_manifest_command(args)
        
        "dimension":
            return process_dimension_command(args)
        
        "connect":
            return process_connect_command(args)
        
        "evolve":
            return process_evolve_command(args)
        
        "turn":
            return process_turn_command(args)
        
        "sync":
            return process_sync_command(args)
        
        "help":
            return get_help_text()
        
        _:
            # Try to manifest the word directly
            if enable_direct_word_manifestation:
                var entity_id = manifest_word(command_text)
                if entity_id:
                    return "Manifested word: %s (Entity ID: %s)" % [command_text, entity_id]
            
            return "Unknown command: " + cmd

func process_manifest_command(args):
    if args.empty():
        return "Usage: manifest <word> [system]"
    
    var parts = args.split(" ")
    var word = parts[0]
    var system = parts[1] if parts.size() > 1 else "integration"
    
    var entity_id = manifest_word(word, system)
    
    if entity_id:
        return "Manifested word '%s' in %s system (Entity ID: %s)" % [word, system, entity_id]
    else:
        return "Failed to manifest word: " + word

func process_dimension_command(args):
    if args.empty():
        return "Current dimension: %d (%s - %s)" % [
            active_dimension,
            get_dimension_symbols()[active_dimension - 1],
            get_dimension_names()[active_dimension - 1]
        ]
    
    if args.is_valid_integer():
        var dimension = int(args)
        if dimension < 1 or dimension > 12:
            return "Invalid dimension. Must be between 1 and 12."
        
        if synchronize_dimensions(dimension):
            return "Changed to dimension %d (%s - %s)" % [
                dimension,
                get_dimension_symbols()[dimension - 1],
                get_dimension_names()[dimension - 1]
            ]
        else:
            return "Failed to change dimension"
    
    return "Usage: dimension [1-12]"

func process_connect_command(args):
    if args.empty():
        return "Usage: connect <entity1_id> <entity2_id> [connection_type]"
    
    var parts = args.split(" ")
    
    if parts.size() < 2:
        return "Usage: connect <entity1_id> <entity2_id> [connection_type]"
    
    var entity1_id = parts[0]
    var entity2_id = parts[1]
    var connection_type = parts[2] if parts.size() > 2 else "default"
    
    if connect_entities(entity1_id, entity2_id, connection_type):
        return "Connected entities: %s and %s (%s)" % [entity1_id, entity2_id, connection_type]
    else:
        return "Failed to connect entities"

func process_evolve_command(args):
    if args.empty():
        return "Usage: evolve <entity_id>"
    
    var entity_id = args
    
    if evolve_entity(entity_id):
        return "Evolved entity: " + entity_id
    else:
        return "Failed to evolve entity: " + entity_id

func process_turn_command(args):
    if args == "advance" or args.empty():
        if advance_turn():
            return "Advanced to turn %d: %s (%s)" % [
                active_dimension,
                get_dimension_symbols()[active_dimension - 1],
                get_dimension_names()[active_dimension - 1]
            ]
        else:
            return "Failed to advance turn"
    
    return "Usage: turn [advance]"

func process_sync_command(args):
    if args.empty():
        return "Dimension sync is currently: " + ("ON" if dimension_sync_active else "OFF")
    
    match args:
        "on":
            dimension_sync_active = true
            return "Dimension synchronization enabled"
        "off":
            dimension_sync_active = false
            return "Dimension synchronization disabled"
        "force":
            synchronize_dimensions(active_dimension)
            return "Forced dimension synchronization to: " + str(active_dimension)
        _:
            return "Usage: sync [on|off|force]"

func get_help_text():
    return """
Available Commands:

WORD MANIFESTATION:
  manifest <word> [system] - Manifest a word into an entity
  evolve <entity_id> - Evolve an entity to next stage
  connect <entity1_id> <entity2_id> [type] - Connect two entities

DIMENSION CONTROL:
  dimension [1-12] - View or change dimension
  
TURN SYSTEM:
  turn [advance] - View or advance turn
  
SYNCHRONIZATION:
  sync [on|off|force] - Control dimension synchronization
  
HELP:
  help - Show this help text
  
You can also type any word directly to manifest it.
"""
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/eden_pitopia_integration.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/enhanced_migration_launcher.gd
# SIZE: 13094 bytes
class_name EnhancedMigrationLauncher
extends Node

# ----- COMPONENT REFERENCES -----
var migration_tool = null
var migration_ui = null
var migration_tester = null
var test_runner = null
var color_system = null
var akashic_system = null

# ----- CONFIGURATION -----
@export_category("Migration Settings")
@export var auto_start_ui: bool = true
@export var default_godot3_path: String = ""
@export var default_godot4_path: String = ""
@export var enable_color_integration: bool = true
@export var enable_test_runner: bool = true

# ----- SCENES -----
const MIGRATION_UI_SCENE = "res://12_turns_system/godot4_migration_ui.tscn"
const TEST_RUNNER_SCENE = "res://12_turns_system/godot4_migration_test_runner.tscn"

# ----- STATISTICS -----
var migrations_performed: int = 0
var test_runs_performed: int = 0
var last_migration_stats: Dictionary = {}
var last_test_stats: Dictionary = {}

# ----- SIGNALS -----
signal launcher_initialized()
signal ui_started(ui_instance)
signal test_runner_started(runner_instance)
signal migration_started(from_path, to_path)
signal migration_completed(results)
signal test_run_started()
signal test_run_completed(results)

# ----- INITIALIZATION -----
func _ready():
    _find_or_create_components()
    _connect_signals()
    
    print("Enhanced Migration Launcher initialized")
    
    emit_signal("launcher_initialized")
    
    if auto_start_ui:
        start_migration_ui()
        
    if enable_test_runner:
        start_test_runner()

func _find_or_create_components():
    # Find or create the migration tool
    migration_tool = get_node_or_null("/root/Godot4MigrationTool")
    if not migration_tool:
        migration_tool = _find_node_by_class(get_tree().root, "Godot4MigrationTool")
    
    if not migration_tool:
        migration_tool = Godot4MigrationTool.new()
        add_child(migration_tool)
    
    # Find or create the migration tester
    migration_tester = get_node_or_null("/root/Godot4MigrationTester")
    if not migration_tester:
        migration_tester = _find_node_by_class(get_tree().root, "Godot4MigrationTester")
    
    if not migration_tester:
        migration_tester = Godot4MigrationTester.new()
        add_child(migration_tester)
    
    # Find color system
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find akashic system
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    print("Components found - Migration Tool: %s, Migration Tester: %s, Color System: %s, Akashic System: %s" % [
        "Yes" if migration_tool else "No",
        "Yes" if migration_tester else "No",
        "Yes" if color_system else "No",
        "Yes" if akashic_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _connect_signals():
    # Connect migration tool signals
    if migration_tool:
        migration_tool.migration_started.connect(_on_migration_started)
        migration_tool.migration_completed.connect(_on_migration_completed)
    
    # Connect migration tester signals
    if migration_tester:
        migration_tester.test_started.connect(_on_test_started)
        migration_tester.test_completed.connect(_on_test_completed)

# ----- SIGNAL HANDLERS -----
func _on_migration_started(total_files):
    print("Migration started with " + str(total_files) + " files")

func _on_migration_completed(stats):
    migrations_performed += 1
    last_migration_stats = stats
    
    print("Migration completed - Files processed: " + str(stats.files_processed) + 
          ", Modified: " + str(stats.files_modified) + 
          ", Errors: " + str(stats.errors_encountered) + 
          ", Warnings: " + str(stats.warnings_generated))
    
    emit_signal("migration_completed", stats)
    
    # Integrate with color system
    if enable_color_integration and color_system:
        _update_color_system_with_migration_stats(stats)

func _on_test_started(total_tests):
    test_runs_performed += 1
    print("Test run started with " + str(total_tests) + " tests")
    
    emit_signal("test_run_started")

func _on_test_completed(results):
    last_test_stats = results
    
    print("Test run completed - Total tests: " + str(results.total) + 
          ", Passed: " + str(results.passed) + 
          ", Failed: " + str(results.failed))
    
    emit_signal("test_run_completed", results)
    
    # Integrate with color system
    if enable_color_integration and color_system:
        _update_color_system_with_test_stats(results)

# ----- UI MANAGEMENT -----
func start_migration_ui():
    # Check if UI is already instantiated
    if is_instance_valid(migration_ui):
        print("Migration UI is already running")
        return migration_ui
    
    # Try to load the UI scene
    var ui_scene = load(MIGRATION_UI_SCENE)
    if not ui_scene:
        push_error("Failed to load migration UI scene: " + MIGRATION_UI_SCENE)
        return null
    
    # Instantiate the UI
    migration_ui = ui_scene.instantiate()
    add_child(migration_ui)
    
    # Set default paths if provided
    if migration_ui.has_method("_set_default_paths") and default_godot3_path != "" and default_godot4_path != "":
        migration_ui._set_default_paths(default_godot3_path, default_godot4_path)
    
    print("Migration UI started")
    emit_signal("ui_started", migration_ui)
    
    return migration_ui

func start_test_runner():
    # Check if test runner is already instantiated
    if is_instance_valid(test_runner):
        print("Test runner is already running")
        return test_runner
    
    # Try to load the test runner scene
    var runner_scene = load(TEST_RUNNER_SCENE)
    if not runner_scene:
        push_error("Failed to load test runner scene: " + TEST_RUNNER_SCENE)
        return null
    
    # Instantiate the test runner
    test_runner = runner_scene.instantiate()
    add_child(test_runner)
    
    # Integrate with color system if enabled
    if enable_color_integration and color_system and test_runner.has_method("integrate_with_color_system"):
        test_runner.integrate_with_color_system()
    
    print("Test runner started")
    emit_signal("test_runner_started", test_runner)
    
    return test_runner

# ----- COLOR SYSTEM INTEGRATION -----
func _update_color_system_with_migration_stats(stats):
    if not color_system:
        return
    
    # In a real implementation, this would call methods on the color system
    # to visualize the migration statistics with colors
    
    # Calculate migration success rate
    var success_rate = 0.0
    if stats.files_processed > 0:
        success_rate = float(stats.files_modified) / stats.files_processed
    
    # Example color system integration
    # color_system.visualize_data_point("migration_success", success_rate, Color(0, 1, 0))
    # color_system.visualize_data_point("migration_errors", stats.errors_encountered, Color(1, 0, 0))
    
    print("Migration stats integrated with color system")

func _update_color_system_with_test_stats(results):
    if not color_system:
        return
    
    # In a real implementation, this would call methods on the color system
    # to visualize the test statistics with colors
    
    # Calculate test success rate
    var success_rate = 0.0
    if results.total > 0:
        success_rate = float(results.passed) / results.total
    
    # Example color system integration
    # color_system.visualize_data_point("test_success", success_rate, Color(0, 1, 0))
    # color_system.visualize_data_point("test_failures", results.failed, Color(1, 0, 0))
    
    print("Test stats integrated with color system")

# ----- AKASHIC SYSTEM INTEGRATION -----
func update_akashic_system_with_stats():
    if not akashic_system:
        return
    
    # In a real implementation, this would update the akashic system with
    # statistics about the migrations and tests
    
    # Example akashic system integration
    # akashic_system.record_event("migration", migrations_performed)
    # akashic_system.record_event("test_run", test_runs_performed)
    
    print("Statistics recorded in akashic system")

# ----- MAIN API -----
func migrate_project(from_path: String, to_path: String) -> Dictionary:
    if not migration_tool:
        return {
            "success": false,
            "error": "Migration tool not initialized"
        }
    
    emit_signal("migration_started", from_path, to_path)
    
    return migration_tool.migrate_project(from_path, to_path)

func run_all_tests() -> Dictionary:
    if not migration_tester:
        return {
            "success": false,
            "error": "Migration tester not initialized"
        }
    
    return migration_tester.run_all_tests()

func generate_compatibility_report(project_path: String) -> Dictionary:
    if not migration_tool:
        return {
            "success": false,
            "error": "Migration tool not initialized"
        }
    
    return migration_tool.generate_migration_report(project_path)

func get_migration_statistics() -> Dictionary:
    return {
        "migrations_performed": migrations_performed,
        "test_runs_performed": test_runs_performed,
        "last_migration_stats": last_migration_stats,
        "last_test_stats": last_test_stats
    }

# ----- LAUNCHER SCENE -----
func create_launcher_scene() -> Window:
    # Create a simple launcher window that can start the UI and test runner
    var window = Window.new()
    window.title = "Godot 4 Migration Launcher"
    window.size = Vector2i(500, 300)
    
    # Create UI
    var vbox = VBoxContainer.new()
    vbox.set_anchors_preset(PRESET_FULL_RECT)
    window.add_child(vbox)
    
    # Title
    var title_label = Label.new()
    title_label.text = "Godot 4 Migration Toolkit"
    title_label.horizontal_alignment = HORIZONTAL_ALIGNMENT_CENTER
    vbox.add_child(title_label)
    
    # Paths
    var paths_section = VBoxContainer.new()
    vbox.add_child(paths_section)
    
    var paths_label = Label.new()
    paths_label.text = "Project Paths"
    paths_section.add_child(paths_label)
    
    # Godot 3 path
    var godot3_hbox = HBoxContainer.new()
    paths_section.add_child(godot3_hbox)
    
    var godot3_label = Label.new()
    godot3_label.text = "Godot 3 Project:"
    godot3_hbox.add_child(godot3_label)
    
    var godot3_path_input = LineEdit.new()
    godot3_path_input.size_flags_horizontal = SIZE_EXPAND_FILL
    godot3_path_input.text = default_godot3_path
    godot3_hbox.add_child(godot3_path_input)
    
    # Godot 4 path
    var godot4_hbox = HBoxContainer.new()
    paths_section.add_child(godot4_hbox)
    
    var godot4_label = Label.new()
    godot4_label.text = "Godot 4 Project:"
    godot4_hbox.add_child(godot4_label)
    
    var godot4_path_input = LineEdit.new()
    godot4_path_input.size_flags_horizontal = SIZE_EXPAND_FILL
    godot4_path_input.text = default_godot4_path
    godot4_hbox.add_child(godot4_path_input)
    
    # Buttons
    var buttons_hbox = HBoxContainer.new()
    buttons_hbox.size_flags_horizontal = SIZE_EXPAND_FILL
    buttons_hbox.alignment = BoxContainer.ALIGNMENT_CENTER
    vbox.add_child(buttons_hbox)
    
    var ui_button = Button.new()
    ui_button.text = "Start Migration UI"
    ui_button.pressed.connect(func(): 
        default_godot3_path = godot3_path_input.text
        default_godot4_path = godot4_path_input.text
        start_migration_ui()
    )
    buttons_hbox.add_child(ui_button)
    
    var test_button = Button.new()
    test_button.text = "Start Test Runner"
    test_button.pressed.connect(start_test_runner)
    buttons_hbox.add_child(test_button)
    
    # Statistics
    var stats_section = VBoxContainer.new()
    vbox.add_child(stats_section)
    
    var stats_label = Label.new()
    stats_label.text = "Statistics"
    stats_section.add_child(stats_label)
    
    var migrations_label = Label.new()
    migrations_label.text = "Migrations Performed: " + str(migrations_performed)
    stats_section.add_child(migrations_label)
    
    var tests_label = Label.new()
    tests_label.text = "Test Runs Performed: " + str(test_runs_performed)
    stats_section.add_child(tests_label)
    
    # Update statistics periodically
    var timer = Timer.new()
    window.add_child(timer)
    timer.timeout.connect(func():
        migrations_label.text = "Migrations Performed: " + str(migrations_performed)
        tests_label.text = "Test Runs Performed: " + str(test_runs_performed)
    )
    timer.wait_time = 1.0
    timer.start()
    
    add_child(window)
    window.show()
    
    return window
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/enhanced_migration_launcher.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/enhanced_system_launcher.gd
# SIZE: 21768 bytes
class_name EnhancedSystemLauncher
extends Node

# ----- CORE COMPONENTS -----
var akashic_system = null
var color_system = null
var ethereal_bridge = null
var visual_system = null
var keyboard_system = null
var migration_tool = null
var color_animation_system = null
var terminal_interface = null
var storage_system = null

# ----- SYSTEM LOADERS -----
var systems_loaded = {}
var required_systems = [
    "AkashicNumberSystem",
    "DimensionalColorSystem",
    "EtherealAkashicBridge",
    "VisualIndicatorSystem",
    "KeyboardCommandSystem", 
    "Godot4MigrationTool",
    "ColorAnimationSystem",
    "UnifiedTerminalInterface",
    "StorageIntegrationSystem"
]

# ----- SETTINGS -----
var config = {
    "auto_initialize": true,
    "default_interface": "terminal", # terminal, notepad3d, browser, visual
    "debug_mode": false,
    "starting_turn": 1,
    "max_wish_tokens": 10000,
    "show_welcome": true,
    "color_frequency": 99,
    "dimensional_depth": 1,
    "migration_backup": true
}

# ----- SIGNALS -----
signal system_loaded(system_name)
signal all_systems_loaded()
signal system_failed(system_name, error)
signal system_ready
signal interface_ready(interface_name)
signal turn_changed(new_turn, old_turn)

# ----- INITIALIZATION -----
func _ready():
    print("Enhanced System Launcher starting...")
    
    # Initialize systems
    if config.auto_initialize:
        initialize_system()

func initialize_system():
    print("Initializing Integrated System...")
    
    # Initialize all required systems
    _initialize_systems()
    
    # Ensure proper initialization order
    initialize_akashic_system()
    initialize_ethereal_bridge()
    initialize_color_systems()
    initialize_terminal_interface()
    initialize_storage_system()
    initialize_keyboard_system()
    
    # Connect signals between components
    connect_signals()
    
    # Set initial interface
    set_interface(config.default_interface)
    
    # Show welcome message
    if config.show_welcome:
        show_welcome()
    
    print("Integrated System initialized successfully")
    emit_signal("system_ready")

func _initialize_systems():
    # Initialize all required systems
    for system_name in required_systems:
        var system = _load_system(system_name)
        
        if system:
            systems_loaded[system_name] = true
            emit_signal("system_loaded", system_name)
            
            # Store reference
            match system_name:
                "AkashicNumberSystem":
                    akashic_system = system
                "DimensionalColorSystem":
                    color_system = system
                "EtherealAkashicBridge":
                    ethereal_bridge = system
                "VisualIndicatorSystem":
                    visual_system = system
                "KeyboardCommandSystem":
                    keyboard_system = system
                "Godot4MigrationTool":
                    migration_tool = system
                "ColorAnimationSystem":
                    color_animation_system = system
                "UnifiedTerminalInterface":
                    terminal_interface = system
                "StorageIntegrationSystem":
                    storage_system = system
        else:
            systems_loaded[system_name] = false
            emit_signal("system_failed", system_name, "Failed to initialize")
    
    # Check if all systems loaded
    var all_loaded = true
    for system_name in systems_loaded:
        if not systems_loaded[system_name]:
            all_loaded = false
            break
    
    if all_loaded:
        _log("All systems loaded successfully")
        emit_signal("all_systems_loaded")
    else:
        _log("Some systems failed to load", true)

func _load_system(system_name: String):
    # Check if system already exists in scene tree
    var node = get_node_or_null("/root/" + system_name)
    if node:
        _log("Found existing " + system_name)
        return node
    
    # Check for node with class
    node = _find_node_with_class(get_tree().root, system_name)
    if node:
        _log("Found existing " + system_name + " by class")
        return node
    
    # Try to instantiate the system
    _log("Creating new instance of " + system_name)
    
    var script_path = "res://12_turns_system/" + system_name.to_snake_case() + ".gd"
    if ResourceLoader.exists(script_path):
        var script = load(script_path)
        var instance = script.new()
        add_child(instance)
        return instance
    else:
        _log("Failed to find script for " + system_name + " at " + script_path, true)
        return null

func _find_node_with_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_with_class(child, class_name_str)
        if found:
            return found
    
    return null

# ----- COMPONENT INITIALIZATION -----
func initialize_akashic_system():
    if akashic_system:
        _log("Starting Akashic Number System")
        
        # Set up required variables
        if akashic_system.has_method("initialize_akashic_records"):
            akashic_system.initialize_akashic_records()
        
        print("Akashic System initialized")

func initialize_ethereal_bridge():
    if ethereal_bridge:
        _log("Starting Ethereal Akashic Bridge")
        
        # Enable the bridge
        if ethereal_bridge.has_method("toggle_bridge"):
            ethereal_bridge.toggle_bridge(true)
        
        # Set connection frequency
        if ethereal_bridge.has_method("set_connection_frequency"):
            ethereal_bridge.set_connection_frequency(0.5)
        
        # Connect to akashic system
        if akashic_system and ethereal_bridge.has_method("connect_systems"):
            ethereal_bridge.connect_systems()
        
        # Set firewall level based on turn
        var firewall_level = "standard"
        if config.starting_turn > 7:
            firewall_level = "divine"
        elif config.starting_turn > 3:
            firewall_level = "enhanced"
        
        if ethereal_bridge.has_method("update_firewall"):
            ethereal_bridge.update_firewall(firewall_level, {
                "dimension_access": config.starting_turn
            })
        
        print("Ethereal Bridge initialized")

func initialize_color_systems():
    if color_system:
        _log("Starting Dimensional Color System")
        
        # Highlight mesh points
        if color_system.has_method("highlight_mesh_centers"):
            color_system.highlight_mesh_centers(5.0)
            color_system.highlight_mesh_edges(5.0)
            color_system.highlight_mesh_corners(5.0)
        
        print("Color System initialized")
    
    if color_animation_system:
        _log("Starting Color Animation System")
        
        # Set enabled state
        if "enabled" in color_animation_system:
            color_animation_system.enabled = true
        
        print("Color Animation System initialized")
    
    if visual_system:
        _log("Starting Visual Indicator System")
        
        # Enable visual system
        if visual_system.has_method("toggle_enabled"):
            visual_system.toggle_enabled()
        
        # Set appropriate mode
        if visual_system.has_method("set_mode"):
            visual_system.set_mode(2)  # Detailed mode
        
        print("Visual System initialized")

func initialize_terminal_interface():
    if terminal_interface:
        _log("Starting Terminal Interface")
        
        print("Terminal Interface initialized")
        
        if terminal_interface.has_method("connect_signals"):
            terminal_interface.connect("terminal_ready", Callable(self, "_on_terminal_ready"))

func initialize_storage_system():
    if storage_system:
        _log("Starting Storage System")
        
        print("Storage System initialized")
        
        if storage_system.has_method("connect_cloud_storage"):
            storage_system.connect("storage_connected", Callable(self, "_on_storage_connected"))

func initialize_keyboard_system():
    if keyboard_system:
        _log("Starting Keyboard Command System")
        
        # Enable command system
        if keyboard_system.has_method("set_command_mode"):
            keyboard_system.set_command_mode(true)
        
        # Enable auto-correction
        if keyboard_system.has_method("set_auto_correction"):
            keyboard_system.set_auto_correction(true)
        
        print("Keyboard System initialized")

# ----- SIGNAL CONNECTIONS -----
func connect_signals():
    # Connect system signals for communication
    
    # Connect Akashic -> Ethereal
    if akashic_system and ethereal_bridge:
        # Connect any relevant signals between these systems
        pass
    
    # Connect Color -> Visual
    if color_system and visual_system:
        if color_system.has_signal("color_frequency_updated") and visual_system.has_method("_on_color_frequency_updated"):
            color_system.connect("color_frequency_updated", Callable(visual_system, "_on_color_frequency_updated"))
        
        if color_system.has_signal("mesh_point_activated") and visual_system.has_method("_on_mesh_point_activated"):
            color_system.connect("mesh_point_activated", Callable(visual_system, "_on_mesh_point_activated"))
    
    # Connect Keyboard -> Other systems
    if keyboard_system:
        if keyboard_system.has_signal("symbol_inserted") and color_system and color_system.has_method("_on_symbol_inserted"):
            keyboard_system.connect("symbol_inserted", Callable(color_system, "_on_symbol_inserted"))
        
        if keyboard_system.has_signal("key_sequence_recognized") and ethereal_bridge and ethereal_bridge.has_method("_on_key_sequence_recognized"):
            keyboard_system.connect("key_sequence_recognized", Callable(ethereal_bridge, "_on_key_sequence_recognized"))
    
    # Connect animation system
    if color_animation_system:
        if color_animation_system.has_signal("color_updated") and visual_system and visual_system.has_method("_on_color_updated"):
            color_animation_system.connect("color_updated", Callable(visual_system, "_on_color_updated"))
        
        if color_animation_system.has_signal("frequency_activated") and ethereal_bridge and ethereal_bridge.has_method("_on_frequency_activated"):
            color_animation_system.connect("frequency_activated", Callable(ethereal_bridge, "_on_frequency_activated"))
    
    # Connect Storage signals
    if storage_system:
        storage_system.connect("storage_connected", Callable(self, "_on_storage_connected"))
        storage_system.connect("wish_created", Callable(self, "_on_wish_created"))
        storage_system.connect("wish_completed", Callable(self, "_on_wish_completed"))
    
    # Connect Akashic Bridge signals
    if ethereal_bridge:
        if ethereal_bridge.has_signal("word_stored"):
            ethereal_bridge.connect("word_stored", Callable(self, "_on_word_stored"))
        
        if ethereal_bridge.has_signal("gate_status_changed"):
            ethereal_bridge.connect("gate_status_changed", Callable(self, "_on_gate_status_changed"))
        
        if ethereal_bridge.has_signal("wish_updated"):
            ethereal_bridge.connect("wish_updated", Callable(self, "_on_wish_updated"))
        
        if ethereal_bridge.has_signal("firewall_breached"):
            ethereal_bridge.connect("firewall_breached", Callable(self, "_on_firewall_breached"))
    
    # Connect Terminal Interface signals
    if terminal_interface:
        if terminal_interface.has_signal("command_executed"):
            terminal_interface.connect("command_executed", Callable(self, "_on_command_executed"))
        
        if terminal_interface.has_signal("wish_processed"):
            terminal_interface.connect("wish_processed", Callable(self, "_on_wish_processed"))
        
        if terminal_interface.has_signal("interface_changed"):
            terminal_interface.connect("interface_changed", Callable(self, "_on_interface_changed"))
        
        if terminal_interface.has_signal("terminal_ready"):
            terminal_interface.connect("terminal_ready", Callable(self, "_on_terminal_ready"))

# ----- INTERFACE MANAGEMENT -----
func set_interface(interface_name):
    match interface_name:
        "terminal":
            print("Setting interface to terminal")
            # In actual implementation, this would show terminal interface
            if terminal_interface and terminal_interface.has_method("activate"):
                terminal_interface.activate()
        "notepad3d":
            print("Setting interface to Notepad 3D")
            # In actual implementation, this would show 3D notepad
        "browser":
            print("Setting interface to browser")
            # In actual implementation, this would show browser interface
        "visual":
            print("Setting interface to visual")
            # In actual implementation, this would show visual interface
            if visual_system and visual_system.has_method("toggle_enabled"):
                visual_system.toggle_enabled()
        _:
            print("Unknown interface: " + interface_name)
    
    emit_signal("interface_ready", interface_name)

# ----- WELCOME MESSAGE -----
func show_welcome():
    var message = "Welcome to the Enhanced 12-Turn System\n"
    message += "Current Turn: " + str(config.starting_turn) + "\n"
    message += "Dimensional Depth: " + str(config.dimensional_depth) + "\n"
    message += "Base Frequency: " + str(config.color_frequency) + "\n"
    
    if terminal_interface and terminal_interface.has_method("print_message"):
        terminal_interface.print_message(message)
    else:
        print(message)
    
    # Highlight welcome in color system
    if color_system and color_system.has_method("start_pulse_animation"):
        color_system.start_pulse_animation(config.color_frequency, 5.0)

# ----- WISH PROCESSING -----
func process_wish(wish_text, priority = "normal", metadata = {}):
    if storage_system:
        var wish = storage_system.create_wish(wish_text, priority, metadata)
        
        if wish and ethereal_bridge and ethereal_bridge.has_method("update_wish"):
            # Update wish in Akashic Records
            ethereal_bridge.update_wish(wish.id, "pending", {
                "text": wish_text,
                "priority": priority,
                "created": Time.get_unix_time_from_system()
            })
        
        return wish
    
    return null

# ----- COMMAND EXECUTION -----
func execute_command(command):
    if terminal_interface and terminal_interface.has_method("process_command"):
        return terminal_interface.process_command(command)
    else:
        print("Terminal interface not available")
        return false

# ----- SIGNAL HANDLERS -----
func _on_storage_connected(platform, status):
    print("Storage connected: " + platform + " - " + str(status))

func _on_wish_created(wish_id, wish_text):
    print("Wish created: " + wish_id + " - " + wish_text)
    
    # Highlight in color system
    if color_animation_system:
        color_animation_system.animate_line(wish_text, "wish_" + wish_id, 1, 5.0)  # Pulse animation

func _on_wish_completed(wish_id):
    print("Wish completed: " + wish_id)

func _on_word_stored(word, power, metadata):
    print("Word stored: " + word + " (power: " + str(power) + ")")
    
    # Highlight in color system
    if color_system and color_system.has_method("start_pulse_animation"):
        var frequency = 99 + (power * 10)  # Scale power to frequency
        frequency = clamp(frequency, 99, 999)
        color_system.start_pulse_animation(frequency, 3.0)

func _on_gate_status_changed(gate_name, status):
    print("Gate status changed: " + gate_name + " - " + str(status))

func _on_wish_updated(wish_id, new_status):
    print("Wish updated: " + wish_id + " -> " + new_status)

func _on_firewall_breached(breach_info):
    print("FIREWALL BREACH: " + breach_info.type + " - " + breach_info.message)
    
    # Flash warning in visual system
    if visual_system and visual_system.has_method("set_mode"):
        visual_system.set_mode(3)  # Symbolic mode (warning)

func _on_command_executed(command, result):
    if config.debug_mode:
        print("Command executed: " + command)
    
    # Highlight command in color system
    if color_animation_system:
        color_animation_system.animate_line(command, "cmd_" + str(Time.get_unix_time_from_system()), 4, 2.0)  # Flash animation

func _on_wish_processed(wish_id, result):
    print("Wish processed: " + wish_id)

func _on_interface_changed(interface_name):
    print("Interface changed to: " + interface_name)

func _on_terminal_ready():
    print("Terminal interface ready")

# ----- TURN MANAGEMENT -----
func change_turn(new_turn):
    var old_turn = config.starting_turn
    config.starting_turn = new_turn
    
    # Update all systems with new turn
    if visual_system and visual_system.has_method("update_turn_indicator"):
        visual_system.update_turn_indicator(new_turn, 12)
    
    if color_animation_system and color_animation_system.has_method("update_turn"):
        color_animation_system.update_turn(new_turn, 12)
    
    if ethereal_bridge and ethereal_bridge.has_method("update_firewall"):
        var firewall_level = "standard"
        if new_turn > 7:
            firewall_level = "divine"
        elif new_turn > 3:
            firewall_level = "enhanced"
        
        ethereal_bridge.update_firewall(firewall_level, {
            "dimension_access": new_turn
        })
    
    print("Turn changed from " + str(old_turn) + " to " + str(new_turn))
    emit_signal("turn_changed", new_turn, old_turn)

# ----- GODOT 4 MIGRATION -----
func run_migration(godot3_path: String, godot4_path: String):
    if migration_tool:
        _log("Starting Godot 4 migration")
        
        # Configure migration
        migration_tool.godot3_project_path = godot3_path
        migration_tool.godot4_project_path = godot4_path
        migration_tool.backup_before_migration = config.migration_backup
        migration_tool.auto_fix_deprecated = true
        migration_tool.migrate_resources = true
        
        # Run migration
        return migration_tool.start_migration()
    else:
        _log("Migration tool not available", true)
        return false

func check_project_compatibility(project_path: String):
    if migration_tool:
        _log("Checking project compatibility")
        return migration_tool.generate_migration_report(project_path)
    else:
        _log("Migration tool not available", true)
        return null

# ----- COLOR SYSTEM CONTROL -----
func highlight_frequency(frequency: int, duration: float = 5.0):
    if color_system and color_system.has_method("start_pulse_animation"):
        _log("Highlighting frequency: " + str(frequency))
        color_system.start_pulse_animation(frequency, duration)
        return true
    return false

func animate_text(text: String, animation_type: int = 0):
    if color_animation_system and color_animation_system.has_method("animate_line"):
        _log("Animating text with " + str(animation_type) + " animation")
        var animation_id = color_animation_system.animate_line(text, "text_" + str(Time.get_unix_time_from_system()), animation_type)
        return animation_id
    return -1

func colorize_text(text: String, frequency: int = 99):
    if color_animation_system and color_animation_system.has_method("colorize_text"):
        return color_animation_system.colorize_text(text, frequency)
    elif color_system and color_system.has_method("colorize_line"):
        return color_system.colorize_line(text, frequency)
    return text

# ----- UTILITY FUNCTIONS -----
func _log(message, is_error = false):
    if config.debug_mode:
        if is_error:
            push_error("EnhancedSystemLauncher: " + message)
        else:
            print("EnhancedSystemLauncher: " + message)

# ----- PUBLIC API -----
func is_system_loaded(system_name):
    return systems_loaded.get(system_name, false)

func get_system_status():
    var status = {
        "akashic_system": akashic_system != null,
        "ethereal_bridge": ethereal_bridge != null,
        "color_system": color_system != null,
        "visual_system": visual_system != null,
        "keyboard_system": keyboard_system != null,
        "migration_tool": migration_tool != null,
        "color_animation_system": color_animation_system != null,
        "terminal_interface": terminal_interface != null,
        "storage_system": storage_system != null,
        "current_turn": config.starting_turn,
        "dimensional_depth": config.dimensional_depth,
        "base_frequency": config.color_frequency
    }
    
    # Add storage status if available
    if storage_system and storage_system.has_method("get_storage_status"):
        status["storage"] = storage_system.get_storage_status()
    
    # Add akashic status if available
    if ethereal_bridge and ethereal_bridge.has_method("get_status"):
        status["akashic"] = ethereal_bridge.get_status()
    
    return status

func create_wish(wish_text, priority = "normal"):
    return process_wish(wish_text, priority)

func run_command(command):
    return execute_command(command)

func connect_cloud_storage(service, credentials = {}):
    if storage_system and storage_system.has_method("connect_cloud_storage"):
        return storage_system.connect_cloud_storage(service, credentials)
    return false
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/enhanced_system_launcher.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/ethereal_akashic_bridge.gd
# SIZE: 36899 bytes
extends Node

class_name EtherealAkashicBridge

# ----- BRIDGE SETTINGS -----
@export_category("Bridge Configuration")
@export var enabled: bool = true
@export var auto_connect: bool = true
@export var ethereal_engine_path: String = "res://ethereal_engine_integration.gd"
@export var akashic_bridge_path: String = "res://claude_akashic_bridge.gd"
@export var connection_frequency: float = 0.5  # How often to synchronize (in seconds)
@export var dimensional_depth: int = 8
@export var max_data_transfer: int = 888

# ----- CONNECTION VARIABLES -----
var ethereal_engine: Node = null
var akashic_bridge: Node = null
var memory_system: Node = null
var turn_system: Node = null

# ----- DATA CHANNELS -----
var data_channels: Dictionary = {}
var active_channels: Array = []
var frequency_channels: Dictionary = {}

# ----- DIMENSIONAL CONNECTIONS -----
var dimension_map: Dictionary = {}
var current_dimension: String = "0-0-0"
var dimension_stack: Array = []

# ----- VISUALIZATION DATA -----
var fractal_points: Array = []
var connection_nodes: Array = []
var visualization_ready: bool = false

# ----- PROCESSING -----
var process_interval: float = 0.1
var last_process_time: float = 0.0
var connection_timer: Timer
var sync_timer: Timer

# ----- SIGNALS -----
signal connection_established(system_name)
signal dimension_changed(previous, current)
signal data_transferred(channel, size)
signal bridge_synchronization_completed()
signal fractal_data_updated(points)
signal memory_recorded(content, dimension)

# ----- INITIALIZATION -----
func _ready():
    # Initialize timers
    _setup_timers()
    
    # Find components
    _find_components()
    
    # Initialize dimension map
    _initialize_dimension_map()
    
    # Initialize fractal points for visualization
    _initialize_fractal_visualization()
    
    # Auto-connect if enabled
    if auto_connect:
        connect_systems()
    
    print("Ethereal Akashic Bridge initialized in dimension: " + current_dimension)

func _setup_timers():
    # Create connection timer
    connection_timer = Timer.new()
    connection_timer.wait_time = 1.0  # Check connections every second
    connection_timer.one_shot = false
    connection_timer.autostart = true
    connection_timer.connect("timeout", _on_connection_timer_timeout)
    add_child(connection_timer)
    
    # Create sync timer
    sync_timer = Timer.new()
    sync_timer.wait_time = connection_frequency
    sync_timer.one_shot = false
    sync_timer.autostart = true
    sync_timer.connect("timeout", _on_sync_timer_timeout)
    add_child(sync_timer)

func _find_components():
    # Find Ethereal Engine
    ethereal_engine = _load_or_find_node("EtherealEngine")
    
    # Find Akashic Bridge
    akashic_bridge = _load_or_find_node("ClaudeAkashicBridge")
    
    # Find Memory System
    memory_system = _find_node_by_class(get_tree().root, "IntegratedMemorySystem")
    
    # Find Turn System
    turn_system = _find_node_by_class(get_tree().root, "TurnSystem")
    if not turn_system:
        turn_system = _find_node_by_class(get_tree().root, "TurnCycleController")

func _load_or_find_node(class_name_str):
    # First try to find existing node
    var node = _find_node_by_class(get_tree().root, class_name_str)
    
    if node:
        print("Found existing " + class_name_str + ": " + node.name)
        return node
    
    # If not found, check if we can instance from script
    var script_path = ""
    if class_name_str == "EtherealEngine":
        script_path = ethereal_engine_path
    elif class_name_str == "ClaudeAkashicBridge":
        script_path = akashic_bridge_path
    
    if script_path and ResourceLoader.exists(script_path):
        var script = load(script_path)
        if script:
            var instance = Node.new()
            instance.set_script(script)
            instance.name = class_name_str + "Instance"
            add_child(instance)
            print("Instantiated " + class_name_str + " from script")
            return instance
    
    return null

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_dimension_map():
    # Create dimension coordinates centered at 0,0,0
    for x in range(-dimensional_depth, dimensional_depth + 1):
        for y in range(-dimensional_depth, dimensional_depth + 1):
            for z in range(-dimensional_depth, dimensional_depth + 1):
                # Only create dimensions within a sphere
                var distance = sqrt(x*x + y*y + z*z)
                if distance <= dimensional_depth:
                    var dim_key = str(x) + "-" + str(y) + "-" + str(z)
                    dimension_map[dim_key] = {
                        "coordinates": Vector3(x, y, z),
                        "distance": distance,
                        "connections": [],
                        "data": {},
                        "frequency": _calculate_dimension_frequency(distance),
                        "last_visited": 0,
                        "stability": _calculate_stability(distance)
                    }
                    
                    # Connect to adjacent dimensions
                    _connect_adjacent_dimensions(dim_key, x, y, z)

func _connect_adjacent_dimensions(dim_key, x, y, z):
    # Connect to the 6 adjacent dimensions (if they exist)
    var adjacent = [
        [x+1, y, z], [x-1, y, z],
        [x, y+1, z], [x, y-1, z],
        [x, y, z+1], [x, y, z-1]
    ]
    
    for adj in adjacent:
        var adj_key = str(adj[0]) + "-" + str(adj[1]) + "-" + str(adj[2])
        if dimension_map.has(adj_key):
            dimension_map[dim_key].connections.append(adj_key)

func _calculate_dimension_frequency(distance):
    # Dimensions closer to center have higher frequencies
    return 1.0 - (distance / (dimensional_depth * 1.5))

func _calculate_stability(distance):
    # Dimensions closer to center are more stable
    var stability = 1.0 - (distance / (dimensional_depth * 2.0))
    return clamp(stability, 0.1, 0.95)  # Never fully stable or unstable

func _initialize_fractal_visualization():
    fractal_points.clear()
    connection_nodes.clear()
    
    # Create fractal points from dimension map
    for dim_key in dimension_map:
        var dim_data = dimension_map[dim_key]
        
        # Scale coordinates for visualization
        var coords = dim_data.coordinates * 20.0
        
        fractal_points.append({
            "position": coords,
            "frequency": dim_data.frequency,
            "stability": dim_data.stability,
            "key": dim_key
        })
        
        # Create connection nodes (edges of the graph)
        for connection in dim_data.connections:
            if connection > dim_key:  # Only add each connection once
                if dimension_map.has(connection):
                    var conn_coords = dimension_map[connection].coordinates * 20.0
                    
                    connection_nodes.append({
                        "from": coords,
                        "to": conn_coords,
                        "strength": (dim_data.stability + dimension_map[connection].stability) / 2.0
                    })
    
    visualization_ready = true
    emit_signal("fractal_data_updated", fractal_points)

# ----- CONNECTION MANAGEMENT -----
func connect_systems():
    if not enabled:
        return false
    
    var success = true
    
    # Connect to Ethereal Engine
    if ethereal_engine:
        _setup_ethereal_engine()
        emit_signal("connection_established", "EtherealEngine")
    else:
        print("Warning: Ethereal Engine not found")
        success = false
    
    # Connect to Akashic Bridge
    if akashic_bridge:
        _setup_akashic_bridge()
        emit_signal("connection_established", "AkashicBridge")
    else:
        print("Warning: Akashic Bridge not found")
        success = false
    
    # Connect to Memory System
    if memory_system:
        _setup_memory_system()
        emit_signal("connection_established", "MemorySystem")
    else:
        print("Warning: Memory System not found")
    
    # Connect to Turn System
    if turn_system:
        _setup_turn_system()
        emit_signal("connection_established", "TurnSystem")
    else:
        print("Warning: Turn System not found")
    
    # Initialize data channels
    _initialize_data_channels()
    
    return success

func _setup_ethereal_engine():
    # Connect signals if available
    if ethereal_engine.has_signal("dimension_shifted"):
        ethereal_engine.connect("dimension_shifted", _on_ethereal_dimension_shifted)
    
    if ethereal_engine.has_signal("data_processed"):
        ethereal_engine.connect("data_processed", _on_ethereal_data_processed)
    
    # Initialize engine with our current dimension
    if ethereal_engine.has_method("set_current_dimension"):
        ethereal_engine.set_current_dimension(current_dimension)

func _setup_akashic_bridge():
    # Connect signals if available
    if akashic_bridge.has_signal("record_accessed"):
        akashic_bridge.connect("record_accessed", _on_akashic_record_accessed)
    
    if akashic_bridge.has_signal("data_stored"):
        akashic_bridge.connect("data_stored", _on_akashic_data_stored)
    
    # Initialize bridge with our dimension map
    if akashic_bridge.has_method("set_dimension_data"):
        var simplified_dimensions = {}
        for dim_key in dimension_map:
            simplified_dimensions[dim_key] = {
                "frequency": dimension_map[dim_key].frequency,
                "stability": dimension_map[dim_key].stability
            }
        
        akashic_bridge.set_dimension_data(simplified_dimensions)

func _setup_memory_system():
    # Connect signals if available
    if memory_system.has_signal("memory_stored"):
        memory_system.connect("memory_stored", _on_memory_stored)
    
    if memory_system.has_signal("wish_added"):
        memory_system.connect("wish_added", _on_wish_added)

func _setup_turn_system():
    # Connect signals if available
    if turn_system.has_signal("turn_advanced"):
        turn_system.connect("turn_advanced", _on_turn_advanced)
    
    if turn_system.has_method("get_current_turn"):
        var turn = turn_system.get_current_turn()
        _update_frequency_for_turn(turn)

func _initialize_data_channels():
    # Create standard data channels
    data_channels = {
        "memory": { "active": true, "buffer": [], "capacity": max_data_transfer, "frequency": 1.0 },
        "akashic": { "active": true, "buffer": [], "capacity": max_data_transfer, "frequency": 0.8 },
        "ethereal": { "active": true, "buffer": [], "capacity": max_data_transfer, "frequency": 0.7 },
        "dimensional": { "active": true, "buffer": [], "capacity": max_data_transfer, "frequency": 0.9 },
        "turn": { "active": true, "buffer": [], "capacity": max_data_transfer, "frequency": 0.5 },
        "wish": { "active": true, "buffer": [], "capacity": max_data_transfer, "frequency": 0.3 }
    }
    
    # Update active channels list
    _update_active_channels()

func _update_active_channels():
    active_channels.clear()
    
    for channel_name in data_channels:
        var channel = data_channels[channel_name]
        if channel.active:
            active_channels.append(channel_name)
    
    # Update frequency channels
    _update_frequency_channels()

func _update_frequency_channels():
    frequency_channels.clear()
    
    for channel_name in data_channels:
        var channel = data_channels[channel_name]
        var freq_key = str(snappedf(channel.frequency, 0.1))
        
        if not frequency_channels.has(freq_key):
            frequency_channels[freq_key] = []
        
        frequency_channels[freq_key].append(channel_name)

# ----- DIMENSION MANAGEMENT -----
func change_dimension(dimension_key: String):
    if not dimension_map.has(dimension_key):
        print("Warning: Dimension " + dimension_key + " does not exist")
        return false
    
    var previous = current_dimension
    current_dimension = dimension_key
    
    # Update dimension stack
    dimension_stack.append(previous)
    if dimension_stack.size() > 12:  # Keep only last 12 dimensions
        dimension_stack.remove_at(0)
    
    # Update dimension data
    dimension_map[current_dimension].last_visited = Time.get_unix_time_from_system()
    
    # Notify connected systems
    if ethereal_engine and ethereal_engine.has_method("set_current_dimension"):
        ethereal_engine.set_current_dimension(current_dimension)
    
    # Update data channel
    var dimension_data = {
        "previous": previous,
        "current": current_dimension,
        "timestamp": Time.get_unix_time_from_system(),
        "stack": dimension_stack.duplicate()
    }
    
    _add_to_channel("dimensional", dimension_data)
    
    # Emit signal
    emit_signal("dimension_changed", previous, current_dimension)
    
    return true

func get_connected_dimensions():
    if dimension_map.has(current_dimension):
        return dimension_map[current_dimension].connections
    return []

func get_dimension_at_coordinates(x, y, z):
    var key = str(x) + "-" + str(y) + "-" + str(z)
    if dimension_map.has(key):
        return key
    return null

func store_in_dimension(dimension_key, key, value):
    if dimension_map.has(dimension_key):
        dimension_map[dimension_key].data[key] = value
        return true
    return false

func retrieve_from_dimension(dimension_key, key):
    if dimension_map.has(dimension_key) and dimension_map[dimension_key].data.has(key):
        return dimension_map[dimension_key].data[key]
    return null

# ----- DATA CHANNEL MANAGEMENT -----
func _add_to_channel(channel_name, data):
    if not data_channels.has(channel_name):
        return false
    
    var channel = data_channels[channel_name]
    
    # Add timestamp if not present
    if typeof(data) == TYPE_DICTIONARY and not data.has("_timestamp"):
        data["_timestamp"] = Time.get_unix_time_from_system()
    
    # Add to buffer
    channel.buffer.append(data)
    
    # Ensure buffer doesn't exceed capacity
    while channel.buffer.size() > channel.capacity:
        channel.buffer.remove_at(0)
    
    return true

func clear_channel(channel_name):
    if not data_channels.has(channel_name):
        return false
    
    data_channels[channel_name].buffer.clear()
    return true

func get_channel_data(channel_name):
    if not data_channels.has(channel_name):
        return []
    
    return data_channels[channel_name].buffer.duplicate()

func set_channel_frequency(channel_name, frequency):
    if not data_channels.has(channel_name):
        return false
    
    data_channels[channel_name].frequency = clamp(frequency, 0.0, 1.0)
    _update_frequency_channels()
    
    return true

func toggle_channel(channel_name, active: bool):
    if not data_channels.has(channel_name):
        return false
    
    data_channels[channel_name].active = active
    _update_active_channels()
    
    return true

# ----- AKASHIC RECORD OPERATIONS -----
func record_memory(content, tags = [], dimension_key = ""):
    if dimension_key.is_empty():
        dimension_key = current_dimension
    
    if not dimension_map.has(dimension_key):
        return false
    
    # Create memory structure
    var memory = {
        "content": content,
        "tags": tags,
        "dimension": dimension_key,
        "timestamp": Time.get_unix_time_from_system(),
        "frequency": dimension_map[dimension_key].frequency
    }
    
    # Store in akashic channel
    _add_to_channel("akashic", memory)
    
    # If memory system is available, also store there
    if memory_system and memory_system.has_method("store_memory"):
        # Add dimension info to tags
        var combined_tags = tags.duplicate()
        combined_tags.append("dimension:" + dimension_key)
        
        var memory_id = memory_system.store_memory(content, combined_tags, "akashic", -1)
        memory["memory_id"] = memory_id
    
    # Emit signal
    emit_signal("memory_recorded", content, dimension_key)
    
    return true

func search_akashic_records(query, dimension_key = ""):
    var results = []
    
    # Search in akashic channel
    var akashic_data = get_channel_data("akashic")
    
    for entry in akashic_data:
        if typeof(entry) != TYPE_DICTIONARY:
            continue
        
        # Check dimension constraint
        if not dimension_key.is_empty() and entry.has("dimension") and entry.dimension != dimension_key:
            continue
        
        # Check query match
        if entry.has("content") and entry.content.to_lower().contains(query.to_lower()):
            results.append(entry)
    
    # If memory system is available, also search there
    if memory_system and memory_system.has_method("search_memories"):
        var tags = []
        if not dimension_key.is_empty():
            tags.append("dimension:" + dimension_key)
        
        var memory_results = memory_system.search_memories(query, tags)
        
        # Add results that aren't already included
        for memory in memory_results:
            var already_included = false
            
            for existing in results:
                if existing.has("memory_id") and memory.id == existing.memory_id:
                    already_included = true
                    break
            
            if not already_included:
                results.append({
                    "content": memory.content,
                    "tags": memory.tags,
                    "timestamp": memory.timestamp,
                    "memory_id": memory.id,
                    "dimension": dimension_key.is_empty() ? current_dimension : dimension_key
                })
    
    return results

# ----- ETHEREAL ENGINE OPERATIONS -----
func process_ethereal_data(data_type, content):
    if not ethereal_engine:
        return false
    
    # Create data structure
    var data = {
        "type": data_type,
        "content": content,
        "dimension": current_dimension,
        "timestamp": Time.get_unix_time_from_system()
    }
    
    # Store in ethereal channel
    _add_to_channel("ethereal", data)
    
    # Forward to ethereal engine if it has the method
    if ethereal_engine.has_method("process_data"):
        ethereal_engine.process_data(data_type, content, current_dimension)
    
    return true

func create_ethereal_scene(scene_data):
    if not ethereal_engine:
        return false
    
    # Store in ethereal channel
    _add_to_channel("ethereal", {
        "type": "scene",
        "data": scene_data,
        "dimension": current_dimension,
        "timestamp": Time.get_unix_time_from_system()
    })
    
    # Forward to ethereal engine if it has the method
    if ethereal_engine.has_method("create_scene"):
        return ethereal_engine.create_scene(scene_data, current_dimension)
    
    return false

func perform_ethereal_action(action_name, parameters = {}):
    if not ethereal_engine:
        return false
    
    # Store in ethereal channel
    _add_to_channel("ethereal", {
        "type": "action",
        "name": action_name,
        "parameters": parameters,
        "dimension": current_dimension,
        "timestamp": Time.get_unix_time_from_system()
    })
    
    # Forward to ethereal engine if it has the method
    if ethereal_engine.has_method("perform_action"):
        return ethereal_engine.perform_action(action_name, parameters, current_dimension)
    
    return false

# ----- BRIDGE SYNCHRONIZATION -----
func _process(delta):
    if not enabled:
        return
    
    # Update processing at regular intervals
    last_process_time += delta
    if last_process_time >= process_interval:
        last_process_time = 0.0
        _process_active_channels(delta)

func _process_active_channels(delta):
    # Process channels based on their frequency
    for channel_name in active_channels:
        var channel = data_channels[channel_name]
        
        # Skip empty channels
        if channel.buffer.is_empty():
            continue
        
        # Process based on frequency and random chance
        if randf() < (channel.frequency * process_interval / connection_frequency):
            _process_channel_data(channel_name)

func _process_channel_data(channel_name):
    var channel = data_channels[channel_name]
    
    # Skip empty channels
    if channel.buffer.is_empty():
        return
    
    match channel_name:
        "memory":
            _process_memory_channel()
        "akashic":
            _process_akashic_channel()
        "ethereal":
            _process_ethereal_channel()
        "dimensional":
            _process_dimensional_channel()
        "turn":
            _process_turn_channel()
        "wish":
            _process_wish_channel()

func _process_memory_channel():
    # Process a few items from the memory channel
    var channel = data_channels["memory"]
    var count = min(3, channel.buffer.size())
    
    if count == 0:
        return
    
    for i in range(count):
        var memory = channel.buffer[i]
        
        # If memory system is available, ensure it's stored there
        if memory_system and memory_system.has_method("store_memory") and not memory.has("memory_id"):
            var tags = memory.has("tags") ? memory.tags.duplicate() : []
            
            # Add dimension tag
            if memory.has("dimension"):
                tags.append("dimension:" + memory.dimension)
            
            var memory_id = memory_system.store_memory(
                memory.content,
                tags,
                "bridge_memory",
                -1
            )
            
            memory["memory_id"] = memory_id
    
    # Remove processed items
    for i in range(count):
        channel.buffer.remove_at(0)
    
    emit_signal("data_transferred", "memory", count)

func _process_akashic_channel():
    # Process a few items from the akashic channel
    var channel = data_channels["akashic"]
    var count = min(2, channel.buffer.size())
    
    if count == 0:
        return
    
    for i in range(count):
        var record = channel.buffer[i]
        
        # Forward to akashic bridge if available
        if akashic_bridge and akashic_bridge.has_method("store_record"):
            akashic_bridge.store_record(record.content, record.dimension, record.has("tags") ? record.tags : [])
    
    # Remove processed items
    for i in range(count):
        channel.buffer.remove_at(0)
    
    emit_signal("data_transferred", "akashic", count)

func _process_ethereal_channel():
    # Process a few items from the ethereal channel
    var channel = data_channels["ethereal"]
    var count = min(2, channel.buffer.size())
    
    if count == 0:
        return
    
    # Most ethereal operations are processed immediately when called,
    # so we just need to clean up old items
    var current_time = Time.get_unix_time_from_system()
    var items_to_remove = []
    
    for i in range(channel.buffer.size()):
        var data = channel.buffer[i]
        
        # Remove items older than 5 minutes
        if data.has("_timestamp") and (current_time - data._timestamp) > 300:
            items_to_remove.append(i)
    
    # Remove old items (in reverse order to maintain indices)
    items_to_remove.sort()
    items_to_remove.reverse()
    
    for idx in items_to_remove:
        channel.buffer.remove_at(idx)
    
    emit_signal("data_transferred", "ethereal", items_to_remove.size())

func _process_dimensional_channel():
    # Process a few items from the dimensional channel
    var channel = data_channels["dimensional"]
    var count = min(1, channel.buffer.size())
    
    if count == 0:
        return
    
    # Most dimensional operations are processed immediately when called,
    # so we just update dimension stability based on frequency of use
    
    var current_time = Time.get_unix_time_from_system()
    var items_to_remove = []
    
    for i in range(channel.buffer.size()):
        var data = channel.buffer[i]
        
        # Process dimensional stability updates
        if data.has("current") and dimension_map.has(data.current):
            var dim_data = dimension_map[data.current]
            
            # More frequent visits improve stability slightly
            if data.has("_timestamp") and (current_time - data._timestamp) < 3600:  # Within last hour
                dim_data.stability = min(dim_data.stability + 0.01, 0.95)
            
            # Update last visited time
            dim_data.last_visited = data._timestamp if data.has("_timestamp") else current_time
        
        # Remove items older than 10 minutes
        if data.has("_timestamp") and (current_time - data._timestamp) > 600:
            items_to_remove.append(i)
    
    # Remove old items (in reverse order to maintain indices)
    items_to_remove.sort()
    items_to_remove.reverse()
    
    for idx in items_to_remove:
        channel.buffer.remove_at(idx)
    
    emit_signal("data_transferred", "dimensional", items_to_remove.size())

func _process_turn_channel():
    # Process a few items from the turn channel
    var channel = data_channels["turn"]
    var count = min(1, channel.buffer.size())
    
    if count == 0:
        return
    
    # Most turn operations are processed immediately when turn changes,
    # so we just need to clean up old items
    var current_time = Time.get_unix_time_from_system()
    var items_to_remove = []
    
    for i in range(channel.buffer.size()):
        var data = channel.buffer[i]
        
        # Remove items older than 5 minutes
        if data.has("_timestamp") and (current_time - data._timestamp) > 300:
            items_to_remove.append(i)
    
    # Remove old items (in reverse order to maintain indices)
    items_to_remove.sort()
    items_to_remove.reverse()
    
    for idx in items_to_remove:
        channel.buffer.remove_at(idx)
    
    emit_signal("data_transferred", "turn", items_to_remove.size())

func _process_wish_channel():
    # Process a few items from the wish channel
    var channel = data_channels["wish"]
    var count = min(1, channel.buffer.size())
    
    if count == 0:
        return
    
    for i in range(count):
        var wish = channel.buffer[i]
        
        # If memory system is available, add wish there
        if memory_system and memory_system.has_method("add_wish") and not wish.has("wish_id"):
            var tags = wish.has("tags") ? wish.tags.duplicate() : []
            
            # Add dimension tag
            if wish.has("dimension"):
                tags.append("dimension:" + wish.dimension)
            
            var wish_id = memory_system.add_wish(
                wish.content,
                wish.has("priority") ? wish.priority : 5,
                tags
            )
            
            wish["wish_id"] = wish_id
    
    # Remove processed items
    for i in range(count):
        channel.buffer.remove_at(0)
    
    emit_signal("data_transferred", "wish", count)

# ----- FRACTAL VISUALIZATION -----
func get_fractal_visualization_data():
    return {
        "points": fractal_points,
        "connections": connection_nodes,
        "current_dimension": current_dimension,
        "dimension_stack": dimension_stack
    }

func get_dimension_fractal(dimension_key = ""):
    if dimension_key.is_empty():
        dimension_key = current_dimension
    
    if not dimension_map.has(dimension_key):
        return null
    
    # Get dimension data
    var dim_data = dimension_map[dimension_key]
    
    # Create fractal representation
    var fractal = {
        "position": dim_data.coordinates,
        "frequency": dim_data.frequency,
        "stability": dim_data.stability,
        "connections": dim_data.connections.duplicate(),
        "data_size": dim_data.data.size(),
        "last_visited": dim_data.last_visited
    }
    
    return fractal

# ----- EVENT HANDLERS -----
func _on_connection_timer_timeout():
    # Check connections and reconnect if needed
    if not ethereal_engine:
        ethereal_engine = _load_or_find_node("EtherealEngine")
        if ethereal_engine:
            _setup_ethereal_engine()
            emit_signal("connection_established", "EtherealEngine")
    
    if not akashic_bridge:
        akashic_bridge = _load_or_find_node("ClaudeAkashicBridge")
        if akashic_bridge:
            _setup_akashic_bridge()
            emit_signal("connection_established", "AkashicBridge")
    
    if not memory_system:
        memory_system = _find_node_by_class(get_tree().root, "IntegratedMemorySystem")
        if memory_system:
            _setup_memory_system()
            emit_signal("connection_established", "MemorySystem")
    
    if not turn_system:
        turn_system = _find_node_by_class(get_tree().root, "TurnSystem")
        if not turn_system:
            turn_system = _find_node_by_class(get_tree().root, "TurnCycleController")
        
        if turn_system:
            _setup_turn_system()
            emit_signal("connection_established", "TurnSystem")

func _on_sync_timer_timeout():
    # Perform full synchronization
    _synchronize_all_systems()
    emit_signal("bridge_synchronization_completed")

func _synchronize_all_systems():
    # Update connection between all systems
    
    # 1. Update dimension frequencies based on turn
    if turn_system:
        var turn = 1
        if turn_system.has_method("get_current_turn"):
            turn = turn_system.get_current_turn()
        
        _update_frequency_for_turn(turn)
    
    # 2. Update ethereal engine with current dimension data
    if ethereal_engine and ethereal_engine.has_method("update_dimension_data"):
        var dim_data = null
        if dimension_map.has(current_dimension):
            dim_data = dimension_map[current_dimension]
        
        ethereal_engine.update_dimension_data(current_dimension, dim_data)
    
    # 3. Update akashic bridge with current frequencies
    if akashic_bridge and akashic_bridge.has_method("update_frequencies"):
        var frequencies = {}
        for channel_name in data_channels:
            frequencies[channel_name] = data_channels[channel_name].frequency
        
        akashic_bridge.update_frequencies(frequencies)
    
    # 4. Update fractal visualization
    _update_fractal_visualization()

func _update_frequency_for_turn(turn_number):
    var turn_factor = float(turn_number) / 12.0  # Assuming 12 turns max
    
    # Adjust channel frequencies based on turn
    data_channels["memory"].frequency = 0.7 + turn_factor * 0.3
    data_channels["akashic"].frequency = 0.5 + turn_factor * 0.5
    data_channels["ethereal"].frequency = 0.4 + turn_factor * 0.6
    data_channels["dimensional"].frequency = 0.6 + turn_factor * 0.4
    data_channels["turn"].frequency = 0.3 + turn_factor * 0.7
    data_channels["wish"].frequency = 0.2 + turn_factor * 0.8
    
    # Update channel lists
    _update_active_channels()
    
    # Add to turn channel
    _add_to_channel("turn", {
        "turn": turn_number,
        "frequencies_updated": true,
        "timestamp": Time.get_unix_time_from_system()
    })

func _update_fractal_visualization():
    # Update fractal points based on current data
    for i in range(fractal_points.size()):
        var point = fractal_points[i]
        var dim_key = point.key
        
        if dimension_map.has(dim_key):
            point.frequency = dimension_map[dim_key].frequency
            point.stability = dimension_map[dim_key].stability
    
    # Update connection strengths
    for i in range(connection_nodes.size()):
        var conn = connection_nodes[i]
        var from_point = null
        var to_point = null
        
        # Find corresponding points
        for p in fractal_points:
            if p.position == conn.from:
                from_point = p
            if p.position == conn.to:
                to_point = p
            
            if from_point and to_point:
                break
        
        if from_point and to_point:
            conn.strength = (dimension_map[from_point.key].stability + dimension_map[to_point.key].stability) / 2.0
    
    emit_signal("fractal_data_updated", fractal_points)

func _on_ethereal_dimension_shifted(from_dim, to_dim):
    # Update our dimension to match
    if dimension_map.has(to_dim):
        change_dimension(to_dim)

func _on_ethereal_data_processed(data_type, content, dim):
    # Add to memory channel
    _add_to_channel("memory", {
        "content": "Ethereal data processed: " + data_type + " in dimension " + dim,
        "dimension": dim,
        "timestamp": Time.get_unix_time_from_system(),
        "type": "ethereal_data"
    })

func _on_akashic_record_accessed(record_id, content):
    # Add to akashic channel
    _add_to_channel("akashic", {
        "content": content,
        "record_id": record_id,
        "dimension": current_dimension,
        "timestamp": Time.get_unix_time_from_system(),
        "type": "record_access"
    })

func _on_akashic_data_stored(record_id, content):
    # Data already in akashic channel, nothing to do
    pass

func _on_memory_stored(memory_id, content):
    # Add to memory channel
    _add_to_channel("memory", {
        "content": content,
        "memory_id": memory_id,
        "dimension": current_dimension,
        "timestamp": Time.get_unix_time_from_system(),
        "type": "memory_storage"
    })

func _on_wish_added(wish_id, content):
    # Add to wish channel
    _add_to_channel("wish", {
        "content": content,
        "wish_id": wish_id,
        "dimension": current_dimension,
        "timestamp": Time.get_unix_time_from_system(),
        "type": "wish_creation"
    })

func _on_turn_advanced(old_turn, new_turn):
    # Update frequencies for new turn
    _update_frequency_for_turn(new_turn)
    
    # Record in memory
    record_memory("Advanced from Turn " + str(old_turn) + " to Turn " + str(new_turn), ["turn_change"])

# ----- PUBLIC API -----
func toggle_bridge(enabled_state: bool):
    enabled = enabled_state
    return enabled

func create_wish(content, priority = 5, tags = []):
    # Add to wish channel
    _add_to_channel("wish", {
        "content": content,
        "priority": priority,
        "tags": tags,
        "dimension": current_dimension,
        "timestamp": Time.get_unix_time_from_system()
    })
    
    # Forward to memory system if available
    if memory_system and memory_system.has_method("add_wish"):
        var combined_tags = tags.duplicate()
        combined_tags.append("dimension:" + current_dimension)
        
        return memory_system.add_wish(content, priority, combined_tags)
    
    return true

func set_connection_frequency(freq: float):
    connection_frequency = max(0.1, freq)
    sync_timer.wait_time = connection_frequency
    return connection_frequency

func get_active_dimensions():
    var active = []
    
    # Get dimensions visited in the last 24 hours
    var current_time = Time.get_unix_time_from_system()
    var time_threshold = current_time - 86400  # 24 hours
    
    for dim_key in dimension_map:
        var dim_data = dimension_map[dim_key]
        if dim_data.last_visited > time_threshold:
            active.append({
                "key": dim_key,
                "coordinates": dim_data.coordinates,
                "last_visited": dim_data.last_visited,
                "frequency": dim_data.frequency,
                "stability": dim_data.stability
            })
    
    return active

func get_bridge_status():
    return {
        "enabled": enabled,
        "current_dimension": current_dimension,
        "connections": {
            "ethereal_engine": ethereal_engine != null,
            "akashic_bridge": akashic_bridge != null,
            "memory_system": memory_system != null,
            "turn_system": turn_system != null
        },
        "channels": {
            "active_count": active_channels.size(),
            "channel_sizes": {
                "memory": data_channels.memory.buffer.size(),
                "akashic": data_channels.akashic.buffer.size(),
                "ethereal": data_channels.ethereal.buffer.size(),
                "dimensional": data_channels.dimensional.buffer.size(),
                "turn": data_channels.turn.buffer.size(),
                "wish": data_channels.wish.buffer.size()
            }
        },
        "dimensions": {
            "count": dimension_map.size(),
            "stack_size": dimension_stack.size()
        }
    }
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/ethereal_akashic_bridge.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/ethereal_migration_bridge.gd
# SIZE: 52667 bytes
class_name EtherealMigrationBridge
extends Node

# ----- INTEGRATION WITH JSH ETHEREAL ENGINE -----
@export_category("Ethereal Engine Integration")
@export var use_akashic_records: bool = true
@export var track_reality_changes: bool = true
@export var enable_word_manifestation: bool = true
@export var dimensional_records_path: String = "res://akashic_records/migration"

# ----- MIGRATION TOOL REFERENCE -----
var migration_tool = null
var akashic_system = null
var color_system = null
var records_system = null
var banks_combiner = null
var word_manager = null

# ----- MIGRATION RECORDS -----
var migration_records = {}
var migration_timestamp = 0
var migration_reality = "digital_migration"
var migration_memory = {}
var active_record_sets = []

# ----- MIGRATION STATISTICS -----
var ethereal_nodes_migrated = 0
var reality_contexts_migrated = 0
var word_manifestations_migrated = 0
var datapoints_migrated = 0
var records_migrated = 0

# ----- SIGNALS -----
signal ethereal_migration_started(records_count)
signal ethereal_migration_completed(stats)
signal reality_transition_migrated(reality_type)
signal word_manifestation_migrated(word, position)
signal record_set_migrated(set_name, records_count)

# ----- INITIALIZATION -----
func _ready():
    _find_components()
    _setup_record_sets()
    
    print("Ethereal Migration Bridge initialized")

func _find_components():
    # Find Migration Tool
    migration_tool = get_node_or_null("/root/Godot4MigrationTool")
    if not migration_tool:
        migration_tool = _find_node_by_class(get_tree().root, "Godot4MigrationTool")
    
    if not migration_tool:
        migration_tool = Godot4MigrationTool.new()
        add_child(migration_tool)
    
    # Find other systems by checking for JSH systems
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Look for JSH Records System
    records_system = get_node_or_null("/root/JSH_records_system")
    if not records_system:
        records_system = _find_node_by_class(get_tree().root, "JSH_records_system")
    
    # Look for BanksCombiner
    banks_combiner = get_node_or_null("/root/BanksCombiner")
    if not banks_combiner:
        banks_combiner = _find_node_by_class(get_tree().root, "BanksCombiner")
    
    # Look for WordManager
    word_manager = get_node_or_null("/root/WordManager")
    if not word_manager:
        word_manager = _find_node_by_class(get_tree().root, "WordManager")
    
    print("Components found - Migration Tool: %s, Akashic System: %s, Color System: %s" % [
        "Yes" if migration_tool else "No",
        "Yes" if akashic_system else "No",
        "Yes" if color_system else "No"
    ])
    
    print("Ethereal components found - Records System: %s, Banks Combiner: %s, Word Manager: %s" % [
        "Yes" if records_system else "No",
        "Yes" if banks_combiner else "No",
        "Yes" if word_manager else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _setup_record_sets():
    # Initialize record sets for migration
    migration_timestamp = Time.get_unix_time_from_system()
    active_record_sets = [
        "migration_metadata",
        "node_migrations",
        "reality_migrations",
        "word_migrations",
        "datapoint_migrations",
        "records_migrations"
    ]
    
    # Initialize record structures
    for set_name in active_record_sets:
        migration_records[set_name] = []
    
    # Create metadata record
    var metadata = {
        "timestamp": migration_timestamp,
        "godot3_version": "3.5", # Default, will be updated during migration
        "godot4_version": "4.5",
        "reality_context": migration_reality,
        "engine_type": "JSH Ethereal Engine"
    }
    
    migration_records["migration_metadata"].append(metadata)
    
    # Register with records system if available
    if use_akashic_records and records_system and records_system.has_method("add_basic_set"):
        for set_name in active_record_sets:
            if not records_system.has_set(set_name):
                records_system.add_basic_set(set_name)
        
        # Register with BanksCombiner if available
        if banks_combiner:
            for set_name in active_record_sets:
                if not banks_combiner.data_sets_names_0.has(set_name):
                    banks_combiner.data_sets_names_0.append(set_name)
    
    # Initialize memory system for d√©j√† vu detection
    migration_memory = {
        "node_type": [],
        "reality_transition": [],
        "word_manifestation": []
    }

# ----- ETHEREAL MIGRATION FUNCTIONS -----
func migrate_ethereal_project(from_path: String, to_path: String) -> Dictionary:
    if not migration_tool:
        return {
            "success": false,
            "error": "Migration tool not found"
        }
    
    # Reset statistics
    ethereal_nodes_migrated = 0
    reality_contexts_migrated = 0
    word_manifestations_migrated = 0
    datapoints_migrated = 0
    records_migrated = 0
    
    # Start migration process
    var result = migration_tool.migrate_project(from_path, to_path)
    
    if not result.success:
        return result
    
    # Enhance the migration with Ethereal Engine specific changes
    _migrate_ethereal_specific_code(from_path, to_path)
    
    # Process JSH record migration if records system exists
    if use_akashic_records and records_system:
        _migrate_record_sets(from_path, to_path)
    
    # Migrate reality contexts
    if track_reality_changes:
        _migrate_reality_contexts(from_path, to_path)
    
    # Migrate word manifestations
    if enable_word_manifestation and word_manager:
        _migrate_word_manifestations(from_path, to_path)
    
    # Save migration records
    _save_migration_records(to_path)
    
    # Compile enhanced results
    var enhanced_result = result.duplicate()
    enhanced_result.ethereal_nodes_migrated = ethereal_nodes_migrated
    enhanced_result.reality_contexts_migrated = reality_contexts_migrated
    enhanced_result.word_manifestations_migrated = word_manifestations_migrated
    enhanced_result.datapoints_migrated = datapoints_migrated
    enhanced_result.records_migrated = records_migrated
    
    emit_signal("ethereal_migration_completed", enhanced_result)
    
    return enhanced_result

func _migrate_ethereal_specific_code(from_path: String, to_path: String) -> void:
    # Find all GDScript files in project
    var script_files = _get_all_script_files(from_path)
    
    # Process each script for JSH specific patterns
    for file_path in script_files:
        var rel_path = file_path.replace(from_path, "")
        var output_path = to_path + rel_path
        
        _process_ethereal_script(file_path, output_path)

func _process_ethereal_script(file_path: String, output_path: String) -> void:
    # Read the original file
    var file = FileAccess.open(file_path, FileAccess.READ)
    if not file:
        print("Failed to open file: " + file_path)
        return
    
    var content = file.get_as_text()
    file.close()
    
    # Apply JSH-specific migrations
    var updated_content = content
    
    # 1. BanksCombiner pattern updates
    updated_content = _update_banks_combiner_patterns(updated_content)
    
    # 2. JSH_records_system pattern updates
    updated_content = _update_records_system_patterns(updated_content)
    
    # 3. Reality context transitions
    updated_content = _update_reality_transitions(updated_content)
    
    # 4. Word manifestation patterns
    updated_content = _update_word_manifestation_patterns(updated_content)
    
    # 5. DataPoint system updates
    updated_content = _update_datapoint_system(updated_content)
    
    # 6. Thread safety pattern updates
    updated_content = _update_thread_safety_patterns(updated_content)
    
    # Write the file if changes were made
    if updated_content != content:
        # Ensure directory exists
        var dir = DirAccess.open(output_path.get_base_dir())
        if not dir:
            var err = DirAccess.make_dir_recursive_absolute(output_path.get_base_dir())
            if err != OK:
                print("Failed to create directory: " + output_path.get_base_dir())
                return
        
        var output_file = FileAccess.open(output_path, FileAccess.WRITE)
        if not output_file:
            print("Failed to open file for writing: " + output_path)
            return
        
        output_file.store_string(updated_content)
        output_file.close()
        
        # Record the migration
        _record_node_migration(file_path, "ethereal_script")
        ethereal_nodes_migrated += 1
        
        print("Updated Ethereal Engine script: " + output_path)

func _update_banks_combiner_patterns(content: String) -> String:
    var updated_content = content
    
    # Pattern 1: BanksCombiner.data_sets_names_0 access
    var regex = RegEx.new()
    regex.compile("BanksCombiner\\.data_sets_names_0\\.has\\(([^)]+)\\)")
    
    var matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var set_name = match_result.get_string(1)
        var new_text = "BanksCombiner.has_data_set(" + set_name + ")"
        updated_content = updated_content.replace(old_text, new_text)
    
    # Pattern 2: BanksCombiner.data_sets_names_0.append
    regex = RegEx.new()
    regex.compile("BanksCombiner\\.data_sets_names_0\\.append\\(([^)]+)\\)")
    
    matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var set_name = match_result.get_string(1)
        var new_text = "BanksCombiner.add_data_set(" + set_name + ")"
        updated_content = updated_content.replace(old_text, new_text)
    
    # Pattern 3: BanksCombiner.container_set_name access
    regex = RegEx.new()
    regex.compile("BanksCombiner\\.container_set_name\\[([^\\]]+)\\]")
    
    matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var container_name = match_result.get_string(1)
        var new_text = "BanksCombiner.get_container_set_names(" + container_name + ")"
        updated_content = updated_content.replace(old_text, new_text)
    
    return updated_content

func _update_records_system_patterns(content: String) -> String:
    var updated_content = content
    
    # Pattern 1: add_basic_set syntax update
    var regex = RegEx.new()
    regex.compile("JSH_records_system\\.add_basic_set\\(([^)]+)\\)")
    
    var matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var set_name = match_result.get_string(1)
        var new_text = "JSH_records_system.create_record_set(" + set_name + ")"
        updated_content = updated_content.replace(old_text, new_text)
        
        # Record migration
        _record_record_set_migration(set_name.strip_edges().replace("\"", "").replace("'", ""))
    
    # Pattern 2: remember function update
    regex = RegEx.new()
    regex.compile("remember\\(([^,]+),\\s*([^)]+)\\)")
    
    matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var concept = match_result.get_string(1)
        var details = match_result.get_string(2)
        var new_text = "create_memory_record(" + concept + ", " + details + ")"
        updated_content = updated_content.replace(old_text, new_text)
    
    # Pattern 3: recall function update
    regex = RegEx.new()
    regex.compile("recall\\(([^)]+)\\)")
    
    matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var concept = match_result.get_string(1)
        var new_text = "get_memory_record(" + concept + ")"
        updated_content = updated_content.replace(old_text, new_text)
    
    # Pattern 4: add_record_to_set updates
    regex = RegEx.new()
    regex.compile("add_record_to_set\\(([^,]+),\\s*([^)]+)\\)")
    
    matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var set_name = match_result.get_string(1)
        var record_data = match_result.get_string(2)
        var new_text = "JSH_records_system.add_record(" + set_name + ", " + record_data + ")"
        updated_content = updated_content.replace(old_text, new_text)
    
    # Pattern 5: get_records_from_set updates
    regex = RegEx.new()
    regex.compile("get_records_from_set\\(([^,)]+)(?:,\\s*([^)]+))?\\)")
    
    matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var set_name = match_result.get_string(1)
        var filter_params = ""
        if match_result.get_string(2):
            filter_params = ", " + match_result.get_string(2)
        var new_text = "JSH_records_system.get_records(" + set_name + filter_params + ")"
        updated_content = updated_content.replace(old_text, new_text)
    
    return updated_content

func _update_reality_transitions(content: String) -> String:
    var updated_content = content
    
    # Pattern 1: Reality transitions
    var regex = RegEx.new()
    regex.compile("remember\\(\\s*[\"']reality_shift[\"']\\s*,\\s*\\{\\s*[\"']new_reality[\"']\\s*:\\s*([^}]+)\\}\\)")
    
    var matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var reality_type = match_result.get_string(1)
        var new_text = "transition_to_reality(" + reality_type + ")"
        updated_content = updated_content.replace(old_text, new_text)
        
        # Record migration
        _record_reality_transition_migration(reality_type.strip_edges().replace("\"", "").replace("'", ""))
    
    # Pattern 2: Reality context in memory
    regex = RegEx.new()
    regex.compile("(player_memory\\[[^\\]]+\\]\\.append\\(\\{[^}]*)[\"']reality[\"']\\s*:\\s*current_reality([^}]*\\})")
    
    matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var prefix = match_result.get_string(1)
        var suffix = match_result.get_string(2)
        var new_text = prefix + "\"reality_context\": get_current_reality()" + suffix
        updated_content = updated_content.replace(old_text, new_text)
    
    return updated_content

func _update_word_manifestation_patterns(content: String) -> String:
    var updated_content = content
    
    # Pattern 1: Word manifestation arrays
    var regex = RegEx.new()
    regex.compile("\\{\\s*[\"']word[\"']\\s*:\\s*[\"']([^\"']+)[\"']\\s*,\\s*[\"']position[\"']\\s*:\\s*([^}]+)\\}")
    
    var matches = regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var word = match_result.get_string(1)
        var position = match_result.get_string(2)
        
        # Record the word manifestation
        _record_word_manifestation_migration(word, position)
    
    return updated_content

func _update_datapoint_system(content: String) -> String:
    var updated_content = content
    
    # Pattern 1: DataPoint state serialization
    var regex = RegEx.new()
    regex.compile("var\\s+datapoint_state\\s*=\\s*\\{[^}]*\\}")
    
    var matches = regex.search_all(updated_content)
    for match_result in matches:
        datapoints_migrated += 1
    
    return updated_content

func _update_thread_safety_patterns(content: String) -> String:
    var updated_content = content
    
    # Pattern 1: Update mutex patterns to new Godot 4 style
    var mutex_patterns = [
        ["memory_mutex", "memory_mutex"],
        ["active_r_s_mut", "active_record_set_mutex"],
        ["cached_r_s_mutex", "cached_record_set_mutex"]
    ]
    
    for pattern in mutex_patterns:
        var old_mutex = pattern[0]
        var new_mutex = pattern[1]
        
        # Lock update
        updated_content = updated_content.replace(old_mutex + ".lock()", new_mutex + ".lock()")
        
        # Unlock update
        updated_content = updated_content.replace(old_mutex + ".unlock()", new_mutex + ".unlock()")
    
    return updated_content

func _migrate_record_sets(from_path: String, to_path: String) -> void:
    # Create directory for records
    var records_dir = to_path.path_join("akashic_records")
    
    if not DirAccess.dir_exists_absolute(records_dir):
        var err = DirAccess.make_dir_recursive_absolute(records_dir)
        if err != OK:
            print("Failed to create records directory: " + records_dir)
            return
    
    # Process each record set
    for set_name in active_record_sets:
        var set_file = records_dir.path_join(set_name + ".json")
        
        # Convert records to JSON
        var set_data = {
            "set_name": set_name,
            "records": migration_records[set_name],
            "metadata": {
                "count": migration_records[set_name].size(),
                "timestamp": migration_timestamp,
                "reality_context": migration_reality
            }
        }
        
        var json_text = JSON.stringify(set_data, "  ")
        
        # Write record set file
        var file = FileAccess.open(set_file, FileAccess.WRITE)
        if file:
            file.store_string(json_text)
            file.close()
            
            print("Saved record set: " + set_file)
            records_migrated += 1
        else:
            print("Failed to save record set: " + set_file)

func _migrate_reality_contexts(from_path: String, to_path: String) -> void:
    # Create directory for reality contexts
    var reality_dir = to_path.path_join("reality_contexts")
    
    if not DirAccess.dir_exists_absolute(reality_dir):
        var err = DirAccess.make_dir_recursive_absolute(reality_dir)
        if err != OK:
            print("Failed to create reality directory: " + reality_dir)
            return
    
    # Define standard reality types based on JSH patterns
    var reality_types = ["physical_reality", "digital_reality", "astral_reality"]
    
    # Create a file for each reality context with migration notes
    for reality_type in reality_types:
        var reality_file = reality_dir.path_join(reality_type + ".json")
        
        # Reality metadata
        var reality_data = {
            "type": reality_type,
            "migration_timestamp": migration_timestamp,
            "migration_reality": migration_reality,
            "preserved_records": 0
        }
        
        # Check for migrated records of this reality
        for record in migration_records["reality_migrations"]:
            if record.reality_type == reality_type:
                reality_data.preserved_records += 1
        
        var json_text = JSON.stringify(reality_data, "  ")
        
        # Write reality file
        var file = FileAccess.open(reality_file, FileAccess.WRITE)
        if file:
            file.store_string(json_text)
            file.close()
            
            print("Saved reality context: " + reality_file)
        else:
            print("Failed to save reality context: " + reality_file)

func _migrate_word_manifestations(from_path: String, to_path: String) -> void:
    # Create directory for word manifestations
    var words_dir = to_path.path_join("word_manifestations")
    
    if not DirAccess.dir_exists_absolute(words_dir):
        var err = DirAccess.make_dir_recursive_absolute(words_dir)
        if err != OK:
            print("Failed to create words directory: " + words_dir)
            return
    
    # Compile all word manifestations into a single file
    var words_file = words_dir.path_join("migrated_words.json")
    
    # Word manifestation data
    var words_data = {
        "words": migration_records["word_migrations"],
        "metadata": {
            "count": migration_records["word_migrations"].size(),
            "timestamp": migration_timestamp,
            "reality_context": migration_reality
        }
    }
    
    var json_text = JSON.stringify(words_data, "  ")
    
    # Write words file
    var file = FileAccess.open(words_file, FileAccess.WRITE)
    if file:
        file.store_string(json_text)
        file.close()
        
        print("Saved word manifestations: " + words_file)
    else:
        print("Failed to save word manifestations: " + words_file)

func _save_migration_records(to_path: String) -> void:
    # Create directory for dimensional records
    var dim_records_dir = to_path.path_join(dimensional_records_path)
    
    if not DirAccess.dir_exists_absolute(dim_records_dir):
        var err = DirAccess.make_dir_recursive_absolute(dim_records_dir)
        if err != OK:
            print("Failed to create dimensional records directory: " + dim_records_dir)
            return
    
    # Create a summary file with all migration statistics
    var summary_file = dim_records_dir.path_join("migration_summary_" + str(migration_timestamp) + ".json")
    
    # Summary data
    var summary_data = {
        "timestamp": migration_timestamp,
        "reality_context": migration_reality,
        "statistics": {
            "ethereal_nodes_migrated": ethereal_nodes_migrated,
            "reality_contexts_migrated": reality_contexts_migrated,
            "word_manifestations_migrated": word_manifestations_migrated,
            "datapoints_migrated": datapoints_migrated,
            "records_migrated": records_migrated
        },
        "metadata": {
            "godot3_version": "3.5",
            "godot4_version": "4.5",
            "engine_type": "JSH Ethereal Engine"
        }
    }
    
    var json_text = JSON.stringify(summary_data, "  ")
    
    # Write summary file
    var file = FileAccess.open(summary_file, FileAccess.WRITE)
    if file:
        file.store_string(json_text)
        file.close()
        
        print("Saved migration summary: " + summary_file)
    else:
        print("Failed to save migration summary: " + summary_file)

# ----- RECORD MANAGEMENT -----
func _record_node_migration(node_path: String, node_type: String) -> void:
    var record = {
        "node_path": node_path,
        "node_type": node_type,
        "timestamp": Time.get_unix_time_from_system(),
        "godot3_type": node_type,
        "godot4_type": node_type
    }
    
    migration_records["node_migrations"].append(record)
    
    # Check for d√©j√† vu
    if migration_memory["node_type"].has(node_type):
        print("D√©j√† vu detected for node type: " + node_type)
    else:
        migration_memory["node_type"].append(node_type)

func _record_reality_transition_migration(reality_type: String) -> void:
    var record = {
        "reality_type": reality_type,
        "timestamp": Time.get_unix_time_from_system(),
        "transition_count": 1
    }
    
    # Update existing record if already tracked
    var found = false
    for existing in migration_records["reality_migrations"]:
        if existing.reality_type == reality_type:
            existing.transition_count += 1
            found = true
            break
    
    if not found:
        migration_records["reality_migrations"].append(record)
        reality_contexts_migrated += 1
        
        # Check for d√©j√† vu
        if migration_memory["reality_transition"].has(reality_type):
            print("D√©j√† vu detected for reality transition: " + reality_type)
        else:
            migration_memory["reality_transition"].append(reality_type)
        
        emit_signal("reality_transition_migrated", reality_type)

func _record_word_manifestation_migration(word: String, position: String) -> void:
    var record = {
        "word": word,
        "position": position,
        "timestamp": Time.get_unix_time_from_system(),
        "reality_context": migration_reality
    }
    
    migration_records["word_migrations"].append(record)
    word_manifestations_migrated += 1
    
    # Check for d√©j√† vu
    if migration_memory["word_manifestation"].has(word):
        print("D√©j√† vu detected for word manifestation: " + word)
    else:
        migration_memory["word_manifestation"].append(word)
    
    emit_signal("word_manifestation_migrated", word, position)

func _record_record_set_migration(set_name: String) -> void:
    var record = {
        "set_name": set_name,
        "timestamp": Time.get_unix_time_from_system(),
        "record_count": 1
    }
    
    # Update existing record if already tracked
    var found = false
    for existing in migration_records["records_migrations"]:
        if existing.set_name == set_name:
            existing.record_count += 1
            found = true
            break
    
    if not found:
        migration_records["records_migrations"].append(record)
        
        emit_signal("record_set_migrated", set_name, 1)

# ----- HELPER FUNCTIONS -----
func _get_all_script_files(path: String) -> Array:
    var files = []
    var dir = DirAccess.open(path)
    
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            var full_path = path.path_join(file_name)
            
            if dir.current_is_dir() and file_name != "." and file_name != "..":
                # Recursively process subdirectories
                files.append_array(_get_all_script_files(full_path))
            elif file_name.ends_with(".gd"):
                files.append(full_path)
            
            file_name = dir.get_next()
    else:
        push_error("Failed to open directory: " + path)
    
    return files

# ----- PUBLIC API -----
func migrate_jsh_ethereal_project(from_path: String, to_path: String) -> Dictionary:
    return migrate_ethereal_project(from_path, to_path)

func check_ethereal_compatibility(file_path: String) -> Dictionary:
    # Check if file exists
    if not FileAccess.file_exists(file_path):
        return {
            "is_ethereal": false,
            "ethereal_patterns": 0,
            "error": "File does not exist"
        }
    
    # Read file content
    var file = FileAccess.open(file_path, FileAccess.READ)
    if not file:
        return {
            "is_ethereal": false,
            "ethereal_patterns": 0,
            "error": "Failed to open file"
        }
    
    var content = file.get_as_text()
    file.close()
    
    # Check for JSH Ethereal Engine patterns
    var ethereal_patterns = 0
    var pattern_matches = {}
    
    # Pattern 1: BanksCombiner
    if content.find("BanksCombiner") != -1:
        ethereal_patterns += 1
        pattern_matches["banks_combiner"] = true
    
    # Pattern 2: JSH_records_system
    if content.find("JSH_records_system") != -1:
        ethereal_patterns += 1
        pattern_matches["records_system"] = true
    
    # Pattern 3: remember/recall functions
    if content.find("remember(") != -1 or content.find("recall(") != -1:
        ethereal_patterns += 1
        pattern_matches["memory_functions"] = true
    
    # Pattern 4: Reality transitions
    if content.find("reality_shift") != -1:
        ethereal_patterns += 1
        pattern_matches["reality_transitions"] = true
    
    # Pattern 5: Word manifestation
    if content.find("\"word\":") != -1 and content.find("\"position\":") != -1:
        ethereal_patterns += 1
        pattern_matches["word_manifestation"] = true
    
    return {
        "is_ethereal": ethereal_patterns > 0,
        "ethereal_patterns": ethereal_patterns,
        "pattern_matches": pattern_matches,
        "file_path": file_path
    }

func generate_ethereal_migration_report(project_path: String) -> Dictionary:
    var report = {
        "timestamp": Time.get_unix_time_from_system(),
        "project_path": project_path,
        "ethereal_files": 0,
        "total_files": 0,
        "ethereal_patterns_detected": 0,
        "pattern_distribution": {
            "banks_combiner": 0,
            "records_system": 0,
            "memory_functions": 0,
            "reality_transitions": 0,
            "word_manifestation": 0
        },
        "files": []
    }
    
    # Find all script files
    var script_files = _get_all_script_files(project_path)
    report.total_files = script_files.size()
    
    # Check each file for ethereal patterns
    for file_path in script_files:
        var file_report = check_ethereal_compatibility(file_path)
        
        if file_report.is_ethereal:
            report.ethereal_files += 1
            report.ethereal_patterns_detected += file_report.ethereal_patterns
            
            # Update pattern distribution
            if file_report.pattern_matches.has("banks_combiner") and file_report.pattern_matches.banks_combiner:
                report.pattern_distribution.banks_combiner += 1
            
            if file_report.pattern_matches.has("records_system") and file_report.pattern_matches.records_system:
                report.pattern_distribution.records_system += 1
            
            if file_report.pattern_matches.has("memory_functions") and file_report.pattern_matches.memory_functions:
                report.pattern_distribution.memory_functions += 1
            
            if file_report.pattern_matches.has("reality_transitions") and file_report.pattern_matches.reality_transitions:
                report.pattern_distribution.reality_transitions += 1
            
            if file_report.pattern_matches.has("word_manifestation") and file_report.pattern_matches.word_manifestation:
                report.pattern_distribution.word_manifestation += 1
        }
        
        # Add file info to report
        var rel_path = file_path.replace(project_path, "")
        
        report.files.append({
            "path": rel_path,
            "is_ethereal": file_report.is_ethereal,
            "patterns_count": file_report.ethereal_patterns,
            "patterns": file_report.pattern_matches if file_report.is_ethereal else {}
        })
    
    return report

func apply_post_migration_enhancements(project_path: String) -> Dictionary:
    # Apply additional enhancements after a standard migration
    var enhancement_stats = {
        "total_enhancements": 0,
        "akashic_integration": 0,
        "reality_enhancements": 0,
        "word_enhancements": 0
    }
    
    # 1. Enhance Akashic integration
    var akashic_result = _enhance_akashic_integration(project_path)
    enhancement_stats.akashic_integration = akashic_result.count
    enhancement_stats.total_enhancements += akashic_result.count
    
    # 2. Enhance reality transitions
    var reality_result = _enhance_reality_transitions(project_path)
    enhancement_stats.reality_enhancements = reality_result.count
    enhancement_stats.total_enhancements += reality_result.count
    
    # 3. Enhance word manifestations
    var word_result = _enhance_word_manifestations(project_path)
    enhancement_stats.word_enhancements = word_result.count
    enhancement_stats.total_enhancements += word_result.count
    
    return enhancement_stats

func _enhance_akashic_integration(project_path: String) -> Dictionary:
    # Integrates with AkashicNumberSystem if available
    var count = 0
    
    if akashic_system:
        # Create integration file
        var integration_file = project_path.path_join("ethereal_akashic_bridge.gd")
        
        var content = """class_name EtherealAkashicBridge
extends Node

# Integration between JSH Ethereal Engine and AkashicNumberSystem

@export var enable_akashic_integration: bool = true
@export var record_migration_numbers: bool = true

var akashic_system = null
var records_system = null

func _ready():
    _find_systems()
    _setup_integration()

func _find_systems():
    # Find AkashicNumberSystem
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        push_warning("AkashicNumberSystem not found")
    
    # Find JSH_records_system
    records_system = get_node_or_null("/root/JSH_records_system")
    if not records_system:
        push_warning("JSH_records_system not found")

func _setup_integration():
    if not enable_akashic_integration or not akashic_system or not records_system:
        return
    
    # Register migration timestamp with AkashicNumberSystem
    if record_migration_numbers:
        akashic_system.register_number(""" + str(migration_timestamp) + """, "migration_timestamp")
    
    # Connect signals
    records_system.connect("record_added", _on_record_added)
    records_system.connect("record_set_created", _on_record_set_created)

func _on_record_added(set_name, record_data):
    if not enable_akashic_integration or not akashic_system:
        return
    
    # Record number pattern in Akashic system
    if record_data is Dictionary and record_data.has("timestamp"):
        akashic_system.register_number(record_data.timestamp, "record_timestamp")

func _on_record_set_created(set_name):
    if not enable_akashic_integration or not akashic_system:
        return
    
    # Record set creation in Akashic system
    var set_hash = set_name.hash()
    akashic_system.register_number(set_hash, "record_set_hash")
"""
        
        var file = FileAccess.open(integration_file, FileAccess.WRITE)
        if file:
            file.store_string(content)
            file.close()
            count += 1
            
            print("Created Ethereal-Akashic integration bridge: " + integration_file)
        else:
            print("Failed to create Ethereal-Akashic integration bridge")
    
    return {
        "count": count
    }

func _enhance_reality_transitions(project_path: String) -> Dictionary:
    # Enhances reality transition system for Godot 4
    var count = 0
    
    # Create enhanced reality transition system
    var reality_file = project_path.path_join("enhanced_reality_system.gd")
    
    var content = """class_name EnhancedRealitySystem
extends Node

signal reality_changed(old_reality, new_reality)
signal reality_transition_started(from_reality, to_reality)
signal reality_transition_completed(new_reality)

@export var default_reality: String = "digital_reality"
@export var transition_duration: float = 1.0
@export var enable_visual_effects: bool = true
@export var enable_akashic_recording: bool = true

var current_reality: String = ""
var transitioning: bool = false
var akashic_system = null
var records_system = null

# Shader for transition effects
var transition_shader: ShaderMaterial = null
var transition_overlay: ColorRect = null

func _ready():
    _find_systems()
    _setup_transition_effects()
    
    # Set initial reality
    current_reality = default_reality
    emit_signal("reality_changed", "", current_reality)

func _find_systems():
    # Find AkashicNumberSystem
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    
    # Find JSH_records_system
    records_system = get_node_or_null("/root/JSH_records_system")

func _setup_transition_effects():
    if not enable_visual_effects:
        return
    
    # Create transition overlay
    transition_overlay = ColorRect.new()
    transition_overlay.set_anchors_preset(Control.PRESET_FULL_RECT)
    transition_overlay.mouse_filter = Control.MOUSE_FILTER_IGNORE
    transition_overlay.visible = false
    
    # Load shader
    var shader_path = "res://shaders/transition_overlay.gdshader"
    if FileAccess.file_exists(shader_path):
        transition_shader = ShaderMaterial.new()
        transition_shader.shader = load(shader_path)
        transition_overlay.material = transition_shader
    
    add_child(transition_overlay)

func transition_to_reality(reality_type: String):
    if transitioning or current_reality == reality_type:
        return
    
    transitioning = true
    var old_reality = current_reality
    
    emit_signal("reality_transition_started", old_reality, reality_type)
    
    # Record transition if records system is available
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("reality_shift", {
            "old_reality": old_reality,
            "new_reality": reality_type,
            "timestamp": Time.get_unix_time_from_system()
        })
    
    # Record in akashic system if available
    if enable_akashic_recording and akashic_system and akashic_system.has_method("register_number"):
        var transition_hash = (old_reality + "_to_" + reality_type).hash()
        akashic_system.register_number(transition_hash, "reality_transition")
    
    # Visual transition effect
    if enable_visual_effects and transition_overlay and transition_shader:
        # Set shader parameters
        transition_shader.set_shader_parameter("from_reality", _get_reality_color(old_reality))
        transition_shader.set_shader_parameter("to_reality", _get_reality_color(reality_type))
        transition_shader.set_shader_parameter("progress", 0.0)
        
        transition_overlay.visible = true
        
        # Animate transition
        var tween = create_tween()
        tween.tween_method(_update_transition_progress, 0.0, 1.0, transition_duration)
        await tween.finished()
        
        transition_overlay.visible = false
    else:
        # Simple delay if no visual effects
        await get_tree().create_timer(transition_duration).timeout
    
    # Complete transition
    current_reality = reality_type
    transitioning = false
    
    emit_signal("reality_changed", old_reality, reality_type)
    emit_signal("reality_transition_completed", reality_type)

func get_current_reality() -> String:
    return current_reality

func _update_transition_progress(progress: float):
    if transition_shader:
        transition_shader.set_shader_parameter("progress", progress)

func _get_reality_color(reality_type: String) -> Color:
    match reality_type:
        "physical_reality":
            return Color(0.2, 0.6, 0.8)
        "digital_reality":
            return Color(0.1, 0.8, 0.3)
        "astral_reality":
            return Color(0.8, 0.3, 0.7)
        _:
            return Color(0.5, 0.5, 0.5)
"""
    
    var file = FileAccess.open(reality_file, FileAccess.WRITE)
    if file:
        file.store_string(content)
        file.close()
        count += 1
        
        print("Created enhanced reality transition system: " + reality_file)
    else:
        print("Failed to create enhanced reality transition system")
    
    # Create transition shader
    var shader_dir = project_path.path_join("shaders")
    
    if not DirAccess.dir_exists_absolute(shader_dir):
        var err = DirAccess.make_dir_recursive_absolute(shader_dir)
        if err != OK:
            print("Failed to create shader directory: " + shader_dir)
        else:
            # Create transition shader
            var shader_file = shader_dir.path_join("transition_overlay.gdshader")
            
            var shader_content = """shader_type canvas_item;

uniform vec4 from_reality : source_color = vec4(0.2, 0.6, 0.8, 1.0);
uniform vec4 to_reality : source_color = vec4(0.1, 0.8, 0.3, 1.0);
uniform float progress : hint_range(0.0, 1.0) = 0.0;

void fragment() {
    // Complex transition effect based on UV coordinates
    vec2 uv = UV;
    float distortion = sin(UV.x * 10.0 + TIME) * 0.02 * (1.0 - progress);
    uv.y += distortion;
    
    // Radial transition pattern
    float dist = distance(uv, vec2(0.5, 0.5));
    float circle_progress = smoothstep(0.0, 0.8, progress);
    float mask = smoothstep(circle_progress, circle_progress + 0.1, dist);
    
    // Edge glow
    float edge = smoothstep(circle_progress - 0.05, circle_progress, dist) - 
                smoothstep(circle_progress, circle_progress + 0.05, dist);
    vec4 edge_color = mix(from_reality, to_reality, progress);
    edge_color.a = edge * 2.0;
    
    // Final color
    vec4 base_color = mix(from_reality, to_reality, 1.0 - mask);
    base_color.a = smoothstep(1.0, 0.0, mask) * 0.7;
    
    // Add some subtle noise
    float noise = fract(sin(dot(uv, vec2(12.9898, 78.233))) * 43758.5453);
    base_color.rgb += noise * 0.05 * (1.0 - progress);
    
    // Combine with edge glow
    vec4 final_color = mix(base_color, edge_color, edge);
    final_color.a = max(base_color.a, edge_color.a);
    
    COLOR = final_color;
}
"""
            
            var shader_f = FileAccess.open(shader_file, FileAccess.WRITE)
            if shader_f:
                shader_f.store_string(shader_content)
                shader_f.close()
                count += 1
                
                print("Created transition shader: " + shader_file)
            else:
                print("Failed to create transition shader")
    
    return {
        "count": count
    }

func _enhance_word_manifestations(project_path: String) -> Dictionary:
    # Enhances word manifestation system for Godot 4
    var count = 0
    
    # Create enhanced word manifestation system
    var word_file = project_path.path_join("enhanced_word_manifestation.gd")
    
    var content = """class_name EnhancedWordManifestation
extends Node

signal word_manifested(word, position, entity)
signal word_transformed(word, new_form)
signal word_dematerialized(word, position)

@export var enable_visual_effects: bool = true
@export var enable_akashic_recording: bool = true
@export var enable_physics_interaction: bool = true
@export var manifestation_cooldown: float = 0.5

var akashic_system = null
var records_system = null
var reality_system = null
var manifested_words = {}
var manifestation_timer = 0.0
var word_scene = preload("res://word_manifestation.tscn") if FileAccess.file_exists("res://word_manifestation.tscn") else null

func _ready():
    _find_systems()

func _process(delta):
    if manifestation_timer > 0:
        manifestation_timer -= delta

func _find_systems():
    # Find AkashicNumberSystem
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    
    # Find JSH_records_system
    records_system = get_node_or_null("/root/JSH_records_system")
    
    # Find EnhancedRealitySystem
    reality_system = get_node_or_null("/root/EnhancedRealitySystem")

func manifest_word(word: String, position: Vector3) -> Node3D:
    if manifestation_timer > 0:
        push_warning("Word manifestation cooldown active")
        return null
    
    if not word_scene:
        push_error("Word manifestation scene not found")
        return null
    
    # Reset cooldown
    manifestation_timer = manifestation_cooldown
    
    # Create the word entity
    var entity = word_scene.instantiate()
    add_child(entity)
    
    # Set properties
    entity.name = "WordEntity_" + word
    entity.position = position
    
    if entity.has_method("set_word"):
        entity.set_word(word)
    
    # Record manifestation
    manifested_words[entity.get_instance_id()] = {
        "word": word,
        "position": position,
        "timestamp": Time.get_unix_time_from_system(),
        "reality": reality_system.get_current_reality() if reality_system else "unknown"
    }
    
    # Record in records system if available
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("word_manifestation", {
            "word": word,
            "position": position,
            "timestamp": Time.get_unix_time_from_system(),
            "reality": reality_system.get_current_reality() if reality_system else "unknown"
        })
    
    # Record in akashic system if available
    if enable_akashic_recording and akashic_system and akashic_system.has_method("register_number"):
        var word_hash = word.hash()
        akashic_system.register_number(word_hash, "word_manifestation")
    
    emit_signal("word_manifested", word, position, entity)
    
    return entity

func transform_word(entity: Node3D, new_form: String) -> bool:
    if not entity or not manifested_words.has(entity.get_instance_id()):
        return false
    
    # Get original word data
    var entity_id = entity.get_instance_id()
    var original_data = manifested_words[entity_id]
    var original_word = original_data.word
    
    # Update manifestation data
    manifested_words[entity_id].word = new_form
    
    # Set new word
    if entity.has_method("set_word"):
        entity.set_word(new_form)
    
    # Record transformation
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("word_transformation", {
            "original_word": original_word,
            "new_word": new_form,
            "position": entity.position,
            "timestamp": Time.get_unix_time_from_system(),
            "reality": reality_system.get_current_reality() if reality_system else "unknown"
        })
    
    emit_signal("word_transformed", original_word, new_form)
    
    return true

func dematerialize_word(entity: Node3D) -> bool:
    if not entity or not manifested_words.has(entity.get_instance_id()):
        return false
    
    # Get word data
    var entity_id = entity.get_instance_id()
    var word_data = manifested_words[entity_id]
    
    # Record dematerialization
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("word_dematerialization", {
            "word": word_data.word,
            "position": entity.position,
            "timestamp": Time.get_unix_time_from_system(),
            "reality": reality_system.get_current_reality() if reality_system else "unknown"
        })
    
    emit_signal("word_dematerialized", word_data.word, entity.position)
    
    # Remove manifestation data
    manifested_words.erase(entity_id)
    
    # Apply visual effect if enabled
    if enable_visual_effects:
        # Create dematerialization effect
        var tween = create_tween()
        tween.tween_property(entity, "scale", Vector3.ZERO, 0.5)
        await tween.finished
    
    # Remove entity
    entity.queue_free()
    
    return true

func get_manifested_words() -> Array:
    var result = []
    
    for entity_id in manifested_words:
        result.append(manifested_words[entity_id])
    
    return result

func get_manifested_entities() -> Array[Node3D]:
    var result: Array[Node3D] = []
    
    for entity_id in manifested_words:
        var entity = instance_from_id(entity_id)
        if entity and entity is Node3D:
            result.append(entity)
    
    return result
"""
    
    var file = FileAccess.open(word_file, FileAccess.WRITE)
    if file:
        file.store_string(content)
        file.close()
        count += 1
        
        print("Created enhanced word manifestation system: " + word_file)
    else:
        print("Failed to create enhanced word manifestation system")
    
    # Create word manifestation scene template
    var template_dir = project_path.path_join("scene_templates")
    
    if not DirAccess.dir_exists_absolute(template_dir):
        var err = DirAccess.make_dir_recursive_absolute(template_dir)
        if err != OK:
            print("Failed to create template directory: " + template_dir)
        else:
            # Create word manifestation template script
            var template_file = template_dir.path_join("word_manifestation.gd")
            
            var template_content = """class_name WordManifestation
extends Node3D

@export var word: String = ""
@export var font_size: float = 1.0
@export var material: Material = null
@export var enable_physics: bool = true
@export var enable_glow: bool = true

var label_3d: Label3D = null
var collision_shape: CollisionShape3D = null
var static_body: StaticBody3D = null
var animation_player: AnimationPlayer = null

func _ready():
    _setup_components()
    _create_animations()
    
    # Initial animation
    if animation_player:
        animation_player.play("materialize")

func _setup_components():
    # Create 3D label
    label_3d = Label3D.new()
    label_3d.text = word
    label_3d.font_size = int(font_size * 64)
    label_3d.text_alignment = HORIZONTAL_ALIGNMENT_CENTER
    label_3d.vertical_alignment = VERTICAL_ALIGNMENT_CENTER
    label_3d.billboard = BaseMaterial3D.BILLBOARD_ENABLED
    label_3d.no_depth_test = true
    add_child(label_3d)
    
    if material:
        label_3d.material_override = material
    
    # Create physics body if enabled
    if enable_physics:
        static_body = StaticBody3D.new()
        add_child(static_body)
        
        collision_shape = CollisionShape3D.new()
        var box_shape = BoxShape3D.new()
        box_shape.size = Vector3(word.length() * 0.5, 1.0, 0.1)
        collision_shape.shape = box_shape
        static_body.add_child(collision_shape)
    
    # Create animation player
    animation_player = AnimationPlayer.new()
    add_child(animation_player)

func _create_animations():
    if not animation_player:
        return
    
    # Materialize animation
    var materialize_anim = Animation.new()
    var track_idx = materialize_anim.add_track(Animation.TYPE_VALUE)
    materialize_anim.track_set_path(track_idx, ".:scale")
    materialize_anim.track_insert_key(track_idx, 0.0, Vector3.ZERO)
    materialize_anim.track_insert_key(track_idx, 0.5, Vector3.ONE)
    materialize_anim.length = 0.5
    animation_player.add_animation("materialize", materialize_anim)
    
    # Hover animation
    var hover_anim = Animation.new()
    track_idx = hover_anim.add_track(Animation.TYPE_VALUE)
    hover_anim.track_set_path(track_idx, ".:position:y")
    hover_anim.track_insert_key(track_idx, 0.0, 0.0)
    hover_anim.track_insert_key(track_idx, 0.5, 0.2)
    hover_anim.track_insert_key(track_idx, 1.0, 0.0)
    hover_anim.length = 1.0
    hover_anim.loop_mode = Animation.LOOP_LINEAR
    animation_player.add_animation("hover", hover_anim)
    
    # Glow pulse animation if enabled
    if enable_glow and label_3d and label_3d.material_override:
        var pulse_anim = Animation.new()
        track_idx = pulse_anim.add_track(Animation.TYPE_VALUE)
        pulse_anim.track_set_path(track_idx, "Label3D:modulate")
        pulse_anim.track_insert_key(track_idx, 0.0, Color(1, 1, 1, 0.8))
        pulse_anim.track_insert_key(track_idx, 0.5, Color(1.2, 1.2, 1.2, 1.0))
        pulse_anim.track_insert_key(track_idx, 1.0, Color(1, 1, 1, 0.8))
        pulse_anim.length = 1.0
        pulse_anim.loop_mode = Animation.LOOP_LINEAR
        animation_player.add_animation("pulse", pulse_anim)

func set_word(new_word: String):
    word = new_word
    
    if label_3d:
        label_3d.text = word
    
    # Update collision shape size
    if enable_physics and collision_shape and collision_shape.shape is BoxShape3D:
        var box_shape = collision_shape.shape as BoxShape3D
        box_shape.size = Vector3(word.length() * 0.5, 1.0, 0.1)

func start_hover_animation():
    if animation_player and animation_player.has_animation("hover"):
        animation_player.play("hover")

func start_pulse_animation():
    if enable_glow and animation_player and animation_player.has_animation("pulse"):
        animation_player.play("pulse")

func stop_animations():
    if animation_player:
        animation_player.stop()

func play_transformation_effect():
    # Flash effect
    var tween = create_tween()
    tween.tween_property(label_3d, "modulate", Color(2, 2, 2, 1), 0.2)
    tween.tween_property(label_3d, "modulate", Color(1, 1, 1, 1), 0.3)
"""
            
            var template_f = FileAccess.open(template_file, FileAccess.WRITE)
            if template_f:
                template_f.store_string(template_content)
                template_f.close()
                count += 1
                
                print("Created word manifestation template: " + template_file)
            else:
                print("Failed to create word manifestation template")
    
    return {
        "count": count
    }
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/ethereal_migration_bridge.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/example_usage.gd
# SIZE: 1337 bytes
extends Node
# Example usage of the Claude file integration system

func _ready():
  print("Starting Claude file integration example...")
  
  # Create the integrator
  var integrator = ClaudeFileIntegrator.new()
  add_child(integrator)
  
  # Wait for initialization to complete
  await get_tree().process_frame
  
  # Get summary of integration
  var summary = integrator.get_integration_summary()
  print("\nIntegration Summary:\n" + summary)
  
  # Get files with hash symbols
  var files_with_hash = integrator.get_files_with_hash_symbols()
  print("\nFiles with hash symbols:")
  for file in files_with_hash:
    print("- " + file)
  
  # Generate hash visual map
  var hash_map = integrator.generate_hash_visual_map()
  print("\nHash Visual Map:\n" + hash_map)
  
  # Example: Initialize files for a specific category
  var category = "main"
  print("\nInitializing files for category '" + category + "':")
  integrator.initialize_category_files(category)
  
  # Example: Get connections for a specific file
  var file_name = "claude_integration_main"
  var connections = integrator.snake_case_translator.get_connections_to(file_name)
  print("\nConnections to '" + file_name + "':")
  for connection in connections:
    print("- " + connection)
  
  print("\nExample completed!")

# Run the example
func run_example():
  _ready()
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/example_usage.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/extended_color_theme_system.gd
# SIZE: 26368 bytes
extends Node

class_name ExtendedColorThemeSystem

# ----- COLOR DEPTH SETTINGS -----
@export_category("Color Depth Settings")
@export var color_depth: int = 24  # 16, 24, or 32 bits
@export var use_hdr_colors: bool = false  # Enable HDR colors (32-bit)
@export var enable_color_correction: bool = true  # Apply sRGB correction
@export var dithering_enabled: bool = false  # Enable dithering for lower bit depths

# ----- THEME CONFIGURATION -----
@export_category("Theme Settings")
@export var current_theme: String = "default"
@export var auto_theme_switching: bool = false
@export var time_based_themes: bool = false
@export var theme_transition_duration: float = 0.5  # seconds
@export var enable_contrast_adjustment: bool = true
@export var contrast_ratio_target: float = 4.5  # WCAG AA standard

# ----- COLOR HARMONICS -----
@export_category("Color Harmonics")
@export var primary_color: Color = Color(0.1, 0.4, 0.9, 1.0)  # Base blue
@export var secondary_color: Color = Color(0.9, 0.3, 0.1, 1.0)  # Accent orange
@export var tertiary_color: Color = Color(0.1, 0.7, 0.3, 1.0)  # Highlight green
@export var neutral_color: Color = Color(0.2, 0.2, 0.25, 1.0)  # Base neutral
@export var background_color: Color = Color(0.05, 0.05, 0.1, 1.0)  # Dark background

# ----- STATE VARIABLES -----
var themes = {}
var current_colors = {}
var transition_timer: Timer
var is_transitioning = false
var transition_progress = 0.0
var transition_start_colors = {}
var transition_target_colors = {}
var color_correction_lut = []
var color_temperature = 6500  # Kelvin
var color_brightness = 1.0  # 0-1 scale

# ----- SIGNALS -----
signal theme_changed(theme_name)
signal color_component_changed(component_name, color)
signal transition_started(from_theme, to_theme)
signal transition_completed(theme_name)
signal color_temperature_changed(temperature)
signal color_format_changed(format)

# ----- INITIALIZATION -----
func _ready():
    # Initialize timers
    _initialize_timers()
    
    # Initialize default themes
    _initialize_default_themes()
    
    # Initialize color correction lookup table
    _initialize_color_correction()
    
    # Apply default theme
    apply_theme(current_theme, false)
    
    print("Extended Color Theme System initialized")
    print("Current theme: " + current_theme)
    print("Color depth: " + str(color_depth) + "-bit")

func _initialize_timers():
    # Create transition timer
    transition_timer = Timer.new()
    transition_timer.wait_time = 0.016  # ~60fps
    transition_timer.one_shot = false
    transition_timer.autostart = false
    transition_timer.connect("timeout", Callable(self, "_on_transition_timer"))
    add_child(transition_timer)

func _initialize_default_themes():
    # Create preset themes
    
    # Default theme (blue-based)
    themes["default"] = {
        "primary": Color(0.1, 0.4, 0.9, 1.0),        # Blue
        "secondary": Color(0.9, 0.3, 0.1, 1.0),      # Orange
        "tertiary": Color(0.1, 0.7, 0.3, 1.0),       # Green
        "neutral": Color(0.2, 0.2, 0.25, 1.0),       # Slate
        "background": Color(0.05, 0.05, 0.1, 1.0),   # Dark blue
        "success": Color(0.2, 0.8, 0.2, 1.0),        # Green
        "warning": Color(0.9, 0.7, 0.1, 1.0),        # Yellow
        "error": Color(0.9, 0.1, 0.1, 1.0),          # Red
        "info": Color(0.1, 0.6, 0.9, 1.0),           # Light blue
        "text_primary": Color(0.9, 0.9, 0.95, 1.0),  # Near white
        "text_secondary": Color(0.7, 0.7, 0.75, 1.0),# Light gray
        "border": Color(0.3, 0.3, 0.4, 1.0),         # Medium gray
        "highlight": Color(0.4, 0.6, 1.0, 1.0)       # Highlight blue
    }
    
    # Dark theme
    themes["dark"] = {
        "primary": Color(0.2, 0.2, 0.25, 1.0),       # Dark slate
        "secondary": Color(0.5, 0.1, 0.7, 1.0),      # Purple
        "tertiary": Color(0.1, 0.5, 0.5, 1.0),       # Teal
        "neutral": Color(0.15, 0.15, 0.18, 1.0),     # Dark gray
        "background": Color(0.05, 0.05, 0.06, 1.0),  # Nearly black
        "success": Color(0.2, 0.6, 0.2, 1.0),        # Muted green
        "warning": Color(0.7, 0.5, 0.1, 1.0),        # Muted yellow
        "error": Color(0.7, 0.1, 0.1, 1.0),          # Muted red
        "info": Color(0.1, 0.4, 0.7, 1.0),           # Muted blue
        "text_primary": Color(0.9, 0.9, 0.9, 1.0),   # White
        "text_secondary": Color(0.6, 0.6, 0.65, 1.0),# Gray
        "border": Color(0.25, 0.25, 0.3, 1.0),       # Dark gray
        "highlight": Color(0.3, 0.3, 0.5, 1.0)       # Muted highlight
    }
    
    # Light theme
    themes["light"] = {
        "primary": Color(0.2, 0.5, 0.9, 1.0),        # Blue
        "secondary": Color(0.9, 0.4, 0.1, 1.0),      # Orange
        "tertiary": Color(0.1, 0.7, 0.4, 1.0),       # Green
        "neutral": Color(0.9, 0.9, 0.93, 1.0),       # Light gray
        "background": Color(0.98, 0.98, 1.0, 1.0),   # Nearly white
        "success": Color(0.2, 0.8, 0.2, 1.0),        # Green
        "warning": Color(0.9, 0.7, 0.1, 1.0),        # Yellow
        "error": Color(0.9, 0.1, 0.1, 1.0),          # Red
        "info": Color(0.1, 0.6, 0.9, 1.0),           # Light blue
        "text_primary": Color(0.1, 0.1, 0.15, 1.0),  # Nearly black
        "text_secondary": Color(0.4, 0.4, 0.5, 1.0), # Gray
        "border": Color(0.8, 0.8, 0.85, 1.0),        # Light gray
        "highlight": Color(0.7, 0.8, 1.0, 1.0)       # Light highlight
    }
    
    # High contrast theme
    themes["high_contrast"] = {
        "primary": Color(1.0, 1.0, 1.0, 1.0),        # White
        "secondary": Color(1.0, 0.8, 0.0, 1.0),      # Yellow
        "tertiary": Color(0.0, 1.0, 1.0, 1.0),       # Cyan
        "neutral": Color(0.8, 0.8, 0.8, 1.0),        # Light gray
        "background": Color(0.0, 0.0, 0.0, 1.0),     # Black
        "success": Color(0.0, 1.0, 0.0, 1.0),        # Bright green
        "warning": Color(1.0, 1.0, 0.0, 1.0),        # Bright yellow
        "error": Color(1.0, 0.0, 0.0, 1.0),          # Bright red
        "info": Color(0.0, 0.8, 1.0, 1.0),           # Bright blue
        "text_primary": Color(1.0, 1.0, 1.0, 1.0),   # White
        "text_secondary": Color(0.9, 0.9, 0.9, 1.0), # Light gray
        "border": Color(1.0, 1.0, 1.0, 1.0),         # White
        "highlight": Color(1.0, 0.8, 0.0, 1.0)       # Yellow
    }
    
    # Ethereal theme (blue/cyan)
    themes["ethereal"] = {
        "primary": Color(0.05, 0.3, 0.7, 1.0),       # Deep blue
        "secondary": Color(0.1, 0.6, 0.8, 1.0),      # Cyan
        "tertiary": Color(0.3, 0.7, 0.9, 1.0),       # Light blue
        "neutral": Color(0.15, 0.2, 0.3, 1.0),       # Blue-gray
        "background": Color(0.03, 0.05, 0.15, 1.0),  # Dark blue
        "success": Color(0.2, 0.9, 0.7, 1.0),        # Teal
        "warning": Color(0.7, 0.5, 0.9, 1.0),        # Purple
        "error": Color(0.9, 0.3, 0.5, 1.0),          # Pink
        "info": Color(0.3, 0.7, 1.0, 1.0),           # Sky blue
        "text_primary": Color(0.8, 0.9, 1.0, 1.0),   # Light blue-white
        "text_secondary": Color(0.5, 0.7, 0.9, 1.0), # Medium blue
        "border": Color(0.2, 0.4, 0.6, 1.0),         # Blue-gray
        "highlight": Color(0.1, 0.8, 1.0, 1.0)       # Bright cyan
    }
    
    # Akashic theme (purple/gold)
    themes["akashic"] = {
        "primary": Color(0.4, 0.1, 0.6, 1.0),        # Purple
        "secondary": Color(0.8, 0.6, 0.1, 1.0),      # Gold
        "tertiary": Color(0.6, 0.2, 0.8, 1.0),       # Violet
        "neutral": Color(0.25, 0.15, 0.3, 1.0),      # Dark purple
        "background": Color(0.1, 0.05, 0.15, 1.0),   # Deep purple
        "success": Color(0.5, 0.8, 0.2, 1.0),        # Green-gold
        "warning": Color(0.9, 0.6, 0.1, 1.0),        # Orange-gold
        "error": Color(0.8, 0.2, 0.3, 1.0),          # Red-purple
        "info": Color(0.3, 0.2, 0.8, 1.0),           # Blue-purple
        "text_primary": Color(0.9, 0.8, 1.0, 1.0),   # Light purple-white
        "text_secondary": Color(0.7, 0.5, 0.8, 1.0), # Medium purple
        "border": Color(0.4, 0.3, 0.5, 1.0),         # Purple-gray
        "highlight": Color(1.0, 0.8, 0.2, 1.0)       # Bright gold
    }
    
    # Current colors start with default theme
    current_colors = themes["default"].duplicate()

func _initialize_color_correction():
    # Initialize color correction lookup table
    # This would be used for sRGB correction and color temperature adjustment
    
    color_correction_lut.clear()
    
    # Create lookup tables for sRGB correction
    if enable_color_correction:
        # In a real implementation, would create a proper sRGB conversion table
        # For this mock-up, we'll just initialize with identity values
        for i in range(256):
            var normalized = i / 255.0
            
            # Simple gamma correction (gamma = 2.2)
            var corrected = pow(normalized, 1.0 / 2.2)
            
            color_correction_lut.append(corrected)
    else:
        # No correction - identity mapping
        for i in range(256):
            color_correction_lut.append(i / 255.0)

# ----- PROCESS -----
func _process(delta):
    # Process theme transitions
    if is_transitioning:
        # Update transition in _on_transition_timer
        pass
    
    # Process time-based theme switching if enabled
    if time_based_themes and not is_transitioning:
        _update_time_based_theme()

func _on_transition_timer():
    # Update theme transition
    if not is_transitioning:
        transition_timer.stop()
        return
    
    # Update progress
    transition_progress += transition_timer.wait_time / theme_transition_duration
    transition_progress = min(transition_progress, 1.0)
    
    # Interpolate colors
    for key in transition_start_colors.keys():
        var start_color = transition_start_colors[key]
        var target_color = transition_target_colors[key]
        
        # Use smoothstep for nicer easing
        var t = smoothstep(0.0, 1.0, transition_progress)
        var new_color = start_color.lerp(target_color, t)
        
        # Apply the interpolated color
        current_colors[key] = new_color
        
        # Emit signal for each changed color
        emit_signal("color_component_changed", key, new_color)
    
    # Check if transition is complete
    if transition_progress >= 1.0:
        is_transitioning = false
        transition_timer.stop()
        
        emit_signal("transition_completed", current_theme)
        
        print("Theme transition complete: " + current_theme)

func _update_time_based_theme():
    # Switch theme based on time of day
    var time = OS.get_time()
    var hour = time.hour
    
    # Early morning (5-8): Light theme
    if hour >= 5 and hour < 8:
        if current_theme != "light":
            apply_theme("light")
    
    # Day (8-18): Default theme
    elif hour >= 8 and hour < 18:
        if current_theme != "default":
            apply_theme("default")
    
    # Evening (18-22): Ethereal theme
    elif hour >= 18 and hour < 22:
        if current_theme != "ethereal":
            apply_theme("ethereal")
    
    # Night (22-5): Dark theme
    else:
        if current_theme != "dark":
            apply_theme("dark")

# ----- THEME MANAGEMENT -----
func apply_theme(theme_name: String, with_transition: bool = true) -> bool:
    # Apply a theme by name
    if not themes.has(theme_name):
        print("Theme not found: " + theme_name)
        return false
    
    # If already using this theme, do nothing
    if current_theme == theme_name and not is_transitioning:
        return true
    
    print("Applying theme: " + theme_name + (", with transition" if with_transition else ", without transition"))
    
    if with_transition:
        # Start transition to new theme
        _start_theme_transition(current_theme, theme_name)
    else:
        # Apply immediately
        current_colors = themes[theme_name].duplicate()
        current_theme = theme_name
        
        emit_signal("theme_changed", theme_name)
        
        # Emit signals for each color component
        for key in current_colors:
            emit_signal("color_component_changed", key, current_colors[key])
    
    return true

func _start_theme_transition(from_theme: String, to_theme: String):
    # Start a smooth transition between themes
    if not themes.has(from_theme) or not themes.has(to_theme):
        print("Invalid theme for transition")
        return
    
    # Stop any existing transition
    if is_transitioning:
        transition_timer.stop()
    
    # Set up transition
    transition_start_colors = current_colors.duplicate()
    transition_target_colors = themes[to_theme].duplicate()
    transition_progress = 0.0
    is_transitioning = true
    current_theme = to_theme
    
    # Start transition timer
    transition_timer.start()
    
    emit_signal("transition_started", from_theme, to_theme)
    
    print("Starting theme transition from " + from_theme + " to " + to_theme)

func create_theme(theme_name: String, base_color: Color) -> bool:
    # Create a new theme based on a color
    if themes.has(theme_name):
        print("Theme already exists: " + theme_name)
        return false
    
    print("Creating new theme: " + theme_name)
    
    # Generate colors based on the base color
    var h = base_color.h
    var s = base_color.s
    var v = base_color.v
    
    var new_theme = {
        "primary": base_color,
        "secondary": Color.from_hsv(fmod(h + 0.5, 1.0), s, v),  # Complementary
        "tertiary": Color.from_hsv(fmod(h + 0.33, 1.0), s, v),  # Triadic
        "neutral": Color.from_hsv(h, 0.15, 0.8),                # Desaturated
        "background": Color.from_hsv(h, 0.7, 0.1),              # Dark
        "success": Color(0.2, 0.8, 0.2, 1.0),                   # Green
        "warning": Color(0.9, 0.7, 0.1, 1.0),                   # Yellow
        "error": Color(0.9, 0.1, 0.1, 1.0),                     # Red
        "info": Color(0.1, 0.6, 0.9, 1.0),                      # Blue
        "text_primary": Color(0.9, 0.9, 0.95, 1.0),             # Near white
        "text_secondary": Color(0.7, 0.7, 0.75, 1.0),           # Light gray
        "border": Color(0.3, 0.3, 0.4, 1.0),                    # Medium gray
        "highlight": Color.from_hsv(h, 0.7, 1.0)                # Bright variant
    }
    
    # Fix text colors for light themes
    if v > 0.7:
        new_theme.text_primary = Color(0.1, 0.1, 0.15, 1.0)
        new_theme.text_secondary = Color(0.4, 0.4, 0.45, 1.0)
    
    # Apply contrast correction if enabled
    if enable_contrast_adjustment:
        _adjust_theme_contrast(new_theme)
    
    # Store the new theme
    themes[theme_name] = new_theme
    
    return true

func _adjust_theme_contrast(theme_dict: Dictionary):
    # Adjust contrast to meet accessibility standards
    
    # Check and fix text contrast against background
    var bg = theme_dict.background
    var text_primary = theme_dict.text_primary
    var text_secondary = theme_dict.text_secondary
    
    # Calculate contrast ratios
    var primary_contrast = _calculate_contrast_ratio(bg, text_primary)
    var secondary_contrast = _calculate_contrast_ratio(bg, text_secondary)
    
    # Adjust if needed
    if primary_contrast < contrast_ratio_target:
        theme_dict.text_primary = _increase_contrast(bg, text_primary, contrast_ratio_target)
    
    if secondary_contrast < contrast_ratio_target * 0.8:  # Lower target for secondary text
        theme_dict.text_secondary = _increase_contrast(bg, text_secondary, contrast_ratio_target * 0.8)

func _calculate_contrast_ratio(color1: Color, color2: Color) -> float:
    # Calculate WCAG contrast ratio between two colors
    var l1 = _get_relative_luminance(color1)
    var l2 = _get_relative_luminance(color2)
    
    # Ensure lighter color is l1
    if l1 < l2:
        var temp = l1
        l1 = l2
        l2 = temp
    
    return (l1 + 0.05) / (l2 + 0.05)

func _get_relative_luminance(color: Color) -> float:
    # Calculate relative luminance for WCAG contrast
    
    # Convert sRGB to linear RGB
    var r = color.r
    var g = color.g
    var b = color.b
    
    if r <= 0.03928:
        r = r / 12.92
    else:
        r = pow((r + 0.055) / 1.055, 2.4)
    
    if g <= 0.03928:
        g = g / 12.92
    else:
        g = pow((g + 0.055) / 1.055, 2.4)
    
    if b <= 0.03928:
        b = b / 12.92
    else:
        b = pow((b + 0.055) / 1.055, 2.4)
    
    # Calculate luminance
    return 0.2126 * r + 0.7152 * g + 0.0722 * b

func _increase_contrast(background: Color, foreground: Color, target_ratio: float) -> Color:
    # Increase contrast between background and foreground to meet target ratio
    
    # Determine if we need to lighten or darken the foreground
    var bg_lum = _get_relative_luminance(background)
    var fg_lum = _get_relative_luminance(foreground)
    
    var new_color = foreground
    var step = 0.05
    var max_iterations = 10
    
    # If background is dark, lighten the foreground
    if bg_lum < 0.5:
        for i in range(max_iterations):
            new_color = new_color.lightened(step)
            if _calculate_contrast_ratio(background, new_color) >= target_ratio:
                break
    # If background is light, darken the foreground
    else:
        for i in range(max_iterations):
            new_color = new_color.darkened(step)
            if _calculate_contrast_ratio(background, new_color) >= target_ratio:
                break
    
    return new_color

# ----- COLOR MANAGEMENT -----
func get_color(component: String) -> Color:
    # Get a specific color from the current theme
    if current_colors.has(component):
        var color = current_colors[component]
        
        # Apply bit depth limitation if needed
        if color_depth < 24:
            color = _apply_bit_depth(color)
        
        return color
    
    # Return default if not found
    print("Color component not found: " + component)
    return Color(1, 1, 1, 1)

func set_color(component: String, color: Color) -> bool:
    # Set a specific color in the current theme
    if not current_colors.has(component):
        print("Color component not found: " + component)
        return false
    
    current_colors[component] = color
    
    emit_signal("color_component_changed", component, color)
    
    return true

func _apply_bit_depth(color: Color) -> Color:
    # Apply bit depth limitation to a color
    var result = color
    
    match color_depth:
        16:
            # 16-bit color (5:6:5)
            var r = floor(color.r * 31) / 31
            var g = floor(color.g * 63) / 63
            var b = floor(color.b * 31) / 31
            result = Color(r, g, b, 1.0)
            
            # Apply dithering if enabled
            if dithering_enabled:
                # Simple ordered dithering
                var dither_amount = 0.5 / 32.0
                var px = int(OS.get_ticks_msec()) % 4
                var py = int(OS.get_ticks_msec() / 4) % 4
                var dither_matrix = [
                    [0, 8, 2, 10],
                    [12, 4, 14, 6],
                    [3, 11, 1, 9],
                    [15, 7, 13, 5]
                ]
                var dither_value = dither_matrix[py][px] / 16.0 * dither_amount
                
                result.r = clamp(result.r + dither_value, 0, 1)
                result.g = clamp(result.g + dither_value, 0, 1)
                result.b = clamp(result.b + dither_value, 0, 1)
        
        32:
            # 32-bit color with HDR support
            if use_hdr_colors:
                # Allow values > 1.0 for HDR
                result = color
            else:
                # Standard 32-bit color (8:8:8:8)
                result = color
        
        _:  # 24-bit (default)
            # 24-bit color (8:8:8)
            var r = floor(color.r * 255) / 255
            var g = floor(color.g * 255) / 255
            var b = floor(color.b * 255) / 255
            result = Color(r, g, b, color.a)
    
    return result

func set_color_depth(bits: int) -> void:
    # Set the color depth
    if bits in [16, 24, 32]:
        color_depth = bits
        
        print("Color depth set to " + str(color_depth) + "-bit")
        
        # When depth changes, colors may change
        emit_signal("color_format_changed", color_depth)
    else:
        print("Unsupported color depth: " + str(bits))

func set_color_temperature(temperature: int) -> void:
    # Set the color temperature (in Kelvin)
    color_temperature = clamp(temperature, 1000, 12000)
    
    print("Color temperature set to " + str(color_temperature) + "K")
    
    # Update color correction
    _update_color_temperature()
    
    emit_signal("color_temperature_changed", color_temperature)

func _update_color_temperature():
    # Apply color temperature adjustment to all colors
    var strength = 0.3  # Adjustment strength (0-1)
    
    # Calculate temperature factor (0 = cold/blue, 1 = warm/red)
    var temp_factor = clamp((color_temperature - 1000) / 11000.0, 0, 1)
    var inverse_factor = 1.0 - temp_factor
    
    # Adjust current colors
    for key in current_colors.keys():
        var color = current_colors[key]
        
        # Adjust red and blue channels based on temperature
        var r = color.r + (temp_factor * strength)
        var b = color.b + (inverse_factor * strength)
        
        # Clamp values
        r = clamp(r, 0, 1)
        b = clamp(b, 0, 1)
        
        # Create adjusted color
        var adjusted_color = Color(r, color.g, b, color.a)
        
        # Apply to current colors
        current_colors[key] = adjusted_color
        
        # Emit signal for changed color
        emit_signal("color_component_changed", key, adjusted_color)

# ----- COLOR UTILITIES -----
func create_gradient(start_color: Color, end_color: Color, steps: int) -> Array:
    # Create a gradient between two colors
    var colors = []
    
    for i in range(steps):
        var t = float(i) / (steps - 1)
        var color = start_color.lerp(end_color, t)
        
        # Apply bit depth limitation if needed
        if color_depth < 24:
            color = _apply_bit_depth(color)
            
        colors.append(color)
    
    return colors

func create_color_scheme(base_color: Color, scheme_type: String = "complementary") -> Dictionary:
    # Create a color scheme based on a base color
    var h = base_color.h
    var s = base_color.s
    var v = base_color.v
    
    var colors = {}
    
    match scheme_type:
        "complementary":
            colors = {
                "base": base_color,
                "complement": Color.from_hsv(fmod(h + 0.5, 1.0), s, v)
            }
        
        "analogous":
            colors = {
                "base": base_color,
                "analogous1": Color.from_hsv(fmod(h - 0.08, 1.0), s, v),
                "analogous2": Color.from_hsv(fmod(h + 0.08, 1.0), s, v)
            }
        
        "triadic":
            colors = {
                "base": base_color,
                "triadic1": Color.from_hsv(fmod(h + 0.33, 1.0), s, v),
                "triadic2": Color.from_hsv(fmod(h + 0.66, 1.0), s, v)
            }
        
        "tetradic":
            colors = {
                "base": base_color,
                "tetradic1": Color.from_hsv(fmod(h + 0.25, 1.0), s, v),
                "tetradic2": Color.from_hsv(fmod(h + 0.5, 1.0), s, v),
                "tetradic3": Color.from_hsv(fmod(h + 0.75, 1.0), s, v)
            }
        
        "monochromatic":
            colors = {
                "base": base_color,
                "lighter1": Color.from_hsv(h, s * 0.7, min(v * 1.3, 1.0)),
                "lighter2": Color.from_hsv(h, s * 0.5, min(v * 1.6, 1.0)),
                "darker1": Color.from_hsv(h, min(s * 1.2, 1.0), v * 0.7),
                "darker2": Color.from_hsv(h, min(s * 1.4, 1.0), v * 0.4)
            }
            
        _:
            print("Unknown color scheme type: " + scheme_type)
            return {"base": base_color}
    
    # Apply bit depth limitation if needed
    if color_depth < 24:
        for key in colors.keys():
            colors[key] = _apply_bit_depth(colors[key])
    
    return colors

func smoothstep(edge0: float, edge1: float, x: float) -> float:
    # Smoothstep function for smooth transitions
    var t = clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0)
    return t * t * (3.0 - 2.0 * t)

# ----- THEME UTILITIES -----
func get_available_themes() -> Array:
    # Get a list of available themes
    return themes.keys()

func get_current_theme() -> String:
    return current_theme

func toggle_theme(theme1: String, theme2: String) -> void:
    # Toggle between two themes
    if current_theme == theme1:
        apply_theme(theme2)
    else:
        apply_theme(theme1)

func set_auto_theme_switching(enabled: bool) -> void:
    # Enable or disable automatic theme switching
    auto_theme_switching = enabled
    
    print("Auto theme switching " + ("enabled" if enabled else "disabled"))
    
    # If enabling time-based themes, update immediately
    if enabled and time_based_themes:
        _update_time_based_theme()

func export_theme(theme_name: String) -> Dictionary:
    # Export a theme as a JSON-compatible dictionary
    if not themes.has(theme_name):
        print("Theme not found: " + theme_name)
        return {}
    
    var export_data = {
        "name": theme_name,
        "colors": {}
    }
    
    # Convert colors to hex strings for easy serialization
    for key in themes[theme_name]:
        var color = themes[theme_name][key]
        export_data.colors[key] = color.to_html(true)
    
    return export_data

func import_theme(theme_data: Dictionary) -> bool:
    # Import a theme from a JSON-compatible dictionary
    if not theme_data.has("name") or not theme_data.has("colors"):
        print("Invalid theme data format")
        return false
    
    var theme_name = theme_data.name
    var theme_colors = {}
    
    # Convert hex strings back to colors
    for key in theme_data.colors:
        var hex_color = theme_data.colors[key]
        theme_colors[key] = Color(hex_color)
    
    # Store the theme
    themes[theme_name] = theme_colors
    
    print("Imported theme: " + theme_name)
    
    return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/extended_color_theme_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/file_connection_system.gd
# SIZE: 8383 bytes
extends Node
class_name FileConnectionSystem

# File connection system for Claude integration
# Connects all claude-related files with snake_case naming

# Main file connections
var file_connections = {
  # Main system files
  "main_controller": "/mnt/c/Users/Percision 15/12_turns_system/main.gd",
  "desktop_main": "/mnt/c/Users/Percision 15/Desktop/main.gd",
  
  # Claude core files
  "claude_config": "/mnt/c/Users/Percision 15/CLAUDE.md",
  "claude_akashic_bridge": "/mnt/c/Users/Percision 15/12_turns_system/claude_akashic_bridge.gd",
  "claude_akashic_demo": "/mnt/c/Users/Percision 15/12_turns_system/claude_akashic_demo.gd",
  "claude_terminal_interface": "/mnt/c/Users/Percision 15/12_turns_system/claude_terminal_interface.sh",
  "claude_ethereal_bridge": "/mnt/c/Users/Percision 15/12_turns_system/claude_ethereal_bridge.gd",
  "claude_integration_bridge": "/mnt/c/Users/Percision 15/12_turns_system/claude_integration_bridge.gd",
  "claude_wsl_config": "/mnt/c/Users/Percision 15/Desktop/wsl claude.txt",
  
  # Memory system files
  "word_memory_system": "/mnt/c/Users/Percision 15/word_memory_system.gd",
  "divine_memory_system": "/mnt/c/Users/Percision 15/12_turns_system/divine_memory_system.sh",
  "memory_investment_system": "/mnt/c/Users/Percision 15/12_turns_system/memory_investment_system.gd",
  "dimensional_memory_integration": "/mnt/c/Users/Percision 15/dimensional_memory_integration.gd",
  "dimensional_memory_splitter": "/mnt/c/Users/Percision 15/dimensional_memory_splitter.gd",
  "terminal_memory_system": "/mnt/c/Users/Percision 15/12_turns_system/terminal_memory_system.gd",
  "project_memory_system": "/mnt/c/Users/Percision 15/12_turns_system/project_memory_system.gd",
  "memory_manager": "/mnt/c/Users/Percision 15/Desktop/memory_manager.gd",
  "memory_drive_connector": "/mnt/c/Users/Percision 15/Desktop/memory_drive_connector.gd",
  
  # 3D Notepad files
  "notepad_3d_html": "/mnt/c/Users/Percision 15/12_turns_system/3d_notepad.html",
  "notepad_3d_readme": "/mnt/c/Users/Percision 15/12_turns_system/NOTEPAD3D_README.md",
  "notepad_3d_visualizer": "/mnt/c/Users/Percision 15/12_turns_system/notepad3d_visualizer.gd",
  "notepad_3d_manifesto": "/mnt/c/Users/Percision 15/12_turns_system/notepad3d_manifesto.md",
  
  # Datapoint files
  "datapoint_js": "/mnt/c/Users/Percision 15/Downloads/datapoint-js.txt",
  "terminal_datapoint_handlers": "/mnt/c/Users/Percision 15/Downloads/terminal-datapoint-handlers.txt",
  
  # Container files (custom containers for the system)
  "data_container_system": "/mnt/c/Users/Percision 15/12_turns_system/data_container_system.gd",
  
  # Archive files
  "memory_archive_system": "/mnt/c/Users/Percision 15/12_turns_system/memory_archive_system.gd",
  "past_memory_archive": "/mnt/c/Users/Percision 15/12_turns_system/past_memory_archive.gd"
}

# Logical groupings of files
var file_groups = {
  "claude_core": [
    "claude_config",
    "claude_akashic_bridge",
    "claude_akashic_demo",
    "claude_terminal_interface",
    "claude_ethereal_bridge",
    "claude_integration_bridge"
  ],
  
  "memory_systems": [
    "word_memory_system",
    "divine_memory_system",
    "memory_investment_system", 
    "dimensional_memory_integration",
    "dimensional_memory_splitter",
    "terminal_memory_system",
    "project_memory_system",
    "memory_manager",
    "memory_drive_connector",
    "memory_archive_system",
    "past_memory_archive"
  ],
  
  "notepad_3d": [
    "notepad_3d_html",
    "notepad_3d_readme",
    "notepad_3d_visualizer",
    "notepad_3d_manifesto"
  ],
  
  "datapoint_systems": [
    "datapoint_js",
    "terminal_datapoint_handlers",
    "data_container_system"
  ],
  
  "main_controllers": [
    "main_controller",
    "desktop_main"
  ]
}

# Connection links between files - directional links showing which files reference others
var file_connections_map = {
  "claude_integration_bridge": ["claude_akashic_bridge", "claude_ethereal_bridge", "claude_terminal_interface"],
  "claude_akashic_bridge": ["word_memory_system", "memory_investment_system"],
  "claude_ethereal_bridge": ["dimensional_memory_integration", "project_memory_system"],
  "memory_manager": ["memory_drive_connector", "word_memory_system", "dimensional_memory_splitter"],
  "notepad_3d_visualizer": ["memory_manager", "datapoint_js"],
  "main_controller": ["claude_integration_bridge", "memory_manager", "notepad_3d_visualizer"]
}

# Initialize the system
func _ready():
  print("File Connection System initialized")
  print("Found " + str(file_connections.size()) + " files in the system")
  
  # Check which files actually exist
  _verify_file_existence()

# Verify that the files exist
func _verify_file_existence():
  var existing_files = 0
  var missing_files = []
  
  for key in file_connections:
    var file_path = file_connections[key]
    var file = FileAccess.open(file_path, FileAccess.READ)
    
    if file != null:
      existing_files += 1
      file.close()
    else:
      missing_files.append(key)
  
  print("Found " + str(existing_files) + " existing files")
  if missing_files.size() > 0:
    print("Missing " + str(missing_files.size()) + " files: " + str(missing_files))

# Get a file path by its snake_case key
func get_file_path(key: String) -> String:
  if key in file_connections:
    return file_connections[key]
  return ""

# Get all files in a group
func get_group_files(group: String) -> Array:
  if group in file_groups:
    var result = []
    for key in file_groups[group]:
      result.append(file_connections[key])
    return result
  return []

# Get files that connect to a specific file
func get_connections_to(key: String) -> Array:
  var result = []
  for source in file_connections_map:
    if key in file_connections_map[source]:
      result.append(source)
  return result

# Check if a file is connected to another
func is_connected_to(source: String, target: String) -> bool:
  if source in file_connections_map:
    return target in file_connections_map[source]
  return false

# Load content from a file
func load_file_content(key: String) -> String:
  var file_path = get_file_path(key)
  if file_path.is_empty():
    return ""
    
  var file = FileAccess.open(file_path, FileAccess.READ)
  if file == null:
    return ""
    
  var content = file.get_as_text()
  file.close()
  return content

# Create a visual representation of the file connections
func create_connection_visualization() -> String:
  var result = "digraph FileConnections {\n"
  
  # Add nodes by group
  for group in file_groups:
    result += "  subgraph cluster_" + group + " {\n"
    result += "    label=\"" + group + "\";\n"
    
    for key in file_groups[group]:
      result += "    \"" + key + "\";\n"
    
    result += "  }\n\n"
  
  # Add connections
  for source in file_connections_map:
    for target in file_connections_map[source]:
      result += "  \"" + source + "\" -> \"" + target + "\";\n"
  
  result += "}\n"
  return result

# Generate a markdown report of the file system
func generate_markdown_report() -> String:
  var report = "# Claude File Connection System\n\n"
  
  # Overview
  report += "## Overview\n\n"
  report += "Total files: " + str(file_connections.size()) + "\n"
  report += "File groups: " + str(file_groups.size()) + "\n\n"
  
  # Groups
  report += "## File Groups\n\n"
  for group in file_groups:
    report += "### " + group + "\n\n"
    for key in file_groups[group]:
      var file_path = file_connections[key]
      report += "- **" + key + "**: `" + file_path + "`\n"
    report += "\n"
  
  # Connections
  report += "## File Connections\n\n"
  for source in file_connections_map:
    report += "### " + source + " connects to:\n\n"
    for target in file_connections_map[source]:
      report += "- " + target + "\n"
    report += "\n"
  
  return report

# Save the markdown report
func save_markdown_report(path: String) -> bool:
  var report = generate_markdown_report()
  var file = FileAccess.open(path, FileAccess.WRITE)
  
  if file == null:
    return false
    
  file.store_string(report)
  file.close()
  return true

# Save the visualization dot file
func save_visualization(path: String) -> bool:
  var visualization = create_connection_visualization()
  var file = FileAccess.open(path, FileAccess.WRITE)
  
  if file == null:
    return false
    
  file.store_string(visualization)
  file.close()
  return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/file_connection_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/fluid_2d_renderer.gd
# SIZE: 25896 bytes
extends Node2D

class_name Fluid2DRenderer

# Reference to fluid simulation
var simulation: FluidSimulationCore = null

# Rendering properties
@export_category("Rendering Properties")
@export var particle_size: float = 20.0
@export var smoothing: bool = true
@export var use_metaballs: bool = true
@export var metaball_threshold: float = 0.5
@export var metaball_falloff: float = 0.8
@export var use_shader: bool = true
@export_color var gradient_top_color: Color = Color(0.0, 0.6, 1.0, 0.8)
@export_color var gradient_bottom_color: Color = Color(0.0, 0.4, 0.8, 0.9)

# Custom rendering options
@export_category("Visual Effects")
@export var add_ripples: bool = true
@export var ripple_frequency: float = 3.0
@export var ripple_amplitude: float = 0.2
@export var add_caustics: bool = true
@export var add_foam: bool = true
@export var foam_threshold: float = 0.7
@export_color var foam_color: Color = Color(1.0, 1.0, 1.0, 0.7)
@export_color var outline_color: Color = Color(0.0, 0.3, 0.6, 0.4)
@export var outline_width: float = 2.0

# Optimization
@export_category("Optimization")
@export var render_quality: float = 1.0 # 0.0-1.0 multiplier
@export var max_particles_to_render: int = 2000
@export var cull_offscreen_particles: bool = true
@export var use_instancing: bool = true

# Internal variables
var particle_shader: Shader = null
var metaball_shader: Shader = null
var render_texture: RenderTexture2D = null
var _time: float = 0.0
var _fluid_surface_mesh: Array = [] # Vertices for fluid surface
var _particle_draw_list: Array = [] # Optimized list for drawing
var _metaball_resolution: Vector2 = Vector2(512, 512)

# Caching
var _cached_viewport_size: Vector2 = Vector2.ZERO
var _cached_particles: Array = []
var _needs_surface_rebuild: bool = true

func _ready():
    # Initialize shaders
    if use_shader:
        _init_shaders()
    
    # Initialize render texture
    if use_metaballs:
        _init_render_texture()
    
    # Set initial viewport size cache
    _cached_viewport_size = get_viewport_rect().size

func _init_shaders():
    # Load fluid particle shader
    particle_shader = load("res://shaders/fluid_particle.gdshader")
    if particle_shader == null:
        # Create default shader if not found
        particle_shader = Shader.new()
        particle_shader.code = _get_default_particle_shader_code()
    
    # Load metaball shader
    metaball_shader = load("res://shaders/fluid_metaball.gdshader")
    if metaball_shader == null:
        # Create default shader if not found
        metaball_shader = Shader.new()
        metaball_shader.code = _get_default_metaball_shader_code()

func _init_render_texture():
    # Create render texture for metaballs
    var size_x = int(get_viewport_rect().size.x * render_quality)
    var size_y = int(get_viewport_rect().size.y * render_quality)
    _metaball_resolution = Vector2(size_x, size_y)
    
    render_texture = RenderTexture2D.new()
    render_texture.size = _metaball_resolution
    render_texture.format = RenderTextureFormat.RGBA8

func _process(delta):
    _time += delta
    
    # Check if viewport size changed
    var new_viewport_size = get_viewport_rect().size
    if new_viewport_size != _cached_viewport_size:
        _cached_viewport_size = new_viewport_size
        
        # Resize render texture if needed
        if use_metaballs and render_texture:
            var size_x = int(new_viewport_size.x * render_quality)
            var size_y = int(new_viewport_size.y * render_quality)
            _metaball_resolution = Vector2(size_x, size_y)
            render_texture.size = _metaball_resolution
    
    # Mark for surface rebuild every frame
    _needs_surface_rebuild = true
    
    # Update cached particles from simulation
    if simulation != null:
        _cached_particles = simulation.get_particles_for_rendering()
        
        # Sort particles by depth (for correct alpha blending)
        if smoothing:
            _cached_particles.sort_custom(_sort_particles_by_depth)
        
        # Prepare optimized draw list if using instances
        if use_instancing:
            _prepare_particle_draw_list()
    
    # Request redraw
    queue_redraw()

func _draw():
    if simulation == null or _cached_particles.size() == 0:
        return
    
    # Determine rendering method
    if use_metaballs:
        _draw_fluid_metaballs()
    elif smoothing:
        _draw_smooth_particles()
    else:
        _draw_simple_particles()

func _draw_simple_particles():
    # Draw simple circles for each particle
    var particles_to_render = _get_renderable_particles()
    
    for p in particles_to_render:
        var pos = Vector2(p.position.x, p.position.y)
        
        if cull_offscreen_particles and not _is_on_screen(pos, particle_size):
            continue
        
        var color = _get_particle_color(p)
        
        # Draw circle
        draw_circle(pos, particle_size * 0.5, color)
        
        # Draw outline if needed
        if outline_width > 0:
            draw_arc(pos, particle_size * 0.5, 0, TAU, 32, outline_color, outline_width)

func _draw_smooth_particles():
    # Draw particles with antialiasing and smooth gradients
    var particles_to_render = _get_renderable_particles()
    
    for p in particles_to_render:
        var pos = Vector2(p.position.x, p.position.y)
        
        if cull_offscreen_particles and not _is_on_screen(pos, particle_size):
            continue
        
        var color = _get_particle_color(p)
        
        # Draw circle with gradient
        var rect = Rect2(pos - Vector2(particle_size, particle_size) * 0.5, 
                        Vector2(particle_size, particle_size))
        
        # Draw main colored circle with gradient
        var center_color = color
        var edge_color = Color(color.r, color.g, color.b, 0.0)
        
        _draw_radial_gradient_circle(pos, particle_size * 0.5, center_color, edge_color)
        
        # Add foam on surface particles if enabled
        if add_foam and p.is_surface and randf() < foam_threshold:
            var foam_size = particle_size * 0.3
            var foam_offset = Vector2(randf_range(-0.2, 0.2), randf_range(-0.2, 0.0)) * particle_size
            _draw_radial_gradient_circle(pos + foam_offset, foam_size, foam_color, 
                                        Color(foam_color.r, foam_color.g, foam_color.b, 0.0))

func _draw_fluid_metaballs():
    # Regenerate surface mesh if needed
    if _needs_surface_rebuild:
        _rebuild_fluid_surface()
        _needs_surface_rebuild = false
    
    # Draw the metaball surface
    if _fluid_surface_mesh.size() >= 3:  # At least one triangle
        var colors = _get_metaball_colors()
        draw_polygon(_fluid_surface_mesh, colors)
        
        # Draw outline if needed
        if outline_width > 0:
            var outline_points = _get_surface_outline(_fluid_surface_mesh)
            for i in range(outline_points.size() - 1):
                draw_line(outline_points[i], outline_points[i+1], outline_color, outline_width)
            # Connect last to first
            if outline_points.size() > 2:
                draw_line(outline_points[-1], outline_points[0], outline_color, outline_width)
    
    # Debug: draw particles as small circles if needed
    if false:  # Change to true for debugging
        var particles_to_render = _get_renderable_particles()
        for p in particles_to_render:
            var pos = Vector2(p.position.x, p.position.y)
            if cull_offscreen_particles and not _is_on_screen(pos, 4):
                continue
            var debug_color = Color(1, 1, 1, 0.3)
            draw_circle(pos, 2, debug_color)

func _rebuild_fluid_surface():
    """Generate a mesh surface for the fluid using metaballs technique"""
    _fluid_surface_mesh.clear()
    
    if _cached_particles.size() == 0:
        return
    
    # Use marching squares algorithm (2D equivalent of marching cubes)
    var grid_resolution = 40  # Adjust for quality vs performance
    var bounds = _get_particles_bounds()
    
    # Add padding to bounds
    bounds.position -= Vector2(particle_size, particle_size)
    bounds.size += Vector2(particle_size, particle_size) * 2
    
    var cell_size = Vector2(bounds.size.x / grid_resolution, 
                           bounds.size.y / grid_resolution)
    
    # Generate implicit field values (metaball field)
    var field = {}
    for x in range(grid_resolution + 1):
        for y in range(grid_resolution + 1):
            var pos = bounds.position + Vector2(x * cell_size.x, y * cell_size.y)
            var value = 0.0
            
            # Sum contribution from each particle
            for p in _cached_particles:
                var particle_pos = Vector2(p.position.x, p.position.y)
                var dist = pos.distance_to(particle_pos)
                if dist < particle_size * 2:
                    value += pow(1.0 - dist / (particle_size * 2), metaball_falloff)
            
            # Store grid value
            field[Vector2i(x, y)] = value
    
    # Generate polygons using marching squares
    _fluid_surface_mesh = _marching_squares(field, grid_resolution, 
                                         bounds, metaball_threshold)

func _marching_squares(field, resolution, bounds, threshold):
    """Implement marching squares algorithm for metaball rendering"""
    var vertices = []
    var visited_edges = {}
    
    # Process each cell in the grid
    for x in range(resolution):
        for y in range(resolution):
            # Get the values at the 4 corners of this cell
            var cell_type = 0
            var corners = [
                Vector2i(x, y),
                Vector2i(x + 1, y),
                Vector2i(x + 1, y + 1),
                Vector2i(x, y + 1)
            ]
            
            var corner_values = []
            for i in range(4):
                var value = field[corners[i]]
                corner_values.append(value)
                if value >= threshold:
                    cell_type |= (1 << i)
            
            # Skip empty or full cells
            if cell_type == 0 or cell_type == 15:
                continue
            
            # Calculate the positions where the metaball surface intersects the cell edges
            var positions = []
            
            # Look up interpolation positions for this cell type
            match cell_type:
                1: # 0001 - Bottom-left corner
                    positions.append(_interpolate_position(corners[0], corners[3], corner_values[0], corner_values[3], threshold, bounds))
                    positions.append(_interpolate_position(corners[0], corners[1], corner_values[0], corner_values[1], threshold, bounds))
                2: # 0010 - Bottom-right corner
                    positions.append(_interpolate_position(corners[1], corners[0], corner_values[1], corner_values[0], threshold, bounds))
                    positions.append(_interpolate_position(corners[1], corners[2], corner_values[1], corner_values[2], threshold, bounds))
                3: # 0011 - Bottom edge
                    positions.append(_interpolate_position(corners[1], corners[2], corner_values[1], corner_values[2], threshold, bounds))
                    positions.append(_interpolate_position(corners[0], corners[3], corner_values[0], corner_values[3], threshold, bounds))
                4: # 0100 - Top-right corner
                    positions.append(_interpolate_position(corners[2], corners[1], corner_values[2], corner_values[1], threshold, bounds))
                    positions.append(_interpolate_position(corners[2], corners[3], corner_values[2], corner_values[3], threshold, bounds))
                5: # 0101 - Diagonal case 1
                    positions.append(_interpolate_position(corners[0], corners[1], corner_values[0], corner_values[1], threshold, bounds))
                    positions.append(_interpolate_position(corners[0], corners[3], corner_values[0], corner_values[3], threshold, bounds))
                    positions.append(_interpolate_position(corners[2], corners[1], corner_values[2], corner_values[1], threshold, bounds))
                    positions.append(_interpolate_position(corners[2], corners[3], corner_values[2], corner_values[3], threshold, bounds))
                6: # 0110 - Right edge
                    positions.append(_interpolate_position(corners[1], corners[0], corner_values[1], corner_values[0], threshold, bounds))
                    positions.append(_interpolate_position(corners[2], corners[3], corner_values[2], corner_values[3], threshold, bounds))
                7: # 0111 - All except top-left
                    positions.append(_interpolate_position(corners[0], corners[3], corner_values[0], corner_values[3], threshold, bounds))
                    positions.append(_interpolate_position(corners[0], corners[1], corner_values[0], corner_values[1], threshold, bounds))
                8: # 1000 - Top-left corner
                    positions.append(_interpolate_position(corners[3], corners[0], corner_values[3], corner_values[0], threshold, bounds))
                    positions.append(_interpolate_position(corners[3], corners[2], corner_values[3], corner_values[2], threshold, bounds))
                9: # 1001 - Left edge
                    positions.append(_interpolate_position(corners[0], corners[1], corner_values[0], corner_values[1], threshold, bounds))
                    positions.append(_interpolate_position(corners[3], corners[2], corner_values[3], corner_values[2], threshold, bounds))
                10: # 1010 - Diagonal case 2
                    positions.append(_interpolate_position(corners[1], corners[0], corner_values[1], corner_values[0], threshold, bounds))
                    positions.append(_interpolate_position(corners[1], corners[2], corner_values[1], corner_values[2], threshold, bounds))
                    positions.append(_interpolate_position(corners[3], corners[0], corner_values[3], corner_values[0], threshold, bounds))
                    positions.append(_interpolate_position(corners[3], corners[2], corner_values[3], corner_values[2], threshold, bounds))
                11: # 1011 - All except top-right
                    positions.append(_interpolate_position(corners[1], corners[2], corner_values[1], corner_values[2], threshold, bounds))
                    positions.append(_interpolate_position(corners[3], corners[2], corner_values[3], corner_values[2], threshold, bounds))
                12: # 1100 - Top edge
                    positions.append(_interpolate_position(corners[3], corners[0], corner_values[3], corner_values[0], threshold, bounds))
                    positions.append(_interpolate_position(corners[2], corners[1], corner_values[2], corner_values[1], threshold, bounds))
                13: # 1101 - All except bottom-right
                    positions.append(_interpolate_position(corners[0], corners[1], corner_values[0], corner_values[1], threshold, bounds))
                    positions.append(_interpolate_position(corners[2], corners[1], corner_values[2], corner_values[1], threshold, bounds))
                14: # 1110 - All except bottom-left
                    positions.append(_interpolate_position(corners[1], corners[0], corner_values[1], corner_values[0], threshold, bounds))
                    positions.append(_interpolate_position(corners[3], corners[0], corner_values[3], corner_values[0], threshold, bounds))
                _: # Other cases (shouldn't happen)
                    pass
            
            # Add calculated vertices to the mesh
            for i in range(0, positions.size(), 2):
                if i+1 < positions.size():  # Ensure we have a pair
                    var pos1 = positions[i]
                    var pos2 = positions[i+1]
                    
                    # Create an edge key to track unique edges
                    var edge_key = str(pos1) + str(pos2)
                    if not visited_edges.has(edge_key):
                        visited_edges[edge_key] = true
                        
                        # Add vertices in correct winding order for proper polygon rendering
                        vertices.append(pos1)
                        vertices.append(pos2)
    
    # Convert to proper polygon by forming a convex hull or organizing vertices
    return _organize_polygon_vertices(vertices)

func _interpolate_position(p1, p2, val1, val2, threshold, bounds):
    """Linearly interpolate between grid points to find exact threshold position"""
    # Avoid division by zero
    if abs(val2 - val1) < 0.0001:
        return Vector2.ZERO
    
    # Calculate interpolation factor
    var t = (threshold - val1) / (val2 - val1)
    
    # Clamp interpolation to 0-1 range
    t = clamp(t, 0.0, 1.0)
    
    # Calculate cell size
    var cell_size = Vector2(bounds.size.x / 40.0, bounds.size.y / 40.0)
    
    # Calculate interpolated position
    var pos = Vector2(
        bounds.position.x + (p1.x * (1.0 - t) + p2.x * t) * cell_size.x,
        bounds.position.y + (p1.y * (1.0 - t) + p2.y * t) * cell_size.y
    )
    
    return pos

func _organize_polygon_vertices(vertices):
    """Organize vertices into a proper polygon"""
    if vertices.size() <= 2:
        return []
    
    # Find center point of all vertices
    var center = Vector2.ZERO
    for v in vertices:
        center += v
    center /= vertices.size()
    
    # Sort vertices by angle around center point
    var sorted_vertices = vertices.duplicate()
    sorted_vertices.sort_custom(func(a, b): 
        return atan2(a.y - center.y, a.x - center.x) < atan2(b.y - center.y, b.x - center.x)
    )
    
    return sorted_vertices

func _get_surface_outline(polygon):
    """Extract the outline edges from the polygon"""
    var edges = {}
    var outline = []
    
    # Track edge frequencies
    for i in range(polygon.size()):
        var p1 = polygon[i]
        var p2 = polygon[(i + 1) % polygon.size()]
        
        var edge_key = str(p1) + "__" + str(p2)
        var rev_edge_key = str(p2) + "__" + str(p1)
        
        if edges.has(edge_key):
            edges[edge_key] += 1
        else:
            edges[edge_key] = 1
        
        if edges.has(rev_edge_key):
            edges[rev_edge_key] += 1
        else:
            edges[rev_edge_key] = 1
    
    # Find edges that appear only once (outline edges)
    for i in range(polygon.size()):
        var p1 = polygon[i]
        var p2 = polygon[(i + 1) % polygon.size()]
        
        var edge_key = str(p1) + "__" + str(p2)
        
        if edges[edge_key] == 1:
            outline.append(p1)
    
    return outline

func _draw_radial_gradient_circle(center, radius, inner_color, outer_color):
    """Draw a circle with a radial gradient from center to edge"""
    # Create a gradient texture
    var gradient = Gradient.new()
    gradient.add_point(0.0, inner_color)
    gradient.add_point(1.0, outer_color)
    
    var gradient_texture = GradientTexture2D.new()
    gradient_texture.gradient = gradient
    gradient_texture.fill = GradientTexture2D.FILL_RADIAL
    gradient_texture.width = int(radius * 2)
    gradient_texture.height = int(radius * 2)
    
    # Draw textured circle
    var rect = Rect2(center - Vector2(radius, radius), Vector2(radius * 2, radius * 2))
    draw_texture_rect(gradient_texture, rect, false)

func _get_particle_color(particle):
    """Get color for a particle, with vertical gradient"""
    if particle.has("color"):
        return particle.color
    
    # Calculate vertical position for gradient
    var t = (particle.position.y - min_bounds().y) / (max_bounds().y - min_bounds().y)
    t = clamp(t, 0.0, 1.0)
    
    # Lerp between top and bottom colors
    var color = gradient_top_color.lerp(gradient_bottom_color, t)
    
    # Modify alpha for surface particles
    if particle.has("is_surface") and particle.is_surface:
        color.a *= 1.2  # Make surface particles slightly more opaque
    
    return color

func _get_metaball_colors():
    """Get colors for the metaball polygon"""
    var colors = []
    
    # Create a gradient from top to bottom of the fluid surface
    for vertex in _fluid_surface_mesh:
        var t = (vertex.y - min_bounds().y) / (max_bounds().y - min_bounds().y)
        t = clamp(t, 0.0, 1.0)
        
        var color = gradient_top_color.lerp(gradient_bottom_color, t)
        
        # Add some ripple effects based on time and position
        if add_ripples:
            var ripple = sin((vertex.x * 0.1 + _time * 2.0) * ripple_frequency) * 
                        sin((vertex.y * 0.1 + _time) * ripple_frequency) * 
                        ripple_amplitude
            
            # Adjust color brightness based on ripple
            color = color.lightened(ripple * 0.2)
        
        # Add to colors array
        colors.append(color)
    
    return colors

func _get_default_particle_shader_code():
    """Return default particle shader code if no shader is available"""
    return """
    shader_type canvas_item;
    
    uniform vec4 inner_color : source_color = vec4(0.0, 0.6, 1.0, 0.7);
    uniform vec4 outer_color : source_color = vec4(0.0, 0.4, 0.8, 0.0);
    uniform float inner_radius = 0.4;
    
    void fragment() {
        float dist = distance(UV, vec2(0.5));
        
        // Circular shape with soft edges
        float alpha = smoothstep(0.5, inner_radius, dist);
        
        // Interpolate between inner and outer color
        vec4 color = mix(outer_color, inner_color, alpha);
        
        COLOR = color;
    }
    """

func _get_default_metaball_shader_code():
    """Return default metaball shader code if no shader is available"""
    return """
    shader_type canvas_item;
    
    uniform vec4 top_color : source_color = vec4(0.0, 0.6, 1.0, 0.8);
    uniform vec4 bottom_color : source_color = vec4(0.0, 0.4, 0.8, 0.9);
    uniform float wave_speed = 2.0;
    uniform float wave_frequency = 20.0;
    uniform float wave_amplitude = 0.05;
    uniform float time_offset = 0.0;
    
    void fragment() {
        // Vertical gradient
        float t = UV.y;
        vec4 base_color = mix(top_color, bottom_color, t);
        
        // Add wave effect
        float wave = sin((UV.x * wave_frequency) + time_offset * wave_speed) * 
                    sin((UV.y * wave_frequency * 0.5) + time_offset * wave_speed * 0.7) * 
                    wave_amplitude;
        
        // Apply wave effect
        base_color = base_color * (1.0 + wave);
        
        // Add highlights at top
        if (UV.y < 0.15) {
            base_color = base_color * (1.0 + (0.15 - UV.y) * 2.0);
        }
        
        COLOR = base_color;
    }
    """

func _get_renderable_particles():
    """Get particles that should be rendered, respecting max count"""
    var render_count = min(_cached_particles.size(), max_particles_to_render)
    return _cached_particles.slice(0, render_count - 1)

func _prepare_particle_draw_list():
    """Prepare an optimized list for particle drawing using instancing"""
    _particle_draw_list.clear()
    
    var particles_to_render = _get_renderable_particles()
    for p in particles_to_render:
        var pos = Vector2(p.position.x, p.position.y)
        
        if cull_offscreen_particles and not _is_on_screen(pos, particle_size):
            continue
        
        _particle_draw_list.append({
            "position": pos,
            "color": _get_particle_color(p),
            "size": particle_size,
            "is_surface": p.get("is_surface", false)
        })

func _get_particles_bounds():
    """Get bounds rectangle containing all particles"""
    if _cached_particles.size() == 0:
        return Rect2(0, 0, 1, 1)
    
    var min_p = Vector2(INF, INF)
    var max_p = Vector2(-INF, -INF)
    
    for p in _cached_particles:
        var pos = Vector2(p.position.x, p.position.y)
        min_p.x = min(min_p.x, pos.x)
        min_p.y = min(min_p.y, pos.y)
        max_p.x = max(max_p.x, pos.x)
        max_p.y = max(max_p.y, pos.y)
    
    return Rect2(min_p, max_p - min_p)

func _is_on_screen(position, size):
    """Check if a particle is visible on screen"""
    var screen_rect = get_viewport_rect()
    var extended_rect = screen_rect.grow(size)
    return extended_rect.has_point(position)

func _sort_particles_by_depth(a, b):
    """Sort particles by depth (y position) for correct drawing order"""
    return a.position.y > b.position.y

func min_bounds():
    """Get minimum bounds from simulation if available"""
    if simulation != null:
        return Vector2(simulation.min_bounds.x, simulation.min_bounds.y)
    return Vector2(-10, -10)

func max_bounds():
    """Get maximum bounds from simulation if available"""
    if simulation != null:
        return Vector2(simulation.max_bounds.x, simulation.max_bounds.y)
    return Vector2(10, 10)

func set_simulation(sim):
    """Set the fluid simulation to render"""
    simulation = sim

func add_ripple_at_position(position, strength=1.0, size=1.0):
    """Add a ripple effect at a specific position (for interaction)"""
    if simulation == null:
        return
    
    # Find particles near the position
    for p in simulation.particles:
        var particle_pos = Vector2(p.position.x, p.position.y)
        var dist = particle_pos.distance_to(position)
        
        if dist < particle_size * 4 * size:
            # Apply force based on distance
            var force_dir = (p.position - Vector3(position.x, position.y, 0)).normalized()
            var force_strength = strength * (1.0 - dist / (particle_size * 4 * size))
            p.force += force_dir * force_strength * 10.0
            
            # Increase velocity slightly for more dynamic effect
            p.velocity += force_dir * force_strength * 2.0
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/fluid_2d_renderer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/fluid_3d_renderer.gd
# SIZE: 38480 bytes
extends Node3D

class_name Fluid3DRenderer

# Reference to fluid simulation
var simulation: FluidSimulationCore = null

# Rendering properties
@export_category("Rendering Methods")
@export var render_method: int = 0  # 0=Particles, 1=Metaballs, 2=Mesh Surface
@export var surface_detail: float = 1.0  # Detail level for mesh surface (0.1-2.0)
@export var particle_size: float = 0.1
@export var use_instancing: bool = true
@export var max_particles_to_render: int = 10000
@export var use_imposters: bool = false  # Use billboards instead of spheres
@export_color var base_color: Color = Color(0.0, 0.5, 1.0, 0.8) 

# Fluid mesh properties
@export_category("Fluid Surface Properties")
@export_range(0.1, 2.0) var metaball_threshold: float = 0.5
@export_range(0.1, 2.0) var surface_smoothing: float = 1.0
@export var update_interval: float = 0.1  # Surface update frequency in seconds
@export var use_adaptive_resolution: bool = true  # Adjust resolution based on particle count

# Visual effects
@export_category("Visual Effects")
@export var enable_refraction: bool = true
@export var refraction_strength: float = 0.1
@export var enable_reflection: bool = true
@export var reflection_strength: float = 0.3
@export var enable_foam: bool = true
@export var foam_threshold: float = 0.7
@export_color var foam_color: Color = Color(1.0, 1.0, 1.0, 0.9)
@export var enable_caustics: bool = true
@export var enable_depth_fade: bool = true
@export var depth_fade_distance: float = 2.0
@export var add_ripples: bool = true
@export var ripple_speed: float = 1.0
@export var ripple_height: float = 0.03

# Performance options
@export_category("Performance")
@export_range(8, 100) var surface_resolution: int = 32  # Grid resolution for marching cubes
@export var lod_distance: float = 20.0  # Distance for level of detail changes
@export var occlusion_culling: bool = true  # Cull particles not visible to camera
@export var use_shader_lod: bool = true  # Use LOD in shaders based on distance
@export var frustum_culling: bool = true  # Cull particles outside camera frustum

# Internal variables
var _time: float = 0.0
var _surface_update_timer: float = 0.0
var _particle_mesh_instance: MeshInstance3D = null
var _surface_mesh_instance: MeshInstance3D = null
var _last_camera_position: Vector3 = Vector3.ZERO
var _fluid_material: Material = null
var _foam_material: Material = null
var _particle_material: Material = null
var _impostor_material: Material = null
var _multimesh: MultiMesh = null
var _needs_rebuild: bool = true

# Surface generation variables
var _last_bounds: AABB = AABB()
var _volume_texture: RenderTexture3D = null
var _marching_cubes_data: Array = []
var _surface_mesh_arrays: Array = []

func _ready():
    # Initialize materials
    _init_materials()
    
    # Initialize meshes based on render method
    _init_meshes()
    
    # Initialize camera tracking
    _last_camera_position = _get_camera_position()
    
    # Create initial volume texture for metaball approach
    if render_method == 1:  # Metaballs
        _create_volume_texture()

func _init_materials():
    # Load materials or create default ones
    _fluid_material = _create_fluid_material()
    _foam_material = _create_foam_material()
    _particle_material = _create_particle_material() 
    _impostor_material = _create_impostor_material()

func _init_meshes():
    # Create different mesh objects depending on render method
    match render_method:
        0:  # Particles
            _setup_particle_rendering()
        1:  # Metaballs
            _setup_metaball_rendering()
        2:  # Mesh Surface
            _setup_surface_rendering()

func _process(delta):
    _time += delta
    _surface_update_timer += delta
    
    # Check if camera moved significantly
    var camera_pos = _get_camera_position()
    var camera_moved = camera_pos.distance_to(_last_camera_position) > 0.5
    if camera_moved:
        _last_camera_position = camera_pos
    
    # Update shader parameters that change every frame
    _update_shader_parameters(delta)
    
    # Check if surface needs updating
    if render_method != 0:  # Not particle-only
        if _needs_rebuild or _surface_update_timer >= update_interval:
            _surface_update_timer = 0.0
            _rebuild_fluid_surface()
            _needs_rebuild = false

func _physics_process(delta):
    # Update particles for instanced rendering
    if render_method == 0 and use_instancing and simulation != null:
        _update_particle_instances()

func _setup_particle_rendering():
    # Remove any existing instances
    if _particle_mesh_instance != null:
        _particle_mesh_instance.queue_free()
    
    if use_instancing:
        # Create multimesh for instanced rendering
        _multimesh = MultiMesh.new()
        _multimesh.transform_format = MultiMesh.TRANSFORM_3D
        _multimesh.color_format = MultiMesh.COLOR_FLOAT
        _multimesh.instance_count = 0  # Will be updated dynamically
        
        # Create base sphere mesh
        var sphere = SphereMesh.new()
        sphere.radius = particle_size / 2.0
        sphere.height = particle_size
        sphere.radial_segments = 8
        sphere.rings = 4
        _multimesh.mesh = sphere
        
        # Create mesh instance with multimesh
        _particle_mesh_instance = MeshInstance3D.new()
        _particle_mesh_instance.multimesh = _multimesh
        _particle_mesh_instance.material_override = _particle_material
        add_child(_particle_mesh_instance)
    else:
        # Just create a placeholder - individual spheres will be created later
        _particle_mesh_instance = MeshInstance3D.new()
        add_child(_particle_mesh_instance)

func _setup_metaball_rendering():
    # Create shader-based metaball rendering setup
    _surface_mesh_instance = MeshInstance3D.new()
    add_child(_surface_mesh_instance)
    
    # Initially use a simple plane mesh
    var plane_mesh = PlaneMesh.new()
    plane_mesh.size = Vector2(2, 2)
    _surface_mesh_instance.mesh = plane_mesh
    
    # Assign material
    _surface_mesh_instance.material_override = _fluid_material

func _setup_surface_rendering():
    # Create mesh surface rendering setup
    _surface_mesh_instance = MeshInstance3D.new()
    add_child(_surface_mesh_instance)
    
    # Create empty initial mesh
    var array_mesh = ArrayMesh.new()
    _surface_mesh_instance.mesh = array_mesh
    
    # Assign material
    _surface_mesh_instance.material_override = _fluid_material

func _update_shader_parameters(delta):
    # Update time-dependent parameters in all materials
    if _fluid_material:
        _fluid_material.set_shader_parameter("time", _time)
        
        if add_ripples:
            var wave_params = Vector4(
                ripple_speed, 
                ripple_height,
                1.0 + sin(_time * 0.5) * 0.2,  # Wave frequency modulation
                1.0 + cos(_time * 0.3) * 0.1   # Wave scale modulation
            )
            _fluid_material.set_shader_parameter("wave_params", wave_params)
            
    if _foam_material:
        _foam_material.set_shader_parameter("time", _time)
        
    if _particle_material:
        _particle_material.set_shader_parameter("time", _time)
    
    if _impostor_material:
        _impostor_material.set_shader_parameter("time", _time)
        
        # Update camera position for billboarding
        var camera = get_viewport().get_camera_3d()
        if camera:
            _impostor_material.set_shader_parameter("camera_position", camera.global_position)

func _update_particle_instances():
    if simulation == null or _multimesh == null:
        return
    
    var particles = simulation.get_particles_for_rendering()
    var render_count = min(particles.size(), max_particles_to_render)
    
    # Resize multimesh if needed
    if _multimesh.instance_count != render_count:
        _multimesh.instance_count = render_count
    
    # Skip if no particles
    if render_count == 0:
        return
    
    # Update transforms and colors for each particle
    for i in range(render_count):
        var p = particles[i]
        
        # Create transform
        var pos = p.position
        var scale = Vector3.ONE * (particle_size / 2.0)
        
        # Apply velocity-based stretching for fast particles
        if p.has("velocity"):
            var speed = p.velocity.length()
            if speed > 1.0:
                var stretch_dir = p.velocity.normalized()
                var stretch_factor = min(1.0 + speed * 0.1, 2.0)
                scale += stretch_dir * stretch_factor * 0.1
        
        var transform = Transform3D().scaled(scale)
        transform.origin = pos
        
        # Set instance transform
        _multimesh.set_instance_transform(i, transform)
        
        # Set instance color
        var color = base_color
        if p.has("color"):
            color = p.color
            
        # Adjust color for surface particles
        if p.has("is_surface") and p.is_surface and enable_foam:
            color = color.lerp(foam_color, foam_threshold)
            
        _multimesh.set_instance_color(i, color)

func _rebuild_fluid_surface():
    if simulation == null:
        return
    
    var particles = simulation.get_particles_for_rendering()
    if particles.size() == 0:
        # No particles to render, clear surface
        if render_method == 2 and _surface_mesh_instance:
            var empty_mesh = ArrayMesh.new()
            _surface_mesh_instance.mesh = empty_mesh
        return
    
    # Get fluid bounds
    var bounds = _calculate_fluid_bounds(particles)
    _last_bounds = bounds
    
    match render_method:
        1:  # Metaballs
            _update_volume_texture(particles, bounds)
        2:  # Mesh Surface
            _create_mesh_surface(particles, bounds)

func _calculate_fluid_bounds(particles):
    var min_pos = Vector3(INF, INF, INF)
    var max_pos = Vector3(-INF, -INF, -INF)
    
    for p in particles:
        min_pos.x = min(min_pos.x, p.position.x)
        min_pos.y = min(min_pos.y, p.position.y)
        min_pos.z = min(min_pos.z, p.position.z)
        
        max_pos.x = max(max_pos.x, p.position.x)
        max_pos.y = max(max_pos.y, p.position.y)
        max_pos.z = max(max_pos.z, p.position.z)
    
    # Add padding
    var padding = Vector3.ONE * particle_size * 2.0
    min_pos -= padding
    max_pos += padding
    
    return AABB(min_pos, max_pos - min_pos)

func _create_volume_texture():
    # Create 3D texture for metaball field
    var resolution = Vector3i(32, 32, 32)
    if use_adaptive_resolution:
        # Adjust resolution based on particle count
        var count = simulation.get_particle_count() if simulation else 100
        var factor = clamp(sqrt(count) / 20.0, 0.5, 2.0)
        resolution = Vector3i(32, 32, 32) * factor
        
    # Ensure resolution is between 16 and 64 in each dimension
    resolution.x = clamp(resolution.x, 16, 64)
    resolution.y = clamp(resolution.y, 16, 64)
    resolution.z = clamp(resolution.z, 16, 64)
    
    _volume_texture = RenderTexture3D.new()
    _volume_texture.size = resolution
    _volume_texture.format = RenderTextureFormat.R8

func _update_volume_texture(particles, bounds):
    if _volume_texture == null:
        _create_volume_texture()
    
    # Calculate field values
    var resolution = _volume_texture.size
    var field_data = PackedFloat32Array()
    field_data.resize(resolution.x * resolution.y * resolution.z)
    
    for x in range(resolution.x):
        for y in range(resolution.y):
            for z in range(resolution.z):
                var pos = Vector3(
                    lerp(bounds.position.x, bounds.end.x, float(x) / resolution.x),
                    lerp(bounds.position.y, bounds.end.y, float(y) / resolution.y),
                    lerp(bounds.position.z, bounds.end.z, float(z) / resolution.z)
                )
                
                var density = 0.0
                for p in particles:
                    var dist = pos.distance_to(p.position)
                    if dist < particle_size * 2.0:
                        density += pow(1.0 - dist / (particle_size * 2.0), 2.0)
                
                var idx = x + y * resolution.x + z * resolution.x * resolution.y
                field_data[idx] = density
    
    # Update volume texture data
    var image_3d = Image3D.new()
    image_3d.create_from_data(resolution.x, resolution.y, resolution.z, 
                            Image.FORMAT_R8, field_data)
    
    _volume_texture.data = image_3d
    
    # Update material
    if _fluid_material:
        _fluid_material.set_shader_parameter("volume_texture", _volume_texture)
        _fluid_material.set_shader_parameter("bounds_min", bounds.position)
        _fluid_material.set_shader_parameter("bounds_size", bounds.size)
        _fluid_material.set_shader_parameter("threshold", metaball_threshold)

func _create_mesh_surface(particles, bounds):
    # Create surface mesh using marching cubes
    
    # Determine resolution based on detail level and bounds size
    var base_resolution = int(surface_resolution * surface_detail)
    var x_res = int(base_resolution * (bounds.size.x / max(bounds.size.x, bounds.size.y, bounds.size.z)))
    var y_res = int(base_resolution * (bounds.size.y / max(bounds.size.x, bounds.size.y, bounds.size.z)))
    var z_res = int(base_resolution * (bounds.size.z / max(bounds.size.x, bounds.size.y, bounds.size.z)))
    
    # Ensure minimum resolution
    x_res = max(x_res, 8)
    y_res = max(y_res, 8)
    z_res = max(z_res, 8)
    
    # Calculate cell size
    var cell_size = Vector3(
        bounds.size.x / x_res,
        bounds.size.y / y_res,
        bounds.size.z / z_res
    )
    
    # Generate scalar field
    var field = {}
    for x in range(x_res + 1):
        for y in range(y_res + 1):
            for z in range(z_res + 1):
                var pos = bounds.position + Vector3(
                    x * cell_size.x,
                    y * cell_size.y, 
                    z * cell_size.z
                )
                
                var density = 0.0
                for p in particles:
                    var dist = pos.distance_to(p.position)
                    if dist < particle_size * 2.0:
                        density += pow(1.0 - dist / (particle_size * 2.0), 2.0)
                
                field[Vector3i(x, y, z)] = density
    
    # Generate mesh using marching cubes
    var vertices = []
    var normals = []
    var indices = []
    
    # Apply marching cubes algorithm
    _marching_cubes(field, x_res, y_res, z_res, bounds, 
                   cell_size, metaball_threshold, 
                   vertices, normals, indices)
    
    # Skip if no vertices
    if vertices.size() == 0:
        return
    
    # Create mesh arrays
    var arrays = []
    arrays.resize(Mesh.ARRAY_MAX)
    arrays[Mesh.ARRAY_VERTEX] = PackedVector3Array(vertices)
    arrays[Mesh.ARRAY_NORMAL] = PackedVector3Array(normals)
    arrays[Mesh.ARRAY_INDEX] = PackedInt32Array(indices)
    
    # Create UV coordinates based on position
    var uvs = []
    for v in vertices:
        var uv = Vector2(
            (v.x - bounds.position.x) / bounds.size.x,
            (v.z - bounds.position.z) / bounds.size.z
        )
        uvs.append(uv)
    arrays[Mesh.ARRAY_TEX_UV] = PackedVector2Array(uvs)
    
    # Create colors (can be used for effects)
    var colors = []
    for v in vertices:
        var t = (v.y - bounds.position.y) / bounds.size.y
        var color = base_color
        
        # Adjust color based on height
        color.r += t * 0.1
        color.g += t * 0.2
        color.b += (1.0 - t) * 0.1
        
        colors.append(color)
    arrays[Mesh.ARRAY_COLOR] = PackedColorArray(colors)
    
    # Create or update mesh
    var array_mesh = ArrayMesh.new()
    array_mesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, arrays)
    
    # Smooth normals for better appearance
    if surface_smoothing > 0.0:
        # Would call _smooth_normals here if implemented
        pass
    
    # Assign to mesh instance
    _surface_mesh_instance.mesh = array_mesh

func _marching_cubes(field, x_res, y_res, z_res, bounds, cell_size, 
                    threshold, vertices, normals, indices):
    """Implementation of Marching Cubes algorithm for isosurface extraction"""
    # Marching cubes lookup tables
    var edge_table = _get_marching_cubes_edge_table()
    var tri_table = _get_marching_cubes_tri_table()
    
    # Process each cell
    for x in range(x_res):
        for y in range(y_res):
            for z in range(z_res):
                # Get the values at the 8 corners of the cube
                var cube_values = []
                var positions = []
                
                for i in range(8):
                    var corner = Vector3i(
                        x + (i & 1),
                        y + ((i & 2) >> 1),
                        z + ((i & 4) >> 2)
                    )
                    
                    var pos = bounds.position + Vector3(
                        corner.x * cell_size.x,
                        corner.y * cell_size.y,
                        corner.z * cell_size.z
                    )
                    
                    positions.append(pos)
                    
                    if field.has(corner):
                        cube_values.append(field[corner])
                    else:
                        cube_values.append(0.0)
                
                # Calculate cube index
                var cube_index = 0
                for i in range(8):
                    if cube_values[i] > threshold:
                        cube_index |= (1 << i)
                
                # Skip empty cubes
                if cube_index == 0 or cube_index == 255:
                    continue
                
                # Get edge flags
                var edge_flags = edge_table[cube_index]
                
                # Skip if no edges
                if edge_flags == 0:
                    continue
                
                # Calculate intersection vertices
                var edge_vertices = {}
                
                if edge_flags & 1:    # Edge 0
                    edge_vertices[0] = _interpolate_vertex(positions[0], positions[1], 
                                                         cube_values[0], cube_values[1], threshold)
                
                if edge_flags & 2:    # Edge 1
                    edge_vertices[1] = _interpolate_vertex(positions[1], positions[2], 
                                                         cube_values[1], cube_values[2], threshold)
                
                if edge_flags & 4:    # Edge 2
                    edge_vertices[2] = _interpolate_vertex(positions[2], positions[3], 
                                                         cube_values[2], cube_values[3], threshold)
                
                if edge_flags & 8:    # Edge 3
                    edge_vertices[3] = _interpolate_vertex(positions[3], positions[0], 
                                                         cube_values[3], cube_values[0], threshold)
                
                if edge_flags & 16:   # Edge 4
                    edge_vertices[4] = _interpolate_vertex(positions[4], positions[5], 
                                                         cube_values[4], cube_values[5], threshold)
                
                if edge_flags & 32:   # Edge 5
                    edge_vertices[5] = _interpolate_vertex(positions[5], positions[6], 
                                                         cube_values[5], cube_values[6], threshold)
                
                if edge_flags & 64:   # Edge 6
                    edge_vertices[6] = _interpolate_vertex(positions[6], positions[7], 
                                                         cube_values[6], cube_values[7], threshold)
                
                if edge_flags & 128:  # Edge 7
                    edge_vertices[7] = _interpolate_vertex(positions[7], positions[4], 
                                                         cube_values[7], cube_values[4], threshold)
                
                if edge_flags & 256:  # Edge 8
                    edge_vertices[8] = _interpolate_vertex(positions[0], positions[4], 
                                                         cube_values[0], cube_values[4], threshold)
                
                if edge_flags & 512:  # Edge 9
                    edge_vertices[9] = _interpolate_vertex(positions[1], positions[5], 
                                                         cube_values[1], cube_values[5], threshold)
                
                if edge_flags & 1024: # Edge 10
                    edge_vertices[10] = _interpolate_vertex(positions[2], positions[6], 
                                                         cube_values[2], cube_values[6], threshold)
                
                if edge_flags & 2048: # Edge 11
                    edge_vertices[11] = _interpolate_vertex(positions[3], positions[7], 
                                                         cube_values[3], cube_values[7], threshold)
                
                # Create triangles based on tri_table
                var i = 0
                while i < 16 and tri_table[cube_index][i] != -1:
                    var a = edge_vertices[tri_table[cube_index][i]]
                    var b = edge_vertices[tri_table[cube_index][i+1]]
                    var c = edge_vertices[tri_table[cube_index][i+2]]
                    
                    # Calculate normal
                    var normal = (b - a).cross(c - a).normalized()
                    
                    # Add vertices and normals
                    vertices.append(a)
                    vertices.append(b)
                    vertices.append(c)
                    
                    normals.append(normal)
                    normals.append(normal)
                    normals.append(normal)
                    
                    # Add indices
                    var base_idx = indices.size()
                    indices.append(base_idx)
                    indices.append(base_idx + 1)
                    indices.append(base_idx + 2)
                    
                    i += 3

func _interpolate_vertex(v1, v2, val1, val2, threshold):
    """Linear interpolation between vertices based on field values"""
    if abs(threshold - val1) < 0.00001:
        return v1
    if abs(threshold - val2) < 0.00001:
        return v2
    if abs(val1 - val2) < 0.00001:
        return v1
    
    var t = (threshold - val1) / (val2 - val1)
    return v1 + (v2 - v1) * t

func _create_fluid_material():
    """Create default fluid material with shader"""
    var material = ShaderMaterial.new()
    var shader = Shader.new()
    
    # Load shader code based on render method
    match render_method:
        0:  # Particles
            shader.code = _get_particle_shader_code()
        1:  # Metaballs
            shader.code = _get_metaball_shader_code()
        2:  # Mesh Surface
            shader.code = _get_surface_shader_code()
    
    material.shader = shader
    
    # Set common parameters
    material.set_shader_parameter("base_color", base_color)
    material.set_shader_parameter("refraction_strength", refraction_strength)
    material.set_shader_parameter("reflection_strength", reflection_strength)
    material.set_shader_parameter("depth_fade_distance", depth_fade_distance)
    
    return material

func _create_foam_material():
    """Create foam material with shader"""
    var material = ShaderMaterial.new()
    var shader = Shader.new()
    shader.code = _get_foam_shader_code()
    material.shader = shader
    
    # Set parameters
    material.set_shader_parameter("foam_color", foam_color)
    
    return material

func _create_particle_material():
    """Create default particle material"""
    var material = StandardMaterial3D.new()
    material.albedo_color = base_color
    material.metallic = 0.1
    material.roughness = 0.2
    material.clearcoat_enabled = true
    material.clearcoat = 0.5
    material.clearcoat_roughness = 0.1
    material.refraction_enabled = enable_refraction
    material.refraction_scale = refraction_strength
    material.transparency = BaseMaterial3D.TRANSPARENCY_ALPHA
    
    return material

func _create_impostor_material():
    """Create billboarded impostor material for particles"""
    var material = ShaderMaterial.new()
    var shader = Shader.new()
    shader.code = _get_impostor_shader_code()
    material.shader = shader
    
    # Set parameters
    material.set_shader_parameter("particle_color", base_color)
    
    return material

func _get_camera_position():
    """Get current camera position"""
    var camera = get_viewport().get_camera_3d()
    if camera:
        return camera.global_position
    return Vector3.ZERO

func _get_particle_shader_code():
    """Get shader code for particle rendering"""
    return """
shader_type spatial;
render_mode blend_mix, depth_prepass, cull_back, diffuse_burley, specular_schlick_ggx;

uniform vec4 base_color : source_color = vec4(0.0, 0.5, 1.0, 0.8);
uniform float time;
uniform float refraction_strength : hint_range(0.0, 1.0) = 0.1;
uniform float roughness : hint_range(0.0, 1.0) = 0.2;
uniform float metallic : hint_range(0.0, 1.0) = 0.1;

void vertex() {
    // Add slight wobble to particles
    VERTEX.y += sin(VERTEX.x * 4.0 + time * 2.0) * 0.01;
}

void fragment() {
    ALBEDO = base_color.rgb;
    ALPHA = base_color.a;
    METALLIC = metallic;
    ROUGHNESS = roughness;
    SPECULAR = 0.5;
    
    // Add refraction
    REFRACTION = refraction_strength;
    
    // Fresnel effect for edge highlights
    float fresnel = pow(1.0 - dot(NORMAL, VIEW), 5.0);
    EMISSION = base_color.rgb * fresnel * 0.2;
}
"""

func _get_metaball_shader_code():
    """Get shader code for metaball volume rendering"""
    return """
shader_type spatial;
render_mode blend_mix, depth_draw_always, cull_back, diffuse_burley, specular_schlick_ggx;

uniform sampler3D volume_texture;
uniform vec3 bounds_min;
uniform vec3 bounds_size;
uniform float threshold = 0.5;
uniform vec4 base_color : source_color = vec4(0.0, 0.5, 1.0, 0.8);
uniform float time;
uniform float refraction_strength : hint_range(0.0, 1.0) = 0.1;
uniform float reflection_strength : hint_range(0.0, 1.0) = 0.3;
uniform float depth_fade_distance = 2.0;
uniform vec4 wave_params = vec4(1.0, 0.03, 1.0, 1.0); // speed, height, freq mod, scale mod

// Ray marching parameters
const int MAX_STEPS = 128;
const float STEP_SIZE = 0.05;
const float EPSILON = 0.001;

float sample_volume(vec3 pos) {
    // Convert to normalized coordinates in the volume texture
    vec3 norm_pos = (pos - bounds_min) / bounds_size;
    
    // Check if outside bounds
    if (any(lessThan(norm_pos, vec3(0.0))) || any(greaterThan(norm_pos, vec3(1.0)))) {
        return 0.0;
    }
    
    return texture(volume_texture, norm_pos).r;
}

vec3 estimate_normal(vec3 pos) {
    vec2 e = vec2(EPSILON, 0.0);
    return normalize(vec3(
        sample_volume(pos + e.xyy) - sample_volume(pos - e.xyy),
        sample_volume(pos + e.yxy) - sample_volume(pos - e.yxy),
        sample_volume(pos + e.yyx) - sample_volume(pos - e.yyx)
    ));
}

void fragment() {
    // Ray marching setup
    vec3 ray_origin = CAMERA_POSITION;
    vec3 ray_dir = normalize(VERTEX - CAMERA_POSITION);
    
    // Intersect with bounding box
    vec3 inv_ray_dir = 1.0 / ray_dir;
    vec3 t1 = (bounds_min - ray_origin) * inv_ray_dir;
    vec3 t2 = (bounds_min + bounds_size - ray_origin) * inv_ray_dir;
    vec3 tmin = min(t1, t2);
    vec3 tmax = max(t1, t2);
    
    float t_near = max(max(tmin.x, tmin.y), tmin.z);
    float t_far = min(min(tmax.x, tmax.y), tmax.z);
    
    // Skip if ray doesn't intersect box
    if (t_near > t_far || t_far < 0.0) {
        discard;
    }
    
    // Clamp to near plane
    t_near = max(t_near, 0.0);
    
    // Ray march through volume
    float t = t_near;
    bool hit = false;
    vec3 hit_pos = vec3(0.0);
    
    for (int i = 0; i < MAX_STEPS; i++) {
        if (t > t_far) break;
        
        vec3 pos = ray_origin + ray_dir * t;
        float value = sample_volume(pos);
        
        if (value > threshold) {
            hit = true;
            hit_pos = pos;
            break;
        }
        
        t += STEP_SIZE;
    }
    
    if (!hit) {
        discard;
    }
    
    // Calculate surface properties
    vec3 normal = estimate_normal(hit_pos);
    
    // Add wave displacement
    float wave_speed = wave_params.x;
    float wave_height = wave_params.y;
    float wave_freq_mod = wave_params.z;
    float wave_scale_mod = wave_params.w;
    
    float wave = sin((hit_pos.x + hit_pos.z) * 2.0 * wave_freq_mod + time * wave_speed) * 
                 sin((hit_pos.z - hit_pos.x) * 3.0 * wave_scale_mod + time * wave_speed * 0.7) * 
                 wave_height;
    
    // Adjust normal for waves
    normal.y += wave * 5.0;
    normal = normalize(normal);
    
    // Basic lighting
    ALBEDO = base_color.rgb;
    ALPHA = base_color.a;
    METALLIC = 0.1;
    ROUGHNESS = 0.2;
    SPECULAR = 0.5;
    
    // Add fresnel effect for edge highlights
    float fresnel = pow(1.0 - dot(normal, VIEW), 5.0);
    EMISSION = base_color.rgb * fresnel * 0.3;
    
    // Refraction based on depth
    float depth = length(hit_pos - CAMERA_POSITION);
    float depth_fade = 1.0 - exp(-depth / depth_fade_distance);
    
    REFRACTION = refraction_strength * (1.0 - depth_fade);
    
    // Adjust alpha based on depth
    ALPHA *= mix(0.7, 1.0, depth_fade);
    
    // Set correct depth
    DEPTH = length(hit_pos - CAMERA_POSITION);
}
"""

func _get_surface_shader_code():
    """Get shader code for mesh surface rendering"""
    return """
shader_type spatial;
render_mode blend_mix, depth_draw_always, cull_back, diffuse_burley, specular_schlick_ggx;

uniform vec4 base_color : source_color = vec4(0.0, 0.5, 1.0, 0.8);
uniform float time;
uniform float refraction_strength : hint_range(0.0, 1.0) = 0.1;
uniform float reflection_strength : hint_range(0.0, 1.0) = 0.3;
uniform float depth_fade_distance = 2.0;
uniform vec4 wave_params = vec4(1.0, 0.03, 1.0, 1.0); // speed, height, freq mod, scale mod
uniform sampler2D surface_normal_map : hint_normal;
uniform sampler2D foam_texture : hint_default_white;
uniform bool enable_caustics = true;
uniform bool enable_foam = true;
uniform float foam_threshold = 0.7;
uniform vec4 foam_color : source_color = vec4(1.0, 1.0, 1.0, 0.9);

void vertex() {
    // Add wave displacement
    float wave_speed = wave_params.x;
    float wave_height = wave_params.y;
    float wave_freq_mod = wave_params.z;
    float wave_scale_mod = wave_params.w;
    
    float wave = sin((VERTEX.x + VERTEX.z) * 2.0 * wave_freq_mod + time * wave_speed) * 
                 sin((VERTEX.z - VERTEX.x) * 3.0 * wave_scale_mod + time * wave_speed * 0.7) * 
                 wave_height;
    
    // Apply wave displacement to vertex
    VERTEX.y += wave;
    
    // Adjust normal for waves
    NORMAL.y += wave * 5.0;
    NORMAL = normalize(NORMAL);
}

void fragment() {
    // Basic color
    ALBEDO = base_color.rgb;
    ALPHA = base_color.a;
    METALLIC = 0.1;
    ROUGHNESS = 0.2;
    SPECULAR = 0.5;
    
    // Use vertex color if available
    if (COLOR.a > 0.0) {
        ALBEDO = COLOR.rgb;
        ALPHA = COLOR.a;
    }
    
    // Normal mapping for ripples
    vec3 normal_map = texture(surface_normal_map, UV * 3.0 + vec2(time * 0.05, time * 0.03)).rgb * 2.0 - 1.0;
    normal_map = mix(vec3(0.0, 1.0, 0.0), normal_map, 0.3);
    NORMAL_MAP = normal_map;
    NORMAL_MAP_DEPTH = 0.2;
    
    // Add fresnel effect for edge highlights
    float fresnel = pow(1.0 - dot(NORMAL, VIEW), 5.0);
    EMISSION = base_color.rgb * fresnel * 0.3;
    
    // Refraction based on depth
    float depth = texture(DEPTH_TEXTURE, SCREEN_UV).r;
    vec4 world_pos = INV_PROJECTION_MATRIX * vec4(SCREEN_UV * 2.0 - 1.0, depth, 1.0);
    world_pos.xyz /= world_pos.w;
    
    float depth_diff = length(world_pos.xyz - VERTEX);
    float depth_fade = 1.0 - exp(-depth_diff / depth_fade_distance);
    
    REFRACTION = refraction_strength * (1.0 - depth_fade);
    
    // Add foam
    if (enable_foam) {
        float foam_noise = texture(foam_texture, UV * 5.0 + vec2(time * 0.1, 0.0)).r;
        float foam_pattern = texture(foam_texture, UV * 3.0 - vec2(time * 0.2, 0.0)).r;
        float foam = foam_noise * foam_pattern;
        
        // Apply foam at edges and shallow areas
        float foam_mask = fresnel * 0.7 + (1.0 - depth_fade) * 0.5;
        
        if (foam_mask > foam_threshold && foam > 0.4) {
            ALBEDO = mix(ALBEDO, foam_color.rgb, foam_mask);
            ROUGHNESS = mix(ROUGHNESS, 0.7, foam_mask);
            SPECULAR = mix(SPECULAR, 0.1, foam_mask);
        }
    }
    
    // Add caustics
    if (enable_caustics && depth_fade < 0.5) {
        float caustic1 = texture(foam_texture, UV * 4.0 + vec2(time * 0.05, time * 0.03)).r;
        float caustic2 = texture(foam_texture, UV * 3.0 - vec2(time * 0.07, time * 0.02)).r;
        float caustic = pow(caustic1 * caustic2, 2.0) * (1.0 - depth_fade);
        
        EMISSION += vec3(0.2, 0.4, 0.8) * caustic * 0.5;
    }
}
"""

func _get_foam_shader_code():
    """Get shader code for foam rendering"""
    return """
shader_type spatial;
render_mode blend_add, depth_draw_never, cull_back, unshaded;

uniform vec4 foam_color : source_color = vec4(1.0, 1.0, 1.0, 0.9);
uniform float time;
uniform sampler2D foam_texture : hint_default_white;

void vertex() {
    // Push foam slightly above surface
    VERTEX.y += 0.005;
}

void fragment() {
    float foam_noise = texture(foam_texture, UV * 5.0 + vec2(time * 0.1, 0.0)).r;
    float foam_pattern = texture(foam_texture, UV * 3.0 - vec2(time * 0.2, 0.0)).r;
    float foam = foam_noise * foam_pattern * COLOR.a;
    
    ALBEDO = foam_color.rgb;
    ALPHA = foam * foam_color.a;
    EMISSION = foam_color.rgb * 0.5;
}
"""

func _get_impostor_shader_code():
    """Get shader code for particle impostors (billboards)"""
    return """
shader_type spatial;
render_mode blend_mix, depth_prepass, cull_disabled;

uniform vec4 particle_color : source_color = vec4(0.0, 0.5, 1.0, 0.8);
uniform float time;
uniform vec3 camera_position;

void vertex() {
    // Billboard the quad to face camera
    vec3 up = vec3(0.0, 1.0, 0.0);
    vec3 forward = normalize(camera_position - VERTEX);
    vec3 right = normalize(cross(up, forward));
    up = cross(forward, right);
    
    vec3 pos = VERTEX;
    vec3 offset = VERTEX - MODEL_MATRIX[3].xyz;
    
    // Apply billboard transform
    VERTEX = MODEL_MATRIX[3].xyz;
    VERTEX += right * offset.x;
    VERTEX += up * offset.y;
    VERTEX += forward * offset.z * 0.1; // Flatten slightly
    
    // Add subtle animation
    VERTEX.y += sin(time * 2.0 + pos.x + pos.z) * 0.01;
}

void fragment() {
    // Calculate distance from fragment to center of quad
    vec2 center = vec2(0.5, 0.5);
    float dist = distance(UV, center) * 2.0;
    
    // Create soft circular shape
    float circle = 1.0 - smoothstep(0.8, 1.0, dist);
    
    // Add internal detail
    float detail = sin(dist * 3.1415) * 0.5 + 0.5;
    
    // Apply highlight in center
    float highlight = 1.0 - smoothstep(0.0, 0.3, dist);
    
    ALBEDO = particle_color.rgb;
    ALPHA = circle * particle_color.a;
    METALLIC = 0.1;
    ROUGHNESS = mix(0.2, 0.4, detail);
    SPECULAR = 0.5;
    
    // Add subtle emission for highlighting
    EMISSION = particle_color.rgb * highlight * 0.2;
}
"""

func _get_marching_cubes_edge_table():
    """Return edge table for marching cubes algorithm"""
    # This would typically contain a 256-entry array of integers
    # representing edge intersections for each cube configuration
    # For brevity, returning a placeholder
    var edge_table = []
    edge_table.resize(256)
    
    # Fill with actual values (first 16 entries shown as example)
    edge_table[0] = 0x0
    edge_table[1] = 0x109
    edge_table[2] = 0x203
    edge_table[3] = 0x30a
    edge_table[4] = 0x406
    edge_table[5] = 0x50f
    edge_table[6] = 0x605
    edge_table[7] = 0x70c
    edge_table[8] = 0x80c
    edge_table[9] = 0x905
    edge_table[10] = 0xa0f
    edge_table[11] = 0xb06
    edge_table[12] = 0xc0a
    edge_table[13] = 0xd03
    edge_table[14] = 0xe09
    edge_table[15] = 0xf00
    
    # Note: Complete table would have all 256 entries
    # For a complete implementation, load from a file or define the full array
    
    return edge_table

func _get_marching_cubes_tri_table():
    """Return triangle table for marching cubes algorithm"""
    # This would typically contain a 256-entry array of arrays
    # Each sub-array contains indices of up to 15 edges forming triangles
    # For brevity, returning a placeholder
    var tri_table = []
    tri_table.resize(256)
    
    # Fill with actual values (first entry shown as example)
    tri_table[0] = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
    tri_table[1] = [0, 8, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
    
    # Note: Complete table would have all 256 entries
    # For a complete implementation, load from a file or define the full array
    
    return tri_table

func set_simulation(sim):
    """Set the fluid simulation to render"""
    simulation = sim
    _needs_rebuild = true

func set_render_method(method):
    """Change the rendering method"""
    if method != render_method:
        render_method = method
        
        # Clean up existing instances
        if _particle_mesh_instance:
            _particle_mesh_instance.queue_free()
            _particle_mesh_instance = null
        
        if _surface_mesh_instance:
            _surface_mesh_instance.queue_free()
            _surface_mesh_instance = null
        
        # Initialize with new method
        _init_materials()
        _init_meshes()
        _needs_rebuild = true

func add_splash(position, force=5.0, size=1.0):
    """Create a splash effect at a specific position (for interaction)"""
    if simulation == null:
        return
        
    # Add particles for splash
    simulation.create_splash(position, size, int(20 * size), force)
    
    # Force surface rebuild
    _needs_rebuild = true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/fluid_3d_renderer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/fluid_simulation_core.gd
# SIZE: 26065 bytes
extends Node

class_name FluidSimulationCore

# Fluid simulation parameters
var gravity = Vector3(0, -9.8, 0)
var rest_density = 1000.0  # Water density at rest (kg/m^3)
var gas_constant = 2000.0  # For pressure calculation
var viscosity = 0.01  # Fluid viscosity
var surface_tension = 0.072  # Surface tension coefficient (N/m)
var restitution = 0.3  # Bounce factor when hitting boundaries
var particle_mass = 0.02  # Mass of each particle (kg)
var smooth_radius = 0.1  # Smoothing kernel radius
var time_step = 0.016  # 60fps simulation
var boundary_damping = 0.9  # Velocity damping when hitting boundaries

# Simulation space boundaries
var min_bounds = Vector3(-10, -10, -10)
var max_bounds = Vector3(10, 10, 10)

# Particles and forces
var particles = []
var grid_cells = {}
var cell_size = smooth_radius * 2.0

# Precomputed constants for SPH
var poly6_constant = 0.0
var spiky_gradient_constant = 0.0
var viscosity_laplacian_constant = 0.0

# Performance optimization
var use_spatial_hashing = true
var max_particles = 10000
var adaptive_time_step = true
var min_time_step = 0.005
var max_time_step = 0.03

# Visualization
var fluid_color = Color(0.2, 0.4, 0.8, 0.7)
var highlight_surface = true
var surface_detection_threshold = 0.7

# Signals
signal simulation_step_completed(particles)
signal particle_collision(particle, position)
signal particle_merged(particle1, particle2)
signal particle_split(original_particle, new_particles)

func _init():
    # Initialize SPH constants
    _init_sph_constants()
    
    # Initialize grid for spatial hashing
    if use_spatial_hashing:
        _init_spatial_grid()

func _init_sph_constants():
    # Poly6 kernel constant for density
    poly6_constant = 315.0 / (64.0 * PI * pow(smooth_radius, 9))
    
    # Spiky gradient constant for pressure
    spiky_gradient_constant = -45.0 / (PI * pow(smooth_radius, 6))
    
    # Viscosity laplacian constant
    viscosity_laplacian_constant = 45.0 / (PI * pow(smooth_radius, 6))

func _init_spatial_grid():
    grid_cells.clear()

func _ready():
    # Setup 3D scene if needed
    if Engine.is_editor_hint():
        return

func create_particles(positions, velocities=null, particle_count=100):
    """Create a batch of fluid particles at given positions with optional velocities"""
    var new_particles = []
    
    for i in range(min(positions.size(), particle_count)):
        var pos = positions[i]
        var vel = Vector3.ZERO
        if velocities != null and i < velocities.size():
            vel = velocities[i]
            
        var particle = {
            "position": pos,
            "velocity": vel,
            "force": Vector3.ZERO,
            "density": rest_density,
            "pressure": 0.0,
            "is_surface": false,
            "neighbors": [],
            "id": particles.size() + i,
            "color": fluid_color,
            "lifetime": 0.0,
            "temperature": 20.0,  # 20¬∞C
            "mass": particle_mass
        }
        
        new_particles.append(particle)
    
    particles.append_array(new_particles)
    
    # Limit max particles
    if particles.size() > max_particles:
        particles = particles.slice(particles.size() - max_particles, particles.size() - 1)
    
    return new_particles

func create_fluid_cube(min_pos, max_pos, spacing, initial_velocity=Vector3.ZERO):
    """Create a cube of fluid particles with specified spacing"""
    var positions = []
    var velocities = []
    
    for x in range(ceil((max_pos.x - min_pos.x) / spacing)):
        for y in range(ceil((max_pos.y - min_pos.y) / spacing)):
            for z in range(ceil((max_pos.z - min_pos.z) / spacing)):
                var pos = Vector3(
                    min_pos.x + x * spacing,
                    min_pos.y + y * spacing,
                    min_pos.z + z * spacing
                )
                positions.append(pos)
                velocities.append(initial_velocity)
    
    return create_particles(positions, velocities, positions.size())

func create_fluid_sphere(center, radius, spacing, initial_velocity=Vector3.ZERO):
    """Create a sphere of fluid particles with specified radius and spacing"""
    var positions = []
    var velocities = []
    
    # Calculate bounds for iteration
    var min_pos = Vector3(center.x - radius, center.y - radius, center.z - radius)
    var max_pos = Vector3(center.x + radius, center.y + radius, center.z + radius)
    
    # Iterate through a cube and keep points within sphere radius
    for x in range(ceil((max_pos.x - min_pos.x) / spacing)):
        for y in range(ceil((max_pos.y - min_pos.y) / spacing)):
            for z in range(ceil((max_pos.z - min_pos.z) / spacing)):
                var pos = Vector3(
                    min_pos.x + x * spacing,
                    min_pos.y + y * spacing,
                    min_pos.z + z * spacing
                )
                
                # Only include if within sphere radius
                if pos.distance_to(center) <= radius:
                    positions.append(pos)
                    velocities.append(initial_velocity)
    
    return create_particles(positions, velocities, positions.size())

func create_fluid_cylinder(center, radius, height, spacing, initial_velocity=Vector3.ZERO):
    """Create a cylinder of fluid particles with specified dimensions"""
    var positions = []
    var velocities = []
    
    # Calculate bounds for iteration
    var min_pos = Vector3(center.x - radius, center.y, center.z - radius)
    var max_pos = Vector3(center.x + radius, center.y + height, center.z + radius)
    
    # Iterate through a box and keep points within cylinder radius
    for x in range(ceil((max_pos.x - min_pos.x) / spacing)):
        for y in range(ceil((max_pos.y - min_pos.y) / spacing)):
            for z in range(ceil((max_pos.z - min_pos.z) / spacing)):
                var pos = Vector3(
                    min_pos.x + x * spacing,
                    min_pos.y + y * spacing,
                    min_pos.z + z * spacing
                )
                
                # Calculate horizontal distance from center axis
                var horizontal_dist = Vector2(pos.x - center.x, pos.z - center.z).length()
                
                # Only include if within cylinder radius
                if horizontal_dist <= radius:
                    positions.append(pos)
                    velocities.append(initial_velocity)
    
    return create_particles(positions, velocities, positions.size())

func create_fluid_2d_rect(min_pos, max_pos, spacing, initial_velocity=Vector2.ZERO):
    """Create a 2D rectangle of fluid particles (using only X,Y coordinates)"""
    var positions = []
    var velocities = []
    
    for x in range(ceil((max_pos.x - min_pos.x) / spacing)):
        for y in range(ceil((max_pos.y - min_pos.y) / spacing)):
            var pos = Vector3(
                min_pos.x + x * spacing, 
                min_pos.y + y * spacing,
                0  # 2D simulation so Z=0
            )
            positions.append(pos)
            velocities.append(Vector3(initial_velocity.x, initial_velocity.y, 0))
    
    return create_particles(positions, velocities, positions.size())

func create_wave(start_pos, width, height, wave_count, particle_count):
    """Create a wave pattern of fluid particles"""
    var positions = []
    var velocities = []
    
    for i in range(particle_count):
        var t = float(i) / particle_count
        var x = start_pos.x + t * width
        var y = start_pos.y + sin(t * wave_count * TAU) * height
        
        positions.append(Vector3(x, y, 0))
        velocities.append(Vector3(0.5, 0, 0))  # Moving right
    
    return create_particles(positions, velocities, positions.size())

func create_splash(center, radius, particle_count, splash_force):
    """Create a splash effect with particles moving outward"""
    var positions = []
    var velocities = []
    
    for i in range(particle_count):
        var angle = randf() * TAU
        var distance = randf() * radius
        
        # Position on circle with some randomness
        var x = center.x + cos(angle) * distance
        var y = center.y + sin(angle) * distance
        var z = center.z + (randf() * 2 - 1) * distance * 0.5
        
        positions.append(Vector3(x, y, z))
        
        # Velocity moving outward + upward
        var dir = Vector3(cos(angle), 0.5 + randf() * 0.5, sin(angle)).normalized()
        velocities.append(dir * splash_force * (0.8 + randf() * 0.4))
    
    var splash_particles = create_particles(positions, velocities, positions.size())
    
    # Set lifetime for splash particles
    for p in splash_particles:
        p.lifetime = 2.0 + randf() * 1.0  # 2-3 seconds lifetime
    
    return splash_particles

func add_force_field(center, radius, force_strength, falloff=1.0):
    """Add a force field affecting particles within radius"""
    for p in particles:
        var dist = p.position.distance_to(center)
        if dist < radius:
            var force_dir = (p.position - center).normalized()
            var force_magnitude = force_strength * pow(1.0 - dist/radius, falloff)
            p.force += force_dir * force_magnitude

func add_vortex(center, axis, radius, strength, falloff=1.0):
    """Add a vortex force around an axis"""
    for p in particles:
        var to_particle = p.position - center
        var dist = to_particle.length()
        
        if dist < radius and dist > 0.0001:
            var tangent = axis.cross(to_particle).normalized()
            var force_magnitude = strength * pow(1.0 - dist/radius, falloff)
            p.force += tangent * force_magnitude

func simulate_step(delta=null):
    """Run a single simulation step"""
    if delta == null:
        delta = time_step
    
    if adaptive_time_step:
        # Adjust time step based on maximum velocity
        var max_vel = 0.0
        for p in particles:
            max_vel = max(max_vel, p.velocity.length())
        
        # Scale time step inverse to max velocity (faster particles = smaller steps)
        if max_vel > 0.001:
            delta = clamp(smooth_radius / max_vel * 0.4, min_time_step, max_time_step)
        else:
            delta = max_time_step
    
    # Reset forces and update spatial grid
    _reset_forces()
    
    if use_spatial_hashing:
        _update_spatial_grid()
    
    # Find neighbors for all particles
    _find_neighbors()
    
    # Calculate density and pressure
    _calculate_density_pressure()
    
    # Detect surface particles
    if highlight_surface:
        _detect_surface_particles()
    
    # Calculate forces
    _calculate_forces()
    
    # Integrate forces to update positions
    _integrate(delta)
    
    # Handle boundary collisions
    _handle_boundary_collisions()
    
    # Handle merging and splitting
    _handle_merging_splitting()
    
    # Update lifetime and remove expired particles
    _update_particle_lifetime(delta)
    
    emit_signal("simulation_step_completed", particles)

func _reset_forces():
    """Reset forces for all particles and apply gravity"""
    for p in particles:
        p.force = gravity * p.mass
        p.neighbors.clear()

func _update_spatial_grid():
    """Update spatial grid for efficient neighbor search"""
    grid_cells.clear()
    
    for i in range(particles.size()):
        var p = particles[i]
        var cell_coord = _get_cell_coordinate(p.position)
        var cell_key = str(cell_coord.x) + "_" + str(cell_coord.y) + "_" + str(cell_coord.z)
        
        if not grid_cells.has(cell_key):
            grid_cells[cell_key] = []
        
        grid_cells[cell_key].append(i)

func _get_cell_coordinate(position):
    """Convert position to cell coordinate for spatial hashing"""
    return Vector3(
        floor(position.x / cell_size),
        floor(position.y / cell_size),
        floor(position.z / cell_size)
    )

func _find_neighbors():
    """Find neighboring particles for SPH calculations"""
    if use_spatial_hashing:
        _find_neighbors_spatial_hash()
    else:
        _find_neighbors_brute_force()

func _find_neighbors_spatial_hash():
    """Find neighbors using spatial hashing for efficiency"""
    for i in range(particles.size()):
        var p = particles[i]
        var cell_coord = _get_cell_coordinate(p.position)
        
        # Check surrounding cells (27 cells - current + 26 neighbors)
        for x in range(-1, 2):
            for y in range(-1, 2):
                for z in range(-1, 2):
                    var neighbor_coord = Vector3(
                        cell_coord.x + x,
                        cell_coord.y + y,
                        cell_coord.z + z
                    )
                    
                    var cell_key = str(neighbor_coord.x) + "_" + str(neighbor_coord.y) + "_" + str(neighbor_coord.z)
                    
                    if grid_cells.has(cell_key):
                        for j in grid_cells[cell_key]:
                            if i != j:  # Don't include self as neighbor
                                var p2 = particles[j]
                                var dist = p.position.distance_to(p2.position)
                                
                                if dist < smooth_radius:
                                    p.neighbors.append(j)

func _find_neighbors_brute_force():
    """Find neighbors using brute force approach (slower)"""
    for i in range(particles.size()):
        var p1 = particles[i]
        
        for j in range(particles.size()):
            if i != j:
                var p2 = particles[j]
                var dist = p1.position.distance_to(p2.position)
                
                if dist < smooth_radius:
                    p1.neighbors.append(j)

func _calculate_density_pressure():
    """Calculate density and pressure for all particles"""
    for i in range(particles.size()):
        var p = particles[i]
        
        # Start with self-density
        p.density = 0.0
        
        # Add density contribution from each neighbor
        for j in p.neighbors:
            var p2 = particles[j]
            var r = p.position.distance_to(p2.position)
            
            if r < smooth_radius:
                # Poly6 kernel for density
                var kernel_r = smooth_radius * smooth_radius - r * r
                p.density += p2.mass * poly6_constant * kernel_r * kernel_r * kernel_r
        
        # Minimum density to avoid division by zero
        p.density = max(p.density, 0.001)
        
        # Calculate pressure using equation of state
        p.pressure = gas_constant * (p.density - rest_density)

func _detect_surface_particles():
    """Detect which particles are on the fluid surface"""
    for i in range(particles.size()):
        var p = particles[i]
        
        # Count neighbors in all directions
        var neighbor_count = p.neighbors.size()
        
        # Surface particles have fewer neighbors
        p.is_surface = neighbor_count < 20  # This threshold may need tuning
        
        # Alternatively: Calculate normalized neighbor count
        var normalized_count = float(neighbor_count) / 26.0  # Max possible in grid
        p.is_surface = normalized_count < surface_detection_threshold

func _calculate_forces():
    """Calculate forces for SPH: pressure, viscosity, surface tension"""
    for i in range(particles.size()):
        var p = particles[i]
        var pressure_force = Vector3.ZERO
        var viscosity_force = Vector3.ZERO
        var surface_tension_force = Vector3.ZERO
        
        for j in p.neighbors:
            var p2 = particles[j]
            
            if p == p2:
                continue
                
            var r_vec = p.position - p2.position
            var r = r_vec.length()
            
            if r > 0.0001:  # Avoid division by zero
                var r_norm = r_vec / r
                
                # Pressure force using spiky kernel gradient
                var kernel_r = smooth_radius - r
                var pressure_kernel = spiky_gradient_constant * kernel_r * kernel_r
                
                # Symmetrized pressure force
                var shared_pressure = (p.pressure + p2.pressure) / (2.0 * p2.density)
                pressure_force -= r_norm * pressure_kernel * shared_pressure * p2.mass
                
                # Viscosity force using laplacian kernel
                var velocity_diff = p2.velocity - p.velocity
                viscosity_force += velocity_diff * viscosity_laplacian_constant * kernel_r * p2.mass / p2.density
                
                # Surface tension (for surface particles)
                if p.is_surface and p2.is_surface:
                    var surface_kernel = poly6_constant * pow(smooth_radius * smooth_radius - r * r, 3)
                    surface_tension_force -= r_norm * surface_tension * surface_kernel * p2.mass
        
        # Apply all forces
        p.force += pressure_force
        p.force += viscosity_force * viscosity
        p.force += surface_tension_force

func _integrate(delta):
    """Integrate forces to update velocity and position using Velocity Verlet"""
    for p in particles:
        var acceleration = p.force / p.mass
        
        # Update velocity (first half of Velocity Verlet)
        var half_delta_v = acceleration * (delta * 0.5)
        p.velocity += half_delta_v
        
        # Update position
        p.position += p.velocity * delta
        
        # Recalculate forces (typically done in the next simulation step)
        
        # Update velocity (second half of Velocity Verlet)
        # This second update will use the forces calculated in the next step
        # For simplicity, we approximate by using the same acceleration twice
        p.velocity += half_delta_v

func _handle_boundary_collisions():
    """Handle collisions with simulation boundaries"""
    for p in particles:
        var collision = false
        
        # Check each axis for collisions with boundaries
        for i in range(3):
            if p.position[i] < min_bounds[i]:
                p.position[i] = min_bounds[i]
                p.velocity[i] *= -restitution
                p.velocity *= boundary_damping
                collision = true
                
            elif p.position[i] > max_bounds[i]:
                p.position[i] = max_bounds[i]
                p.velocity[i] *= -restitution
                p.velocity *= boundary_damping
                collision = true
        
        if collision:
            emit_signal("particle_collision", p, p.position)

func _handle_merging_splitting():
    """Handle particle merging and splitting based on physical conditions"""
    # This is a simplified model - more sophisticated algorithms would be used
    # for production-quality simulations
    
    var merged_particles = []
    var i = 0
    
    while i < particles.size():
        if merged_particles.has(i):
            i += 1
            continue
            
        var p = particles[i]
        var merge_happened = false
        
        # Check neighbors for potential merging
        for j in p.neighbors:
            if j <= i or merged_particles.has(j):
                continue
                
            var p2 = particles[j]
            var rel_vel = p.velocity - p2.velocity
            var approach_speed = -rel_vel.dot((p.position - p2.position).normalized())
            
            # Merge if particles are close and moving towards each other slowly
            if approach_speed > 0 and approach_speed < 0.5:
                var dist = p.position.distance_to(p2.position)
                if dist < smooth_radius * 0.25:
                    # Merge particles
                    var merged_mass = p.mass + p2.mass
                    var merged_pos = (p.position * p.mass + p2.position * p2.mass) / merged_mass
                    var merged_vel = (p.velocity * p.mass + p2.velocity * p2.mass) / merged_mass
                    
                    p.position = merged_pos
                    p.velocity = merged_vel
                    p.mass = merged_mass
                    
                    merged_particles.append(j)
                    merge_happened = true
                    
                    emit_signal("particle_merged", p, p2)
        
        # Check for splitting
        if p.mass > particle_mass * 1.5:
            var stretch = p.velocity.length() * delta
            
            # Split if moving fast enough
            if stretch > smooth_radius * 0.5:
                # Create new particle from split
                var new_dir = p.velocity.normalized()
                var split_mass = p.mass * 0.4  # 40% of mass goes to new particle
                
                var new_pos = p.position + new_dir * smooth_radius * 0.6
                var new_vel = p.velocity * 1.1  # Slightly faster
                
                var new_particles = create_particles([new_pos], [new_vel], 1)
                new_particles[0].mass = split_mass
                
                # Update original particle
                p.mass -= split_mass
                p.velocity *= 0.9  # Slightly slower
                
                emit_signal("particle_split", p, new_particles)
        
        i += 1
    
    # Remove merged particles (from highest index to lowest to maintain valid indices)
    merged_particles.sort()
    merged_particles.invert()
    
    for idx in merged_particles:
        particles.remove(idx)

func _update_particle_lifetime(delta):
    """Update lifetime for temporary particles like splashes"""
    var particles_to_remove = []
    
    for i in range(particles.size()):
        var p = particles[i]
        
        # Skip particles with no lifetime (permanent particles)
        if p.lifetime <= 0.0:
            continue
            
        # Decrease lifetime
        p.lifetime -= delta
        
        # Mark for removal if expired
        if p.lifetime <= 0.0:
            particles_to_remove.append(i)
            
        # Fade out color as lifetime decreases
        if p.lifetime < 1.0:
            p.color.a = p.lifetime
    
    # Remove expired particles (from highest index to lowest)
    particles_to_remove.sort()
    particles_to_remove.invert()
    
    for idx in particles_to_remove:
        particles.remove(idx)

func _convert_to_2d():
    """Convert 3D simulation to 2D by locking z-coordinate"""
    for p in particles:
        p.position.z = 0
        p.velocity.z = 0
        p.force.z = 0
    gravity.z = 0

func set_simulation_2d(is_2d):
    """Set simulation to 2D mode"""
    if is_2d:
        _convert_to_2d()
        # Make z-bounds very small to ensure particles stay on z=0 plane
        min_bounds.z = -0.01
        max_bounds.z = 0.01
    else:
        # Reset to default 3D bounds
        min_bounds = Vector3(-10, -10, -10)
        max_bounds = Vector3(10, 10, 10)

func get_particles_for_rendering():
    """Get particles in format suitable for rendering"""
    return particles

func get_surface_particles():
    """Get only surface particles"""
    var surface = []
    for p in particles:
        if p.is_surface:
            surface.append(p)
    return surface

func clear_particles():
    """Remove all particles"""
    particles.clear()
    grid_cells.clear()

func get_particle_count():
    """Get current number of particles"""
    return particles.size()

func marching_cubes_surface(grid_resolution=20):
    """Generate a surface mesh using marching cubes algorithm"""
    # This would typically be implemented in a separate mesh generation class
    # Here we'll provide a simplified placeholder
    
    var implicit_surface = {}
    var grid_size = (max_bounds - min_bounds) / grid_resolution
    
    # Build implicit surface values
    for x in range(grid_resolution + 1):
        for y in range(grid_resolution + 1):
            for z in range(grid_resolution + 1):
                var pos = min_bounds + Vector3(x, y, z) * grid_size
                var density = 0.0
                
                # Calculate density at this position by summing contributions
                for p in particles:
                    var r = pos.distance_to(p.position)
                    if r < smooth_radius:
                        var kernel_r = smooth_radius * smooth_radius - r * r
                        density += p.mass * poly6_constant * kernel_r * kernel_r * kernel_r
                
                var key = Vector3(x, y, z)
                implicit_surface[key] = density
    
    # This would normally return vertices and triangles for the isosurface
    return implicit_surface

# Helper functions for fluid dynamics

func calculate_vorticity(particle_idx):
    """Calculate vorticity (curl of velocity field) at a particle"""
    var p = particles[particle_idx]
    var curl = Vector3.ZERO
    
    for j in p.neighbors:
        var p2 = particles[j]
        var r = p.position - p2.position
        var vel_diff = p2.velocity - p.velocity
        
        # Cross product for curl
        curl += r.cross(vel_diff) / (r.length_squared() + 0.0001)
    
    return curl

func add_vorticity_confinement(strength=0.1):
    """Add vorticity confinement force to enhance turbulence"""
    for i in range(particles.size()):
        var curl = calculate_vorticity(i)
        var curl_length = curl.length()
        
        if curl_length > 0.0001:
            var n = curl / curl_length
            particles[i].force += n.cross(curl) * strength
    
func apply_wave_generator(origin, direction, amplitude, frequency, time):
    """Apply a wave generating force to particles"""
    for p in particles:
        var dist = p.position - origin
        var along_dir = dist.dot(direction)
        
        if along_dir > 0 and along_dir < 10.0:
            var phase = frequency * (time - along_dir / 5.0)
            var wave_height = amplitude * sin(phase * TAU)
            p.force.y += wave_height * 20.0  # Arbitrary scale factor
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/fluid_simulation_core.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/fluid_simulation_demo.gd
# SIZE: 18955 bytes
extends Node

class_name FluidSimulationDemo

# Reference to the simulation components
var simulation: FluidSimulationCore
var renderer2D: Fluid2DRenderer = null
var renderer3D: Fluid3DRenderer = null

# Demo properties
@export_category("Demo Setup")
@export var use_2d_mode: bool = true
@export var particle_count: int = 1000
@export var auto_run: bool = true
@export var simulation_speed: float = 1.0
@export var demo_type: int = 0  # 0=Water Tank, 1=Wave, 2=Splash, 3=Dam Break, 4=Fountain, 5=Vortex

# Interactive properties
@export_category("Interaction")
@export var enable_interaction: bool = true
@export var interaction_strength: float = 5.0
@export var click_to_splash: bool = true
@export var drag_to_move: bool = true
@export var use_physics_objects: bool = true

# Demo-specific settings
@export_category("Demo Settings")
@export var tank_size: Vector3 = Vector3(10, 5, 5)
@export var wave_amplitude: float = 0.5
@export var wave_frequency: float = 1.0
@export var splash_size: float = 0.5
@export var fountain_height: float = 5.0
@export var vortex_strength: float = 3.0

# Debug visualization
@export_category("Debug")
@export var show_velocities: bool = false
@export var show_forces: bool = false
@export var show_boundaries: bool = true
@export var show_performance: bool = true

# Internal variables
var _time: float = 0.0
var _fps_display: Label
var _particle_count_display: Label
var _simulation_time_display: Label
var _demo_running: bool = false
var _paused: bool = false
var _last_mouse_position: Vector2 = Vector2.ZERO
var _physics_objects = []
var _user_interaction_force: Vector3 = Vector3.ZERO
var _frame_times = []
var _last_click_time: float = 0.0

func _ready():
    # Initialize simulation
    simulation = FluidSimulationCore.new()
    add_child(simulation)
    
    # Initialize renderer based on mode
    if use_2d_mode:
        _init_2d_renderer()
    else:
        _init_3d_renderer()
    
    # Setup UI
    _setup_ui()
    
    # Start selected demo
    if auto_run:
        start_demo()

func _init_2d_renderer():
    renderer2D = Fluid2DRenderer.new()
    add_child(renderer2D)
    renderer2D.set_simulation(simulation)
    
    # Set simulation to 2D mode
    simulation.set_simulation_2d(true)
    
    # Adjust bounds to match screen size
    var viewport_size = get_viewport().get_visible_rect().size
    var aspect_ratio = viewport_size.x / viewport_size.y
    
    var bounds_y = 10.0  # Arbitrary unit size
    var bounds_x = bounds_y * aspect_ratio
    
    simulation.min_bounds = Vector3(-bounds_x/2, -bounds_y/2, -0.1)
    simulation.max_bounds = Vector3(bounds_x/2, bounds_y/2, 0.1)

func _init_3d_renderer():
    renderer3D = Fluid3DRenderer.new()
    add_child(renderer3D)
    renderer3D.set_simulation(simulation)
    
    # Configure camera for 3D view
    var camera = get_viewport().get_camera_3d()
    if camera:
        camera.global_position = Vector3(0, 5, 10)
        camera.look_at(Vector3(0, 0, 0))

func _setup_ui():
    # Create basic UI for debugging and controls
    var control = Control.new()
    control.anchor_right = 1.0
    control.anchor_bottom = 1.0
    add_child(control)
    
    # Performance display
    var performance_container = VBoxContainer.new()
    performance_container.anchor_left = 1.0
    performance_container.anchor_right = 1.0
    performance_container.offset_left = -150
    performance_container.offset_top = 10
    control.add_child(performance_container)
    
    _fps_display = Label.new()
    _fps_display.text = "FPS: 60"
    performance_container.add_child(_fps_display)
    
    _particle_count_display = Label.new()
    _particle_count_display.text = "Particles: 0"
    performance_container.add_child(_particle_count_display)
    
    _simulation_time_display = Label.new()
    _simulation_time_display.text = "Sim Time: 0.0ms"
    performance_container.add_child(_simulation_time_display)
    
    # Controls
    var button_container = HBoxContainer.new()
    button_container.anchor_top = 1.0
    button_container.anchor_bottom = 1.0
    button_container.anchor_right = 1.0
    button_container.offset_top = -50
    button_container.alignment = BoxContainer.ALIGNMENT_CENTER
    control.add_child(button_container)
    
    # Demo selector
    var demo_selector = OptionButton.new()
    demo_selector.add_item("Water Tank")
    demo_selector.add_item("Wave")
    demo_selector.add_item("Splash")
    demo_selector.add_item("Dam Break")
    demo_selector.add_item("Fountain")
    demo_selector.add_item("Vortex")
    demo_selector.selected = demo_type
    demo_selector.custom_minimum_size.x = 120
    button_container.add_child(demo_selector)
    demo_selector.connect("item_selected", _on_demo_selected)
    
    # Start button
    var start_button = Button.new()
    start_button.text = "Start"
    start_button.custom_minimum_size.x = 80
    button_container.add_child(start_button)
    start_button.connect("pressed", start_demo)
    
    # Reset button
    var reset_button = Button.new()
    reset_button.text = "Reset"
    reset_button.custom_minimum_size.x = 80
    button_container.add_child(reset_button)
    reset_button.connect("pressed", reset_demo)
    
    # Pause button
    var pause_button = Button.new()
    pause_button.text = "Pause"
    pause_button.custom_minimum_size.x = 80
    button_container.add_child(pause_button)
    pause_button.connect("pressed", toggle_pause)
    
    # 2D/3D toggle
    var mode_toggle = Button.new()
    mode_toggle.text = "2D/3D"
    mode_toggle.custom_minimum_size.x = 80
    button_container.add_child(mode_toggle)
    mode_toggle.connect("pressed", toggle_mode)
    
    # Hide UI if not showing performance
    if not show_performance:
        _fps_display.visible = false
        _particle_count_display.visible = false
        _simulation_time_display.visible = false

func _process(delta):
    if _paused:
        return
    
    # Update time counter
    _time += delta
    
    # Run simulation steps
    if _demo_running:
        var sim_start_time = Time.get_ticks_usec()
        
        # Run simulation at specified speed
        simulation.simulate_step(delta * simulation_speed)
        
        var sim_end_time = Time.get_ticks_usec()
        var sim_time_ms = (sim_end_time - sim_start_time) / 1000.0
        
        # Update performance displays
        if show_performance:
            # Track frame times for smoother FPS display
            _frame_times.append(1.0 / delta)
            if _frame_times.size() > 30:
                _frame_times.pop_front()
            
            var avg_fps = 0
            for fps in _frame_times:
                avg_fps += fps
            avg_fps /= _frame_times.size()
            
            _fps_display.text = "FPS: " + str(int(avg_fps))
            _particle_count_display.text = "Particles: " + str(simulation.get_particle_count())
            _simulation_time_display.text = "Sim Time: " + str(sim_time_ms).pad_decimals(1) + "ms"
    
    # Update demo-specific effects
    if _demo_running:
        match demo_type:
            1:  # Wave
                _update_wave_demo(delta)
            4:  # Fountain
                _update_fountain_demo(delta)
            5:  # Vortex
                _update_vortex_demo(delta)
    
    # Handle interactive physics objects
    if use_physics_objects and _physics_objects.size() > 0:
        _update_physics_objects(delta)
    
    # Apply user interaction forces
    if _user_interaction_force != Vector3.ZERO:
        simulation.add_force_field(
            _user_interaction_force, 
            particle_size * 10, 
            interaction_strength * 10, 
            1.0
        )
        _user_interaction_force = Vector3.ZERO

func _input(event):
    if not enable_interaction or not _demo_running:
        return
    
    # Handle mouse interaction
    if event is InputEventMouseButton:
        if event.button_index == MOUSE_BUTTON_LEFT and event.pressed:
            if click_to_splash and _time - _last_click_time > 0.2:
                _last_click_time = _time
                var click_pos = _get_world_position_from_mouse()
                _create_splash_at_position(click_pos, interaction_strength, splash_size)
        
        # Start dragging
        if event.button_index == MOUSE_BUTTON_LEFT:
            _last_mouse_position = event.position
    
    # Handle mouse drag
    elif event is InputEventMouseMotion and drag_to_move:
        if Input.is_mouse_button_pressed(MOUSE_BUTTON_LEFT):
            var mouse_pos = _get_world_position_from_mouse()
            var force_dir = Vector3.ZERO
            
            if use_2d_mode:
                # In 2D, create a force in the direction of mouse movement
                var current_mouse_screen = event.position
                var movement = current_mouse_screen - _last_mouse_position
                _last_mouse_position = current_mouse_screen
                
                if movement.length_squared() > 4:  # Minimum movement threshold
                    force_dir = Vector3(movement.x, movement.y, 0).normalized()
                    _user_interaction_force = mouse_pos + force_dir * 0.2
            else:
                # In 3D, pull particles toward mouse position
                _user_interaction_force = mouse_pos

func _get_world_position_from_mouse():
    var mouse_pos = get_viewport().get_mouse_position()
    
    if use_2d_mode:
        # Convert 2D screen position to simulation coordinates
        var viewport_size = get_viewport().get_visible_rect().size
        var x_ratio = mouse_pos.x / viewport_size.x
        var y_ratio = mouse_pos.y / viewport_size.y
        
        var sim_width = simulation.max_bounds.x - simulation.min_bounds.x
        var sim_height = simulation.max_bounds.y - simulation.min_bounds.y
        
        var world_x = simulation.min_bounds.x + sim_width * x_ratio
        var world_y = simulation.min_bounds.y + sim_height * y_ratio
        
        return Vector3(world_x, world_y, 0)
    else:
        # Cast ray into 3D scene
        var camera = get_viewport().get_camera_3d()
        if camera:
            var from = camera.project_ray_origin(mouse_pos)
            var to = from + camera.project_ray_normal(mouse_pos) * 100
            
            # Intersect with a plane at y=0 for simplicity
            var plane = Plane(Vector3.UP, 0)
            var intersection = plane.intersects_ray(from, to - from)
            
            if intersection:
                return intersection
        
        return Vector3.ZERO

func _create_splash_at_position(position, strength, size):
    var particle_count = int(50 * size)
    simulation.create_splash(position, size, particle_count, strength)
    
    # Apply to 2D renderer if available
    if renderer2D:
        renderer2D.add_ripple_at_position(Vector2(position.x, position.y), strength, size)
    
    # Apply to 3D renderer if available
    if renderer3D:
        renderer3D.add_splash(position, strength, size)

func _update_wave_demo(delta):
    # Generate continuous waves
    var origin = Vector3(simulation.min_bounds.x, 0, 0)
    var direction = Vector3(1, 0, 0)
    
    simulation.apply_wave_generator(
        origin,
        direction,
        wave_amplitude,
        wave_frequency,
        _time
    )

func _update_fountain_demo(delta):
    # Continuous fountain from center bottom
    var fountain_pos = Vector3(0, simulation.min_bounds.y, 0)
    var spawn_interval = 0.05
    
    # Spawn particles periodically
    if int(_time / spawn_interval) > int((_time - delta) / spawn_interval):
        var particle_count = 5
        var positions = []
        var velocities = []
        
        for i in range(particle_count):
            var angle = randf() * TAU
            var radius = randf() * 0.2
            
            var pos = fountain_pos + Vector3(cos(angle) * radius, 0, sin(angle) * radius)
            var vel = Vector3(cos(angle) * 0.5, fountain_height, sin(angle) * 0.5)
            
            positions.append(pos)
            velocities.append(vel)
        
        simulation.create_particles(positions, velocities, particle_count)

func _update_vortex_demo(delta):
    # Create a vortex in the center
    var center = Vector3(0, 0, 0)
    var axis = Vector3(0, 1, 0)  # Vertical axis
    
    simulation.add_vortex(
        center,
        axis,
        tank_size.x * 0.8,
        vortex_strength,
        1.5
    )

func _update_physics_objects(delta):
    # Update positions of physics objects
    for obj in _physics_objects:
        # Apply gravity
        obj.velocity += simulation.gravity * delta
        
        # Update position
        obj.position += obj.velocity * delta
        
        # Check bounds collision
        for i in range(3):
            if obj.position[i] - obj.radius < simulation.min_bounds[i]:
                obj.position[i] = simulation.min_bounds[i] + obj.radius
                obj.velocity[i] *= -0.7  # Bounce with damping
            elif obj.position[i] + obj.radius > simulation.max_bounds[i]:
                obj.position[i] = simulation.max_bounds[i] - obj.radius
                obj.velocity[i] *= -0.7  # Bounce with damping
        
        # Interact with fluid particles
        simulation.add_force_field(
            obj.position,
            obj.radius * 2,
            obj.velocity.length() * 2,
            1.5
        )

func start_demo():
    # Clear existing particles
    simulation.clear_particles()
    
    # Reset time
    _time = 0.0
    
    # Remove any physics objects
    _physics_objects.clear()
    
    # Initialize selected demo
    match demo_type:
        0:  # Water Tank
            _init_water_tank_demo()
        1:  # Wave
            _init_wave_demo()
        2:  # Splash
            _init_splash_demo()
        3:  # Dam Break
            _init_dam_break_demo()
        4:  # Fountain
            _init_fountain_demo()
        5:  # Vortex
            _init_vortex_demo()
    
    _demo_running = true
    _paused = false

func reset_demo():
    start_demo()

func toggle_pause():
    _paused = !_paused

func toggle_mode():
    use_2d_mode = !use_2d_mode
    
    # Clean up existing renderer
    if renderer2D:
        renderer2D.queue_free()
        renderer2D = null
    
    if renderer3D:
        renderer3D.queue_free()
        renderer3D = null
    
    # Initialize new renderer
    if use_2d_mode:
        _init_2d_renderer()
    else:
        _init_3d_renderer()
    
    # Restart demo
    start_demo()

func _init_water_tank_demo():
    # Create a tank of water particles
    var tank_min = simulation.min_bounds + Vector3(1, 1, 1)
    var tank_max = Vector3(
        simulation.max_bounds.x - 1,
        tank_min.y + tank_size.y * 0.6,
        simulation.max_bounds.z - 1
    )
    
    var spacing = simulation.smooth_radius * 0.8
    simulation.create_fluid_cube(tank_min, tank_max, spacing)
    
    # Add a few physics objects if enabled
    if use_physics_objects:
        _add_physics_objects(3)

func _init_wave_demo():
    # Create a flat water surface
    var tank_min = Vector3(
        simulation.min_bounds.x + 1,
        0,
        simulation.min_bounds.z + 1
    )
    var tank_max = Vector3(
        simulation.max_bounds.x - 1,
        0.5,
        simulation.max_bounds.z - 1
    )
    
    var spacing = simulation.smooth_radius * 0.8
    simulation.create_fluid_cube(tank_min, tank_max, spacing)
    
    # If 2D mode, create a wave shape
    if use_2d_mode:
        var width = simulation.max_bounds.x - simulation.min_bounds.x - 2
        simulation.create_wave(
            Vector3(simulation.min_bounds.x + 1, 0, 0),
            width,
            wave_amplitude,
            3,  # 3 complete waves
            particle_count
        )

func _init_splash_demo():
    # Create a pool of water with a central splash
    var tank_min = Vector3(
        simulation.min_bounds.x + 1,
        simulation.min_bounds.y + 1,
        simulation.min_bounds.z + 1
    )
    var tank_max = Vector3(
        simulation.max_bounds.x - 1,
        tank_min.y + 1,
        simulation.max_bounds.z - 1
    )
    
    var spacing = simulation.smooth_radius * 0.8
    simulation.create_fluid_cube(tank_min, tank_max, spacing)
    
    # Create a splash in the center
    var center = Vector3(0, tank_max.y + 1, 0)
    simulation.create_splash(center, 1.0, 100, 3.0)

func _init_dam_break_demo():
    # Create a column of water on one side that will collapse
    var tank_width = simulation.max_bounds.x - simulation.min_bounds.x - 2
    var dam_position = simulation.min_bounds.x + tank_width * 0.3
    
    var dam_min = Vector3(
        simulation.min_bounds.x + 1,
        simulation.min_bounds.y + 1,
        simulation.min_bounds.z + 1
    )
    var dam_max = Vector3(
        dam_position,
        simulation.max_bounds.y - 1,
        simulation.max_bounds.z - 1
    )
    
    var spacing = simulation.smooth_radius * 0.8
    simulation.create_fluid_cube(dam_min, dam_max, spacing)

func _init_fountain_demo():
    # Start with empty tank, fountain will generate particles
    var tank_min = Vector3(
        simulation.min_bounds.x + 1,
        simulation.min_bounds.y + 1,
        simulation.min_bounds.z + 1
    )
    var tank_max = Vector3(
        simulation.max_bounds.x - 1,
        tank_min.y + 0.5,
        simulation.max_bounds.z - 1
    )
    
    var spacing = simulation.smooth_radius * 0.8
    simulation.create_fluid_cube(tank_min, tank_max, spacing, Vector3.ZERO)

func _init_vortex_demo():
    # Create a pool of water for the vortex
    var tank_min = Vector3(
        simulation.min_bounds.x + 1,
        simulation.min_bounds.y + 1,
        simulation.min_bounds.z + 1
    )
    var tank_max = Vector3(
        simulation.max_bounds.x - 1,
        tank_min.y + 2,
        simulation.max_bounds.z - 1
    )
    
    var spacing = simulation.smooth_radius * 0.8
    simulation.create_fluid_cube(tank_min, tank_max, spacing)
    
    # Add initial swirl velocity
    for p in simulation.particles:
        var to_center = Vector3.ZERO - p.position
        to_center.y = 0  # Keep horizontal
        var dist = to_center.length()
        
        if dist > 0.001:
            var tangent = Vector3(to_center.z, 0, -to_center.x).normalized()
            p.velocity = tangent * min(1.0, 3.0 / dist) * vortex_strength * 0.2

func _add_physics_objects(count):
    for i in range(count):
        var obj = {
            "position": Vector3(
                randf_range(simulation.min_bounds.x + 2, simulation.max_bounds.x - 2),
                simulation.max_bounds.y - 1,
                randf_range(simulation.min_bounds.z + 2, simulation.max_bounds.z - 2)
            ),
            "velocity": Vector3.ZERO,
            "radius": randf_range(0.3, 0.7),
            "mass": 1.0
        }
        
        _physics_objects.append(obj)

func _on_demo_selected(index):
    demo_type = index
    if _demo_running:
        start_demo()
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/fluid_simulation_demo.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/function_grid_manager.gd
# SIZE: 30276 bytes
extends Node

class_name FunctionGridManager

# ----- GRID SETTINGS -----
@export_category("Grid Settings")
@export var grid_size: Vector2i = Vector2i(4, 4)  # 4x4 grid by default
@export var enable_dynamic_resizing: bool = true
@export var min_grid_size: Vector2i = Vector2i(2, 2)
@export var max_grid_size: Vector2i = Vector2i(9, 9)

# ----- REFRESH SETTINGS -----
@export_category("Refresh Settings")
@export var auto_refresh_enabled: bool = true
@export var refresh_interval: float = 60.0  # Default: 1 minute
@export var staggered_refresh: bool = true
@export var minimum_refresh_interval: float = 5.0  # Seconds
@export var enable_per_cell_refresh_rates: bool = true

# ----- COMPRESSION SETTINGS -----
@export_category("Compression Settings")
@export var enable_data_compression: bool = true
@export var compression_level: int = 6  # 0-9, higher = more compression
@export var compressed_storage_path: String = "user://function_grid_compressed/"
@export var apply_delta_compression: bool = true  # Only store changes

# ----- STATE VARIABLES -----
var function_grid = []  # 2D array of function cells
var cell_states = {}    # Dictionary of cell states
var cell_refresh_timers = {}
var main_refresh_timer: Timer
var precise_timing_system = null
var turn_controller = null
var blink_controller = null
var translation_system = null

# ----- CELL STATE CONSTANTS -----
enum CellState {
    IDLE,
    ACTIVE,
    PROCESSING,
    ERROR,
    DISABLED,
    HIGHLIGHTED
}

# ----- SIGNALS -----
signal grid_initialized(width, height)
signal grid_resized(old_size, new_size)
signal cell_refreshed(x, y, function_id)
signal cell_state_changed(x, y, old_state, new_state)
signal compression_completed(compression_ratio, bytes_saved)
signal function_executed(function_id, result)
signal all_cells_refreshed()

# ----- INITIALIZATION -----
func _ready():
    # Find related systems
    _find_systems()
    
    # Initialize the function grid
    _initialize_grid()
    
    # Set up refresh timer
    _setup_refresh_timer()
    
    # Register with turn controller if available
    if turn_controller:
        turn_controller.register_system(self)
    
    # Connect to precise timing if available
    if precise_timing_system:
        _connect_precise_timing()
    
    print("Function Grid Manager initialized")
    print("Grid size: " + str(grid_size.x) + "x" + str(grid_size.y))
    print("Refresh interval: " + str(refresh_interval) + "s")

func _find_systems():
    # Find turn controller
    turn_controller = get_node_or_null("/root/TurnController")
    if not turn_controller:
        turn_controller = _find_node_by_class(get_tree().root, "TurnController")
    
    # Find precise timing system
    precise_timing_system = get_node_or_null("/root/PreciseTimingSystem")
    if not precise_timing_system:
        precise_timing_system = _find_node_by_class(get_tree().root, "PreciseTimingSystem")
    
    # Find blink controller
    blink_controller = get_node_or_null("/root/BlinkAnimationController")
    if not blink_controller:
        blink_controller = _find_node_by_class(get_tree().root, "BlinkAnimationController")
    
    # Find translation system
    translation_system = get_node_or_null("/root/TranslationSystem")
    if not translation_system:
        translation_system = _find_node_by_class(get_tree().root, "TranslationSystem")
    
    print("Systems found - Turn Controller: %s, Precise Timing: %s, Blink Controller: %s, Translation: %s" % [
        "Yes" if turn_controller else "No",
        "Yes" if precise_timing_system else "No",
        "Yes" if blink_controller else "No",
        "Yes" if translation_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_grid():
    # Initialize the function grid with the specified size
    function_grid = []
    cell_states = {}
    
    for x in range(grid_size.x):
        var column = []
        for y in range(grid_size.y):
            # Create a new cell with default function
            var cell = {
                "function_id": _generate_cell_id(x, y),
                "function_name": "func_" + str(x) + "_" + str(y),
                "function": Callable(),
                "last_refresh": 0,
                "refresh_count": 0,
                "last_result": null,
                "metadata": {
                    "position": Vector2i(x, y),
                    "created_at": Time.get_unix_time_from_system(),
                    "tags": []
                }
            }
            
            column.append(cell)
            
            # Set initial state
            _set_cell_state(x, y, CellState.IDLE)
            
            # Set up individual refresh timer if enabled
            if enable_per_cell_refresh_rates:
                _setup_cell_refresh_timer(x, y)
        
        function_grid.append(column)
    
    emit_signal("grid_initialized", grid_size.x, grid_size.y)
    print("Grid initialized with size " + str(grid_size.x) + "x" + str(grid_size.y))

func _setup_refresh_timer():
    # Set up the main refresh timer
    main_refresh_timer = Timer.new()
    main_refresh_timer.wait_time = refresh_interval
    main_refresh_timer.one_shot = false
    main_refresh_timer.connect("timeout", Callable(self, "_on_refresh_timer_timeout"))
    add_child(main_refresh_timer)
    
    if auto_refresh_enabled:
        main_refresh_timer.start()

func _setup_cell_refresh_timer(x: int, y: int):
    # Set up individual refresh timer for a cell
    var timer = Timer.new()
    var cell_id = _generate_cell_id(x, y)
    
    # Calculate a slightly different interval for each cell if staggered
    var base_interval = refresh_interval
    if staggered_refresh:
        # Add a slight offset based on position
        var offset = (x * y * 0.1) % (refresh_interval * 0.2)
        base_interval += offset
    
    timer.wait_time = base_interval
    timer.one_shot = false
    timer.connect("timeout", Callable(self, "_on_cell_refresh_timeout").bind(x, y))
    add_child(timer)
    
    cell_refresh_timers[cell_id] = timer
    
    if auto_refresh_enabled:
        timer.start()

func _connect_precise_timing():
    # Connect to precise timing system events
    
    # Register for minute markers
    if precise_timing_system.has_method("register_minute_callback"):
        for minute in [0, 15, 30, 45]:
            precise_timing_system.register_minute_callback(-1, minute, func(h, m):
                # Refresh a quarter of the grid every 15 minutes
                var section = minute / 15
                _refresh_grid_section(section)
            )
    
    # Set up special timing for turn 15
    if precise_timing_system.has_method("register_time_callback"):
        precise_timing_system.register_time_callback(15, 0, 0, func(h, m, s):
            # Special grid refresh behavior at exactly 15:00
            print("Executing special grid refresh at exactly 15:00")
            _full_grid_refresh_sequence()
        )

# ----- GRID MANAGEMENT -----
func resize_grid(new_size: Vector2i) -> bool:
    # Resize the function grid to a new size
    if not enable_dynamic_resizing:
        print("Dynamic grid resizing is disabled")
        return false
    
    # Validate new size
    if new_size.x < min_grid_size.x or new_size.y < min_grid_size.y or 
       new_size.x > max_grid_size.x or new_size.y > max_grid_size.y:
        print("Invalid grid size: " + str(new_size.x) + "x" + str(new_size.y))
        return false
    
    var old_size = grid_size
    grid_size = new_size
    
    print("Resizing grid from " + str(old_size.x) + "x" + str(old_size.y) + 
          " to " + str(new_size.x) + "x" + str(new_size.y))
    
    # Save existing cell data
    var existing_cells = {}
    for x in range(min(old_size.x, new_size.x)):
        for y in range(min(old_size.y, new_size.y)):
            var cell_id = _generate_cell_id(x, y)
            existing_cells[cell_id] = function_grid[x][y]
    
    # Re-initialize the grid with new size
    _initialize_grid()
    
    # Restore existing cell data
    for x in range(min(old_size.x, new_size.x)):
        for y in range(min(old_size.y, new_size.y)):
            var cell_id = _generate_cell_id(x, y)
            if existing_cells.has(cell_id):
                function_grid[x][y] = existing_cells[cell_id]
    
    emit_signal("grid_resized", old_size, new_size)
    
    return true

func _generate_cell_id(x: int, y: int) -> String:
    # Generate a unique ID for a cell
    return "cell_" + str(x) + "_" + str(y)

func get_cell(x: int, y: int) -> Dictionary:
    # Get a cell at specified coordinates
    if _validate_coordinates(x, y):
        return function_grid[x][y].duplicate()
    
    return {}

func get_cell_state(x: int, y: int):
    # Get the state of a cell
    var cell_id = _generate_cell_id(x, y)
    if cell_states.has(cell_id):
        return cell_states[cell_id]
    
    return CellState.DISABLED

func _set_cell_state(x: int, y: int, new_state):
    # Set the state of a cell
    var cell_id = _generate_cell_id(x, y)
    var old_state = cell_states.get(cell_id, CellState.DISABLED)
    
    if old_state != new_state:
        cell_states[cell_id] = new_state
        emit_signal("cell_state_changed", x, y, old_state, new_state)
        
        # Visual feedback with blink controller if available
        if blink_controller and new_state == CellState.ACTIVE:
            blink_controller.trigger_blink(cell_id)
        elif blink_controller and new_state == CellState.ERROR:
            blink_controller.trigger_flicker(cell_id, 2)
    
    return new_state

func _validate_coordinates(x: int, y: int) -> bool:
    # Validate if coordinates are within grid bounds
    return x >= 0 and x < grid_size.x and y >= 0 and y < grid_size.y

# ----- FUNCTION MANAGEMENT -----
func register_function(x: int, y: int, function_name: String, function: Callable, metadata: Dictionary = {}) -> bool:
    # Register a function at specified coordinates
    if not _validate_coordinates(x, y):
        print("Invalid coordinates: " + str(x) + "," + str(y))
        return false
    
    var cell = function_grid[x][y]
    cell.function_name = function_name
    cell.function = function
    
    # Merge metadata
    for key in metadata:
        cell.metadata[key] = metadata[key]
    
    print("Registered function '" + function_name + "' at " + str(x) + "," + str(y))
    
    # Change state to idle (or active if it's already processing)
    if get_cell_state(x, y) != CellState.PROCESSING:
        _set_cell_state(x, y, CellState.IDLE)
    
    return true

func execute_function(x: int, y: int, args: Array = []) -> Variant:
    # Execute a function at specified coordinates
    if not _validate_coordinates(x, y):
        print("Invalid coordinates: " + str(x) + "," + str(y))
        return null
    
    var cell = function_grid[x][y]
    var function = cell.function
    
    if not function.is_valid():
        print("No valid function at " + str(x) + "," + str(y))
        _set_cell_state(x, y, CellState.ERROR)
        return null
    
    print("Executing function '" + cell.function_name + "' at " + str(x) + "," + str(y))
    
    # Set state to processing
    _set_cell_state(x, y, CellState.PROCESSING)
    
    var result = null
    try:
        # Execute the function with provided arguments
        if args.size() > 0:
            result = function.callv(args)
        else:
            result = function.call()
        
        # Store result and update state
        cell.last_result = result
        cell.last_refresh = Time.get_unix_time_from_system()
        cell.refresh_count += 1
        
        _set_cell_state(x, y, CellState.ACTIVE)
        
        # Emit signal
        emit_signal("function_executed", cell.function_id, result)
    except Exception as e:
        print("Error executing function at " + str(x) + "," + str(y) + ": " + str(e))
        _set_cell_state(x, y, CellState.ERROR)
    
    return result

func unregister_function(x: int, y: int) -> bool:
    # Unregister a function at specified coordinates
    if not _validate_coordinates(x, y):
        print("Invalid coordinates: " + str(x) + "," + str(y))
        return false
    
    var cell = function_grid[x][y]
    var old_function_name = cell.function_name
    
    # Reset the cell
    cell.function_name = "func_" + str(x) + "_" + str(y)
    cell.function = Callable()
    cell.last_result = null
    
    print("Unregistered function '" + old_function_name + "' at " + str(x) + "," + str(y))
    
    # Set state to disabled
    _set_cell_state(x, y, CellState.DISABLED)
    
    return true

# ----- REFRESH MANAGEMENT -----
func refresh_cell(x: int, y: int) -> Variant:
    # Refresh a single cell
    if not _validate_coordinates(x, y):
        print("Invalid coordinates: " + str(x) + "," + str(y))
        return null
    
    var cell = function_grid[x][y]
    
    # Execute the function
    var result = execute_function(x, y)
    
    # Emit refresh signal
    emit_signal("cell_refreshed", x, y, cell.function_id)
    
    return result

func refresh_row(y: int) -> bool:
    # Refresh an entire row
    if y < 0 or y >= grid_size.y:
        print("Invalid row: " + str(y))
        return false
    
    print("Refreshing row " + str(y))
    
    for x in range(grid_size.x):
        refresh_cell(x, y)
        
        # Small delay between cells if staggered refresh
        if staggered_refresh:
            await get_tree().create_timer(0.1).timeout
    
    return true

func refresh_column(x: int) -> bool:
    # Refresh an entire column
    if x < 0 or x >= grid_size.x:
        print("Invalid column: " + str(x))
        return false
    
    print("Refreshing column " + str(x))
    
    for y in range(grid_size.y):
        refresh_cell(x, y)
        
        # Small delay between cells if staggered refresh
        if staggered_refresh:
            await get_tree().create_timer(0.1).timeout
    
    return true

func refresh_all() -> bool:
    # Refresh all cells in the grid
    print("Refreshing all cells")
    
    for x in range(grid_size.x):
        for y in range(grid_size.y):
            refresh_cell(x, y)
            
            # Small delay between cells if staggered refresh
            if staggered_refresh:
                await get_tree().create_timer(0.05).timeout
    
    emit_signal("all_cells_refreshed")
    
    return true

func _refresh_grid_section(section: int) -> bool:
    # Refresh a section of the grid (0-3 for quarters)
    if section < 0 or section > 3:
        print("Invalid grid section: " + str(section))
        return false
    
    print("Refreshing grid section " + str(section))
    
    # Calculate section boundaries
    var start_x = 0
    var start_y = 0
    var end_x = grid_size.x
    var end_y = grid_size.y
    
    match section:
        0:  # Top-left quarter
            end_x = grid_size.x / 2
            end_y = grid_size.y / 2
        1:  # Top-right quarter
            start_x = grid_size.x / 2
            end_y = grid_size.y / 2
        2:  # Bottom-left quarter
            start_y = grid_size.y / 2
            end_x = grid_size.x / 2
        3:  # Bottom-right quarter
            start_x = grid_size.x / 2
            start_y = grid_size.y / 2
    
    # Refresh cells in this section
    for x in range(start_x, end_x):
        for y in range(start_y, end_y):
            refresh_cell(x, y)
            
            # Small delay between cells if staggered refresh
            if staggered_refresh:
                await get_tree().create_timer(0.05).timeout
    
    return true

func _full_grid_refresh_sequence():
    # Special sequence for full grid refresh
    
    # First, highlight all cells
    for x in range(grid_size.x):
        for y in range(grid_size.y):
            _set_cell_state(x, y, CellState.HIGHLIGHTED)
    
    await get_tree().create_timer(0.5).timeout
    
    # Then refresh in a specific pattern (spiral, diagonal, or other pattern)
    var refresh_pattern = "spiral"
    
    match refresh_pattern:
        "spiral":
            _refresh_spiral_pattern()
        "diagonal":
            _refresh_diagonal_pattern()
        "waves":
            _refresh_wave_pattern()
        _:
            refresh_all()

func _refresh_spiral_pattern():
    # Refresh in a spiral pattern from the center outward
    var center_x = grid_size.x / 2
    var center_y = grid_size.y / 2
    
    print("Refreshing in spiral pattern from center")
    
    # Start at center
    refresh_cell(center_x, center_y)
    await get_tree().create_timer(0.2).timeout
    
    # Spiral outward
    var max_radius = max(grid_size.x, grid_size.y)
    for radius in range(1, max_radius):
        # Top edge
        for x in range(center_x - radius, center_x + radius + 1):
            var y = center_y - radius
            if _validate_coordinates(x, y):
                refresh_cell(x, y)
                await get_tree().create_timer(0.05).timeout
        
        # Right edge
        for y in range(center_y - radius + 1, center_y + radius + 1):
            var x = center_x + radius
            if _validate_coordinates(x, y):
                refresh_cell(x, y)
                await get_tree().create_timer(0.05).timeout
        
        # Bottom edge
        for x in range(center_x + radius - 1, center_x - radius - 1, -1):
            var y = center_y + radius
            if _validate_coordinates(x, y):
                refresh_cell(x, y)
                await get_tree().create_timer(0.05).timeout
        
        # Left edge
        for y in range(center_y + radius - 1, center_y - radius, -1):
            var x = center_x - radius
            if _validate_coordinates(x, y):
                refresh_cell(x, y)
                await get_tree().create_timer(0.05).timeout

func _refresh_diagonal_pattern():
    # Refresh in diagonal lines
    print("Refreshing in diagonal pattern")
    
    # Main diagonal (top-left to bottom-right)
    for i in range(min(grid_size.x, grid_size.y)):
        refresh_cell(i, i)
        await get_tree().create_timer(0.1).timeout
    
    # Anti-diagonal (top-right to bottom-left)
    for i in range(min(grid_size.x, grid_size.y)):
        refresh_cell(grid_size.x - 1 - i, i)
        await get_tree().create_timer(0.1).timeout
    
    # Other diagonals
    for offset in range(1, max(grid_size.x, grid_size.y)):
        # Above main diagonal
        for i in range(min(grid_size.x - offset, grid_size.y)):
            refresh_cell(i + offset, i)
            await get_tree().create_timer(0.05).timeout
        
        # Below main diagonal
        for i in range(min(grid_size.x, grid_size.y - offset)):
            refresh_cell(i, i + offset)
            await get_tree().create_timer(0.05).timeout

func _refresh_wave_pattern():
    # Refresh in wave pattern from top to bottom
    print("Refreshing in wave pattern")
    
    for y in range(grid_size.y):
        # Alternate direction for each row
        if y % 2 == 0:
            for x in range(grid_size.x):
                refresh_cell(x, y)
                await get_tree().create_timer(0.05).timeout
        else:
            for x in range(grid_size.x - 1, -1, -1):
                refresh_cell(x, y)
                await get_tree().create_timer(0.05).timeout

# ----- TIMER CALLBACKS -----
func _on_refresh_timer_timeout():
    # Called when the main refresh timer expires
    if auto_refresh_enabled:
        refresh_all()

func _on_cell_refresh_timeout(x: int, y: int):
    # Called when a cell's individual refresh timer expires
    if auto_refresh_enabled and _validate_coordinates(x, y):
        refresh_cell(x, y)

# ----- COMPRESSION FUNCTIONS -----
func compress_grid_data() -> Dictionary:
    # Compress the current grid data for storage
    if not enable_data_compression:
        return {"compressed": false, "data": function_grid}
    
    print("Compressing grid data...")
    
    # Convert grid to serializable format
    var serialized_data = _serialize_grid()
    
    # Create directory if it doesn't exist
    var dir = Directory.new()
    if not dir.dir_exists(compressed_storage_path):
        dir.make_dir_recursive(compressed_storage_path)
    
    # Generate filename with timestamp
    var timestamp = Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_")
    var filename = compressed_storage_path + "grid_" + timestamp + ".zip"
    
    # Compress data (simulating compression in this mock implementation)
    var original_size = serialized_data.length()
    var compressed_size = int(original_size * (0.9 - (compression_level * 0.05)))  # Simulate compression ratio
    var compression_ratio = float(original_size) / max(1, compressed_size)
    
    # Save to file (in a real implementation)
    var file = File.new()
    file.open(filename, File.WRITE)
    file.store_string(JSON.print(serialized_data))  # In reality, this would be compressed data
    file.close()
    
    # Calculate savings
    var bytes_saved = original_size - compressed_size
    
    print("Compression complete - Ratio: " + str(compression_ratio) + ", Saved: " + str(bytes_saved) + " bytes")
    emit_signal("compression_completed", compression_ratio, bytes_saved)
    
    return {
        "compressed": true,
        "filename": filename,
        "original_size": original_size,
        "compressed_size": compressed_size,
        "compression_ratio": compression_ratio,
        "timestamp": timestamp
    }

func _serialize_grid() -> Dictionary:
    # Convert grid to serializable format
    var serialized = {
        "size": {"x": grid_size.x, "y": grid_size.y},
        "cells": {},
        "metadata": {
            "timestamp": Time.get_unix_time_from_system(),
            "version": "1.0",
            "compression_level": compression_level
        }
    }
    
    # Store cell data
    for x in range(grid_size.x):
        for y in range(grid_size.y):
            var cell = function_grid[x][y]
            var cell_id = _generate_cell_id(x, y)
            
            # Store cell data without the callable
            serialized.cells[cell_id] = {
                "function_name": cell.function_name,
                "last_refresh": cell.last_refresh,
                "refresh_count": cell.refresh_count,
                "last_result": var_to_str(cell.last_result),  # Convert to string
                "metadata": cell.metadata,
                "state": get_cell_state(x, y)
            }
    
    return serialized

func decompress_grid_data(filename: String) -> bool:
    # Decompress and load grid data from file
    var file = File.new()
    if not file.file_exists(filename):
        print("File does not exist: " + filename)
        return false
    
    print("Decompressing grid data from: " + filename)
    
    # Read and parse file
    file.open(filename, File.READ)
    var content = file.get_as_text()
    file.close()
    
    var json_result = JSON.parse(content)
    if json_result.error != OK:
        print("Error parsing grid data: " + json_result.error_string)
        return false
    
    var data = json_result.result
    
    # Validate data
    if not data.has("size") or not data.has("cells"):
        print("Invalid grid data format")
        return false
    
    # Resize grid if necessary
    var new_size = Vector2i(data.size.x, data.size.y)
    if new_size != grid_size:
        resize_grid(new_size)
    
    # Restore cell data
    for cell_id in data.cells:
        var cell_data = data.cells[cell_id]
        
        # Extract coordinates from cell_id
        var coords = cell_id.split("_")
        if coords.size() >= 3:
            var x = int(coords[1])
            var y = int(coords[2])
            
            if _validate_coordinates(x, y):
                # Restore cell data
                var cell = function_grid[x][y]
                cell.function_name = cell_data.function_name
                cell.last_refresh = cell_data.last_refresh
                cell.refresh_count = cell_data.refresh_count
                cell.last_result = str_to_var(cell_data.last_result)
                cell.metadata = cell_data.metadata
                
                # Restore state
                _set_cell_state(x, y, cell_data.state)
    
    print("Grid data decompressed and restored successfully")
    
    return true

# ----- TURN SYSTEM INTEGRATION -----
func on_turn_changed(turn_number: int, turn_data: Dictionary) -> void:
    # Called when the turn changes
    print("Turn changed to " + str(turn_number))
    
    # Special handling for turn changes
    if turn_number == 12:
        _on_final_turn()
    elif turn_number == 15:
        _on_turn15()
    
    # Refresh grid based on turn data
    if turn_data.has("flags") and turn_data.flags.has("grid_enabled") and turn_data.flags.grid_enabled:
        # Adjust grid size based on turn if needed
        if enable_dynamic_resizing:
            var new_size = Vector2i(
                min(turn_number, max_grid_size.x),
                min(turn_number, max_grid_size.y)
            )
            if new_size != grid_size:
                resize_grid(new_size)
        
        # Full refresh
        refresh_all()

func _on_final_turn():
    # Special handling for final turn
    print("Final turn activated - Compressing all grid data")
    
    # Apply compression to save all data
    compress_grid_data()
    
    # Enable special grid behavior
    staggered_refresh = true
    enable_per_cell_refresh_rates = true
    
    # Increase refresh rate
    refresh_interval = 30.0  # 30 seconds
    main_refresh_timer.wait_time = refresh_interval
    main_refresh_timer.start()

func _on_turn15():
    # Special handling for turn 15
    print("Turn 15 activated - Precision grid mode")
    
    # Dynamic resize to 15x15 grid if supported
    if enable_dynamic_resizing and max_grid_size.x >= 15 and max_grid_size.y >= 15:
        resize_grid(Vector2i(15, 15))
    
    # Set grid to maximum precision
    refresh_interval = 15.0  # 15 seconds
    main_refresh_timer.wait_time = refresh_interval
    main_refresh_timer.start()
    
    # Apply special pattern
    _full_grid_refresh_sequence()

# ----- PUBLIC API -----
func get_grid_size() -> Vector2i:
    return grid_size

func get_active_cell_count() -> int:
    var count = 0
    for cell_id in cell_states:
        if cell_states[cell_id] == CellState.ACTIVE:
            count += 1
    
    return count

func get_all_cells_data() -> Array:
    var cells_data = []
    
    for x in range(grid_size.x):
        for y in range(grid_size.y):
            var cell = function_grid[x][y]
            cells_data.append({
                "x": x,
                "y": y,
                "function_name": cell.function_name,
                "state": get_cell_state(x, y),
                "last_refresh": cell.last_refresh,
                "refresh_count": cell.refresh_count
            })
    
    return cells_data

func highlight_cell(x: int, y: int) -> bool:
    if not _validate_coordinates(x, y):
        return false
    
    _set_cell_state(x, y, CellState.HIGHLIGHTED)
    
    # Visual feedback with blink controller if available
    if blink_controller:
        blink_controller.trigger_wink(_generate_cell_id(x, y))
    
    return true

func get_cell_by_name(function_name: String) -> Dictionary:
    for x in range(grid_size.x):
        for y in range(grid_size.y):
            var cell = function_grid[x][y]
            if cell.function_name == function_name:
                return {
                    "x": x,
                    "y": y,
                    "cell": cell.duplicate()
                }
    
    return {}

func set_auto_refresh(enabled: bool) -> void:
    auto_refresh_enabled = enabled
    
    if auto_refresh_enabled:
        main_refresh_timer.start()
    else:
        main_refresh_timer.stop()
    
    print("Auto refresh " + ("enabled" if enabled else "disabled"))

func clear_grid() -> void:
    # Clear all functions from the grid
    for x in range(grid_size.x):
        for y in range(grid_size.y):
            unregister_function(x, y)
    
    print("Grid cleared")

func register_built_in_functions() -> void:
    # Register some built-in utility functions
    
    # Register time function at 0,0
    register_function(0, 0, "get_time", func():
        return Time.get_time_string_from_system()
    )
    
    # Register random number function at 0,1
    register_function(0, 1, "get_random", func(min_val: int = 0, max_val: int = 100):
        return randi() % (max_val - min_val + 1) + min_val
    )
    
    # Register translation function at 1,0 if translation system is available
    if translation_system:
        register_function(1, 0, "translate", func(text: String, to_lang: String = "en"):
            var request_id = translation_system.translate(text, to_lang)
            return "Translation requested (ID: " + str(request_id) + ")"
        )
    
    # Register turn info function at 1,1 if turn controller is available
    if turn_controller:
        register_function(1, 1, "get_turn_info", func():
            return {
                "current_turn": turn_controller.get_current_turn(),
                "total_turns": turn_controller.get_total_turns(),
                "power": turn_controller.get_power_percentage() * 100
            }
        )
    
    print("Built-in functions registered")

func execute_function_by_name(function_name: String, args: Array = []) -> Variant:
    # Execute a function by name
    var cell_info = get_cell_by_name(function_name)
    
    if cell_info.empty():
        print("Function not found: " + function_name)
        return null
    
    return execute_function(cell_info.x, cell_info.y, args)

# ----- UTILITY FUNCTIONS -----
func get_cell_coordinates_from_id(cell_id: String) -> Vector2i:
    var parts = cell_id.split("_")
    if parts.size() >= 3:
        return Vector2i(int(parts[1]), int(parts[2]))
    
    return Vector2i(-1, -1)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/function_grid_manager.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/gaze_tracking_integration.gd
# SIZE: 10620 bytes
extends Node

class_name GazeTrackingIntegration

# Apple-style eyeball tracking integration for Godot

# Constants
const CALIBRATION_POINTS = 9
const MIN_TRACKING_CONFIDENCE = 0.65
const SMOOTHING_FACTOR = 0.25
const UPDATE_FREQUENCY = 0.033 # ~30Hz

# Tracking state
var is_tracking_active = false
var is_calibrated = false
var tracking_confidence = 0.0
var raw_gaze_point = Vector2(0.5, 0.5)
var smoothed_gaze_point = Vector2(0.5, 0.5)
var gaze_history = []
var calibration_points = []
var calibration_matrices = []
var device_capabilities = {}
var screen_dimensions = Vector2(1920, 1080)
var last_update_time = 0
var fixation_threshold = 0.05
var fixation_time_threshold = 0.3
var current_fixation_point = Vector2(0, 0)
var current_fixation_duration = 0
var heatmap_data = {}
var tracking_quality = "unknown"
var device_with_lidar = false

# Connections
var keyboard_manager = null
var shape_manager = null
var external_device = null

# Signals
signal gaze_updated(point, confidence)
signal calibration_completed(success)
signal fixation_detected(point, duration)
signal tracking_quality_changed(quality)
signal device_connected(device_info)

func _ready():
    # Detect device capabilities
    detect_device_capabilities()
    
    # Set up update timer
    var timer = Timer.new()
    timer.wait_time = UPDATE_FREQUENCY
    timer.autostart = true
    timer.connect("timeout", self, "_on_tracking_update")
    add_child(timer)
    
    # Initialize calibration points
    _generate_calibration_points()
    
    # Connect to keyboard manager if available
    connect_to_keyboard_manager()

func _process(delta):
    # Process fixations
    if is_tracking_active and is_calibrated:
        # Check if gaze point is stable enough to be a fixation
        var distance = smoothed_gaze_point.distance_to(current_fixation_point)
        
        if distance < fixation_threshold:
            # Continue existing fixation
            current_fixation_duration += delta
            
            # Emit signal when fixation exceeds threshold
            if current_fixation_duration >= fixation_time_threshold:
                emit_signal("fixation_detected", current_fixation_point, current_fixation_duration)
                
                # Update heatmap data
                _update_heatmap(current_fixation_point, current_fixation_duration)
        else:
            # Start new fixation
            current_fixation_point = smoothed_gaze_point
            current_fixation_duration = 0

func detect_device_capabilities():
    # Detect current device capabilities
    var device_info = {
        "platform": OS.get_name(),
        "model": OS.get_model_name(),
        "screen_dpi": OS.get_screen_dpi(),
        "screen_size": OS.get_screen_size(),
        "front_camera": false,
        "lidar_sensor": false,
        "processing_cores": OS.get_processor_count()
    }
    
    # Simulate detection of camera and LiDAR based on platform/model
    if device_info["platform"] == "iOS" or device_info["platform"] == "Android":
        device_info["front_camera"] = true
        
        # Check for LiDAR-capable devices (iPhone 12 Pro and newer, iPad Pro 2020 and newer)
        var model = device_info["model"]
        if model.find("iPhone 12 Pro") != -1 or model.find("iPhone 13 Pro") != -1 or \
           model.find("iPhone 14 Pro") != -1 or model.find("iPhone 15 Pro") != -1 or \
           model.find("iPad Pro") != -1:
            device_info["lidar_sensor"] = true
    
    device_capabilities = device_info
    device_with_lidar = device_info["lidar_sensor"]
    
    # Update tracking quality based on device capabilities
    if device_with_lidar:
        tracking_quality = "high"
    elif device_info["front_camera"]:
        tracking_quality = "medium"
    else:
        tracking_quality = "low"
    
    emit_signal("tracking_quality_changed", tracking_quality)
    emit_signal("device_connected", device_info)
    
    print("Detected device: " + device_info["platform"] + " " + device_info["model"])
    print("Eye tracking quality: " + tracking_quality)
    
    return device_capabilities

func connect_to_keyboard_manager():
    # Find keyboard manager node
    if has_node("/root/KeyboardShapeManager") or get_node_or_null("/root/KeyboardShapeManager"):
        keyboard_manager = get_node("/root/KeyboardShapeManager")
        print("Connected to keyboard shape manager")
        return true
    
    # Try to find shape manager
    if has_node("/root/SmartAccountSystem/KeyboardShapeManager") or get_node_or_null("/root/SmartAccountSystem/KeyboardShapeManager"):
        keyboard_manager = get_node("/root/SmartAccountSystem/KeyboardShapeManager")
        print("Connected to keyboard shape manager")
        return true
    
    return false

func start_tracking():
    if tracking_quality == "low":
        print("Device has insufficient capabilities for eye tracking")
        return false
    
    is_tracking_active = true
    last_update_time = OS.get_ticks_msec()
    print("Eye tracking started")
    return true

func stop_tracking():
    is_tracking_active = false
    print("Eye tracking stopped")
    return true

func calibrate():
    # Reset calibration data
    calibration_points = []
    calibration_matrices = []
    is_calibrated = false
    
    # Generate calibration points
    _generate_calibration_points()
    
    # In a real implementation, would guide user through calibration process
    # For this demo, simulate successful calibration
    yield(get_tree().create_timer(2.0), "timeout")
    
    # Simulate calibration result
    var success = true
    is_calibrated = success
    
    if success:
        tracking_confidence = 0.85
    else:
        tracking_confidence = 0.4
    
    emit_signal("calibration_completed", success)
    print("Calibration " + ("successful" if success else "failed"))
    return success

func _generate_calibration_points():
    # Generate a grid of calibration points
    calibration_points = []
    
    var rows = 3
    var cols = 3
    
    for r in range(rows):
        for c in range(cols):
            var point = Vector2(
                (c + 0.5) / cols,
                (r + 0.5) / rows
            )
            calibration_points.append(point)
    
    return calibration_points

func _on_tracking_update():
    if not is_tracking_active:
        return
    
    # Update gaze tracking
    _update_gaze_point()
    
    # Update keyboard manager if connected
    if keyboard_manager and keyboard_manager.has_method("update_eye_position"):
        keyboard_manager.update_eye_position(smoothed_gaze_point)

func _update_gaze_point():
    # In a real implementation, would get data from eye tracking hardware
    # For this demo, simulate eye movement
    
    var now = OS.get_ticks_msec()
    var time_delta = (now - last_update_time) / 1000.0
    last_update_time = now
    
    # Simulate natural eye movement
    if is_calibrated:
        # More precise movement when using LiDAR
        var movement_scale = 0.02 if device_with_lidar else 0.05
        
        # Simulate natural eye movement with noise
        raw_gaze_point.x += (randf() - 0.5) * movement_scale
        raw_gaze_point.y += (randf() - 0.5) * movement_scale
        
        # Apply simulated tracking confidence
        if randf() > 0.95:
            # Occasional tracking loss
            tracking_confidence = randf() * 0.3
        else:
            # Normal tracking
            tracking_confidence = 0.7 + randf() * 0.3
        
        # Clamp to valid range
        raw_gaze_point.x = clamp(raw_gaze_point.x, 0.0, 1.0)
        raw_gaze_point.y = clamp(raw_gaze_point.y, 0.0, 1.0)
        
        # Apply smoothing
        smoothed_gaze_point = smoothed_gaze_point.linear_interpolate(
            raw_gaze_point,
            SMOOTHING_FACTOR
        )
        
        # Add to history
        gaze_history.append({
            "point": smoothed_gaze_point,
            "time": now,
            "confidence": tracking_confidence
        })
        
        # Limit history size
        if gaze_history.size() > 100:
            gaze_history.pop_front()
        
        # Emit signal if confidence is sufficient
        if tracking_confidence >= MIN_TRACKING_CONFIDENCE:
            emit_signal("gaze_updated", smoothed_gaze_point, tracking_confidence)

func _update_heatmap(position, duration):
    # Convert normalized position to grid cell
    var grid_size = 20 # 20x20 grid for heatmap
    var grid_x = int(position.x * grid_size)
    var grid_y = int(position.y * grid_size)
    var grid_key = str(grid_x) + "_" + str(grid_y)
    
    # Update heatmap data
    if not grid_key in heatmap_data:
        heatmap_data[grid_key] = {
            "duration": 0,
            "visits": 0,
            "position": Vector2(grid_x / float(grid_size), grid_y / float(grid_size))
        }
    
    heatmap_data[grid_key]["duration"] += duration
    heatmap_data[grid_key]["visits"] += 1

func get_heatmap_data():
    # Return processed heatmap data
    var result = []
    
    for grid_key in heatmap_data:
        result.append(heatmap_data[grid_key])
    
    return result

func get_device_info():
    # Return detailed device capabilities
    return {
        "capabilities": device_capabilities,
        "tracking_quality": tracking_quality,
        "is_calibrated": is_calibrated,
        "tracking_confidence": tracking_confidence,
        "has_lidar": device_with_lidar
    }

func get_screen_to_world_point(screen_position):
    # Convert screen position to world coordinates (normalized 0-1)
    return Vector2(
        screen_position.x / screen_dimensions.x,
        screen_position.y / screen_dimensions.y
    )

func world_to_screen_point(world_position):
    # Convert normalized world position to screen coordinates
    return Vector2(
        world_position.x * screen_dimensions.x,
        world_position.y * screen_dimensions.y
    )

func connect_external_device(device_data):
    # Connect to external eye tracking device
    external_device = device_data
    
    # Update capabilities based on external device
    if external_device != null:
        if external_device.has("has_lidar") and external_device["has_lidar"]:
            device_with_lidar = true
            tracking_quality = "high"
        elif external_device.has("has_camera") and external_device["has_camera"]:
            tracking_quality = "medium"
        
        emit_signal("tracking_quality_changed", tracking_quality)
        emit_signal("device_connected", external_device)
    
    print("Connected to external device")
    return external_device
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/gaze_tracking_integration.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/github_tools_integration.gd
# SIZE: 19906 bytes
extends Node

class_name GitHubToolsIntegration

# Tool integration system for Github repositories

# Default tool categories
enum ToolCategory {
    INPUT,
    GRAPHICS,
    AUDIO,
    PHYSICS,
    UI,
    NETWORKING,
    UTILITY,
    AI,
    CUSTOM
}

# Connection state
var connection_state = "disconnected"
var auth_token = ""
var github_username = ""
var connected_repositories = []
var downloaded_tools = []
var imported_tools = []
var available_updates = []
var installation_queue = []
var cached_repositories = {}
var tool_categories = {}
var tool_counts = {}

# Tool directory paths
var tools_root_path = "user://github_tools/"
var imported_tools_path = "res://addons/"
var temp_download_path = "user://temp_downloads/"

# API configurations
var api_rate_limit = 60
var api_calls_remaining = 60
var api_reset_time = 0
var proxy_enabled = false
var use_cache = true
var cache_lifetime = 3600 # 1 hour

# Signals
signal connection_state_changed(new_state, message)
signal repository_loaded(repo_data)
signal tool_downloaded(tool_name, version)
signal tool_imported(tool_name, success)
signal tool_list_updated(tool_count)
signal rate_limit_changed(calls_remaining, reset_time)

func _ready():
    # Create necessary directories
    _ensure_directories_exist()
    
    # Load cached repository data
    load_cache()
    
    # Initialize tool categories
    _initialize_tool_categories()
    
    # Count existing tools
    count_imported_tools()

func _ensure_directories_exist():
    var dir = Directory.new()
    
    # Create tools root directory
    if not dir.dir_exists(tools_root_path):
        dir.make_dir_recursive(tools_root_path)
    
    # Create temp download directory
    if not dir.dir_exists(temp_download_path):
        dir.make_dir_recursive(temp_download_path)
    
    # Check addons directory
    if not dir.dir_exists(imported_tools_path):
        dir.make_dir_recursive(imported_tools_path)

func _initialize_tool_categories():
    # Create tool categories
    for category in ToolCategory.values():
        var category_name = ToolCategory.keys()[category]
        tool_categories[category] = {
            "id": category,
            "name": category_name,
            "tools": [],
            "count": 0
        }
        tool_counts[category_name] = 0

func authenticate(token, username = ""):
    # Store authentication info
    auth_token = token
    github_username = username
    
    # Update connection state
    connection_state = "connecting"
    emit_signal("connection_state_changed", connection_state, "Authenticating with GitHub...")
    
    # In a real implementation, would validate the token with GitHub API
    # For this demo, simulate authentication
    
    # Simulate API call
    var success = true
    
    if success:
        connection_state = "connected"
        emit_signal("connection_state_changed", connection_state, "Connected to GitHub")
        
        # Update rate limit
        api_rate_limit = 5000 # Authenticated users get 5000 requests per hour
        api_calls_remaining = api_rate_limit
        api_reset_time = OS.get_unix_time() + 3600
        
        emit_signal("rate_limit_changed", api_calls_remaining, api_reset_time)
        
        print("Authenticated with GitHub as: " + (github_username if !github_username.empty() else "Anonymous"))
        return true
    else:
        connection_state = "error"
        emit_signal("connection_state_changed", connection_state, "Authentication failed")
        
        print("GitHub authentication failed")
        return false

func search_repositories(query, category = -1, sort_by = "stars", count = 10):
    # Check connection state
    if connection_state != "connected":
        print("Not connected to GitHub")
        return []
    
    # Check rate limit
    if api_calls_remaining <= 0:
        print("GitHub API rate limit reached")
        return []
    
    # Decrement API calls
    api_calls_remaining -= 1
    emit_signal("rate_limit_changed", api_calls_remaining, api_reset_time)
    
    # Check if we have cached results
    var cache_key = "search_" + query + "_" + str(category) + "_" + sort_by
    if use_cache and cache_key in cached_repositories:
        var cache_entry = cached_repositories[cache_key]
        
        # Check if cache is still valid
        if OS.get_unix_time() - cache_entry["timestamp"] < cache_lifetime:
            print("Using cached results for: " + query)
            return cache_entry["data"]
    
    # In a real implementation, would call GitHub API
    # For this demo, generate dummy results
    
    # Create repository names based on the query and category
    var category_name = ""
    if category >= 0 and category in ToolCategory.values():
        category_name = ToolCategory.keys()[category].to_lower()
    
    # List of sample tools for different categories
    var tools_by_category = {
        "input": ["keyboard-mapper", "joystick-input", "touch-controls", "eye-tracker", "motion-capture"],
        "graphics": ["shader-collection", "post-processing", "marching-cubes", "particle-system", "procedural-terrain"],
        "audio": ["sound-manager", "music-generator", "voice-synthesis", "audio-visualizer", "spatial-audio"],
        "physics": ["rigid-body", "soft-body", "fluid-dynamics", "cloth-simulation", "vehicle-physics"],
        "ui": ["ui-framework", "theme-editor", "widget-pack", "responsive-layout", "animation-tools"],
        "networking": ["multiplayer-framework", "web-socket", "rest-client", "p2p-networking", "server-browser"],
        "utility": ["debug-tools", "profiler", "file-browser", "resource-optimizer", "build-system"],
        "ai": ["behavior-trees", "pathfinding", "neural-network", "state-machine", "decision-system"],
        "custom": ["game-framework", "dialogue-system", "inventory-system", "quest-manager", "save-system"]
    }
    
    # Get tools based on category
    var tool_names = []
    if category_name in tools_by_category:
        tool_names = tools_by_category[category_name]
    else:
        # Mix tools from all categories
        for cat in tools_by_category:
            tool_names += tools_by_category[cat]
    
    # Create repositories
    var repositories = []
    var max_results = min(count, tool_names.size())
    
    for i in range(max_results):
        var tool_name = tool_names[i]
        var repo_name = "godot-" + tool_name
        
        if query:
            # Only include if query matches
            if repo_name.find(query) < 0 and tool_name.find(query) < 0:
                continue
        
        var stars = int(rand_range(5, 500))
        var forks = int(stars * rand_range(0.1, 0.5))
        var last_update = OS.get_unix_time() - int(rand_range(86400, 7776000)) # 1 day to 90 days ago
        
        repositories.append({
            "name": repo_name,
            "owner": {
                "login": "github-user-" + str(i)
            },
            "full_name": "github-user-" + str(i) + "/" + repo_name,
            "html_url": "https://github.com/github-user-" + str(i) + "/" + repo_name,
            "description": "A " + tool_name.replace("-", " ") + " tool for Godot Engine",
            "stargazers_count": stars,
            "forks_count": forks,
            "open_issues_count": int(rand_range(0, 20)),
            "updated_at": OS.get_datetime_from_unix_time(last_update),
            "topics": [
                "godot",
                "tool",
                "addon",
                tool_name,
                category_name
            ],
            "category": category_name if !category_name.empty() else "misc",
            "version": "v" + str(int(rand_range(0, 3))) + "." + str(int(rand_range(0, 10))) + "." + str(int(rand_range(0, 10))),
            "has_downloads": true,
            "default_branch": "main"
        })
    
    # Sort repositories
    if sort_by == "stars":
        repositories.sort_custom(self, "_sort_by_stars")
    elif sort_by == "updated":
        repositories.sort_custom(self, "_sort_by_update")
    elif sort_by == "name":
        repositories.sort_custom(self, "_sort_by_name")
    
    # Cache results
    if use_cache:
        cached_repositories[cache_key] = {
            "timestamp": OS.get_unix_time(),
            "data": repositories
        }
    
    # Emit signal
    for repo in repositories:
        emit_signal("repository_loaded", repo)
    
    emit_signal("tool_list_updated", repositories.size())
    print("Found " + str(repositories.size()) + " repositories matching: " + query)
    
    return repositories

func get_repository_details(repo_full_name):
    # Check connection state
    if connection_state != "connected":
        print("Not connected to GitHub")
        return null
    
    # Check rate limit
    if api_calls_remaining <= 0:
        print("GitHub API rate limit reached")
        return null
    
    # Decrement API calls
    api_calls_remaining -= 1
    emit_signal("rate_limit_changed", api_calls_remaining, api_reset_time)
    
    # Check if we have cached results
    var cache_key = "repo_" + repo_full_name
    if use_cache and cache_key in cached_repositories:
        var cache_entry = cached_repositories[cache_key]
        
        # Check if cache is still valid
        if OS.get_unix_time() - cache_entry["timestamp"] < cache_lifetime:
            print("Using cached details for: " + repo_full_name)
            return cache_entry["data"]
    
    # In a real implementation, would call GitHub API
    # For this demo, generate dummy details
    
    var parts = repo_full_name.split("/")
    if parts.size() != 2:
        print("Invalid repository name format")
        return null
    
    var owner = parts[0]
    var repo_name = parts[1]
    
    # Extract tool name and category from repo name
    var tool_name = repo_name.replace("godot-", "")
    var category_name = ""
    
    # Try to determine category from tool name
    for cat in ToolCategory.keys():
        if tool_name.find(cat.to_lower()) >= 0:
            category_name = cat.to_lower()
            break
    
    if category_name.empty():
        category_name = "utility" # Default category
    
    # Generate repository details
    var stars = int(rand_range(5, 500))
    var forks = int(stars * rand_range(0.1, 0.5))
    var last_update = OS.get_unix_time() - int(rand_range(86400, 7776000)) # 1 day to 90 days ago
    
    var repo_details = {
        "name": repo_name,
        "owner": {
            "login": owner,
            "avatar_url": "https://github.com/" + owner + ".png"
        },
        "full_name": repo_full_name,
        "html_url": "https://github.com/" + repo_full_name,
        "description": "A " + tool_name.replace("-", " ") + " tool for Godot Engine",
        "stargazers_count": stars,
        "forks_count": forks,
        "open_issues_count": int(rand_range(0, 20)),
        "updated_at": OS.get_datetime_from_unix_time(last_update),
        "created_at": OS.get_datetime_from_unix_time(last_update - 7776000),
        "topics": [
            "godot",
            "tool",
            "addon",
            tool_name,
            category_name
        ],
        "category": category_name,
        "version": "v" + str(int(rand_range(0, 3))) + "." + str(int(rand_range(0, 10))) + "." + str(int(rand_range(0, 10))),
        "has_downloads": true,
        "default_branch": "main",
        "license": {
            "key": "mit",
            "name": "MIT License",
            "url": "https://api.github.com/licenses/mit"
        },
        "readme": "# " + repo_name + "\n\nA " + tool_name.replace("-", " ") + " tool for Godot Engine.\n\n## Features\n\n- Feature 1\n- Feature 2\n- Feature 3\n\n## Installation\n\n1. Download the latest release\n2. Extract to your Godot project's addons folder\n3. Enable the plugin in Project Settings\n\n## Usage\n\nSee the documentation for usage examples.",
        "releases": [
            {
                "tag_name": "v1.0.0",
                "name": "Initial Release",
                "published_at": OS.get_datetime_from_unix_time(last_update - 5184000),
                "assets": [
                    {
                        "name": repo_name + "-v1.0.0.zip",
                        "download_count": int(rand_range(100, 1000)),
                        "browser_download_url": "https://github.com/" + repo_full_name + "/releases/download/v1.0.0/" + repo_name + "-v1.0.0.zip"
                    }
                ]
            }
        ],
        "dependencies": [],
        "godot_version": "4.0+"
    }
    
    # Cache results
    if use_cache:
        cached_repositories[cache_key] = {
            "timestamp": OS.get_unix_time(),
            "data": repo_details
        }
    
    print("Retrieved details for: " + repo_full_name)
    return repo_details

func download_tool(repo_full_name, version = "latest"):
    # Check connection state
    if connection_state != "connected":
        print("Not connected to GitHub")
        return false
    
    # Get repository details
    var repo_details = get_repository_details(repo_full_name)
    if repo_details == null:
        print("Failed to get repository details")
        return false
    
    # In a real implementation, would download from GitHub
    # For this demo, simulate download
    
    # Add to installation queue
    installation_queue.append({
        "repo": repo_details,
        "version": version,
        "status": "downloading",
        "progress": 0
    })
    
    # Simulate download progress
    var index = installation_queue.size() - 1
    
    # Use a timer to simulate download
    var timer = Timer.new()
    timer.wait_time = 0.5
    timer.one_shot = false
    timer.connect("timeout", self, "_on_download_progress", [index])
    add_child(timer)
    timer.start()
    
    print("Started downloading: " + repo_full_name)
    return true

func _on_download_progress(queue_index):
    if queue_index >= installation_queue.size():
        return
    
    var item = installation_queue[queue_index]
    item["progress"] += rand_range(0.1, 0.3)
    
    if item["progress"] >= 1.0:
        # Download complete
        item["progress"] = 1.0
        item["status"] = "downloaded"
        
        # Complete the installation
        var timer = get_child(queue_index)
        timer.stop()
        timer.queue_free()
        
        # Add to downloaded tools
        var tool_data = {
            "name": item["repo"]["name"],
            "version": item["version"],
            "repo": item["repo"]["full_name"],
            "download_path": tools_root_path + item["repo"]["name"],
            "category": item["repo"]["category"],
            "downloaded_at": OS.get_datetime()
        }
        
        downloaded_tools.append(tool_data)
        
        # Update tool counts
        var category = tool_data["category"]
        if category in tool_counts:
            tool_counts[category] += 1
        else:
            tool_counts[category] = 1
        
        emit_signal("tool_downloaded", tool_data["name"], tool_data["version"])
        print("Downloaded: " + tool_data["name"] + " " + tool_data["version"])
        
        # Install the tool
        install_tool(tool_data["name"])

func install_tool(tool_name):
    # Check if tool is downloaded
    var tool_data = null
    for t in downloaded_tools:
        if t["name"] == tool_name:
            tool_data = t
            break
    
    if tool_data == null:
        print("Tool not downloaded: " + tool_name)
        return false
    
    # In a real implementation, would extract and install the plugin
    # For this demo, simulate installation
    
    # Simulate installation delay
    yield(get_tree().create_timer(1.0), "timeout")
    
    # Add to imported tools
    var imported_tool = {
        "name": tool_data["name"],
        "version": tool_data["version"],
        "repo": tool_data["repo"],
        "import_path": imported_tools_path + tool_data["name"],
        "category": tool_data["category"],
        "imported_at": OS.get_datetime(),
        "enabled": true
    }
    
    imported_tools.append(imported_tool)
    
    emit_signal("tool_imported", tool_data["name"], true)
    print("Installed: " + tool_data["name"])
    return true

func update_tool(tool_name):
    # Check if tool is imported
    var tool_data = null
    for t in imported_tools:
        if t["name"] == tool_name:
            tool_data = t
            break
    
    if tool_data == null:
        print("Tool not installed: " + tool_name)
        return false
    
    # Get repository details
    var repo_details = get_repository_details(tool_data["repo"])
    if repo_details == null:
        print("Failed to get repository details")
        return false
    
    # Check if update is available
    if repo_details["version"] == tool_data["version"]:
        print("Tool already up to date: " + tool_name)
        return false
    
    # Download and install new version
    return download_tool(tool_data["repo"], repo_details["version"])

func check_updates():
    # Clear previous updates
    available_updates = []
    
    # Check for updates for all imported tools
    for tool_data in imported_tools:
        # Get repository details
        var repo_details = get_repository_details(tool_data["repo"])
        
        if repo_details != null and repo_details["version"] != tool_data["version"]:
            # Update available
            available_updates.append({
                "name": tool_data["name"],
                "current_version": tool_data["version"],
                "new_version": repo_details["version"],
                "repo": tool_data["repo"]
            })
    
    print("Found " + str(available_updates.size()) + " updates available")
    return available_updates

func enable_tool(tool_name, enabled = true):
    # Check if tool is imported
    var tool_index = -1
    for i in range(imported_tools.size()):
        if imported_tools[i]["name"] == tool_name:
            tool_index = i
            break
    
    if tool_index < 0:
        print("Tool not installed: " + tool_name)
        return false
    
    # Update enabled state
    imported_tools[tool_index]["enabled"] = enabled
    
    # In a real implementation, would enable/disable the plugin
    print("Tool " + tool_name + " " + ("enabled" if enabled else "disabled"))
    return true

func count_imported_tools():
    # Reset counts
    for category in tool_counts:
        tool_counts[category] = 0
    
    # Count tools by category
    for tool_data in imported_tools:
        var category = tool_data["category"]
        if category in tool_counts:
            tool_counts[category] += 1
        else:
            tool_counts[category] = 1
    
    var total = imported_tools.size()
    emit_signal("tool_list_updated", total)
    print("Counted " + str(total) + " imported tools")
    return tool_counts

func load_cache():
    # In a real implementation, would load cached data from file
    # For this demo, initialize empty cache
    cached_repositories = {}
    print("Cache initialized")
    return true

func clear_cache():
    cached_repositories = {}
    print("Cache cleared")
    return true

func _sort_by_stars(a, b):
    return a["stargazers_count"] > b["stargazers_count"]

func _sort_by_update(a, b):
    return a["updated_at"] > b["updated_at"]

func _sort_by_name(a, b):
    return a["name"] < b["name"]

func get_tool_count():
    return imported_tools.size()

func get_tools_by_category(category):
    var result = []
    
    for tool_data in imported_tools:
        if tool_data["category"] == category:
            result.append(tool_data)
    
    return result

func get_connection_status():
    return {
        "state": connection_state,
        "api_calls_remaining": api_calls_remaining,
        "api_reset_time": api_reset_time,
        "connected_as": github_username
    }
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/github_tools_integration.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/godot4_migration_tester.gd
# SIZE: 20678 bytes
class_name Godot4MigrationTester
extends Node

# ----- TESTING SETTINGS -----
@export_category("Testing Settings")
@export var test_scripts_path: String = "res://tests/migration_test_scripts"
@export var output_path: String = "res://tests/migration_output"
@export var verbose_logging: bool = true
@export var run_tests_on_start: bool = false

# ----- INTEGRATION POINTS -----
var migration_tool = null
var color_system = null
var akashic_system = null

# ----- TEST CASES -----
var test_cases = {
    "node_renames": {
        "input": """
extends Spatial

func _ready():
    var body = $KinematicBody
    var mesh = $MeshInstance
    var area = $Area
    var ray = $RayCast
""",
        "expected": """
extends Node3D

func _ready() -> void:
    var body = $CharacterBody3D
    var mesh = $MeshInstance3D
    var area = $Area3D
    var ray = $RayCast3D
"""
    },
    
    "method_renames": {
        "input": """
func test_methods():
    var pos = get_translation()
    set_translation(Vector3(0, 1, 0))
    if is_network_master():
        rpc_id(1, "update")
        rpc_unreliable("update_pos")
    var result = yield(get_tree(), "idle_frame")
""",
        "expected": """
func test_methods() -> void:
    var pos = get_position()
    set_position(Vector3(0, 1, 0))
    if is_multiplayer_authority():
        rpc_id(1, "update")
        rpc("update_pos")
    var result = await get_tree().idle_frame
"""
    },
    
    "property_renames": {
        "input": """
func update_ui():
    $Label.rect_size = Vector2(100, 50)
    $Label.rect_position = Vector2(10, 10)
    $Label.rect_min_size = Vector2(50, 20)
    $Panel.margin_left = 5
    $Panel.margin_right = 95
    $Panel.margin_top = 5
    $Panel.margin_bottom = 45
""",
        "expected": """
func update_ui() -> void:
    $Label.size = Vector2(100, 50)
    $Label.position = Vector2(10, 10)
    $Label.custom_minimum_size = Vector2(50, 20)
    $Panel.position.x = 5
    $Panel.size.x + position.x = 95
    $Panel.position.y = 5
    $Panel.size.y + position.y = 45
"""
    },
    
    "onready_vars": {
        "input": """
extends Node

onready var label = $Label
onready var button = $Button
onready var timer = $Timer

func _ready():
    label.text = "Hello"
""",
        "expected": """
extends Node

@onready var label = $Label
@onready var button = $Button
@onready var timer = $Timer

func _ready() -> void:
    label.text = "Hello"
"""
    },
    
    "exports": {
        "input": """
extends Node

export(int, 0, 100) var health = 100
export(String) var player_name = "Player"
export(float, 0.5, 2.0) var scale_factor = 1.0
export(Color, RGB) var base_color = Color.white

func _ready():
    print(health)
""",
        "expected": """
extends Node

@export var health = 100
@export var player_name = "Player"
@export var scale_factor = 1.0
@export var base_color = Color.white

func _ready() -> void:
    print(health)
"""
    },
    
    "signals": {
        "input": """
extends Node

signal health_changed(amount)
signal player_died

func update_health(damage):
    health -= damage
    emit_signal("health_changed", damage)
    
    if health <= 0:
        emit_signal("player_died")
""",
        "expected": """
extends Node

signal health_changed(amount)
signal player_died

func update_health(damage) -> void:
    health -= damage
    health_changed.emit(damage)
    
    if health <= 0:
        player_died.emit()
"""
    },
    
    "typed_arrays": {
        "input": """
func create_inventory():
    var items = []
    var weapons = []
    var prices = []
    
    return {
        "items": items,
        "weapons": weapons,
        "prices": prices
    }
""",
        "expected": """
func create_inventory() -> void:
    var items: Array = []
    var weapons: Array = []
    var prices: Array = []
    
    return {
        "items": items,
        "weapons": weapons,
        "prices": prices
    }
"""
    },
    
    "physics_bodies": {
        "input": """
extends RigidBody

func _ready():
    mode = MODE_KINEMATIC
    
func _physics_process(delta):
    apply_impulse(Vector3.ZERO, Vector3(0, 10, 0))
""",
        "expected": """
extends RigidBody3D

func _ready() -> void:
    freeze = FREEZE_MODE_KINEMATIC
    
func _physics_process(delta: float) -> void:
    apply_impulse(Vector3.ZERO, Vector3(0, 10, 0))
"""
    },
    
    "characterbody": {
        "input": """
extends KinematicBody

func _physics_process(delta):
    var velocity = Vector3(0, 0, 0)
    velocity = move_and_slide(velocity)
    
    var collision_count = get_slide_count()
    if collision_count > 0:
        var collision = get_slide_collision(0)
        print(collision.collider.name)
""",
        "expected": """
extends CharacterBody3D

func _physics_process(delta: float) -> void:
    var velocity = Vector3(0, 0, 0)
    velocity = move_and_slide(velocity)
    
    var collision_count = get_slide_collision_count()
    if collision_count > 0:
        var collision = get_slide_collision(0)
        print(collision.collider.name)
"""
    },
    
    "tool_script": {
        "input": """
tool
extends Node

export(Color) var editor_color = Color.blue

func _ready():
    print("This is a tool script")
""",
        "expected": """
@tool
extends Node

@export var editor_color = Color.blue

func _ready() -> void:
    print("This is a tool script")
"""
    },
    
    "networking_terms": {
        "input": """
extends Node

func _ready():
    if is_network_master():
        set_network_master(1)
    else:
        rpc_id(1, "slave_func")

slave func slave_func():
    print("I'm a slave")

master func master_func():
    print("I'm the master")
""",
        "expected": """
extends Node

func _ready() -> void:
    if is_multiplayer_authority():
        set_multiplayer_authority(1)
    else:
        rpc_id(1, "slave_func")

puppet func slave_func() -> void:
    print("I'm a slave")

authority func master_func() -> void:
    print("I'm the master")
"""
    }
}

# ----- SIGNALS -----
signal test_started(total_tests)
signal test_completed(results)
signal test_case_started(test_name)
signal test_case_completed(test_name, passed, details)

# ----- INITIALIZATION -----
func _ready():
    _find_components()
    _create_test_directories()
    
    print("Godot4 Migration Tester initialized")
    
    if run_tests_on_start:
        run_all_tests()

func _find_components():
    # Find Migration Tool
    migration_tool = get_node_or_null("/root/Godot4MigrationTool")
    if not migration_tool:
        migration_tool = _find_node_by_class(get_tree().root, "Godot4MigrationTool")
    
    if not migration_tool:
        migration_tool = Godot4MigrationTool.new()
        add_child(migration_tool)
    
    # Find Color System
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find Akashic System
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    print("Components found - Migration Tool: %s, Color System: %s, Akashic System: %s" % [
        "Yes" if migration_tool else "No",
        "Yes" if color_system else "No",
        "Yes" if akashic_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _create_test_directories():
    # Create test scripts and output directories if they don't exist
    if not DirAccess.dir_exists_absolute(test_scripts_path):
        DirAccess.make_dir_recursive_absolute(test_scripts_path)
        print("Created test scripts directory: " + test_scripts_path)
    
    if not DirAccess.dir_exists_absolute(output_path):
        DirAccess.make_dir_recursive_absolute(output_path)
        print("Created output directory: " + output_path)

# ----- TEST EXECUTION -----
func run_all_tests():
    # First, generate test script files
    _generate_test_scripts()
    
    # Run tests
    var results = {
        "total": test_cases.size(),
        "passed": 0,
        "failed": 0,
        "details": {}
    }
    
    emit_signal("test_started", test_cases.size())
    
    for test_name in test_cases.keys():
        emit_signal("test_case_started", test_name)
        
        var test_result = _run_test(test_name)
        results.details[test_name] = test_result
        
        if test_result.passed:
            results.passed += 1
        else:
            results.failed += 1
        
        emit_signal("test_case_completed", test_name, test_result.passed, test_result)
    
    emit_signal("test_completed", results)
    
    # Print results
    _print_test_results(results)
    
    return results

func _generate_test_scripts():
    # Generate test script files from test cases
    for test_name in test_cases.keys():
        var script_content = test_cases[test_name].input
        var script_path = test_scripts_path.path_join(test_name + ".gd")
        
        var file = FileAccess.open(script_path, FileAccess.WRITE)
        if file:
            file.store_string(script_content)
            file.close()
            
            if verbose_logging:
                print("Generated test script: " + script_path)
        else:
            push_error("Failed to create test script: " + script_path)

func _run_test(test_name):
    var input_path = test_scripts_path.path_join(test_name + ".gd")
    var output_path_file = output_path.path_join(test_name + "_migrated.gd")
    
    if verbose_logging:
        print("Running test: " + test_name)
    
    # Run migration on the test script
    var migration_result = migration_tool.migrate_single_file(input_path, output_path_file)
    
    if not migration_result.success:
        return {
            "passed": false,
            "migration_error": migration_result.error,
            "expected": test_cases[test_name].expected,
            "actual": null
        }
    
    # Read the migrated output
    var file = FileAccess.open(output_path_file, FileAccess.READ)
    if not file:
        return {
            "passed": false,
            "error": "Failed to read migrated output file",
            "expected": test_cases[test_name].expected,
            "actual": null
        }
    
    var actual_output = file.get_as_text()
    file.close()
    
    # Compare with expected output
    var expected_output = test_cases[test_name].expected
    var normalized_expected = _normalize_script(expected_output)
    var normalized_actual = _normalize_script(actual_output)
    
    var passed = normalized_expected == normalized_actual
    
    return {
        "passed": passed,
        "expected": normalized_expected,
        "actual": normalized_actual,
        "warnings": migration_result.warnings,
        "errors": migration_result.errors
    }

func _normalize_script(script_text):
    # Normalize script text for comparison (removes extra whitespace, etc.)
    var lines = script_text.split("\n")
    var normalized_lines = []
    
    for line in lines:
        var trimmed = line.strip_edges()
        if trimmed.length() > 0:
            normalized_lines.append(trimmed)
    
    return "\n".join(normalized_lines)

func _print_test_results(results):
    print("\n----- MIGRATION TEST RESULTS -----")
    print("Total tests: " + str(results.total))
    print("Passed: " + str(results.passed))
    print("Failed: " + str(results.failed))
    print("\nDetailed Results:")
    
    for test_name in results.details.keys():
        var test_result = results.details[test_name]
        var status = "‚úì PASSED" if test_result.passed else "‚úó FAILED"
        print("\n" + test_name + ": " + status)
        
        if not test_result.passed:
            print("\nExpected:")
            print(test_result.expected)
            print("\nActual:")
            print(test_result.actual)
            
            if test_result.has("migration_error"):
                print("\nMigration Error: " + test_result.migration_error)
        
        if test_result.has("warnings") and test_result.warnings.size() > 0:
            print("\nWarnings:")
            for warning in test_result.warnings:
                print("  - " + warning)
        
        if test_result.has("errors") and test_result.errors.size() > 0:
            print("\nErrors:")
            for error in test_result.errors:
                print("  - " + error)

# ----- ADDITIONAL TEST UTILITIES -----
func create_custom_test_case(name: String, input_script: String, expected_output: String) -> bool:
    # Add a custom test case
    if test_cases.has(name):
        push_error("Test case with name '" + name + "' already exists")
        return false
    
    test_cases[name] = {
        "input": input_script,
        "expected": expected_output
    }
    
    if verbose_logging:
        print("Added custom test case: " + name)
    
    return true

func run_single_test(test_name: String):
    # Run a single named test
    if not test_cases.has(test_name):
        push_error("Test case '" + test_name + "' does not exist")
        return null
    
    _generate_test_scripts()
    
    var test_result = _run_test(test_name)
    
    # Print result
    print("\n----- TEST RESULT: " + test_name + " -----")
    var status = "‚úì PASSED" if test_result.passed else "‚úó FAILED"
    print("Status: " + status)
    
    if not test_result.passed:
        print("\nExpected:")
        print(test_result.expected)
        print("\nActual:")
        print(test_result.actual)
        
        if test_result.has("migration_error"):
            print("\nMigration Error: " + test_result.migration_error)
    
    return test_result

func test_custom_script(script_content: String) -> Dictionary:
    # Test migration on custom script content without saving to a test case
    
    # Create a temporary file
    var temp_path = test_scripts_path.path_join("temp_test.gd")
    var output_path_file = output_path.path_join("temp_test_migrated.gd")
    
    var file = FileAccess.open(temp_path, FileAccess.WRITE)
    if not file:
        return {
            "success": false,
            "error": "Failed to create temporary test file"
        }
    
    file.store_string(script_content)
    file.close()
    
    # Run migration
    var migration_result = migration_tool.migrate_single_file(temp_path, output_path_file)
    
    if not migration_result.success:
        return {
            "success": false,
            "error": migration_result.error
        }
    
    # Read the migrated output
    file = FileAccess.open(output_path_file, FileAccess.READ)
    if not file:
        return {
            "success": false,
            "error": "Failed to read migrated output file"
        }
    
    var migrated_content = file.get_as_text()
    file.close()
    
    # Clean up temporary file
    var dir = DirAccess.open(test_scripts_path)
    if dir:
        dir.remove("temp_test.gd")
    
    return {
        "success": true,
        "original": script_content,
        "migrated": migrated_content,
        "warnings": migration_result.warnings,
        "errors": migration_result.errors
    }

func generate_test_report(file_path: String = "") -> String:
    # Generate a detailed test report and optionally save to file
    var results = run_all_tests()
    
    var report = "# Godot 4 Migration Test Report\n\n"
    report += "Generated: " + Time.get_datetime_string_from_system() + "\n\n"
    report += "## Summary\n\n"
    report += "- Total Tests: " + str(results.total) + "\n"
    report += "- Passed: " + str(results.passed) + "\n"
    report += "- Failed: " + str(results.failed) + "\n"
    report += "- Success Rate: " + str(float(results.passed) / results.total * 100) + "%\n\n"
    
    report += "## Detailed Results\n\n"
    
    for test_name in results.details.keys():
        var test_result = results.details[test_name]
        var status = "‚úÖ PASSED" if test_result.passed else "‚ùå FAILED"
        
        report += "### " + test_name + ": " + status + "\n\n"
        
        if not test_result.passed:
            report += "#### Expected Output\n\n```gdscript\n" + test_result.expected + "\n```\n\n"
            report += "#### Actual Output\n\n```gdscript\n" + test_result.actual + "\n```\n\n"
            
            if test_result.has("migration_error"):
                report += "#### Migration Error\n\n" + test_result.migration_error + "\n\n"
        
        if test_result.has("warnings") and test_result.warnings.size() > 0:
            report += "#### Warnings\n\n"
            for warning in test_result.warnings:
                report += "- " + warning + "\n"
            report += "\n"
        
        if test_result.has("errors") and test_result.errors.size() > 0:
            report += "#### Errors\n\n"
            for error in test_result.errors:
                report += "- " + error + "\n"
            report += "\n"
    
    # Save to file if path is provided
    if file_path != "":
        var file = FileAccess.open(file_path, FileAccess.WRITE)
        if file:
            file.store_string(report)
            file.close()
            print("Test report saved to: " + file_path)
        else:
            push_error("Failed to save test report to: " + file_path)
    
    return report

# ----- BATCH TESTING -----
func batch_test_directory(directory_path: String) -> Dictionary:
    # Test all GDScript files in a directory
    var files = _get_all_script_files(directory_path)
    var results = {
        "total_files": files.size(),
        "successful_migrations": 0,
        "failed_migrations": 0,
        "details": {}
    }
    
    for file_path in files:
        var file_name = file_path.get_file()
        var output_path_file = output_path.path_join(file_name.get_basename() + "_migrated.gd")
        
        var migration_result = migration_tool.migrate_single_file(file_path, output_path_file)
        
        if migration_result.success and migration_result.modified:
            results.successful_migrations += 1
        else:
            results.failed_migrations += 1
        
        results.details[file_path] = migration_result
    
    return results

func _get_all_script_files(path: String) -> Array:
    var files = []
    var dir = DirAccess.open(path)
    
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            var full_path = path.path_join(file_name)
            
            if dir.current_is_dir() and file_name != "." and file_name != "..":
                # Recursively process subdirectories
                files.append_array(_get_all_script_files(full_path))
            elif file_name.ends_with(".gd"):
                files.append(full_path)
            
            file_name = dir.get_next()
    else:
        push_error("Failed to open directory: " + path)
    
    return files

# ----- ADVANCED TESTING -----
func test_migration_with_color_system():
    # Test the integration between migration and color system
    if not color_system:
        push_error("Color system not found, integration test cannot run")
        return {
            "success": false,
            "error": "Color system not found"
        }
    
    # Run a test that would generate color-coded output when integrated with color system
    var test_results = run_all_tests()
    var nodes_migrated = 0
    var methods_migrated = 0
    var properties_migrated = 0
    
    # Count different types of migrations
    for test_name in test_results.details.keys():
        var test_result = test_results.details[test_name]
        
        if test_name == "node_renames" and test_result.passed:
            nodes_migrated += 1
        elif test_name == "method_renames" and test_result.passed:
            methods_migrated += 1
        elif test_name == "property_renames" and test_result.passed:
            properties_migrated += 1
    
    # In a real implementation, this would call the color system to visualize these statistics
    # For now, we just return the numbers
    return {
        "success": true,
        "nodes_migrated": nodes_migrated,
        "methods_migrated": methods_migrated,
        "properties_migrated": properties_migrated,
        "total_passed": test_results.passed,
        "total_failed": test_results.failed
    }
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/godot4_migration_tester.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/godot4_migration_test_runner.gd
# SIZE: 22654 bytes
class_name Godot4MigrationTestRunner
extends Control

# ----- UI COMPONENTS -----
@onready var test_list = $Layout/TestPanel/ScrollContainer/TestList
@onready var run_all_tests_button = $Layout/ControlPanel/RunAllButton
@onready var run_selected_test_button = $Layout/ControlPanel/RunSelectedButton
@onready var batch_test_button = $Layout/ControlPanel/BatchTestButton
@onready var generate_report_button = $Layout/ControlPanel/GenerateReportButton
@onready var batch_path_input = $Layout/ControlPanel/BatchPathInput
@onready var browse_button = $Layout/ControlPanel/BrowseButton
@onready var progress_bar = $Layout/TestProgress/ProgressBar
@onready var status_label = $Layout/TestProgress/StatusLabel

@onready var result_title = $Layout/ResultPanel/ResultTitle
@onready var result_view = $Layout/ResultPanel/ResultView
@onready var result_tabs = $Layout/ResultPanel/ResultTabs
@onready var expected_tab = $Layout/ResultPanel/ResultTabs/ExpectedTab
@onready var actual_tab = $Layout/ResultPanel/ResultTabs/ActualTab
@onready var diff_tab = $Layout/ResultPanel/ResultTabs/DiffTab
@onready var expected_text = $Layout/ResultPanel/ResultTabs/ExpectedTab/ExpectedText
@onready var actual_text = $Layout/ResultPanel/ResultTabs/ActualTab/ActualText
@onready var diff_text = $Layout/ResultPanel/ResultTabs/DiffTab/DiffText

@onready var summary_panel = $Layout/SummaryPanel/VBoxContainer
@onready var total_tests_label = $Layout/SummaryPanel/VBoxContainer/TotalTests
@onready var passed_tests_label = $Layout/SummaryPanel/VBoxContainer/PassedTests
@onready var failed_tests_label = $Layout/SummaryPanel/VBoxContainer/FailedTests
@onready var success_rate_label = $Layout/SummaryPanel/VBoxContainer/SuccessRate

@onready var file_dialog = $FileDialog

# ----- COMPONENTS -----
var migration_tester = null
var color_system = null

# ----- STATE VARIABLES -----
var current_test_results = {}
var test_items = {}
var selected_test = ""
var is_testing = false

# ----- INITIALIZATION -----
func _ready():
    _find_components()
    _setup_ui()
    _connect_signals()
    _populate_test_list()
    
    print("Godot4 Migration Test Runner initialized")

func _find_components():
    # Find or create the migration tester
    migration_tester = get_node_or_null("/root/Godot4MigrationTester")
    if not migration_tester:
        migration_tester = _find_node_by_class(get_tree().root, "Godot4MigrationTester")
    
    if not migration_tester:
        migration_tester = Godot4MigrationTester.new()
        add_child(migration_tester)
    
    # Find Color System
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    print("Components found - Migration Tester: %s, Color System: %s" % [
        "Yes" if migration_tester else "No",
        "Yes" if color_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _setup_ui():
    # Set up UI components
    if not is_instance_valid(test_list):
        # Create UI components if not using scene
        _create_ui_components()
    
    # Initialize UI state
    run_selected_test_button.disabled = true
    progress_bar.value = 0
    result_title.text = "Test Results"
    result_view.text = "Run a test to see results"
    
    _clear_result_tabs()
    
    total_tests_label.text = "Total Tests: 0"
    passed_tests_label.text = "Passed: 0"
    failed_tests_label.text = "Failed: 0"
    success_rate_label.text = "Success Rate: 0%"

func _create_ui_components():
    # Create UI components programmatically if not using a scene
    # This is a fallback for when the runner is not instantiated from a scene
    
    # Create main layout
    var main_vbox = VBoxContainer.new()
    main_vbox.set_anchors_preset(PRESET_FULL_RECT)
    add_child(main_vbox)
    
    # Create top section with controls
    var control_panel = HBoxContainer.new()
    main_vbox.add_child(control_panel)
    
    run_all_tests_button = Button.new()
    run_all_tests_button.text = "Run All Tests"
    control_panel.add_child(run_all_tests_button)
    
    run_selected_test_button = Button.new()
    run_selected_test_button.text = "Run Selected Test"
    run_selected_test_button.disabled = true
    control_panel.add_child(run_selected_test_button)
    
    batch_test_button = Button.new()
    batch_test_button.text = "Batch Test Directory"
    control_panel.add_child(batch_test_button)
    
    batch_path_input = LineEdit.new()
    batch_path_input.placeholder_text = "Enter directory path for batch testing"
    batch_path_input.size_flags_horizontal = SIZE_EXPAND_FILL
    control_panel.add_child(batch_path_input)
    
    browse_button = Button.new()
    browse_button.text = "Browse"
    control_panel.add_child(browse_button)
    
    generate_report_button = Button.new()
    generate_report_button.text = "Generate Report"
    control_panel.add_child(generate_report_button)
    
    # Create progress section
    var progress_panel = VBoxContainer.new()
    main_vbox.add_child(progress_panel)
    
    progress_bar = ProgressBar.new()
    progress_bar.min_value = 0
    progress_bar.max_value = 100
    progress_bar.value = 0
    progress_bar.size_flags_horizontal = SIZE_EXPAND_FILL
    progress_panel.add_child(progress_bar)
    
    status_label = Label.new()
    status_label.text = "Ready"
    progress_panel.add_child(status_label)
    
    # Create content section with test list and results
    var content_panel = HBoxContainer.new()
    content_panel.size_flags_vertical = SIZE_EXPAND_FILL
    main_vbox.add_child(content_panel)
    
    # Test list panel
    var test_panel = VBoxContainer.new()
    test_panel.size_flags_horizontal = SIZE_EXPAND_FILL
    test_panel.size_flags_stretch_ratio = 0.3
    content_panel.add_child(test_panel)
    
    var test_label = Label.new()
    test_label.text = "Test Cases"
    test_panel.add_child(test_label)
    
    var scroll_container = ScrollContainer.new()
    scroll_container.size_flags_vertical = SIZE_EXPAND_FILL
    test_panel.add_child(scroll_container)
    
    test_list = VBoxContainer.new()
    test_list.size_flags_horizontal = SIZE_EXPAND_FILL
    scroll_container.add_child(test_list)
    
    # Results panel
    var result_panel = VBoxContainer.new()
    result_panel.size_flags_horizontal = SIZE_EXPAND_FILL
    result_panel.size_flags_stretch_ratio = 0.7
    content_panel.add_child(result_panel)
    
    result_title = Label.new()
    result_title.text = "Test Results"
    result_panel.add_child(result_title)
    
    result_view = RichTextLabel.new()
    result_view.bbcode_enabled = true
    result_view.size_flags_vertical = SIZE_EXPAND_FILL
    result_panel.add_child(result_view)
    
    # Result tabs
    result_tabs = TabContainer.new()
    result_tabs.size_flags_vertical = SIZE_EXPAND_FILL
    result_panel.add_child(result_tabs)
    
    expected_tab = VBoxContainer.new()
    expected_tab.name = "Expected"
    result_tabs.add_child(expected_tab)
    
    expected_text = TextEdit.new()
    expected_text.syntax_highlighter = SyntaxHighlighter.new()
    expected_text.editable = false
    expected_text.size_flags_vertical = SIZE_EXPAND_FILL
    expected_tab.add_child(expected_text)
    
    actual_tab = VBoxContainer.new()
    actual_tab.name = "Actual"
    result_tabs.add_child(actual_tab)
    
    actual_text = TextEdit.new()
    actual_text.syntax_highlighter = SyntaxHighlighter.new()
    actual_text.editable = false
    actual_text.size_flags_vertical = SIZE_EXPAND_FILL
    actual_tab.add_child(actual_text)
    
    diff_tab = VBoxContainer.new()
    diff_tab.name = "Diff"
    result_tabs.add_child(diff_tab)
    
    diff_text = RichTextLabel.new()
    diff_text.bbcode_enabled = true
    diff_text.size_flags_vertical = SIZE_EXPAND_FILL
    diff_tab.add_child(diff_text)
    
    # Summary panel
    var summary_panel = VBoxContainer.new()
    summary_panel.size_flags_horizontal = SIZE_EXPAND_FILL
    main_vbox.add_child(summary_panel)
    
    var summary_label = Label.new()
    summary_label.text = "Test Summary"
    summary_panel.add_child(summary_label)
    
    total_tests_label = Label.new()
    total_tests_label.text = "Total Tests: 0"
    summary_panel.add_child(total_tests_label)
    
    passed_tests_label = Label.new()
    passed_tests_label.text = "Passed: 0"
    summary_panel.add_child(passed_tests_label)
    
    failed_tests_label = Label.new()
    failed_tests_label.text = "Failed: 0"
    summary_panel.add_child(failed_tests_label)
    
    success_rate_label = Label.new()
    success_rate_label.text = "Success Rate: 0%"
    summary_panel.add_child(success_rate_label)
    
    # File dialog
    file_dialog = FileDialog.new()
    file_dialog.access = FileDialog.ACCESS_FILESYSTEM
    file_dialog.file_mode = FileDialog.FILE_MODE_OPEN_DIR
    add_child(file_dialog)

func _connect_signals():
    # Connect UI signals
    run_all_tests_button.pressed.connect(_on_run_all_tests_pressed)
    run_selected_test_button.pressed.connect(_on_run_selected_test_pressed)
    batch_test_button.pressed.connect(_on_batch_test_pressed)
    browse_button.pressed.connect(_on_browse_pressed)
    generate_report_button.pressed.connect(_on_generate_report_pressed)
    file_dialog.dir_selected.connect(_on_dir_selected)
    
    # Connect migration tester signals
    migration_tester.test_started.connect(_on_test_started)
    migration_tester.test_completed.connect(_on_test_completed)
    migration_tester.test_case_started.connect(_on_test_case_started)
    migration_tester.test_case_completed.connect(_on_test_case_completed)

func _populate_test_list():
    # Clear existing items
    for child in test_list.get_children():
        child.queue_free()
    
    # Add test cases
    for test_name in migration_tester.test_cases.keys():
        var test_button = Button.new()
        test_button.text = test_name
        test_button.size_flags_horizontal = SIZE_EXPAND_FILL
        test_button.alignment = HORIZONTAL_ALIGNMENT_LEFT
        test_button.pressed.connect(_on_test_selected.bind(test_name))
        
        test_list.add_child(test_button)
        test_items[test_name] = test_button

# ----- UI EVENT HANDLERS -----
func _on_run_all_tests_pressed():
    if is_testing:
        return
    
    is_testing = true
    _clear_result_tabs()
    result_view.text = "Running all tests..."
    
    # Run tests in a deferred call to allow UI to update
    call_deferred("_run_all_tests")

func _run_all_tests():
    var results = migration_tester.run_all_tests()
    current_test_results = results
    is_testing = false

func _on_run_selected_test_pressed():
    if is_testing or selected_test.is_empty():
        return
    
    is_testing = true
    _clear_result_tabs()
    result_view.text = "Running test: " + selected_test + "..."
    
    # Run tests in a deferred call to allow UI to update
    call_deferred("_run_selected_test")

func _run_selected_test():
    var result = migration_tester.run_single_test(selected_test)
    
    # Create a results structure similar to full test run
    current_test_results = {
        "total": 1,
        "passed": 1 if result.passed else 0,
        "failed": 0 if result.passed else 1,
        "details": {}
    }
    current_test_results.details[selected_test] = result
    
    _update_test_result_view(selected_test, result)
    _update_summary(current_test_results)
    
    is_testing = false

func _on_batch_test_pressed():
    if is_testing:
        return
    
    var batch_path = batch_path_input.text
    if batch_path.is_empty() or not DirAccess.dir_exists_absolute(batch_path):
        _show_error("Invalid directory path for batch testing")
        return
    
    is_testing = true
    _clear_result_tabs()
    result_view.text = "Running batch tests on directory: " + batch_path + "..."
    
    # Run batch test in a deferred call to allow UI to update
    call_deferred("_run_batch_test", batch_path)

func _run_batch_test(path):
    var results = migration_tester.batch_test_directory(path)
    
    # Display batch test results
    result_view.clear()
    result_view.push_paragraph(HORIZONTAL_ALIGNMENT_LEFT)
    result_view.append_text("Batch Test Results for: " + path + "\n\n")
    result_view.append_text("Total Files: " + str(results.total_files) + "\n")
    result_view.append_text("Successful Migrations: " + str(results.successful_migrations) + "\n")
    result_view.append_text("Failed Migrations: " + str(results.failed_migrations) + "\n\n")
    
    if results.total_files > 0:
        var success_rate = float(results.successful_migrations) / results.total_files * 100
        result_view.append_text("Success Rate: " + str(success_rate) + "%\n\n")
    
    result_view.append_text("File Details:\n")
    
    for file_path in results.details.keys():
        var file_result = results.details[file_path]
        var status = "‚úì SUCCESS" if file_result.success and file_result.modified else "‚úó FAILED"
        
        result_view.append_text("\n" + file_path + ": " + status + "\n")
        
        if file_result.has("warnings") and file_result.warnings.size() > 0:
            result_view.append_text("  Warnings:\n")
            for warning in file_result.warnings:
                result_view.append_text("  - " + warning + "\n")
        
        if file_result.has("errors") and file_result.errors.size() > 0:
            result_view.append_text("  Errors:\n")
            for error in file_result.errors:
                result_view.append_text("  - " + error + "\n")
    
    result_view.pop()
    
    is_testing = false

func _on_browse_pressed():
    file_dialog.title = "Select Directory for Batch Testing"
    file_dialog.popup_centered_ratio(0.7)

func _on_dir_selected(dir_path):
    batch_path_input.text = dir_path

func _on_generate_report_pressed():
    if is_testing:
        return
    
    is_testing = true
    _clear_result_tabs()
    result_view.text = "Generating test report..."
    
    # Generate report in a deferred call to allow UI to update
    call_deferred("_generate_report")

func _generate_report():
    var report_path = OS.get_user_data_dir().path_join("godot4_migration_test_report.md")
    var report = migration_tester.generate_test_report(report_path)
    
    result_view.clear()
    result_view.push_paragraph(HORIZONTAL_ALIGNMENT_LEFT)
    result_view.append_text("Test Report Generated\n\n")
    result_view.append_text("Report saved to: " + report_path + "\n\n")
    result_view.append_text("Report Preview:\n\n")
    result_view.append_text(report.substr(0, 1000) + "...\n\n")
    result_view.append_text("(Report has been truncated for preview. See full report at the saved path.)")
    result_view.pop()
    
    is_testing = false

func _on_test_selected(test_name):
    selected_test = test_name
    run_selected_test_button.disabled = false
    
    # Highlight selected test
    for name in test_items.keys():
        var button = test_items[name]
        button.disabled = (name == test_name)
    
    # If we have results for this test already, show them
    if current_test_results.has("details") and current_test_results.details.has(test_name):
        _update_test_result_view(test_name, current_test_results.details[test_name])

# ----- MIGRATION TESTER EVENT HANDLERS -----
func _on_test_started(total_tests):
    progress_bar.max_value = total_tests
    progress_bar.value = 0
    
    status_label.text = "Running tests (0/" + str(total_tests) + ")"
    
    _clear_test_item_highlights()

func _on_test_completed(results):
    progress_bar.value = progress_bar.max_value
    status_label.text = "Tests completed: " + str(results.passed) + "/" + str(results.total) + " passed"
    
    _update_summary(results)
    
    # Show overall results
    result_view.clear()
    result_view.push_paragraph(HORIZONTAL_ALIGNMENT_LEFT)
    result_view.append_text("Test Results Summary\n\n")
    result_view.append_text("Total Tests: " + str(results.total) + "\n")
    result_view.append_text("Passed: " + str(results.passed) + "\n")
    result_view.append_text("Failed: " + str(results.failed) + "\n")
    
    if results.total > 0:
        var success_rate = float(results.passed) / results.total * 100
        result_view.append_text("Success Rate: " + str(success_rate) + "%\n\n")
    
    result_view.append_text("Test Details:\n")
    
    for test_name in results.details.keys():
        var test_result = results.details[test_name]
        var status = "‚úì PASSED" if test_result.passed else "‚úó FAILED"
        
        result_view.append_text("\n" + test_name + ": " + status + "\n")
        
        if not test_result.passed:
            result_view.append_text("  (Click on the test name to see details)\n")
    
    result_view.pop()
    
    current_test_results = results

func _on_test_case_started(test_name):
    progress_bar.value += 1
    status_label.text = "Running test: " + test_name + " (" + str(progress_bar.value) + "/" + str(progress_bar.max_value) + ")"
    
    # Highlight current test in list
    if test_items.has(test_name):
        test_items[test_name].modulate = Color(1, 1, 0)  # Yellow for in-progress

func _on_test_case_completed(test_name, passed, details):
    # Update test item in list
    if test_items.has(test_name):
        test_items[test_name].modulate = Color(0, 1, 0) if passed else Color(1, 0, 0)  # Green for passed, red for failed
    
    # If this is the selected test, update the result view
    if test_name == selected_test:
        _update_test_result_view(test_name, details)

func _update_test_result_view(test_name, details):
    result_title.text = "Test Result: " + test_name
    
    # Clear existing content
    _clear_result_tabs()
    
    # Set expected content
    expected_text.text = details.expected
    
    # Set actual content
    actual_text.text = details.actual
    
    # Set diff content
    _update_diff_view(details.expected, details.actual)
    
    # Create summary view
    result_view.clear()
    result_view.push_paragraph(HORIZONTAL_ALIGNMENT_LEFT)
    var status = "‚úì PASSED" if details.passed else "‚úó FAILED"
    result_view.append_text("Test: " + test_name + " - " + status + "\n\n")
    
    if not details.passed:
        result_view.append_text("The migrated code does not match the expected output.\n")
        result_view.append_text("Check the 'Expected', 'Actual', and 'Diff' tabs to see the differences.\n\n")
    
    if details.has("migration_error"):
        result_view.append_text("Migration Error: " + details.migration_error + "\n\n")
    
    if details.has("warnings") and details.warnings.size() > 0:
        result_view.append_text("Warnings:\n")
        for warning in details.warnings:
            result_view.append_text("- " + warning + "\n")
        result_view.append_text("\n")
    
    if details.has("errors") and details.errors.size() > 0:
        result_view.append_text("Errors:\n")
        for error in details.errors:
            result_view.append_text("- " + error + "\n")
    
    result_view.pop()

func _update_diff_view(expected, actual):
    # Create a simple line-by-line diff
    var expected_lines = expected.split("\n")
    var actual_lines = actual.split("\n")
    
    diff_text.clear()
    diff_text.push_paragraph(HORIZONTAL_ALIGNMENT_LEFT)
    
    var max_lines = max(expected_lines.size(), actual_lines.size())
    
    for i in range(max_lines):
        var expected_line = ""
        var actual_line = ""
        
        if i < expected_lines.size():
            expected_line = expected_lines[i]
        
        if i < actual_lines.size():
            actual_line = actual_lines[i]
        
        if expected_line == actual_line:
            diff_text.append_text(str(i + 1) + ": " + expected_line + "\n")
        else:
            diff_text.push_color(Color(1, 0, 0))  # Red for expected that doesn't match
            diff_text.append_text(str(i + 1) + " -: " + expected_line + "\n")
            diff_text.pop()
            
            diff_text.push_color(Color(0, 1, 0))  # Green for actual that doesn't match
            diff_text.append_text(str(i + 1) + " +: " + actual_line + "\n")
            diff_text.pop()
            
            diff_text.append_text("\n")
    
    diff_text.pop()

func _update_summary(results):
    total_tests_label.text = "Total Tests: " + str(results.total)
    passed_tests_label.text = "Passed: " + str(results.passed)
    failed_tests_label.text = "Failed: " + str(results.failed)
    
    if results.total > 0:
        var success_rate = float(results.passed) / results.total * 100
        success_rate_label.text = "Success Rate: " + str(success_rate) + "%"
    else:
        success_rate_label.text = "Success Rate: 0%"

# ----- HELPER FUNCTIONS -----
func _clear_result_tabs():
    expected_text.text = ""
    actual_text.text = ""
    diff_text.clear()

func _clear_test_item_highlights():
    for name in test_items.keys():
        test_items[name].modulate = Color(1, 1, 1)
        test_items[name].disabled = false

func _show_error(message):
    OS.alert(message, "Error")

# ----- COLOR INTEGRATION -----
func integrate_with_color_system():
    if not color_system:
        print("Color system not found, color integration not available")
        return
    
    # In a real implementation, this would:
    # 1. Register test result colors with the color system
    # 2. Set up callback hooks to update UI elements based on color system state
    # 3. Use color system for visualization of test progress and results
    
    print("Color system integration enabled")
    
    # Example: Update summary panel with color system colors
    if current_test_results.has("total") and current_test_results.total > 0:
        var success_rate = float(current_test_results.passed) / current_test_results.total
        
        # In a real implementation, color_system would provide these colors
        var text_color = Color(1, 1, 1)
        var background_color = Color(0.2, 0.2, 0.2)
        
        if success_rate >= 0.8:
            text_color = Color(0, 1, 0)
        elif success_rate >= 0.5:
            text_color = Color(1, 1, 0)
        else:
            text_color = Color(1, 0, 0)
        
        # Apply colors
        summary_panel.modulate = text_color
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/godot4_migration_test_runner.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/godot4_migration_tool.gd
# SIZE: 31814 bytes
class_name Godot4MigrationTool
extends Node

# ----- MIGRATION SETTINGS -----
@export_category("Migration Settings")
@export var godot3_project_path: String = ""
@export var godot4_project_path: String = ""
@export var backup_before_migration: bool = true
@export var auto_fix_deprecated: bool = true
@export var migrate_resources: bool = true
@export var verbose_logging: bool = true

# ----- MIGRATION STATISTICS -----
var files_processed: int = 0
var files_modified: int = 0
var errors_encountered: int = 0
var warnings_generated: int = 0

# ----- CONVERSION MAPS -----
# Node name changes from Godot 3 to 4
const NODE_RENAMES = {
    "Spatial": "Node3D",
    "MeshInstance": "MeshInstance3D",
    "AnimationPlayer": "AnimationPlayer",  # No change
    "RigidBody": "RigidBody3D",
    "KinematicBody": "CharacterBody3D",
    "StaticBody": "StaticBody3D",
    "Camera": "Camera3D",
    "Control": "Control",  # No change
    "RayCast": "RayCast3D",
    "Area": "Area3D",
    "Position2D": "Marker2D",
    "Position3D": "Marker3D",
    "CollisionShape": "CollisionShape3D",
    "CollisionPolygon": "CollisionPolygon3D",
    "VisibilityNotifier": "VisibleOnScreenNotifier3D",
    "VisibilityEnabler": "VisibleOnScreenEnabler3D",
    "Joint": "Joint3D",
    "Navigation": "NavigationRegion3D",
    "NavigationMeshInstance": "NavigationRegion3D",
    "Path": "Path3D",
    "PathFollow": "PathFollow3D",
    "AnimatedSprite": "AnimatedSprite2D",
    "RemoteTransform": "RemoteTransform3D"
}

# Method name changes from Godot 3 to 4
const METHOD_RENAMES = {
    "get_translation": "get_position",
    "set_translation": "set_position",
    "rotate_x": "rotate_x",  # No change but format differs
    "rotate_y": "rotate_y",  # No change but format differs
    "rotate_z": "rotate_z",  # No change but format differs
    "is_network_master": "is_multiplayer_authority",
    "rpc_id": "rpc_id",  # No change but usage differs
    "rpc_unreliable_id": "rpc_id",
    "rpc": "rpc",  # No change but usage differs
    "rpc_unreliable": "rpc",
    "yield": "await",
    "is_action_pressed": "is_action_pressed",  # No change, included for completeness
    "is_action_just_pressed": "is_action_just_pressed",  # No change, included for completeness
    "get_slide_count": "get_slide_collision_count",
    "get_slide_collision": "get_slide_collision",  # No change but usage differs
    "connect": "connect",  # No change but syntax differs
    "emit_signal": "emit_signal",  # No change but can be replaced with direct call
    "get_node": "get_node"  # No change, included for completeness
}

# Property name changes from Godot 3 to 4
const PROPERTY_RENAMES = {
    "translation": "position",
    "rotation_degrees": "rotation_degrees",  # No change but treatment differs
    "visible": "visible",  # No change, included for completeness
    "transform": "transform",  # No change but usage differs
    "global_transform": "global_transform",  # No change but usage differs
    "rect_size": "size",
    "rect_position": "position",
    "rect_global_position": "global_position",
    "rect_min_size": "custom_minimum_size",
    "margin_left": "position.x",  # This is trickier and may need custom handling
    "margin_right": "size.x + position.x",  # This is trickier and may need custom handling
    "margin_top": "position.y",  # This is trickier and may need custom handling
    "margin_bottom": "size.y + position.y",  # This is trickier and may need custom handling
    "mesh_library": "mesh_library",  # No change, included for completeness
    "ray_length": "target_position.length()",  # For RayCast
    "cast_to": "target_position"
}

# Physics layers handling changes
const PHYSICS_LAYER_NAMES = [
    "layer_1",
    "layer_2",
    "layer_3",
    "layer_4",
    "layer_5",
    "layer_6",
    "layer_7",
    "layer_8",
    "layer_9",
    "layer_10",
    "layer_11",
    "layer_12",
    "layer_13",
    "layer_14",
    "layer_15",
    "layer_16",
    "layer_17",
    "layer_18",
    "layer_19",
    "layer_20"
]

# Input map changes
const INPUT_MAP_CHANGES = {
    "KEY_": "Key",
    "JOY_": "Joy",
    "BUTTON_": "Button",
    "MOTION_": "Motion",
    "MOUSE_": "Mouse"
}

# Common patterns that need updating
const CODE_PATTERNS_TO_UPDATE = {
    # Await replacement for yield
    "yield\\s*\\(([^,]+)\\s*,\\s*[\"\']([^\"\']+)[\"\']\\s*\\)": "await $1.$2",
    # Direct signal emission
    "emit_signal\\s*\\([\"\']([^\"\']+)[\"\'](?:,\\s*([^)]+))?\\)": "$1.emit($2)",
    # _physics_process delta parameter type
    "func\\s+_physics_process\\s*\\(\\s*delta\\s*\\)": "func _physics_process(delta: float) -> void",
    # _process delta parameter type
    "func\\s+_process\\s*\\(\\s*delta\\s*\\)": "func _process(delta: float) -> void",
    # Return type hints for builtin functions
    "func\\s+_ready\\s*\\(\\s*\\)": "func _ready() -> void",
    "func\\s+_input\\s*\\(\\s*event\\s*\\)": "func _input(event: InputEvent) -> void",
    # Signal connection with callables
    "connect\\s*\\([\"\']([^\"\']+)[\"\']\\s*,\\s*([^,]+)\\s*,\\s*[\"\']([^\"\']+)[\"\']\\)": "connect(\"$1\", Callable($2, \"$3\"))",
    # RigidBody to RigidBody3D mode property
    "mode\\s*=\\s*RigidBody.MODE_": "freeze = ",
    # Replace Vector2/Vector3 constructors
    "Vector2\\s*\\(\\s*([^,]+)\\s*,\\s*([^)]+)\\s*\\)": "Vector2($1, $2)",
    "Vector3\\s*\\(\\s*([^,]+)\\s*,\\s*([^,]+)\\s*,\\s*([^)]+)\\s*\\)": "Vector3($1, $2, $3)",
    # Add typed array declarations
    "var\\s+([a-zA-Z0-9_]+)\\s*=\\s*\\[\\]": "var $1: Array = []"
}

# ----- COMPONENT REFERENCES -----
var file_system = null
var color_system = null
var akashic_system = null
var progress_dialog = null

# ----- SIGNALS -----
signal migration_started(total_files)
signal migration_completed(stats)
signal file_processed(file_path, modified)
signal migration_error(file_path, error_message)
signal migration_warning(file_path, warning_message)
signal progress_updated(current, total)

# ----- INITIALIZATION -----
func _ready():
    _find_components()
    print("Godot4 Migration Tool initialized")

func _find_components():
    # Find FileSystem
    file_system = get_node_or_null("/root/FileSystem")
    if not file_system:
        file_system = self  # Use basic built-in functions if dedicated FileSystem not found
    
    # Find Color System
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find Akashic System
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    print("Components found - Color System: %s, Akashic System: %s" % [
        "Yes" if color_system else "No",
        "Yes" if akashic_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

# ----- MIGRATION FUNCTIONS -----
func start_migration() -> bool:
    # Check if paths are valid
    if godot3_project_path.is_empty() or godot4_project_path.is_empty():
        push_error("Both Godot 3 and Godot 4 project paths must be specified")
        return false
    
    # Reset statistics
    files_processed = 0
    files_modified = 0
    errors_encountered = 0
    warnings_generated = 0
    
    # Get all script files to process
    var script_files = _get_all_script_files(godot3_project_path)
    if script_files.size() == 0:
        push_error("No script files found at path: " + godot3_project_path)
        return false
    
    print("Starting migration of " + str(script_files.size()) + " script files")
    emit_signal("migration_started", script_files.size())
    
    # Create backup if needed
    if backup_before_migration:
        _create_backup(godot3_project_path)
    
    # Process each script file
    var total_files = script_files.size()
    var current_file = 0
    
    for file_path in script_files:
        current_file += 1
        
        # Update progress
        emit_signal("progress_updated", current_file, total_files)
        
        # Process file
        var result = _process_script_file(file_path)
        files_processed += 1
        
        if result.modified:
            files_modified += 1
        
        if result.errors.size() > 0:
            errors_encountered += result.errors.size()
            for error in result.errors:
                emit_signal("migration_error", file_path, error)
        
        if result.warnings.size() > 0:
            warnings_generated += result.warnings.size()
            for warning in result.warnings:
                emit_signal("migration_warning", file_path, warning)
        
        emit_signal("file_processed", file_path, result.modified)
    
    # Migrate project settings
    _migrate_project_settings()
    
    # Migrate resources if needed
    if migrate_resources:
        _migrate_resources()
    
    # Migration complete
    var stats = {
        "files_processed": files_processed,
        "files_modified": files_modified,
        "errors_encountered": errors_encountered,
        "warnings_generated": warnings_generated
    }
    
    print("Migration completed. Stats: " + str(stats))
    emit_signal("migration_completed", stats)
    
    return true

func _get_all_script_files(path: String) -> Array:
    var files = []
    var dir = DirAccess.open(path)
    
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            var full_path = path.path_join(file_name)
            
            if dir.current_is_dir() and file_name != "." and file_name != "..":
                # Recursively process subdirectories
                files.append_array(_get_all_script_files(full_path))
            elif file_name.ends_with(".gd"):
                files.append(full_path)
            
            file_name = dir.get_next()
    else:
        push_error("Failed to open directory: " + path)
    
    return files

func _create_backup(path: String) -> void:
    # Create a backup directory
    var timestamp = Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_")
    var backup_path = path + "_backup_" + timestamp
    
    var dir = DirAccess.open(path.get_base_dir())
    if dir:
        var err = dir.make_dir(backup_path)
        if err != OK:
            push_error("Failed to create backup directory: " + backup_path)
            return
        
        # Copy files using OS.execute for robustness
        var output = []
        var exit_code = OS.execute("cp", ["-r", path + "/*", backup_path], output, true)
        
        if exit_code != 0:
            push_error("Failed to create backup. Error: " + str(output))
        else:
            print("Backup created at: " + backup_path)
    else:
        push_error("Failed to open directory for backup: " + path.get_base_dir())

func _process_script_file(file_path: String) -> Dictionary:
    # Initialize result
    var result = {
        "modified": false,
        "errors": [],
        "warnings": []
    }
    
    # Read file
    var file = FileAccess.open(file_path, FileAccess.READ)
    if not file:
        result.errors.append("Failed to open file for reading: " + file_path)
        return result
    
    var content = file.get_as_text()
    file.close()
    
    # Process content
    var original_content = content
    content = _update_script_content(content, file_path, result)
    
    # Write back if modified
    if content != original_content:
        # Determine output path in Godot 4 project
        var rel_path = file_path.replace(godot3_project_path, "")
        var output_path = godot4_project_path + rel_path
        
        # Ensure directory exists
        var dir = DirAccess.open(output_path.get_base_dir())
        if not dir:
            # Try to create the directory
            var err = DirAccess.make_dir_recursive_absolute(output_path.get_base_dir())
            if err != OK:
                result.errors.append("Failed to create directory: " + output_path.get_base_dir())
                return result
        
        # Write file
        var output_file = FileAccess.open(output_path, FileAccess.WRITE)
        if not output_file:
            result.errors.append("Failed to open file for writing: " + output_path)
            return result
        
        output_file.store_string(content)
        output_file.close()
        
        result.modified = true
        print("Updated: " + output_path)
    
    return result

func _update_script_content(content: String, file_path: String, result: Dictionary) -> String:
    # Apply all migration updates to script content
    
    # 1. Handle class/node renames
    content = _update_node_references(content, result)
    
    # 2. Handle method renames
    content = _update_method_calls(content, result)
    
    # 3. Handle property renames
    content = _update_property_references(content, result)
    
    # 4. Update code patterns
    content = _update_code_patterns(content, result)
    
    # 5. Handle special cases
    content = _handle_special_cases(content, file_path, result)
    
    # 6. Update for typed GDScript
    if auto_fix_deprecated:
        content = _add_type_hints(content, result)
    
    return content

func _update_node_references(content: String, result: Dictionary) -> String:
    # Update node class references
    var updated_content = content
    
    for old_name in NODE_RENAMES:
        var new_name = NODE_RENAMES[old_name]
        
        # Skip if no change needed
        if old_name == new_name:
            continue
        
        # Update extends statements
        var extends_pattern = "extends\\s+" + old_name
        updated_content = updated_content.replace(extends_pattern, "extends " + new_name)
        
        # Update preload and load statements
        var preload_pattern = "preload\\(\"res://.*/" + old_name + ".gd\"\\)"
        var load_pattern = "load\\(\"res://.*/" + old_name + ".gd\"\\)"
        
        # These would need regex for more accurate replacement
        # For simplicity, we're looking for exact pattern matches
        
        # Update is checks
        var is_pattern = "is\\s+" + old_name
        updated_content = updated_content.replace(is_pattern, "is " + new_name)
        
        # Update class_name declarations
        var class_pattern = "class_name\\s+(" + old_name + ")"
        var regex = RegEx.new()
        regex.compile(class_pattern)
        var matches = regex.search_all(updated_content)
        
        for match_result in matches:
            var old_text = match_result.get_string()
            var new_text = old_text.replace(old_name, new_name)
            updated_content = updated_content.replace(old_text, new_text)
    
    return updated_content

func _update_method_calls(content: String, result: Dictionary) -> String:
    # Update method calls
    var updated_content = content
    
    for old_method in METHOD_RENAMES:
        var new_method = METHOD_RENAMES[old_method]
        
        # Skip if no change needed
        if old_method == new_method:
            continue
        
        # This is a simplified approach for straightforward replacements
        # More complex cases like yield->await need special handling
        var method_pattern = "\\." + old_method + "\\("
        updated_content = updated_content.replace(method_pattern, "." + new_method + "(")
    
    return updated_content

func _update_property_references(content: String, result: Dictionary) -> String:
    # Update property references
    var updated_content = content
    
    for old_prop in PROPERTY_RENAMES:
        var new_prop = PROPERTY_RENAMES[old_prop]
        
        # Skip if no change needed
        if old_prop == new_prop:
            continue
        
        # Simple dot notation property access
        var prop_pattern = "\\." + old_prop + "\\b"
        updated_content = updated_content.replace(prop_pattern, "." + new_prop)
    
    return updated_content

func _update_code_patterns(content: String, result: Dictionary) -> String:
    # Update code patterns using regex
    var updated_content = content
    
    for pattern in CODE_PATTERNS_TO_UPDATE:
        var replacement = CODE_PATTERNS_TO_UPDATE[pattern]
        
        var regex = RegEx.new()
        regex.compile(pattern)
        
        var matches = regex.search_all(updated_content)
        for match_result in matches:
            var old_text = match_result.get_string()
            var new_text = regex.sub(old_text, replacement)
            updated_content = updated_content.replace(old_text, new_text)
    
    return updated_content

func _handle_special_cases(content: String, file_path: String, result: Dictionary) -> String:
    # Handle special cases that need custom processing
    var updated_content = content
    
    # Handle onready vars (Godot 4 supports them but static typing is preferred)
    if auto_fix_deprecated:
        var onready_regex = RegEx.new()
        onready_regex.compile("onready\\s+var\\s+([a-zA-Z0-9_]+)\\s*=\\s*(.+)")
        
        var matches = onready_regex.search_all(updated_content)
        for match_result in matches:
            var old_text = match_result.get_string()
            var var_name = match_result.get_string(1)
            var var_value = match_result.get_string(2)
            
            # Create new format with @onready annotation
            var new_text = "@onready var " + var_name + " = " + var_value
            updated_content = updated_content.replace(old_text, new_text)
    
    # Handle exports (export var -> @export var)
    if auto_fix_deprecated:
        var export_regex = RegEx.new()
        export_regex.compile("export\\s*\\((.+?)\\)\\s+var\\s+([a-zA-Z0-9_]+)")
        
        var matches = export_regex.search_all(updated_content)
        for match_result in matches:
            var old_text = match_result.get_string()
            var export_args = match_result.get_string(1)
            var var_name = match_result.get_string(2)
            
            # Create new format with @export annotation
            var new_text = "@export var " + var_name
            updated_content = updated_content.replace(old_text, new_text)
            
            # Add a warning because export parameters need manual conversion
            result.warnings.append("Export hint converted. Please check @export parameters manually: " + old_text)
    
    # Handle tool annotation
    if auto_fix_deprecated:
        updated_content = updated_content.replace("tool", "@tool")
    
    # Handle network related changes
    updated_content = updated_content.replace("master", "authority")
    updated_content = updated_content.replace("slave", "puppet")
    updated_content = updated_content.replace("set_network_master", "set_multiplayer_authority")
    
    return updated_content

func _add_type_hints(content: String, result: Dictionary) -> String:
    # Add type hints to improve code (optional)
    var updated_content = content
    
    # Add return type void to functions without return types
    var func_regex = RegEx.new()
    func_regex.compile("func\\s+([a-zA-Z0-9_]+)\\s*\\(([^)]*)\\)\\s*:")
    
    var matches = func_regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var func_name = match_result.get_string(1)
        var func_params = match_result.get_string(2)
        
        # Skip functions that already have return type
        if old_text.find("->") != -1:
            continue
        
        # Add basic void return type
        var new_text = old_text.replace("):", ") -> void:")
        updated_content = updated_content.replace(old_text, new_text)
    
    # Add parameter types where reasonable guesses can be made
    var param_regex = RegEx.new()
    param_regex.compile("\\(([^)]*)\\)")
    
    var common_param_types = {
        "delta": "float",
        "event": "InputEvent",
        "body": "Node",
        "area": "Area3D",
        "value": "Variant",
        "pos": "Vector2",
        "position": "Vector3",
        "id": "int",
        "index": "int",
        "name": "String",
        "text": "String"
    }
    
    matches = param_regex.search_all(updated_content)
    for match_result in matches:
        var old_text = match_result.get_string()
        var params = match_result.get_string(1)
        
        # Skip if empty parameters or already has type hints
        if params.strip_edges() == "" or params.find(":") != -1:
            continue
        
        # Add type hints for recognizable parameters
        var param_list = params.split(",")
        var new_params = []
        
        for param in param_list:
            param = param.strip_edges()
            var param_name = param
            
            # Handle default values
            if param.find("=") != -1:
                param_name = param.split("=")[0].strip_edges()
            
            # Check if we can add a type hint
            var typed_param = param
            for common_name in common_param_types:
                if param_name == common_name:
                    var type_hint = common_param_types[common_name]
                    typed_param = param_name + ": " + type_hint
                    
                    # Re-add default value if it was there
                    if param.find("=") != -1:
                        typed_param += " = " + param.split("=")[1].strip_edges()
                    
                    break
            
            new_params.append(typed_param)
        
        var new_text = "(" + ", ".join(new_params) + ")"
        updated_content = updated_content.replace(old_text, new_text)
    
    return updated_content

func _migrate_project_settings() -> void:
    # Read the Godot 3 project.godot file
    var godot3_project_file = godot3_project_path.path_join("project.godot")
    var godot4_project_file = godot4_project_path.path_join("project.godot")
    
    var file = FileAccess.open(godot3_project_file, FileAccess.READ)
    if not file:
        push_error("Failed to open Godot 3 project file: " + godot3_project_file)
        return
    
    var content = file.get_as_text()
    file.close()
    
    # Update syntax and settings for Godot 4
    var updated_content = content
    
    # Update config_version
    updated_content = updated_content.replace("config_version=4", "config_version=5")
    
    # Update input mapping syntax
    for old_key in INPUT_MAP_CHANGES:
        var new_key = INPUT_MAP_CHANGES[old_key]
        updated_content = updated_content.replace(old_key, new_key)
    
    # Write to Godot 4 project file
    var output_file = FileAccess.open(godot4_project_file, FileAccess.WRITE)
    if not output_file:
        push_error("Failed to open Godot 4 project file for writing: " + godot4_project_file)
        return
    
    output_file.store_string(updated_content)
    output_file.close()
    
    print("Project settings migrated: " + godot4_project_file)

func _migrate_resources() -> void:
    # Get all resource files (.tres, .tscn, etc.)
    var resource_extensions = [".tres", ".tscn", ".material", ".mesh", ".shader"]
    var resources = []
    
    for ext in resource_extensions:
        var ext_resources = _get_files_with_extension(godot3_project_path, ext)
        resources.append_array(ext_resources)
    
    # Process each resource file
    for resource_path in resources:
        _migrate_resource_file(resource_path)

func _get_files_with_extension(path: String, extension: String) -> Array:
    var files = []
    var dir = DirAccess.open(path)
    
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            var full_path = path.path_join(file_name)
            
            if dir.current_is_dir() and file_name != "." and file_name != "..":
                # Recursively process subdirectories
                files.append_array(_get_files_with_extension(full_path, extension))
            elif file_name.ends_with(extension):
                files.append(full_path)
            
            file_name = dir.get_next()
    else:
        push_error("Failed to open directory: " + path)
    
    return files

func _migrate_resource_file(file_path: String) -> void:
    # Read resource file
    var file = FileAccess.open(file_path, FileAccess.READ)
    if not file:
        push_error("Failed to open resource file: " + file_path)
        return
    
    var content = file.get_as_text()
    file.close()
    
    # Update paths and class references
    var updated_content = content
    
    # Update node type references
    for old_name in NODE_RENAMES:
        var new_name = NODE_RENAMES[old_name]
        
        # Skip if no change needed
        if old_name == new_name:
            continue
        
        # Update type references in resources
        updated_content = updated_content.replace("type=\"" + old_name + "\"", "type=\"" + new_name + "\"")
        updated_content = updated_content.replace("[ext_resource type=\"" + old_name + "\"", "[ext_resource type=\"" + new_name + "\"")
    
    # Determine output path in Godot 4 project
    var rel_path = file_path.replace(godot3_project_path, "")
    var output_path = godot4_project_path + rel_path
    
    # Ensure directory exists
    var dir = DirAccess.open(output_path.get_base_dir())
    if not dir:
        # Try to create the directory
        var err = DirAccess.make_dir_recursive_absolute(output_path.get_base_dir())
        if err != OK:
            push_error("Failed to create directory: " + output_path.get_base_dir())
            return
    
    # Write updated resource file
    var output_file = FileAccess.open(output_path, FileAccess.WRITE)
    if not output_file:
        push_error("Failed to open resource file for writing: " + output_path)
        return
    
    output_file.store_string(updated_content)
    output_file.close()
    
    print("Migrated resource: " + output_path)

# ----- PUBLIC API -----
func migrate_project(from_path: String, to_path: String) -> Dictionary:
    godot3_project_path = from_path
    godot4_project_path = to_path
    
    if start_migration():
        return {
            "success": true,
            "files_processed": files_processed,
            "files_modified": files_modified,
            "errors": errors_encountered,
            "warnings": warnings_generated
        }
    else:
        return {
            "success": false,
            "error": "Migration failed to start"
        }

func migrate_single_file(file_path: String, output_path: String = "") -> Dictionary:
    # Check if file exists
    if not FileAccess.file_exists(file_path):
        return {
            "success": false,
            "error": "File does not exist: " + file_path
        }
    
    # Determine output path
    var actual_output_path = output_path
    if actual_output_path.is_empty():
        actual_output_path = file_path.get_basename() + "_godot4" + file_path.get_extension()
    
    # Initialize result
    var result = {
        "modified": false,
        "errors": [],
        "warnings": []
    }
    
    # Read file
    var file = FileAccess.open(file_path, FileAccess.READ)
    if not file:
        return {
            "success": false,
            "error": "Failed to open file for reading: " + file_path
        }
    
    var content = file.get_as_text()
    file.close()
    
    # Process content
    var original_content = content
    content = _update_script_content(content, file_path, result)
    
    # Write back if modified
    if content != original_content:
        var output_file = FileAccess.open(actual_output_path, FileAccess.WRITE)
        if not output_file:
            return {
                "success": false,
                "error": "Failed to open file for writing: " + actual_output_path
            }
        
        output_file.store_string(content)
        output_file.close()
        
        result.modified = true
        print("Updated: " + actual_output_path)
    
    return {
        "success": true,
        "modified": result.modified,
        "warnings": result.warnings,
        "errors": result.errors,
        "output_path": actual_output_path
    }

func check_compatibility(file_path: String) -> Dictionary:
    # Check a file for Godot 4 compatibility without modifying it
    
    # Check if file exists
    if not FileAccess.file_exists(file_path):
        return {
            "success": false,
            "error": "File does not exist: " + file_path
        }
    
    # Initialize result
    var result = {
        "modified": false,
        "errors": [],
        "warnings": []
    }
    
    # Read file
    var file = FileAccess.open(file_path, FileAccess.READ)
    if not file:
        return {
            "success": false,
            "error": "Failed to open file for reading: " + file_path
        }
    
    var content = file.get_as_text()
    file.close()
    
    # Process content (without saving)
    var updated_content = _update_script_content(content, file_path, result)
    var is_compatible = (content == updated_content)
    
    # Find specific compatibility issues
    var compatibility_issues = []
    
    # Check for node class names
    for old_name in NODE_RENAMES:
        if old_name != NODE_RENAMES[old_name] and content.find(old_name) != -1:
            compatibility_issues.append("Uses deprecated node type: " + old_name)
    
    # Check for method names
    for old_method in METHOD_RENAMES:
        if old_method != METHOD_RENAMES[old_method] and content.find("." + old_method + "(") != -1:
            compatibility_issues.append("Uses deprecated method: " + old_method)
    
    # Check for properties
    for old_prop in PROPERTY_RENAMES:
        if old_prop != PROPERTY_RENAMES[old_prop] and content.find("." + old_prop) != -1:
            compatibility_issues.append("Uses deprecated property: " + old_prop)
    
    # Check for yield pattern
    if content.find("yield") != -1:
        compatibility_issues.append("Uses yield, which should be replaced with await")
    
    return {
        "success": true,
        "compatible": is_compatible,
        "issues": compatibility_issues,
        "warnings": result.warnings,
        "errors": result.errors
    }

func generate_migration_report(directory_path: String) -> Dictionary:
    # Generate a report of all files in a directory and their Godot 4 compatibility
    var report = {
        "total_files": 0,
        "compatible_files": 0,
        "incompatible_files": 0,
        "file_details": []
    }
    
    # Get all script files
    var script_files = _get_all_script_files(directory_path)
    report.total_files = script_files.size()
    
    # Check each file
    for file_path in script_files:
        var compatibility = check_compatibility(file_path)
        
        if compatibility.success:
            if compatibility.compatible:
                report.compatible_files += 1
            else:
                report.incompatible_files += 1
            
            report.file_details.append({
                "path": file_path,
                "compatible": compatibility.compatible,
                "issues": compatibility.issues,
                "warnings": compatibility.warnings,
                "errors": compatibility.errors
            })
    
    return report
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/godot4_migration_tool.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/godot4_migration_ui.gd
# SIZE: 18956 bytes
class_name Godot4MigrationUI
extends Control

# ----- UI COMPONENTS -----
@onready var godot3_path_input = $Paths/Godot3Path/LineEdit
@onready var godot4_path_input = $Paths/Godot4Path/LineEdit
@onready var browse_godot3_button = $Paths/Godot3Path/BrowseButton
@onready var browse_godot4_button = $Paths/Godot4Path/BrowseButton

@onready var backup_checkbox = $Options/BackupCheckbox
@onready var auto_fix_checkbox = $Options/AutoFixCheckbox
@onready var migrate_resources_checkbox = $Options/MigrateResourcesCheckbox
@onready var verbose_checkbox = $Options/VerboseCheckbox

@onready var progress_bar = $Progress/ProgressBar
@onready var status_label = $Progress/StatusLabel
@onready var start_button = $Progress/StartButton
@onready var report_button = $Progress/ReportButton

@onready var log_text = $Log/LogText
@onready var file_tree = $Files/FileTree
@onready var file_dialog = $FileDialog

# ----- MIGRATION TOOL -----
var migration_tool = null

# ----- STATE VARIABLES -----
var is_migrating = false
var current_file = 0
var total_files = 0
var selected_dir = ""
var migration_stats = {}
var file_status = {}

# ----- SIGNALS -----
signal migration_complete()

# ----- INITIALIZATION -----
func _ready():
    _setup_ui()
    _connect_signals()
    _find_migration_tool()
    
    _update_status("Ready to migrate. Please select project paths.")
    print("Godot 4 Migration UI initialized")

func _setup_ui():
    # Set up UI components
    if not is_instance_valid(godot3_path_input):
        # Create UI components if not using scene
        _create_ui_components()
    
    # Initialize UI state
    start_button.disabled = true
    report_button.disabled = true
    progress_bar.value = 0
    progress_bar.max_value = 100

func _create_ui_components():
    # Create UI components if not using scene
    # This is just a fallback for when the UI is not instantiated from a scene
    
    # Create layout containers
    var main_vbox = VBoxContainer.new()
    main_vbox.set_anchors_preset(PRESET_FULL_RECT)
    add_child(main_vbox)
    
    # Create path section
    var paths_section = VBoxContainer.new()
    main_vbox.add_child(paths_section)
    
    var paths_label = Label.new()
    paths_label.text = "Project Paths"
    paths_section.add_child(paths_label)
    
    # Godot 3 path
    var godot3_hbox = HBoxContainer.new()
    paths_section.add_child(godot3_hbox)
    
    var godot3_label = Label.new()
    godot3_label.text = "Godot 3 Project:"
    godot3_hbox.add_child(godot3_label)
    
    godot3_path_input = LineEdit.new()
    godot3_path_input.size_flags_horizontal = SIZE_EXPAND_FILL
    godot3_hbox.add_child(godot3_path_input)
    
    browse_godot3_button = Button.new()
    browse_godot3_button.text = "Browse"
    godot3_hbox.add_child(browse_godot3_button)
    
    # Godot 4 path
    var godot4_hbox = HBoxContainer.new()
    paths_section.add_child(godot4_hbox)
    
    var godot4_label = Label.new()
    godot4_label.text = "Godot 4 Project:"
    godot4_hbox.add_child(godot4_label)
    
    godot4_path_input = LineEdit.new()
    godot4_path_input.size_flags_horizontal = SIZE_EXPAND_FILL
    godot4_hbox.add_child(godot4_path_input)
    
    browse_godot4_button = Button.new()
    browse_godot4_button.text = "Browse"
    godot4_hbox.add_child(browse_godot4_button)
    
    # Options section
    var options_section = VBoxContainer.new()
    main_vbox.add_child(options_section)
    
    var options_label = Label.new()
    options_label.text = "Migration Options"
    options_section.add_child(options_label)
    
    backup_checkbox = CheckBox.new()
    backup_checkbox.text = "Create backup before migration"
    backup_checkbox.pressed = true
    options_section.add_child(backup_checkbox)
    
    auto_fix_checkbox = CheckBox.new()
    auto_fix_checkbox.text = "Auto-fix deprecated features"
    auto_fix_checkbox.pressed = true
    options_section.add_child(auto_fix_checkbox)
    
    migrate_resources_checkbox = CheckBox.new()
    migrate_resources_checkbox.text = "Migrate resources (.tres, .tscn)"
    migrate_resources_checkbox.pressed = true
    options_section.add_child(migrate_resources_checkbox)
    
    verbose_checkbox = CheckBox.new()
    verbose_checkbox.text = "Verbose logging"
    verbose_checkbox.pressed = true
    options_section.add_child(verbose_checkbox)
    
    # Progress section
    var progress_section = VBoxContainer.new()
    main_vbox.add_child(progress_section)
    
    var progress_label = Label.new()
    progress_label.text = "Migration Progress"
    progress_section.add_child(progress_label)
    
    progress_bar = ProgressBar.new()
    progress_bar.min_value = 0
    progress_bar.max_value = 100
    progress_bar.value = 0
    progress_bar.size_flags_horizontal = SIZE_EXPAND_FILL
    progress_section.add_child(progress_bar)
    
    status_label = Label.new()
    status_label.text = "Ready"
    progress_section.add_child(status_label)
    
    var button_hbox = HBoxContainer.new()
    progress_section.add_child(button_hbox)
    
    start_button = Button.new()
    start_button.text = "Start Migration"
    start_button.disabled = true
    button_hbox.add_child(start_button)
    
    report_button = Button.new()
    report_button.text = "Generate Report"
    report_button.disabled = true
    button_hbox.add_child(report_button)
    
    # Log section
    var log_section = VBoxContainer.new()
    main_vbox.add_child(log_section)
    log_section.size_flags_vertical = SIZE_EXPAND_FILL
    
    var log_label = Label.new()
    log_label.text = "Migration Log"
    log_section.add_child(log_label)
    
    log_text = TextEdit.new()
    log_text.editable = false
    log_text.size_flags_vertical = SIZE_EXPAND_FILL
    log_section.add_child(log_text)
    
    # File tree section
    var files_section = VBoxContainer.new()
    main_vbox.add_child(files_section)
    files_section.size_flags_vertical = SIZE_EXPAND_FILL
    
    var files_label = Label.new()
    files_label.text = "Project Files"
    files_section.add_child(files_label)
    
    file_tree = Tree.new()
    file_tree.size_flags_vertical = SIZE_EXPAND_FILL
    files_section.add_child(file_tree)
    
    # File dialog
    file_dialog = FileDialog.new()
    file_dialog.access = FileDialog.ACCESS_FILESYSTEM
    file_dialog.file_mode = FileDialog.FILE_MODE_OPEN_DIR
    add_child(file_dialog)

func _connect_signals():
    # Connect UI signals
    browse_godot3_button.pressed.connect(_on_browse_godot3_pressed)
    browse_godot4_button.pressed.connect(_on_browse_godot4_pressed)
    
    start_button.pressed.connect(_on_start_pressed)
    report_button.pressed.connect(_on_report_pressed)
    
    godot3_path_input.text_changed.connect(_on_path_changed)
    godot4_path_input.text_changed.connect(_on_path_changed)
    
    file_dialog.dir_selected.connect(_on_dir_selected)
    
    # Connect migration tool signals if available
    if migration_tool:
        migration_tool.migration_started.connect(_on_migration_started)
        migration_tool.migration_completed.connect(_on_migration_completed)
        migration_tool.file_processed.connect(_on_file_processed)
        migration_tool.migration_error.connect(_on_migration_error)
        migration_tool.migration_warning.connect(_on_migration_warning)
        migration_tool.progress_updated.connect(_on_progress_updated)

func _find_migration_tool():
    # Find migration tool instance
    migration_tool = get_node_or_null("/root/Godot4MigrationTool")
    
    if not migration_tool:
        # Try to find using class name
        migration_tool = _find_node_by_class(get_tree().root, "Godot4MigrationTool")
    
    if not migration_tool:
        # Create a new instance
        migration_tool = Godot4MigrationTool.new()
        add_child(migration_tool)
    
    # Connect signals
    if migration_tool:
        migration_tool.migration_started.connect(_on_migration_started)
        migration_tool.migration_completed.connect(_on_migration_completed)
        migration_tool.file_processed.connect(_on_file_processed)
        migration_tool.migration_error.connect(_on_migration_error)
        migration_tool.migration_warning.connect(_on_migration_warning)
        migration_tool.progress_updated.connect(_on_progress_updated)
        
        print("Migration tool initialized")
    else:
        push_error("Failed to find or create migration tool")

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

# ----- UI EVENT HANDLERS -----
func _on_browse_godot3_pressed():
    file_dialog.title = "Select Godot 3 Project Directory"
    file_dialog.popup_centered_ratio(0.7)
    selected_dir = "godot3"

func _on_browse_godot4_pressed():
    file_dialog.title = "Select Godot 4 Project Directory"
    file_dialog.popup_centered_ratio(0.7)
    selected_dir = "godot4"

func _on_dir_selected(dir_path):
    if selected_dir == "godot3":
        godot3_path_input.text = dir_path
    elif selected_dir == "godot4":
        godot4_path_input.text = dir_path
    
    _update_file_tree(dir_path)
    _check_paths()

func _on_path_changed(new_text):
    _check_paths()

func _check_paths():
    # Enable/disable start button based on path validity
    var godot3_path = godot3_path_input.text
    var godot4_path = godot4_path_input.text
    
    var godot3_valid = DirAccess.dir_exists_absolute(godot3_path)
    var godot4_valid = DirAccess.dir_exists_absolute(godot4_path)
    
    start_button.disabled = not (godot3_valid and godot4_valid)
    report_button.disabled = not godot3_valid
    
    if start_button.disabled:
        if not godot3_valid:
            _update_status("Godot 3 project path is invalid")
        elif not godot4_valid:
            _update_status("Godot 4 project path is invalid")
    else:
        _update_status("Ready to migrate")

func _on_start_pressed():
    # Get options
    migration_tool.godot3_project_path = godot3_path_input.text
    migration_tool.godot4_project_path = godot4_path_input.text
    migration_tool.backup_before_migration = backup_checkbox.button_pressed
    migration_tool.auto_fix_deprecated = auto_fix_checkbox.button_pressed
    migration_tool.migrate_resources = migrate_resources_checkbox.button_pressed
    migration_tool.verbose_logging = verbose_checkbox.button_pressed
    
    # Clear log
    log_text.text = ""
    file_status.clear()
    
    # Start migration
    is_migrating = true
    start_button.disabled = true
    report_button.disabled = true
    
    # Log start
    _log_message("Starting migration from:\n" + godot3_path_input.text + "\nto:\n" + godot4_path_input.text)
    _log_message("Options: Backup=" + str(backup_checkbox.button_pressed) + 
                 ", AutoFix=" + str(auto_fix_checkbox.button_pressed) + 
                 ", MigrateResources=" + str(migrate_resources_checkbox.button_pressed))
    
    # Start migration process
    migration_tool.start_migration()

func _on_report_pressed():
    # Generate compatibility report
    var report = migration_tool.generate_migration_report(godot3_path_input.text)
    
    # Display report
    _log_message("\n----- COMPATIBILITY REPORT -----")
    _log_message("Total files: " + str(report.total_files))
    _log_message("Compatible files: " + str(report.compatible_files))
    _log_message("Incompatible files: " + str(report.incompatible_files))
    _log_message("\nFile details:")
    
    for file_info in report.file_details:
        var status = "‚úì Compatible" if file_info.compatible else "‚úó Incompatible"
        _log_message("\n" + file_info.path + ": " + status)
        
        if not file_info.compatible:
            _log_message("Issues:")
            for issue in file_info.issues:
                _log_message("  - " + issue)
        
        if file_info.warnings.size() > 0:
            _log_message("Warnings:")
            for warning in file_info.warnings:
                _log_message("  - " + warning)
        
        if file_info.errors.size() > 0:
            _log_message("Errors:")
            for error in file_info.errors:
                _log_message("  - " + error)
    
    _update_status("Report generated successfully")

# ----- MIGRATION TOOL EVENT HANDLERS -----
func _on_migration_started(total):
    total_files = total
    current_file = 0
    progress_bar.max_value = total
    progress_bar.value = 0
    
    _update_status("Migration started. Total files: " + str(total))
    _log_message("\n----- MIGRATION STARTED -----")
    _log_message("Total files to process: " + str(total))

func _on_migration_completed(stats):
    migration_stats = stats
    is_migrating = false
    start_button.disabled = false
    report_button.disabled = false
    
    _update_status("Migration completed")
    _log_message("\n----- MIGRATION COMPLETED -----")
    _log_message("Files processed: " + str(stats.files_processed))
    _log_message("Files modified: " + str(stats.files_modified))
    _log_message("Errors encountered: " + str(stats.errors_encountered))
    _log_message("Warnings generated: " + str(stats.warnings_generated))
    
    # Update progress to 100%
    progress_bar.value = progress_bar.max_value
    
    emit_signal("migration_complete")

func _on_file_processed(file_path, modified):
    current_file += 1
    progress_bar.value = current_file
    
    # Create relative path
    var rel_path = file_path.replace(godot3_path_input.text, "")
    if rel_path.begins_with("/"):
        rel_path = rel_path.substr(1)
    
    # Log file status
    var status = "Modified" if modified else "No changes needed"
    _log_message(rel_path + ": " + status)
    
    # Update file status dictionary
    file_status[rel_path] = {
        "status": status,
        "modified": modified
    }
    
    # Update file tree
    _update_file_status_in_tree(rel_path, modified)
    
    _update_status("Processing: " + str(current_file) + "/" + str(total_files) + " - " + rel_path)

func _on_migration_error(file_path, error_message):
    # Create relative path
    var rel_path = file_path.replace(godot3_path_input.text, "")
    if rel_path.begins_with("/"):
        rel_path = rel_path.substr(1)
    
    # Log error
    _log_message("ERROR in " + rel_path + ": " + error_message)
    
    # Update file status
    if file_status.has(rel_path):
        file_status[rel_path].errors = file_status[rel_path].get("errors", [])
        file_status[rel_path].errors.append(error_message)
    else:
        file_status[rel_path] = {
            "status": "Error",
            "errors": [error_message]
        }
    
    # Update file tree
    _update_file_status_in_tree(rel_path, false, true)

func _on_migration_warning(file_path, warning_message):
    # Create relative path
    var rel_path = file_path.replace(godot3_path_input.text, "")
    if rel_path.begins_with("/"):
        rel_path = rel_path.substr(1)
    
    # Log warning
    _log_message("WARNING in " + rel_path + ": " + warning_message)
    
    # Update file status
    if file_status.has(rel_path):
        file_status[rel_path].warnings = file_status[rel_path].get("warnings", [])
        file_status[rel_path].warnings.append(warning_message)
    else:
        file_status[rel_path] = {
            "status": "Warning",
            "warnings": [warning_message]
        }
    
    # Update file tree
    _update_file_status_in_tree(rel_path, false, false, true)

func _on_progress_updated(current, total):
    current_file = current
    progress_bar.value = current
    
    var percentage = int((float(current) / total) * 100)
    _update_status("Progress: " + str(current) + "/" + str(total) + " (" + str(percentage) + "%)")

# ----- HELPER FUNCTIONS -----
func _update_status(text):
    status_label.text = text

func _log_message(message):
    log_text.text += message + "\n"
    log_text.scroll_vertical = log_text.get_line_count()

func _update_file_tree(dir_path):
    # Build file tree for the selected directory
    file_tree.clear()
    var root = file_tree.create_item()
    root.set_text(0, dir_path.get_file() if dir_path.get_file() != "" else dir_path)
    
    _populate_file_tree(root, dir_path)

func _populate_file_tree(parent_item, dir_path):
    var dir = DirAccess.open(dir_path)
    
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            if file_name != "." and file_name != "..":
                var full_path = dir_path.path_join(file_name)
                
                if dir.current_is_dir():
                    var item = file_tree.create_item(parent_item)
                    item.set_text(0, file_name)
                    item.set_icon(0, _get_folder_icon())
                    _populate_file_tree(item, full_path)
                elif file_name.ends_with(".gd") or file_name.ends_with(".tscn") or file_name.ends_with(".tres"):
                    var item = file_tree.create_item(parent_item)
                    item.set_text(0, file_name)
                    item.set_icon(0, _get_file_icon(file_name))
                
            file_name = dir.get_next()
    else:
        _log_message("Could not open directory: " + dir_path)

func _update_file_status_in_tree(rel_path, modified = false, has_error = false, has_warning = false):
    # Find and update file in tree
    var root = file_tree.get_root()
    if not root:
        return
    
    var parts = rel_path.split("/")
    var current_item = root
    var found = true
    
    # Navigate to file
    for i in range(parts.size()):
        var part = parts[i]
        var found_part = false
        
        var child = current_item.get_first_child()
        while child:
            if child.get_text(0) == part:
                current_item = child
                found_part = true
                break
            child = child.get_next()
        
        if not found_part:
            found = false
            break
    
    # Update item if found
    if found:
        if has_error:
            current_item.set_custom_color(0, Color(1, 0, 0))  # Red for error
        elif has_warning:
            current_item.set_custom_color(0, Color(1, 0.7, 0))  # Orange for warning
        elif modified:
            current_item.set_custom_color(0, Color(0, 0.8, 0))  # Green for modified
        else:
            current_item.set_custom_color(0, Color(0.5, 0.5, 0.5))  # Gray for unchanged

func _get_folder_icon():
    # Return a folder icon
    # In a real implementation, this would load an actual icon
    return null

func _get_file_icon(file_name):
    # Return appropriate icon based on file type
    # In a real implementation, this would load actual icons
    return null
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/godot4_migration_ui.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/godot_data_channel.gd
# SIZE: 17240 bytes
extends Node

class_name GodotDataChannel

# Godot Data Channel System
# Connects any device data stream to the Godot Engine across time dimensions
# Provides synchronized data flow with the 12-turn system

# Signal declarations
signal data_received(source, data_packet, timestamp)
signal dimension_changed(old_dimension, new_dimension)
signal channel_opened(device_id, channel_id)
signal channel_closed(device_id, channel_id)
signal token_advanced(token_number, dimension)

# Configuration
var config = {
	"lines_per_token": 9,
	"token_speed": 1.0,
	"auto_synchronize": true,
	"time_dilation_enabled": true,
	"persistent_channels": true,
	"channel_capacity": 12
}

# Channel states
var active_channels = {}
var channel_buffers = {}
var time_markers = {}

# Dimension tracking
var current_dimension = 3 # Default to 3D space
var current_token = 1
var tokens_completed = 0

# Turn symbols and concepts
var TURN_SYMBOLS = ["Œ±", "Œ≤", "Œ≥", "Œ¥", "Œµ", "Œ∂", "Œ∑", "Œ∏", "Œπ", "Œ∫", "Œª", "Œº"]
var TURN_DIMENSIONS = ["1D", "2D", "3D", "4D", "5D", "6D", "7D", "8D", "9D", "10D", "11D", "12D"]
var TURN_CONCEPTS = ["Point", "Line", "Space", "Time", "Consciousness", "Connection", "Creation", "Network", "Harmony", "Unity", "Transcendence", "Infinity"]

# Device connection registry
var connected_devices = {}

# ===== INITIALIZATION =====

func _ready():
	print("Godot Data Channel initialized")
	
	# Set up connection monitoring
	_setup_connection_monitor()
	
	# Initialize channel buffers
	_initialize_buffers()
	
	# Load channel configuration if available
	_load_config()
	
	# Connect to TurnSystem if available
	_connect_to_turn_system()

func _setup_connection_monitor():
	# Set up timer for checking device connections
	var timer = Timer.new()
	timer.wait_time = 5.0
	timer.autostart = true
	timer.connect("timeout", self, "_check_device_connections")
	add_child(timer)

func _initialize_buffers():
	# Create buffers for all 12 dimensions
	for i in range(1, 13):
		channel_buffers[i] = []
		time_markers[i] = OS.get_unix_time()

func _load_config():
	var file = File.new()
	var config_path = "user://godot_data_channel_config.json"
	
	if file.file_exists(config_path):
		file.open(config_path, File.READ)
		var text = file.get_as_text()
		file.close()
		
		var result = JSON.parse(text)
		if result.error == OK:
			# Apply saved configuration
			var saved_config = result.result
			for key in saved_config.keys():
				if config.has(key):
					config[key] = saved_config[key]
			
			print("Loaded channel configuration")
		else:
			print("Error parsing channel configuration")

func _connect_to_turn_system():
	# Find TurnSystem if present in the scene tree
	var turn_system = get_node_or_null("/root/TurnSystem")
	
	if turn_system:
		# Connect to the turn system signals
		turn_system.connect("dimension_changed", self, "_on_dimension_changed")
		turn_system.connect("token_advanced", self, "_on_token_advanced")
		
		# Sync current dimension
		current_dimension = turn_system.current_dimension
		print("Connected to Turn System, dimension: " + str(current_dimension))
	else:
		print("Turn System not found, operating in standalone mode")

# ===== CHANNEL MANAGEMENT =====

# Open a data channel for a device
func open_channel(device_id, device_type, auth_token = ""):
	# Generate unique channel ID
	var channel_id = _generate_channel_id(device_id)
	
	# Create channel data structure
	var channel = {
		"id": channel_id,
		"device_id": device_id,
		"device_type": device_type,
		"status": "active",
		"opened_at": OS.get_unix_time(),
		"dimension": current_dimension,
		"auth_token": auth_token,
		"packet_count": 0
	}
	
	# Store in active channels
	active_channels[channel_id] = channel
	
	# Register connected device
	connected_devices[device_id] = {
		"last_seen": OS.get_unix_time(),
		"type": device_type,
		"channels": [channel_id]
	}
	
	# Emit signal
	emit_signal("channel_opened", device_id, channel_id)
	
	print("Channel opened for device: " + device_id + " (Type: " + device_type + ")")
	
	return channel_id

# Close a data channel
func close_channel(channel_id):
	if active_channels.has(channel_id):
		var channel = active_channels[channel_id]
		
		# Update status
		channel.status = "closed"
		channel.closed_at = OS.get_unix_time()
		
		# Update device registry
		if connected_devices.has(channel.device_id):
			var device = connected_devices[channel.device_id]
			if device.channels.has(channel_id):
				device.channels.erase(channel_id)
			
			# Remove device if no more channels
			if device.channels.empty() and not config.persistent_channels:
				connected_devices.erase(channel.device_id)
		
		# Emit signal
		emit_signal("channel_closed", channel.device_id, channel_id)
		
		print("Channel closed: " + channel_id)
		
		return true
	
	return false

# Get list of all active channels
func get_active_channels():
	var active = []
	
	for channel_id in active_channels.keys():
		var channel = active_channels[channel_id]
		if channel.status == "active":
			active.append(channel)
	
	return active

# Check if device is connected
func is_device_connected(device_id):
	return connected_devices.has(device_id)

# ===== DATA TRANSMISSION =====

# Send data packet through a channel
func send_data(channel_id, data, metadata = {}):
	if not active_channels.has(channel_id):
		return false
	
	var channel = active_channels[channel_id]
	
	# Verify channel is active
	if channel.status != "active":
		return false
	
	# Create data packet
	var packet = {
		"id": _generate_packet_id(),
		"timestamp": OS.get_datetime(),
		"source": channel.device_id,
		"dimension": current_dimension,
		"token": current_token,
		"data": data,
		"metadata": metadata
	}
	
	# Process packet based on dimension rules
	_process_packet(packet, channel)
	
	# Update packet count
	channel.packet_count += 1
	
	# Update last seen
	connected_devices[channel.device_id].last_seen = OS.get_unix_time()
	
	return true

# Receive data packet from external source
func receive_data(device_id, data, metadata = {}):
	# Get channel for device
	var channel_id = null
	
	if connected_devices.has(device_id):
		var device = connected_devices[device_id]
		if not device.channels.empty():
			channel_id = device.channels[0]
	
	# Create channel if needed and allowed
	if channel_id == null:
		channel_id = open_channel(device_id, metadata.get("device_type", "unknown"))
	
	# Forward to send_data once we have a channel
	return send_data(channel_id, data, metadata)

# Get data for current dimension
func get_data_for_dimension(dimension = null):
	if dimension == null:
		dimension = current_dimension
	
	# Ensure dimension is in range
	if dimension < 1 or dimension > 12:
		return []
	
	return channel_buffers[dimension]

# Clear data for a specific dimension
func clear_dimension_data(dimension):
	if dimension >= 1 and dimension <= 12:
		channel_buffers[dimension] = []
		return true
	
	return false

# Process incoming packet according to dimension rules
func _process_packet(packet, channel):
	var dimension = current_dimension
	
	# Apply dimension-specific modifications
	match dimension:
		1: # Point - store only the most recent packet per device
			# Remove any existing packets from this device
			var buffer = channel_buffers[dimension]
			for i in range(buffer.size() - 1, -1, -1):
				if buffer[i].source == packet.source:
					buffer.remove(i)
			
			# Add new packet
			channel_buffers[dimension].append(packet)
			
		2: # Line - packets flow in linear sequence
			# Add packet in order
			channel_buffers[dimension].append(packet)
			
			# Enforce maximum buffer length for line dimension
			if channel_buffers[dimension].size() > config.channel_capacity * 2:
				channel_buffers[dimension].pop_front()
			
		3: # Space - regular 3D space processing
			# Store packet with full metadata
			channel_buffers[dimension].append(packet)
			
		4: # Time - enable time-based lookups
			# Add timestamp marker
			packet.time_index = OS.get_unix_time()
			channel_buffers[dimension].append(packet)
			time_markers[dimension] = packet.time_index
			
		5: # Consciousness - enable awareness of other packets
			# Add self-awareness references
			packet.awareness = {
				"dimension": dimension,
				"token": current_token,
				"total_packets": channel_buffers[dimension].size(),
				"device_count": connected_devices.size()
			}
			channel_buffers[dimension].append(packet)
			
		6: # Connection - link related data across dimensions
			# Add connection references
			packet.connections = []
			
			# Look for related packets in other dimensions
			for d in range(1, 13):
				if d == dimension:
					continue
				
				for p in channel_buffers[d]:
					if p.source == packet.source:
						packet.connections.append({
							"dimension": d,
							"packet_id": p.id,
							"timestamp": p.timestamp
						})
						break
			
			channel_buffers[dimension].append(packet)
			
		7: # Creation - enable data transformation
			# Add transformation capabilities
			if packet.data is Dictionary:
				# Apply creative transformation based on data type
				if packet.data.has("text"):
					packet.data.word_count = packet.data.text.split(" ").size()
				elif packet.data.has("value") and packet.data.value is int:
					packet.data.binary = "%b" % packet.data.value
			
			channel_buffers[dimension].append(packet)
			
		8: # Network - track relationship between all data points
			# Build network graph
			packet.network = {
				"connections": connected_devices.size(),
				"position": channel_buffers[dimension].size(),
				"links": []
			}
			
			# Create links to related packets
			var link_count = min(3, channel_buffers[dimension].size())
			for i in range(link_count):
				if not channel_buffers[dimension].empty():
					var index = channel_buffers[dimension].size() - 1 - i
					if index >= 0:
						var linked_packet = channel_buffers[dimension][index]
						packet.network.links.append(linked_packet.id)
			
			channel_buffers[dimension].append(packet)
			
		9: # Harmony - balance data across channels
			# Check for imbalance across dimensions
			var max_size = 0
			var min_size = 999999
			
			for d in range(1, 13):
				var size = channel_buffers[d].size()
				max_size = max(max_size, size)
				if size > 0:
					min_size = min(min_size, size)
			
			# Calculate harmony score
			var imbalance = max_size - min_size
			packet.harmony = {
				"balance_score": clamp(1.0 - (float(imbalance) / max(1, max_size)), 0.0, 1.0),
				"imbalance": imbalance,
				"dimensions_active": 0
			}
			
			# Count active dimensions
			for d in range(1, 13):
				if channel_buffers[d].size() > 0:
					packet.harmony.dimensions_active += 1
			
			channel_buffers[dimension].append(packet)
			
		10: # Unity - combine aspects of all dimensions
			# Create unified view
			packet.unified_view = {}
			
			# Sample from each dimension
			for d in range(1, 13):
				if not channel_buffers[d].empty():
					# Get most recent packet from this dimension
					var sample = channel_buffers[d].back()
					packet.unified_view[str(d)] = {
						"id": sample.id,
						"timestamp": sample.timestamp,
						"source": sample.source
					}
			
			channel_buffers[dimension].append(packet)
			
		11: # Transcendence - exist beyond normal constraints
			# Add transcendent properties
			packet.transcended = true
			packet.accessible_in_all_dimensions = true
			
			# Add to this dimension
			channel_buffers[dimension].append(packet)
			
			# Add references to all other dimensions
			for d in range(1, 13):
				if d != dimension:
					var reference = {
						"id": packet.id + "_ref_" + str(d),
						"timestamp": packet.timestamp,
						"source": packet.source,
						"dimension": d,
						"token": current_token,
						"is_reference": true,
						"original_dimension": dimension,
						"original_id": packet.id,
						"data": packet.data
					}
					channel_buffers[d].append(reference)
			
		12: # Infinity - no limits
			# Add to all possible buffers, past and future
			packet.infinite = true
			
			# Store in all dimensions simultaneously
			for d in range(1, 13):
				var clone = packet.duplicate()
				clone.manifest_dimension = d
				channel_buffers[d].append(clone)
	
	# Emit signal for listeners
	emit_signal("data_received", packet.source, packet, OS.get_datetime())

# ===== DIMENSION MANAGEMENT =====

# Handle dimension changes
func _on_dimension_changed(new_dimension, old_dimension):
	current_dimension = new_dimension
	
	# Emit signal for listeners
	emit_signal("dimension_changed", old_dimension, new_dimension)
	
	print("Data channel dimension changed: " + str(old_dimension) + " ‚Üí " + str(new_dimension) + 
		" (" + TURN_SYMBOLS[new_dimension-1] + " - " + TURN_DIMENSIONS[new_dimension-1] + " - " + TURN_CONCEPTS[new_dimension-1] + ")")

# Handle token advancement
func _on_token_advanced(token_number, dimension):
	current_token = token_number
	current_dimension = dimension
	
	# Apply time dilation if enabled
	if config.time_dilation_enabled:
		# Time flows differently in different dimensions
		match dimension:
			4: # Time dimension - accelerated token processing
				config.token_speed = 0.5
			5: # Consciousness - slower, more deliberate
				config.token_speed = 2.0
			12: # Infinity - extremely fast
				config.token_speed = 0.1
			_: # Default
				config.token_speed = 1.0
	
	# Update token counter
	if token_number == 1:
		tokens_completed += 1
	
	# Emit signal for listeners
	emit_signal("token_advanced", token_number, dimension)

# Manually change dimension
func change_dimension(new_dimension):
	if new_dimension >= 1 and new_dimension <= 12:
		var old_dimension = current_dimension
		current_dimension = new_dimension
		
		_on_dimension_changed(new_dimension, old_dimension)
		return true
	
	return false

# ===== UTILITY FUNCTIONS =====

# Generate unique channel ID
func _generate_channel_id(device_id):
	var timestamp = OS.get_unix_time()
	var random = randi() % 10000
	return device_id.substr(0, 8) + "_" + str(timestamp) + "_" + str(random)

# Generate unique packet ID
func _generate_packet_id():
	var timestamp = OS.get_unix_time()
	var random = randi() % 1000000
	return str(timestamp) + "_" + str(random)

# Check device connections periodically
func _check_device_connections():
	var current_time = OS.get_unix_time()
	var timeout_threshold = 300 # 5 minutes
	
	# Check all devices for timeout
	for device_id in connected_devices.keys():
		var device = connected_devices[device_id]
		var time_diff = current_time - device.last_seen
		
		if time_diff > timeout_threshold:
			print("Device timed out: " + device_id)
			
			# Close all channels for this device
			for channel_id in device.channels:
				if active_channels.has(channel_id):
					close_channel(channel_id)
			
			# Remove device from registry
			connected_devices.erase(device_id)

# Save current configuration
func save_config():
	var file = File.new()
	var config_path = "user://godot_data_channel_config.json"
	
	file.open(config_path, File.WRITE)
	file.store_string(JSON.print(config, "  "))
	file.close()
	
	print("Saved channel configuration")

# ===== EXTERNAL API =====

# Get current dimension info
func get_current_dimension_info():
	return {
		"number": current_dimension,
		"symbol": TURN_SYMBOLS[current_dimension-1],
		"name": TURN_DIMENSIONS[current_dimension-1],
		"concept": TURN_CONCEPTS[current_dimension-1],
		"token": current_token,
		"tokens_completed": tokens_completed,
		"active_channels": get_active_channels().size(),
		"connected_devices": connected_devices.size(),
		"data_packets": channel_buffers[current_dimension].size()
	}

# Get channel statistics
func get_channel_stats():
	var stats = {
		"total_channels": active_channels.size(),
		"active_channels": 0,
		"total_devices": connected_devices.size(),
		"packets_by_dimension": {},
		"total_packets": 0
	}
	
	# Count active channels
	for channel_id in active_channels.keys():
		if active_channels[channel_id].status == "active":
			stats.active_channels += 1
	
	# Count packets by dimension
	for d in range(1, 13):
		var count = channel_buffers[d].size()
		stats.packets_by_dimension[str(d)] = count
		stats.total_packets += count
	
	return stats

# Update configuration setting
func set_config_value(key, value):
	if config.has(key):
		config[key] = value
		save_config()
		return true
	
	return false

# Export all data for a device
func export_device_data(device_id):
	if not connected_devices.has(device_id):
		return null
	
	var export_data = {
		"device_id": device_id,
		"device_type": connected_devices[device_id].type,
		"channels": [],
		"packets": [],
		"exported_at": OS.get_datetime()
	}
	
	# Add channel information
	for channel_id in connected_devices[device_id].channels:
		if active_channels.has(channel_id):
			export_data.channels.append(active_channels[channel_id])
	
	# Collect all packets from this device
	for d in range(1, 13):
		for packet in channel_buffers[d]:
			if packet.source == device_id:
				export_data.packets.append(packet)
	
	return export_data

# Clear all data but keep configuration
func clear_all_data():
	# Reset all buffers
	for d in range(1, 13):
		channel_buffers[d] = []
	
	# Reset active channels
	active_channels = {}
	
	# Reset connected devices
	connected_devices = {}
	
	# Reset counters
	tokens_completed = 0
	
	print("All channel data cleared")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/godot_data_channel.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/godot_file_automator.gd
# SIZE: 10203 bytes
extends Node
# Godot File Automator
# Bridges Windows folders and files with Godot project
# Automatically processes files for use in Godot projects

# Configuration - Change these to match your system
const WINDOWS_SOURCE_DIR = "C:/Users/Percision 15/12_turns_system"
const GODOT_PROJECT_DIR = "res://"

# File extensions to monitor
const MONITORED_EXTENSIONS = [".txt", ".md", ".gd", ".tscn", ".json", ".csv"]

# Initialization 
func _ready():
	print("Godot File Automator initialized")
	print("Monitoring source directory: " + WINDOWS_SOURCE_DIR)
	print("Target Godot directory: " + GODOT_PROJECT_DIR)
	
	# Ensure the required directories exist
	_ensure_directories()
	
	# Initial scan to display what we're monitoring
	var initial_files = scan_source_directory()
	print("Found " + str(initial_files.size()) + " files to monitor")
	
	# Set up a timer to check for changes periodically
	var timer = Timer.new()
	timer.wait_time = 5.0  # Check every 5 seconds
	timer.one_shot = false
	timer.timeout.connect(_on_timer_timeout)
	add_child(timer)
	timer.start()

# Ensure required directories exist
func _ensure_directories():
	# Convert Windows path to a path format that DirAccess can use
	var unix_path = WINDOWS_SOURCE_DIR.replace("C:/", "/mnt/c/").replace("\\", "/")
	
	# Check if directory exists
	if not DirAccess.dir_exists_absolute(unix_path):
		print("WARNING: Source directory does not exist: " + unix_path)
		return
		
	# Create Godot directories if they don't exist
	var godot_data_dir = GODOT_PROJECT_DIR + "imported_data"
	if not DirAccess.dir_exists_absolute(godot_data_dir):
		DirAccess.make_dir_recursive_absolute(godot_data_dir)
		print("Created directory: " + godot_data_dir)

# Timer callback to check for file changes
func _on_timer_timeout():
	print("Checking for file changes...")
	var files = scan_source_directory()
	
	# Check for changes and process files
	for file_path in files:
		var modified_time = FileAccess.get_modified_time(file_path)
		
		# Get the last stored modification time from metadata
		var prev_modified_time = _get_file_metadata(file_path, "last_modified", 0)
		
		if modified_time > prev_modified_time:
			print("Changes detected in file: " + file_path)
			process_file(file_path)
			
			# Update metadata
			_set_file_metadata(file_path, "last_modified", modified_time)

# Scan the source directory for files to monitor
func scan_source_directory():
	var files = []
	
	# Convert Windows path to a path format that DirAccess can use
	var unix_path = WINDOWS_SOURCE_DIR.replace("C:/", "/mnt/c/").replace("\\", "/")
	
	# Process all files in the directory recursively
	_scan_directory_recursive(unix_path, files)
	
	return files

# Recursively scan directories for files with monitored extensions
func _scan_directory_recursive(path, files):
	var dir = DirAccess.open(path)
	
	if dir:
		dir.list_dir_begin()
		var file_name = dir.get_next()
		
		while file_name != "":
			# Skip . and .. directories
			if file_name != "." and file_name != "..":
				var full_path = path.path_join(file_name)
				
				if dir.current_is_dir():
					# Recursively scan subdirectories
					_scan_directory_recursive(full_path, files)
				else:
					# Check if the file has a monitored extension
					for ext in MONITORED_EXTENSIONS:
						if file_name.ends_with(ext):
							files.append(full_path)
							break
			
			file_name = dir.get_next()
		
		dir.list_dir_end()
	else:
		print("Failed to open directory: " + path)

# Process a file based on its type
func process_file(file_path):
	print("Processing file: " + file_path)
	
	# Determine file type based on extension
	var extension = file_path.get_extension().to_lower()
	
	match extension:
		"txt", "md":
			_process_text_file(file_path)
		"gd":
			_process_godot_script(file_path)
		"json", "csv":
			_process_data_file(file_path)
		"tscn":
			_process_scene_file(file_path)
		_:
			print("Unsupported file type: " + extension)

# Process text files (txt, md)
func _process_text_file(file_path):
	var file = FileAccess.open(file_path, FileAccess.READ)
	if file:
		var content = file.get_as_text()
		
		# Generate a Godot-friendly file name
		var file_name = file_path.get_file()
		var godot_path = GODOT_PROJECT_DIR + "imported_data/" + file_name
		
		# Save to Godot project
		var godot_file = FileAccess.open(godot_path, FileAccess.WRITE)
		if godot_file:
			godot_file.store_string(content)
			print("File imported to Godot: " + godot_path)
		else:
			print("Failed to write to Godot file: " + godot_path)

# Process Godot script files (gd)
func _process_godot_script(file_path):
	var file = FileAccess.open(file_path, FileAccess.READ)
	if file:
		var content = file.get_as_text()
		
		# Generate a Godot-friendly file name
		var file_name = file_path.get_file()
		var godot_path = GODOT_PROJECT_DIR + "imported_scripts/" + file_name
		
		# Ensure the scripts directory exists
		if not DirAccess.dir_exists_absolute(GODOT_PROJECT_DIR + "imported_scripts"):
			DirAccess.make_dir_recursive_absolute(GODOT_PROJECT_DIR + "imported_scripts")
		
		# Save to Godot project
		var godot_file = FileAccess.open(godot_path, FileAccess.WRITE)
		if godot_file:
			godot_file.store_string(content)
			print("Script imported to Godot: " + godot_path)
		else:
			print("Failed to write to Godot script: " + godot_path)

# Process data files (json, csv)
func _process_data_file(file_path):
	var file = FileAccess.open(file_path, FileAccess.READ)
	if file:
		var content = file.get_as_text()
		
		# Generate a Godot-friendly file name
		var file_name = file_path.get_file()
		var godot_path = GODOT_PROJECT_DIR + "imported_data/" + file_name
		
		# Ensure the data directory exists
		if not DirAccess.dir_exists_absolute(GODOT_PROJECT_DIR + "imported_data"):
			DirAccess.make_dir_recursive_absolute(GODOT_PROJECT_DIR + "imported_data")
		
		# Save to Godot project
		var godot_file = FileAccess.open(godot_path, FileAccess.WRITE)
		if godot_file:
			godot_file.store_string(content)
			print("Data file imported to Godot: " + godot_path)
		else:
			print("Failed to write to Godot data file: " + godot_path)
		
		# If it's a JSON file, try to parse it
		if file_path.ends_with(".json"):
			_parse_json_file(godot_path)

# Process scene files (tscn)
func _process_scene_file(file_path):
	var file = FileAccess.open(file_path, FileAccess.READ)
	if file:
		var content = file.get_as_text()
		
		# Generate a Godot-friendly file name
		var file_name = file_path.get_file()
		var godot_path = GODOT_PROJECT_DIR + "imported_scenes/" + file_name
		
		# Ensure the scenes directory exists
		if not DirAccess.dir_exists_absolute(GODOT_PROJECT_DIR + "imported_scenes"):
			DirAccess.make_dir_recursive_absolute(GODOT_PROJECT_DIR + "imported_scenes")
		
		# Save to Godot project
		var godot_file = FileAccess.open(godot_path, FileAccess.WRITE)
		if godot_file:
			godot_file.store_string(content)
			print("Scene imported to Godot: " + godot_path)
		else:
			print("Failed to write to Godot scene: " + godot_path)

# Parse a JSON file and create a Resource
func _parse_json_file(file_path):
	var file = FileAccess.open(file_path, FileAccess.READ)
	if file:
		var content = file.get_as_text()
		var json = JSON.new()
		var error = json.parse(content)
		
		if error == OK:
			var data = json.data
			print("JSON parsed successfully: " + str(data))
			
			# Create a resource from the JSON data
			var resource = _create_resource_from_json(data, file_path.get_file().get_basename())
			
			# Save the resource
			if resource:
				var resource_path = GODOT_PROJECT_DIR + "imported_resources/" + file_path.get_file().get_basename() + ".tres"
				
				# Ensure the resources directory exists
				if not DirAccess.dir_exists_absolute(GODOT_PROJECT_DIR + "imported_resources"):
					DirAccess.make_dir_recursive_absolute(GODOT_PROJECT_DIR + "imported_resources")
				
				var error = ResourceSaver.save(resource, resource_path)
				if error == OK:
					print("Resource saved: " + resource_path)
				else:
					print("Failed to save resource: " + str(error))
		else:
			print("JSON parse error: " + str(error) + " at line " + str(json.get_error_line()))

# Create a Resource from JSON data
func _create_resource_from_json(json_data, resource_name):
	# Create a custom resource
	var resource = Resource.new()
	resource.resource_name = resource_name
	
	# Store the JSON data as properties in the resource
	for key in json_data.keys():
		if json_data[key] is Dictionary or json_data[key] is Array:
			# For complex types, convert to JSON string
			resource.set_meta(key, JSON.stringify(json_data[key]))
		else:
			# For simple types, store directly
			resource.set_meta(key, json_data[key])
	
	return resource

# Helper function to get file metadata
func _get_file_metadata(file_path, key, default_value):
	var metadata_path = GODOT_PROJECT_DIR + "imported_metadata.json"
	var metadata = {}
	
	# Load existing metadata if it exists
	if FileAccess.file_exists(metadata_path):
		var file = FileAccess.open(metadata_path, FileAccess.READ)
		if file:
			var content = file.get_as_text()
			var json = JSON.new()
			var error = json.parse(content)
			
			if error == OK:
				metadata = json.data
	
	# Create an entry for this file if it doesn't exist
	if not metadata.has(file_path):
		metadata[file_path] = {}
	
	# Return the requested value or the default if not found
	if metadata[file_path].has(key):
		return metadata[file_path][key]
	else:
		return default_value

# Helper function to set file metadata
func _set_file_metadata(file_path, key, value):
	var metadata_path = GODOT_PROJECT_DIR + "imported_metadata.json"
	var metadata = {}
	
	# Load existing metadata if it exists
	if FileAccess.file_exists(metadata_path):
		var file = FileAccess.open(metadata_path, FileAccess.READ)
		if file:
			var content = file.get_as_text()
			var json = JSON.new()
			var error = json.parse(content)
			
			if error == OK:
				metadata = json.data
	
	# Create an entry for this file if it doesn't exist
	if not metadata.has(file_path):
		metadata[file_path] = {}
	
	# Set the value
	metadata[file_path][key] = value
	
	# Save the updated metadata
	var file = FileAccess.open(metadata_path, FileAccess.WRITE)
	if file:
		file.store_string(JSON.stringify(metadata, "  "))
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/godot_file_automator.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/godot_turn_system.gd
# SIZE: 17052 bytes
extends Node

class_name TurnSystem

# ----- TURN SYSTEM SETTINGS -----
@export_category("Turn System Settings")
@export var turns_enabled: bool = true
@export var max_turns: int = 12
@export var current_turn: int = 3
@export var time_per_turn: float = 300.0  # 5 minutes per turn
@export var auto_advance: bool = true

# ----- COMPONENT REFERENCES -----
var game_controller: Node
var time_progression_system: Node
var multiverse_evolution_system: Node

# ----- TIME TRACKING -----
var time_in_current_turn: float = 0.0
var total_system_time: float = 0.0
var last_save_time: float = 0.0
var save_interval: float = 60.0  # Save data every minute

# ----- TURN PHASES -----
var turn_phases = [
    "Genesis", 
    "Formation", 
    "Complexity", 
    "Consciousness", 
    "Awakening", 
    "Enlightenment", 
    "Manifestation", 
    "Connection", 
    "Harmony", 
    "Transcendence", 
    "Unity", 
    "Beyond"
]

# ----- DATA PATHS -----
var c_drive_path = "C:/Users/Percision 15/12_turns_system"
var d_drive_path = "D:/JSH_Turn_Data"
var screenshots_path = "C:/Users/Percision 15/Pictures/Screenshots"

# ----- SIGNALS -----
signal turn_advanced(old_turn, new_turn)
signal turn_data_saved(turn, path)
signal turn_time_updated(time_remaining)

# ----- INITIALIZATION -----
func _ready():
    # Initialize time tracking
    time_in_current_turn = 0.0
    
    # Create a timer for saving data
    var save_timer = Timer.new()
    save_timer.wait_time = save_interval
    save_timer.one_shot = false
    save_timer.autostart = true
    save_timer.connect("timeout", _on_save_timer_timeout)
    add_child(save_timer)
    
    # Make sure data directories exist
    _ensure_directories_exist()
    
    # Load current turn from file system
    _load_current_turn()
    
    # Notify of initialized state
    print("Turn System initialized: Current Turn " + str(current_turn) + " - " + get_current_phase_name())

# ----- PROCESS -----
func _process(delta):
    if not turns_enabled:
        return
    
    # Update time tracking
    time_in_current_turn += delta
    total_system_time += delta
    
    # Check for turn advancement
    if auto_advance and time_in_current_turn >= time_per_turn:
        advance_turn()
    
    # Emit time updated signal
    var time_remaining = max(0.0, time_per_turn - time_in_current_turn)
    emit_signal("turn_time_updated", time_remaining)

# ----- TURN MANAGEMENT -----
func advance_turn():
    # Save data for current turn
    save_turn_data(current_turn)
    
    # Store old turn for signal
    var old_turn = current_turn
    
    # Advance turn
    current_turn = (current_turn % max_turns) + 1
    time_in_current_turn = 0.0
    
    # Save current turn to filesystem
    _save_current_turn()
    
    # Sync with bash system if possible
    _sync_with_bash_system()
    
    # Emit signal
    emit_signal("turn_advanced", old_turn, current_turn)
    
    # Log turn advancement
    print("Advanced to Turn " + str(current_turn) + " - " + get_current_phase_name())
    
    # Apply turn effects
    apply_turn_effects()
    
    # If we completed a full cycle (reached turn 1 again)
    if current_turn == 1:
        on_cycle_completed()

func get_current_phase_name() -> String:
    return turn_phases[current_turn - 1]

func get_turn_progress() -> float:
    return time_in_current_turn / time_per_turn

func get_total_progress() -> float:
    return float(current_turn - 1 + get_turn_progress()) / float(max_turns)

# ----- DATA MANAGEMENT -----
func save_turn_data(turn_number: int):
    # Create base turn data
    var turn_data = {
        "turn": turn_number,
        "phase": turn_phases[turn_number - 1],
        "time_spent": time_in_current_turn,
        "timestamp": Time.get_unix_time_from_system(),
        "game_state": {}
    }
    
    # Add game state if game controller exists
    if game_controller and game_controller.has_method("get_game_state"):
        turn_data.game_state = game_controller.get_game_state()
    
    # Add time system data if available
    if time_progression_system:
        turn_data.time_system = {
            "current_time": time_progression_system.get_current_time(),
            "story_segment": time_progression_system.get_current_story_segment(),
            "story_arc": time_progression_system.get_current_story_arc()
        }
    
    # Add multiverse data if available
    if multiverse_evolution_system:
        turn_data.multiverse = {
            "current_universe": multiverse_evolution_system.get_current_universe_id(),
            "universe_count": multiverse_evolution_system.get_universe_count(),
            "current_age": multiverse_evolution_system.get_current_age()
        }
    
    # Save to C drive
    var c_drive_file = c_drive_path + "/turn_" + str(turn_number) + "/data/turn_data.json"
    _save_json_file(c_drive_file, turn_data)
    
    # Also save to D drive if it exists
    var d_drive_dir = d_drive_path + "/turn_" + str(turn_number) + "/data"
    var d_drive_file = d_drive_dir + "/turn_data.json"
    
    if DirAccess.dir_exists_absolute(d_drive_path):
        if not DirAccess.dir_exists_absolute(d_drive_dir):
            DirAccess.make_dir_recursive_absolute(d_drive_dir)
        _save_json_file(d_drive_file, turn_data)
    
    # Capture screenshots
    _capture_screenshots(turn_number)
    
    # Emit signal
    emit_signal("turn_data_saved", turn_number, c_drive_file)
    
    # Update last save time
    last_save_time = total_system_time

func _save_json_file(file_path: String, data):
    var file = FileAccess.open(file_path, FileAccess.WRITE)
    if file:
        var json_string = JSON.stringify(data, "  ")
        file.store_string(json_string)
        file.close()
    else:
        push_error("Failed to save turn data to: " + file_path)

func _ensure_directories_exist():
    # Create C drive directories
    for i in range(1, max_turns + 1):
        var dir_path = c_drive_path + "/turn_" + str(i) + "/data"
        if not DirAccess.dir_exists_absolute(dir_path):
            DirAccess.make_dir_recursive_absolute(dir_path)
    
    # Create D drive base directory if D drive exists
    if DirAccess.dir_exists_absolute("D:/"):
        if not DirAccess.dir_exists_absolute(d_drive_path):
            DirAccess.make_dir_recursive_absolute(d_drive_path)

func _capture_screenshots(turn_number: int):
    # Create screenshot directory if it doesn't exist
    var screenshot_dir = screenshots_path + "/turn_" + str(turn_number)
    if not DirAccess.dir_exists_absolute(screenshot_dir):
        DirAccess.make_dir_recursive_absolute(screenshot_dir)
    
    # Capture viewport screenshot
    var image = get_viewport().get_texture().get_image()
    var time_str = Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_")
    var file_name = screenshot_dir + "/turn" + str(turn_number) + "_" + time_str + ".png"
    image.save_png(file_name)

# ----- BASH INTEGRATION -----
func _sync_with_bash_system():
    # Create a bash command to sync turn numbers
    var bash_script = """
    #!/bin/bash
    echo "%d" > "%s/current_turn.txt"
    
    # Run turn manager if it exists
    if [ -x "%s/turn_manager.sh" ]; then
        "%s/turn_manager.sh"
    fi
    
    # Copy data to D drive if it exists
    if [ -d "D:" ]; then
        mkdir -p "D:/JSH_Turn_Data/turn_%d/data"
        cp -r "%s/turn_%d/data/"* "D:/JSH_Turn_Data/turn_%d/data/"
    fi
    """ % [current_turn, c_drive_path, c_drive_path, c_drive_path, current_turn, c_drive_path, current_turn, current_turn]
    
    # Execute bash command
    var output = []
    var exit_code = OS.execute("bash", ["-c", bash_script], output, true)
    if exit_code != 0:
        push_error("Failed to sync with bash system: " + str(output))

func _save_current_turn():
    # Save current turn to file
    var file_path = c_drive_path + "/current_turn.txt"
    var file = FileAccess.open(file_path, FileAccess.WRITE)
    if file:
        file.store_string(str(current_turn))
        file.close()
    else:
        push_error("Failed to save current turn to: " + file_path)

func _load_current_turn():
    # Load current turn from file if it exists
    var file_path = c_drive_path + "/current_turn.txt"
    if FileAccess.file_exists(file_path):
        var file = FileAccess.open(file_path, FileAccess.READ)
        if file:
            var content = file.get_as_text().strip_edges()
            if content.is_valid_int():
                current_turn = content.to_int()
                current_turn = clamp(current_turn, 1, max_turns)
            file.close()

# ----- EFFECTS -----
func apply_turn_effects():
    # Apply effects based on current turn
    match current_turn:
        1: # Genesis
            _apply_genesis_effects()
        2: # Formation
            _apply_formation_effects()
        3: # Complexity
            _apply_complexity_effects()
        4: # Consciousness
            _apply_consciousness_effects()
        5: # Awakening
            _apply_awakening_effects()
        6: # Enlightenment
            _apply_enlightenment_effects()
        7: # Manifestation
            _apply_manifestation_effects()
        8: # Connection
            _apply_connection_effects()
        9: # Harmony
            _apply_harmony_effects()
        10: # Transcendence
            _apply_transcendence_effects()
        11: # Unity
            _apply_unity_effects()
        12: # Beyond
            _apply_beyond_effects()

func _apply_genesis_effects():
    if game_controller:
        # Start with minimal entities
        if game_controller.has_method("reset_entities"):
            game_controller.reset_entities()
        
        # Set dim lighting
        if game_controller.has_method("set_ambient_light"):
            game_controller.set_ambient_light(0.2)

func _apply_formation_effects():
    if game_controller:
        # Generate basic structures
        if game_controller.has_method("generate_basic_structures"):
            game_controller.generate_basic_structures(5)
        
        # Increase light slightly
        if game_controller.has_method("set_ambient_light"):
            game_controller.set_ambient_light(0.4)

func _apply_complexity_effects():
    if game_controller:
        # Create more interconnected systems
        if game_controller.has_method("increase_system_complexity"):
            game_controller.increase_system_complexity(0.7)
        
        # Adjust time flow
        if time_progression_system:
            time_progression_system.base_time_scale = 1.2

func _apply_consciousness_effects():
    if game_controller:
        # Enable awareness and feedback
        if game_controller.has_method("enable_feedback_systems"):
            game_controller.enable_feedback_systems(true)
        
        # Increase brightness
        if game_controller.has_method("set_ambient_light"):
            game_controller.set_ambient_light(0.6)

func _apply_awakening_effects():
    if game_controller:
        # Entities become aware
        if game_controller.has_method("trigger_entity_awakening"):
            game_controller.trigger_entity_awakening()
        
        # Adjust time flow - slows during awakening
        if time_progression_system:
            time_progression_system.base_time_scale = 0.8

func _apply_enlightenment_effects():
    if game_controller:
        # Increase knowledge connections
        if game_controller.has_method("increase_knowledge_connections"):
            game_controller.increase_knowledge_connections(0.8)
        
        # Brighter light
        if game_controller.has_method("set_ambient_light"):
            game_controller.set_ambient_light(0.8)

func _apply_manifestation_effects():
    if game_controller:
        # Enable creation abilities
        if game_controller.has_method("enable_creation_mode"):
            game_controller.enable_creation_mode(true)
        
        # Faster time flow during creation
        if time_progression_system:
            time_progression_system.base_time_scale = 1.5

func _apply_connection_effects():
    if game_controller:
        # Connect all entities
        if game_controller.has_method("connect_all_entities"):
            game_controller.connect_all_entities(0.7)
        
        # Normal time flow
        if time_progression_system:
            time_progression_system.base_time_scale = 1.0

func _apply_harmony_effects():
    if game_controller:
        # Balance all systems
        if game_controller.has_method("balance_all_systems"):
            game_controller.balance_all_systems()
        
        # Calm, measured time flow
        if time_progression_system:
            time_progression_system.base_time_scale = 0.9

func _apply_transcendence_effects():
    if game_controller:
        # Enable higher dimensional effects
        if game_controller.has_method("enable_transcendence"):
            game_controller.enable_transcendence(true)
        
        # Faster time flow during transcendence
        if time_progression_system:
            time_progression_system.base_time_scale = 1.7

func _apply_unity_effects():
    if game_controller:
        # Unify all systems
        if game_controller.has_method("unify_all_systems"):
            game_controller.unify_all_systems()
        
        # Full light
        if game_controller.has_method("set_ambient_light"):
            game_controller.set_ambient_light(1.0)

func _apply_beyond_effects():
    if game_controller:
        # Prepare for the next cycle
        if game_controller.has_method("prepare_for_rebirth"):
            game_controller.prepare_for_rebirth()
        
        # Time begins to slow as cycle completes
        if time_progression_system:
            time_progression_system.base_time_scale = 0.5

func on_cycle_completed():
    # Handle cycle completion
    print("Full 12-turn cycle completed! Starting new cycle...")
    
    # Archive previous cycle data
    _archive_previous_cycle()
    
    # Reset systems while preserving key data
    if game_controller and game_controller.has_method("on_cycle_completed"):
        game_controller.on_cycle_completed()

func _archive_previous_cycle():
    # Create archive directory with timestamp
    var timestamp = Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_")
    var archive_dir = c_drive_path + "/cycles/cycle_" + timestamp
    
    # Ensure the directory exists
    if not DirAccess.dir_exists_absolute(archive_dir):
        DirAccess.make_dir_recursive_absolute(archive_dir)
    
    # Create archive bash command
    var bash_script = """
    #!/bin/bash
    timestamp=$(date +"%Y-%m-%d_%H-%M-%S")
    archive_dir="%s/cycles/cycle_${timestamp}"
    mkdir -p "$archive_dir"
    
    # Copy all turn data to archive
    cp -r "%s/turn_"* "$archive_dir/"
    
    # Also archive to D drive if available
    if [ -d "D:" ]; then
        d_archive="D:/JSH_Turn_Data/cycles/cycle_${timestamp}"
        mkdir -p "$d_archive"
        cp -r "D:/JSH_Turn_Data/turn_"* "$d_archive/"
    fi
    
    echo "Cycle archived to: $archive_dir"
    """ % [c_drive_path, c_drive_path]
    
    # Execute bash command
    var output = []
    OS.execute("bash", ["-c", bash_script], output, true)
    print("Cycle archived: " + str(output))

# ----- EVENTS -----
func _on_save_timer_timeout():
    # Periodically save data without advancing turn
    if total_system_time - last_save_time >= save_interval:
        save_turn_data(current_turn)
        last_save_time = total_system_time

# ----- PUBLIC API -----
func manually_advance_turn():
    advance_turn()
    return current_turn

func set_turn(turn_number: int):
    if turn_number < 1 or turn_number > max_turns:
        return false
    
    # Save current turn data before changing
    save_turn_data(current_turn)
    
    # Set new turn
    var old_turn = current_turn
    current_turn = turn_number
    time_in_current_turn = 0.0
    
    # Save and sync
    _save_current_turn()
    _sync_with_bash_system()
    
    # Apply effects
    apply_turn_effects()
    
    # Emit signal
    emit_signal("turn_advanced", old_turn, current_turn)
    
    return true

func toggle_auto_advance(enabled: bool):
    auto_advance = enabled
    return auto_advance

func get_time_remaining() -> float:
    return max(0.0, time_per_turn - time_in_current_turn)

func get_formatted_time_remaining() -> String:
    var seconds = int(get_time_remaining())
    var minutes = seconds / 60
    seconds = seconds % 60
    return "%02d:%02d" % [minutes, seconds]

func get_turn_info() -> Dictionary:
    return {
        "current_turn": current_turn,
        "max_turns": max_turns,
        "current_phase": get_current_phase_name(),
        "time_remaining": get_time_remaining(),
        "progress": get_turn_progress(),
        "total_progress": get_total_progress(),
        "auto_advance": auto_advance
    }

func set_references(game_ctrl, time_prog, multiverse_evol):
    game_controller = game_ctrl
    time_progression_system = time_prog
    multiverse_evolution_system = multiverse_evol
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/godot_turn_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/google_drive_connector.gd
# SIZE: 13012 bytes
extends "cloud_storage_connector.gd"

class_name GoogleDriveConnector

# Google Drive specific constants
const API_BASE_URL = "https://www.googleapis.com/drive/v3"
const AUTH_URL = "https://accounts.google.com/o/oauth2/auth"
const TOKEN_URL = "https://oauth2.googleapis.com/token"
const SCOPE = "https://www.googleapis.com/auth/drive"
const REDIRECT_URI = "urn:ietf:wg:oauth:2.0:oob"
const API_VERSION = "v3"

# Google Drive specific properties
var drive_id = "" # For shared drives
var team_drive_support = false
var use_app_data_folder = false
var folder_cache = {}
var file_cache = {}
var thumbnail_cache = {}

# OpenAI API key for processing files
var openai_api_key = ""

func _ready():
    # Call parent _ready
    ._ready()
    
    # Set default provider to Google Drive
    default_provider = StorageProvider.GOOGLE_DRIVE
    active_provider = StorageProvider.GOOGLE_DRIVE
    
    # Set up Google Drive specific configuration
    _setup_google_drive_config()
    
    # Register additional signals
    self.add_user_signal("drive_changed", [{"name": "drive_id", "type": TYPE_STRING}])
    self.add_user_signal("file_processed", [
        {"name": "file_id", "type": TYPE_STRING},
        {"name": "metadata", "type": TYPE_DICTIONARY}
    ])

func _setup_google_drive_config():
    # Configure Google Drive specific settings
    team_drive_support = true
    
    # Add Google Drive specific folders to sync
    add_sync_folder("user://google_drive_cache", "appDataFolder", "both")
    add_sync_folder("user://documents", "Documents", "both")
    add_sync_folder("user://images", "Images", "download")
    
    # Set default cache size for Google Drive
    cache_size_mb = 1000

func configure_google_drive(api_key, client_id, client_secret):
    # Set API credentials for Google Drive
    return set_api_key(StorageProvider.GOOGLE_DRIVE, api_key, client_id, client_secret)

func set_openai_api_key(api_key):
    # Store OpenAI API key for processing
    openai_api_key = api_key
    print("Set OpenAI API key for file processing")
    return true

func authenticate_with_token(access_token, refresh_token, expires_in):
    # Skip OAuth flow using provided tokens
    var provider = StorageProvider.GOOGLE_DRIVE
    
    credentials[provider]["access_token"] = access_token
    credentials[provider]["refresh_token"] = refresh_token
    credentials[provider]["expires_at"] = OS.get_unix_time() + expires_in
    
    auth_state = AuthState.AUTHENTICATED
    emit_signal("authentication_changed", provider, auth_state)
    
    print("Authenticated with Google Drive using provided tokens")
    return true

func switch_drive(new_drive_id):
    # Change drive context
    drive_id = new_drive_id
    
    # Clear caches
    folder_cache.clear()
    file_cache.clear()
    
    print("Switched to Google Drive ID: " + new_drive_id)
    emit_signal("drive_changed", new_drive_id)
    return true

func search_files(query, max_results = 100):
    # Search for files in Google Drive with query
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated to Google Drive")
        return []
    
    # In real implementation, would make API call with query
    # For demo, generate sample results
    var results = []
    var file_types = ["application/pdf", "image/jpeg", "video/mp4", "text/plain", "application/vnd.google-apps.document"]
    var type_names = {
        "application/pdf": "PDF",
        "image/jpeg": "JPEG Image",
        "video/mp4": "MP4 Video",
        "text/plain": "Text File",
        "application/vnd.google-apps.document": "Google Doc"
    }
    
    # Generate relevant results based on query
    var result_count = randi() % max_results + 1
    
    for i in range(result_count):
        var mime_type = file_types[randi() % file_types.size()]
        var name = "Result " + str(i) + " for \"" + query + "\" - " + type_names[mime_type]
        
        results.append({
            "id": "file_" + str(OS.get_unix_time()) + "_" + str(i),
            "name": name,
            "mimeType": mime_type,
            "modifiedTime": OS.get_datetime_from_unix_time(OS.get_unix_time() - randi() % 10000000),
            "size": str(randi() % 10000000),
            "parents": ["folder_" + str(randi() % 10)],
            "thumbnailLink": "",
            "webViewLink": "https://drive.google.com/file/d/sample" + str(i),
            "capabilities": {
                "canEdit": randi() % 2 == 0,
                "canComment": true,
                "canShare": true,
                "canDownload": true
            }
        })
    
    print("Found " + str(results.size()) + " results for query: " + query)
    return results

func create_folder(folder_name, parent_id = "root"):
    # Create a new folder in Google Drive
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated to Google Drive")
        return null
    
    # In real implementation, would make API call
    # For demo, generate folder ID
    var folder_id = "folder_" + str(OS.get_unix_time())
    
    # Add to folder cache
    folder_cache[folder_id] = {
        "id": folder_id,
        "name": folder_name,
        "mimeType": "application/vnd.google-apps.folder",
        "parents": [parent_id],
        "modifiedTime": OS.get_datetime(),
        "capabilities": {
            "canEdit": true,
            "canComment": true,
            "canShare": true,
            "canDownload": true
        }
    }
    
    print("Created folder: " + folder_name + " (ID: " + folder_id + ")")
    return folder_id

func process_document_with_ai(file_id, processing_type = "summarize"):
    # Process a document with OpenAI
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated to Google Drive")
        return false
    
    if openai_api_key.empty():
        print("OpenAI API key not set")
        return false
    
    # In real implementation, would download file, process with OpenAI API, and store results
    # For demo, simulate processing
    
    # Allocate a thread for AI processing if available
    if _multi_threaded_processor:
        var account_id = _account_manager.active_account_id if _account_manager else "default"
        var task_description = "Processing document with AI: " + processing_type
        
        var thread_id = _multi_threaded_processor.allocate_thread(
            account_id,
            task_description,
            _multi_threaded_processor.Priority.HIGH
        )
        
        if thread_id:
            print("Processing document with AI in thread: " + thread_id)
            # In real implementation, would start thread function
            # For now, simulate processing after a delay
            var process_timer = Timer.new()
            process_timer.wait_time = 3.0 # 3 seconds for simulation
            process_timer.one_shot = true
            process_timer.connect("timeout", self, "_on_document_processed", [file_id, processing_type, thread_id, account_id])
            add_child(process_timer)
            process_timer.start()
            return true
    
    # Fallback if thread processor not available
    var process_timer = Timer.new()
    process_timer.wait_time = 3.0 # 3 seconds for simulation
    process_timer.one_shot = true
    process_timer.connect("timeout", self, "_on_document_processed", [file_id, processing_type, "none", "default"])
    add_child(process_timer)
    process_timer.start()
    return true

func _on_document_processed(file_id, processing_type, thread_id, account_id):
    # Simulate AI processing results
    var metadata = {}
    
    match processing_type:
        "summarize":
            metadata = {
                "summary": "This is an automatically generated summary of the document content, created by analyzing the text with AI.",
                "key_points": [
                    "First main point extracted from document",
                    "Second important concept identified in text",
                    "Third critical insight from content"
                ],
                "sentiment": "positive",
                "word_count": randi() % 5000 + 500,
                "processing_time": randi() % 10 + 2
            }
        "extract":
            metadata = {
                "entities": [
                    {"name": "Example Corp", "type": "ORGANIZATION"},
                    {"name": "Jane Smith", "type": "PERSON"},
                    {"name": "New York", "type": "LOCATION"}
                ],
                "dates": [
                    {"text": "January 15, 2025", "iso": "2025-01-15"},
                    {"text": "next quarter", "iso": "2025-04-01"}
                ],
                "topics": ["business", "technology", "finance"],
                "processing_time": randi() % 15 + 3
            }
        _:
            metadata = {
                "result": "Generic processing completed for " + processing_type,
                "processing_time": randi() % 5 + 1
            }
    
    # Update file cache with processed metadata
    if file_id in file_cache:
        file_cache[file_id]["ai_metadata"] = metadata
    
    # Emit signal
    emit_signal("file_processed", file_id, metadata)
    print("Processed document: " + file_id + " with " + processing_type)
    
    # Release thread if allocated
    if thread_id != "none" and _multi_threaded_processor:
        _multi_threaded_processor.release_thread(account_id, thread_id)
    
    return metadata

func enable_team_drive_support(enabled = true):
    team_drive_support = enabled
    print("Team Drive support: " + str(team_drive_support))
    return true

func enable_app_data_folder(enabled = true):
    use_app_data_folder = enabled
    print("AppData folder support: " + str(use_app_data_folder))
    return true

# Google Drive specific helper methods

func get_file_metadata(file_id):
    # Get comprehensive metadata for a file
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated to Google Drive")
        return null
    
    # Check cache first
    if file_id in file_cache:
        return file_cache[file_id]
    
    # In real implementation, would make API call
    # For demo, generate sample metadata
    var mime_types = ["application/pdf", "image/jpeg", "video/mp4", "text/plain", "application/vnd.google-apps.document"]
    var mime_type = mime_types[randi() % mime_types.size()]
    var file_size = randi() % 10000000 + 1000
    
    var metadata = {
        "id": file_id,
        "name": "File " + file_id.substr(0, 8),
        "mimeType": mime_type,
        "modifiedTime": OS.get_datetime_from_unix_time(OS.get_unix_time() - randi() % 10000000),
        "createdTime": OS.get_datetime_from_unix_time(OS.get_unix_time() - randi() % 20000000),
        "size": str(file_size),
        "parents": ["folder_" + str(randi() % 10)],
        "owners": [
            {
                "displayName": "Owner Name",
                "emailAddress": "owner@example.com"
            }
        ],
        "lastModifyingUser": {
            "displayName": "Editor Name",
            "emailAddress": "editor@example.com"
        },
        "capabilities": {
            "canEdit": true,
            "canComment": true,
            "canShare": true,
            "canDownload": true
        },
        "viewedByMe": randi() % 2 == 0,
        "viewedByMeTime": OS.get_datetime_from_unix_time(OS.get_unix_time() - randi() % 5000000),
        "shared": randi() % 2 == 0,
        "thumbnailLink": "",
        "webViewLink": "https://drive.google.com/file/d/" + file_id,
        "iconLink": "",
        "starred": randi() % 2 == 0,
        "trashed": false
    }
    
    # Cache the metadata
    file_cache[file_id] = metadata
    
    print("Retrieved metadata for: " + metadata["name"])
    return metadata

func list_folders(parent_id = "root"):
    # List folders in Google Drive
    if auth_state != AuthState.AUTHENTICATED:
        print("Not authenticated to Google Drive")
        return []
    
    # In real implementation, would make API call
    # For demo, generate sample folders
    var folders = []
    var folder_count = randi() % 10 + 2 # 2-12 folders
    
    for i in range(folder_count):
        var folder_id = "folder_" + str(parent_id) + "_" + str(i)
        var folder_name = "Folder " + str(i) + " in " + parent_id
        
        folders.append({
            "id": folder_id,
            "name": folder_name,
            "mimeType": "application/vnd.google-apps.folder",
            "parents": [parent_id],
            "modifiedTime": OS.get_datetime_from_unix_time(OS.get_unix_time() - randi() % 10000000),
            "capabilities": {
                "canEdit": randi() % 2 == 0,
                "canComment": true,
                "canShare": true,
                "canDownload": true
            }
        })
        
        # Cache the folder
        folder_cache[folder_id] = folders[i]
    }
    
    print("Listed " + str(folders.size()) + " folders in parent: " + parent_id)
    return folders
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/google_drive_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/initialize_system.gd
# SIZE: 5840 bytes
extends Node

# Main initialization script for Smart Account System with all components

func _ready():
    print("Initializing Smart Account System...")
    
    # Wait for all nodes to be ready
    yield(get_tree().create_timer(0.5), "timeout")
    
    # Get references to all system components
    var components = {
        "account_manager": get_node_or_null("/root/SmartAccountSystem/SmartAccountManager"),
        "connector": get_node_or_null("/root/SmartAccountSystem/SharedAccountConnector"),
        "akashic": get_node_or_null("/root/SmartAccountSystem/AkashicDatabaseConnector"),
        "analyzer": get_node_or_null("/root/SmartAccountSystem/PlayerPreferenceAnalyzer"),
        "auto_correction": get_node_or_null("/root/SmartAccountSystem/AutoCorrectionSystem"),
        "multi_account": get_node_or_null("/root/SmartAccountSystem/MultiAccountManager"),
        "processor": get_node_or_null("/root/SmartAccountSystem/MultiThreadedProcessor"),
        "cloud_storage": get_node_or_null("/root/SmartAccountSystem/CloudStorageConnector"),
        "google_drive": get_node_or_null("/root/SmartAccountSystem/GoogleDriveConnector"),
        "api_manager": get_node_or_null("/root/SmartAccountSystem/ApiKeyManager")
    }
    
    # Verify all components exist
    var missing_components = []
    for component_name in components:
        if components[component_name] == null:
            missing_components.append(component_name)
    
    if missing_components.size() > 0:
        print("ERROR: Missing components: " + str(missing_components))
        return
    
    print("All system components found")
    
    # Set up API keys
    setup_api_keys(components)
    
    # Create and configure account tiers
    setup_account_tiers(components)
    
    # Connect to Google Drive
    connect_to_google_drive(components)
    
    # Initialize point distribution system
    initialize_points_system(components)
    
    # Configure multi-threading
    configure_threading(components)
    
    print("Smart Account System initialization complete")

func setup_api_keys(components):
    # Set OpenAI API key
    var openai_api_key = "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"
    
    # Import to API manager
    var api_key_id = components["api_manager"].import_openai_api_key(openai_api_key)
    print("Imported OpenAI API key: " + str(api_key_id))
    
    # Set for Google Drive
    components["google_drive"].set_openai_api_key(openai_api_key)
    
    # Set simulated Google API credentials
    components["google_drive"].configure_google_drive(
        "simulated_google_key",
        "simulated_client_id",
        "simulated_client_secret"
    )
    
    print("API keys configured")

func setup_account_tiers(components):
    # Create accounts for different tiers
    var free_account = components["multi_account"].create_account(
        "Free Account",
        components["multi_account"].AccountTier.FREE
    )
    
    var plus_account = components["multi_account"].create_account(
        "Plus Account",
        components["multi_account"].AccountTier.PLUS
    )
    
    var max_account = components["multi_account"].create_account(
        "Max Account",
        components["multi_account"].AccountTier.MAX
    )
    
    var enterprise_account = components["multi_account"].create_account(
        "Google Drive 2TB",
        components["multi_account"].AccountTier.ENTERPRISE
    )
    
    # Set Google Drive account as active
    components["multi_account"].switch_account(enterprise_account)
    
    # Link 2TB storage
    components["multi_account"].link_luno_storage(enterprise_account, 2000)
    
    print("Account tiers created")

func connect_to_google_drive(components):
    # Connect to Google Drive
    components["google_drive"].connect_provider(components["cloud_storage"].StorageProvider.GOOGLE_DRIVE)
    
    # Configure sync folders
    components["google_drive"].add_sync_folder("user://game_data", "GameData", "both")
    components["google_drive"].add_sync_folder("user://saved_games", "SavedGames", "both")
    components["google_drive"].add_sync_folder("user://exports", "Exports", "upload")
    
    # Start synchronization
    components["google_drive"].synchronize_folders()
    
    print("Connected to Google Drive")

func initialize_points_system(components):
    # Configure dimension progression
    var account_manager = components["account_manager"]
    
    # Initialize with some points in each category
    account_manager.add_points(100, "creation")
    account_manager.add_points(75, "exploration")
    account_manager.add_points(50, "interaction")
    account_manager.add_points(25, "challenge")
    account_manager.add_points(25, "mastery")
    
    # Configure auto-correction
    components["auto_correction"].adjustment_intensity = 0.7
    components["auto_correction"].notification_level = 1
    
    print("Points system initialized")

func configure_threading(components):
    # Configure thread pool
    var processor = components["processor"]
    
    # Allocate threads for key tasks
    var storage_thread = processor.allocate_thread(
        components["multi_account"].active_account_id,
        "Storage synchronization",
        processor.Priority.NORMAL
    )
    
    var analytics_thread = processor.allocate_thread(
        components["multi_account"].active_account_id,
        "User analytics processing",
        processor.Priority.LOW
    )
    
    var ai_thread = processor.allocate_thread(
        components["multi_account"].active_account_id,
        "AI document analysis",
        processor.Priority.HIGH
    )
    
    print("Threading configured with " + str(processor.get_active_thread_count()) + " active threads")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/initialize_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/integrated_game_system.gd
# SIZE: 43227 bytes
extends Node

# Integrated Game System
# Combines 12 Turns, Notepad3D, Akashic Records, and Word Evolution
# into a complete game experience with unified interface and gameplay

class_name IntegratedGameSystem

# ----- COMPONENT REFERENCES -----
var akashic_controller = null
var system_integrator = null
var main_controller = null
var word_manifestation_system = null
var universal_connector = null
var spatial_storage = null
var notepad_visualizer = null

# ----- INTEGRATION NODES -----
var akashic_scene = null
var dimension_scene = null
var terminal_ui = null
var word_ui = null
var entity_manager = null

# ----- STATE VARIABLES -----
var current_turn = 3  # Default to 3D dimension
var current_symbol = "Œ≥"
var current_dimension = "3D"
var current_cosmic_age = "Complexity"
var current_project = "12_turns_system"
var visualization_active = false
var current_entities = {}
var entity_types = ["word", "note", "akashic", "shape", "terminal", "node"]
var evolution_stages = ["seed", "sprout", "sapling", "tree", "transcendent"]
var active_folder_paths = []
var connected_folders = {}

# ----- SIGNAL HANDLING -----
signal system_initialized
signal entity_created(entity_id, entity_type, entity_data)
signal entity_evolved(entity_id, old_stage, new_stage)
signal dimension_changed(turn_number, symbol, dimension_name)
signal folder_connected(folder_path, connection_type)
signal project_changed(old_project, new_project)

# ----- INITIALIZATION -----
func _ready():
    print("Initializing Integrated Game System...")
    
    # Create core components
    setup_components()
    
    # Initialize folder connections
    initialize_folder_connections()
    
    # Wait for all components to be ready
    call_deferred("finalize_initialization")

func setup_components():
    # Create universal connector
    universal_connector = UniversalAkashicConnector.new()
    add_child(universal_connector)
    
    # Create spatial storage
    spatial_storage = SpatialWorldStorage.new()
    add_child(spatial_storage)
    
    # Create system integrator
    system_integrator = load("res://system_integrator.gd").new()
    add_child(system_integrator)
    
    # Create akashic controller
    akashic_controller = load("res://akashic_notepad_controller.gd").new()
    add_child(akashic_controller)
    
    # Create word manifestation system
    word_manifestation_system = load("res://word_manifestation_system.gd").new()
    add_child(word_manifestation_system)
    
    # Create main controller if needed
    if not has_node("/root/MainController"):
        main_controller = load("res://main.gd").new()
        main_controller.name = "MainController"
        add_child(main_controller)
    else:
        main_controller = get_node("/root/MainController")
    
    # Create terminal UI
    terminal_ui = Control.new()
    terminal_ui.name = "TerminalUI"
    terminal_ui.anchor_right = 1.0
    terminal_ui.anchor_bottom = 1.0
    add_child(terminal_ui)
    
    # Create entity manager
    entity_manager = Node.new()
    entity_manager.name = "EntityManager"
    add_child(entity_manager)

func initialize_folder_connections():
    # Define important folders to connect
    var folders_to_connect = [
        "/mnt/c/Users/Percision 15/12_turns_system",
        "/mnt/c/Users/Percision 15/Eden_OS",
        "/mnt/c/Users/Percision 15/LuminusOS"
    ]
    
    # Connect to each folder
    for folder_path in folders_to_connect:
        connect_folder(folder_path)
    
    # Connect subdirectories for deeper integration
    connect_folder("/mnt/c/Users/Percision 15/12_turns_system/data")
    connect_folder("/mnt/c/Users/Percision 15/12_turns_system/core")
    connect_folder("/mnt/c/Users/Percision 15/12_turns_system/messages")
    connect_folder("/mnt/c/Users/Percision 15/LuminusOS/scripts")

func finalize_initialization():
    # Connect components
    connect_components()
    
    # Setup UI elements
    setup_ui()
    
    # Start in 3D mode (default dimension)
    set_current_dimension(current_turn)
    
    # Initialize visualization scene
    setup_visualization_scene()
    
    # Emit initialization signal
    print("Integrated Game System initialization complete!")
    emit_signal("system_initialized")

# ----- COMPONENT CONNECTIONS -----
func connect_components():
    # Connect akashic controller to main controller
    akashic_controller.set_main_controller(main_controller)
    
    # Connect word manifestation system
    if word_manifestation_system:
        akashic_controller.set_word_manifestation_system(word_manifestation_system)
        
        # Connect word manifestation to main controller
        if main_controller and main_controller.has_method("connect_word_manifestation"):
            main_controller.connect_word_manifestation(word_manifestation_system)
    
    # Connect system integrator to akashic controller
    system_integrator.akashic_controller = akashic_controller
    
    # Connect signals from main controller
    if main_controller:
        main_controller.connect("turn_advanced", self, "_on_turn_advanced")
        main_controller.connect("note_created", self, "_on_note_created")
        main_controller.connect("word_manifested", self, "_on_word_manifested")
        
        if main_controller.has_signal("reality_changed"):
            main_controller.connect("reality_changed", self, "_on_reality_changed")
    
    # Connect signals from universal connector
    universal_connector.connect("system_connected", self, "_on_system_connected")
    universal_connector.connect("dimension_accessed", self, "_on_dimension_accessed")
    universal_connector.connect("record_transferred", self, "_on_record_transferred")
    
    # Connect signals from akashic controller
    akashic_controller.connect("record_created", self, "_on_record_created")
    akashic_controller.connect("akashic_synergy_detected", self, "_on_akashic_synergy_detected")
    akashic_controller.connect("dimension_power_calculated", self, "_on_dimension_power_calculated")

func setup_ui():
    # Create the main layout
    var main_layout = VBoxContainer.new()
    main_layout.anchor_right = 1.0
    main_layout.anchor_bottom = 1.0
    terminal_ui.add_child(main_layout)
    
    # Add dimension indicator
    var dimension_label = Label.new()
    dimension_label.name = "DimensionLabel"
    dimension_label.text = "%s: %s (%s)" % [current_turn, current_symbol, current_dimension]
    dimension_label.align = Label.ALIGN_CENTER
    main_layout.add_child(dimension_label)
    
    # Add status bar
    var status_bar = HBoxContainer.new()
    status_bar.name = "StatusBar"
    main_layout.add_child(status_bar)
    
    var turn_label = Label.new()
    turn_label.name = "TurnLabel"
    turn_label.text = "Turn: %d" % current_turn
    status_bar.add_child(turn_label)
    
    var spacer = Control.new()
    spacer.size_flags_horizontal = Control.SIZE_EXPAND_FILL
    status_bar.add_child(spacer)
    
    var entity_count_label = Label.new()
    entity_count_label.name = "EntityCountLabel"
    entity_count_label.text = "Entities: 0"
    status_bar.add_child(entity_count_label)
    
    # Add folder list
    var folder_list = ItemList.new()
    folder_list.name = "FolderList"
    folder_list.size_flags_vertical = Control.SIZE_EXPAND_FILL
    folder_list.size_flags_horizontal = Control.SIZE_EXPAND_FILL
    folder_list.rect_min_size = Vector2(0, 100)
    folder_list.connect("item_selected", self, "_on_folder_selected")
    main_layout.add_child(folder_list)
    
    # Add command line
    var command_line = LineEdit.new()
    command_line.name = "CommandLine"
    command_line.placeholder_text = "Enter command..."
    command_line.clear_button_enabled = true
    command_line.size_flags_horizontal = Control.SIZE_EXPAND_FILL
    command_line.connect("text_entered", self, "_on_command_entered")
    main_layout.add_child(command_line)
    
    # Add visualization toggle
    var button_container = HBoxContainer.new()
    button_container.name = "ButtonContainer"
    main_layout.add_child(button_container)
    
    var vis_button = Button.new()
    vis_button.name = "VisualizationButton"
    vis_button.text = "Toggle 3D View"
    vis_button.connect("pressed", self, "_on_visualization_button_pressed")
    button_container.add_child(vis_button)
    
    var evolution_button = Button.new()
    evolution_button.name = "EvolutionButton"
    evolution_button.text = "Evolve Entities"
    evolution_button.connect("pressed", self, "_on_evolution_button_pressed")
    button_container.add_child(evolution_button)
    
    var connect_folder_button = Button.new()
    connect_folder_button.name = "ConnectFolderButton"
    connect_folder_button.text = "Connect Folder"
    connect_folder_button.connect("pressed", self, "_on_connect_folder_button_pressed")
    button_container.add_child(connect_folder_button)
    
    # Update folder list
    update_folder_list()

# ----- FOLDER MANAGEMENT -----
func connect_folder(folder_path, connection_type = "standard"):
    if not Directory.new().dir_exists(folder_path):
        print("Cannot connect folder: Directory does not exist: %s" % folder_path)
        return false
    
    # Skip if already connected
    if connected_folders.has(folder_path):
        return true
    
    print("Connecting folder: %s" % folder_path)
    
    # Register the folder
    connected_folders[folder_path] = {
        "connection_type": connection_type,
        "connected_at": OS.get_unix_time(),
        "file_count": 0,
        "godot_files": 0,
        "entities": [],
        "synced": false
    }
    
    # Add to active paths
    if not active_folder_paths.has(folder_path):
        active_folder_paths.append(folder_path)
    
    # Count files and scan for Godot scripts
    var file_count = 0
    var godot_files = 0
    _scan_directory(folder_path, file_count, godot_files)
    
    connected_folders[folder_path].file_count = file_count
    connected_folders[folder_path].godot_files = godot_files
    
    # Create akashic entry for the connection
    if akashic_controller:
        var content = "Connected folder: %s with %d files (%d Godot scripts)" % [
            folder_path, file_count, godot_files
        ]
        
        var position = Vector3(
            randf() * 10 - 5,
            randf() * 10,
            randf() * 10 - 5
        )
        
        akashic_controller.create_akashic_entry(
            content,
            position,
            current_turn,
            ["folder", "connection", "project"]
        )
    
    # Update UI if available
    update_folder_list()
    
    # Emit signal
    emit_signal("folder_connected", folder_path, connection_type)
    
    return true

func disconnect_folder(folder_path):
    if not connected_folders.has(folder_path):
        return false
    
    print("Disconnecting folder: %s" % folder_path)
    
    # Remove from connected folders
    var folder_data = connected_folders[folder_path]
    connected_folders.erase(folder_path)
    
    # Remove from active paths
    if active_folder_paths.has(folder_path):
        active_folder_paths.erase(folder_path)
    
    # Update UI
    update_folder_list()
    
    return true

func update_folder_list():
    var folder_list = terminal_ui.get_node_or_null("FolderList")
    if not folder_list:
        folder_list = terminal_ui.find_node("FolderList", true, false)
    
    if not folder_list:
        return
    
    # Clear list
    folder_list.clear()
    
    # Add connected folders
    for folder_path in connected_folders:
        var folder_data = connected_folders[folder_path]
        var folder_name = folder_path.get_file()
        
        var item_text = "%s - %d files" % [folder_name, folder_data.file_count]
        folder_list.add_item(item_text, null, true)
        
        # Store folder path as metadata
        var idx = folder_list.get_item_count() - 1
        folder_list.set_item_metadata(idx, folder_path)
        
        # Set tooltip
        folder_list.set_item_tooltip(idx, folder_path)

func _scan_directory(directory_path, file_count, godot_files):
    var dir = Directory.new()
    
    if dir.open(directory_path) == OK:
        dir.list_dir_begin(true, true)
        
        var file_name = dir.get_next()
        while file_name != "":
            var full_path = directory_path.plus_file(file_name)
            
            if dir.current_is_dir():
                # Recursively scan subdirectory
                _scan_directory(full_path, file_count, godot_files)
            else:
                file_count += 1
                
                # Check for Godot script
                if file_name.ends_with(".gd"):
                    godot_files += 1
                    
                    # Register script with universal connector if appropriate
                    if file_name.find("akashic") >= 0 or file_name.find("word") >= 0 or 
                       file_name.find("note") >= 0 or file_name.find("dimension") >= 0:
                        _register_script_with_connector(full_path, file_name)
            
            file_name = dir.get_next()
        
        dir.list_dir_end()

func _register_script_with_connector(script_path, script_name):
    if universal_connector:
        # Try to determine script type
        var system_type = ""
        
        if script_name.find("akashic") >= 0:
            system_type = "akashic_records"
        elif script_name.find("word") >= 0:
            system_type = "word_processor"
        elif script_name.find("note") >= 0:
            system_type = "notepad"
        elif script_name.find("dimension") >= 0:
            system_type = "dimension_controller"
        else:
            system_type = "unknown"
        
        # Register with universal connector
        universal_connector._try_connect_system(script_name.get_basename(), system_type, script_path)

# ----- VISUALIZATION -----
func setup_visualization_scene():
    # Create akashic scene
    akashic_scene = load("res://akashic_notepad_scene.tscn").instance()
    add_child(akashic_scene)
    
    # Get notepad visualizer reference
    notepad_visualizer = akashic_scene.get_node("VisualizationContainer/Notepad3DVisualizer")
    
    # Connect visualizer to akashic controller
    if notepad_visualizer and akashic_controller:
        akashic_controller.set_visualizer(notepad_visualizer)
        
        # Set visualizer as inactive initially
        toggle_visualization(false)
    
    # Initialize the first dimension
    if akashic_controller:
        akashic_controller.visualize_akashic_record(current_turn)

func toggle_visualization(active = true):
    visualization_active = active
    
    if akashic_scene:
        # Toggle visibility of visualization elements
        var vis_container = akashic_scene.get_node("VisualizationContainer")
        if vis_container:
            vis_container.visible = active
        
        # Toggle camera
        var camera = akashic_scene.get_node("VisualizationContainer/VisualizationCamera")
        if camera:
            camera.current = active
    
    # Update button text
    var vis_button = terminal_ui.find_node("VisualizationButton", true, false)
    if vis_button:
        vis_button.text = "3D View: %s" % ("ON" if active else "OFF")
    
    return active

# ----- ENTITY MANAGEMENT -----
func create_entity(entity_type, data):
    if not entity_type in entity_types:
        push_error("Invalid entity type: %s" % entity_type)
        return null
    
    # Generate entity ID
    var entity_id = "entity_%s_%d" % [entity_type, OS.get_unix_time()]
    
    # Create entity data
    var entity = {
        "id": entity_id,
        "type": entity_type,
        "data": data,
        "created_at": OS.get_unix_time(),
        "turn": current_turn,
        "dimension": current_dimension,
        "symbol": current_symbol,
        "stage": "seed",
        "evolution_points": 0,
        "connections": []
    }
    
    # Add to entity manager
    current_entities[entity_id] = entity
    
    # Update label
    update_entity_count_label()
    
    # Create 3D representation if appropriate
    create_entity_visualization(entity)
    
    # Emit signal
    emit_signal("entity_created", entity_id, entity_type, data)
    
    return entity_id

func evolve_entity(entity_id, force_stage = ""):
    if not current_entities.has(entity_id):
        return false
    
    var entity = current_entities[entity_id]
    var old_stage = entity.stage
    var new_stage = old_stage
    
    # Determine evolution
    if force_stage != "" and evolution_stages.has(force_stage):
        new_stage = force_stage
    else:
        # Increment evolution points
        entity.evolution_points += 1
        
        # Determine new stage based on points
        var stage_index = evolution_stages.find(old_stage)
        
        if entity.evolution_points >= (stage_index + 1) * 5:
            stage_index += 1
            
            if stage_index < evolution_stages.size():
                new_stage = evolution_stages[stage_index]
    
    # Update if stage changed
    if new_stage != old_stage:
        entity.stage = new_stage
        
        # Update visualization
        update_entity_visualization(entity)
        
        # Log the evolution
        print("Entity %s evolved from %s to %s" % [entity_id, old_stage, new_stage])
        
        # Emit signal
        emit_signal("entity_evolved", entity_id, old_stage, new_stage)
        
        return true
    
    return false

func create_entity_visualization(entity):
    if not visualization_active or not akashic_controller:
        return null
    
    # Create visualization based on entity type
    match entity.type:
        "word":
            if "text" in entity.data:
                var position = Vector3(
                    randf() * 10 - 5,
                    randf() * 2 + 1,
                    randf() * 10 - 5
                )
                
                var power = entity.data.get("power", 50)
                
                akashic_controller.create_akashic_entry(
                    entity.data.text,
                    position,
                    current_turn,
                    ["word", entity.stage]
                )
                
                # Remember visualization ID
                entity.visualization_id = entity.data.text
        
        "note":
            if "content" in entity.data:
                var position = Vector3(
                    randf() * 10 - 5,
                    randf() * 2 + 3,
                    randf() * 10 - 5
                )
                
                akashic_controller.create_akashic_entry(
                    entity.data.content,
                    position,
                    current_turn,
                    ["note", entity.stage]
                )
                
                # Remember visualization ID
                entity.visualization_id = entity.data.content
        
        "akashic":
            # Already visualized directly
            pass
        
        "shape":
            if "dimensions" in entity.data:
                var notebook_name = "shapes_%d" % current_turn
                
                # Create notepad if needed
                if not akashic_controller.get_spatial_storage().get_notepad(notebook_name):
                    akashic_controller.create_notepad(notebook_name, ["shape", "geometry"])
                
                # Create 3D cells to represent the shape
                var width = entity.data.dimensions.x
                var height = entity.data.dimensions.y
                var depth = entity.data.dimensions.z
                
                for x in range(width):
                    for y in range(height):
                        for z in range(depth):
                            var cell_pos = Vector3(x, y, z)
                            var content = "Shape: %s" % entity.id
                            var color = entity.data.get("color", Color.white)
                            
                            akashic_controller.add_notepad_cell(notebook_name, cell_pos, content, color)
        
        "terminal":
            if "command" in entity.data:
                var position = Vector3(
                    randf() * 10 - 5,
                    randf() * 2 + 5,
                    randf() * 10 - 5
                )
                
                akashic_controller.create_akashic_entry(
                    "Terminal: " + entity.data.command,
                    position,
                    current_turn,
                    ["terminal", "command", entity.stage]
                )
        
        "node":
            if "script_path" in entity.data:
                var position = Vector3(
                    randf() * 10 - 5,
                    randf() * 2 + 7,
                    randf() * 10 - 5
                )
                
                var script_name = entity.data.script_path.get_file()
                
                akashic_controller.create_akashic_entry(
                    "Script: " + script_name,
                    position,
                    current_turn,
                    ["node", "script", entity.stage]
                )

func update_entity_visualization(entity):
    if not visualization_active or not akashic_controller:
        return false
    
    # Simply recreate the visualization with updated stage
    create_entity_visualization(entity)
    
    return true

func update_entity_count_label():
    var entity_count_label = terminal_ui.find_node("EntityCountLabel", true, false)
    if entity_count_label:
        entity_count_label.text = "Entities: %d" % current_entities.size()

# ----- DIMENSION MANAGEMENT -----
func set_current_dimension(turn_number):
    var prev_turn = current_turn
    current_turn = turn_number
    
    # Update dimension info
    if turn_number > 0 and turn_number <= 12:
        var turn_symbols = ["Œ±", "Œ≤", "Œ≥", "Œ¥", "Œµ", "Œ∂", "Œ∑", "Œ∏", "Œπ", "Œ∫", "Œª", "Œº"]
        var turn_dimensions = ["1D", "2D", "3D", "4D", "5D", "6D", "7D", "8D", "9D", "10D", "11D", "12D"]
        var cosmic_ages = [
            "Genesis", "Formation", "Complexity", "Consciousness", 
            "Awakening", "Enlightenment", "Manifestation", "Connection", 
            "Harmony", "Transcendence", "Unity", "Beyond"
        ]
        
        current_symbol = turn_symbols[turn_number - 1]
        current_dimension = turn_dimensions[turn_number - 1]
        current_cosmic_age = cosmic_ages[turn_number - 1]
    
    # Update UI
    var dimension_label = terminal_ui.find_node("DimensionLabel", true, false)
    if dimension_label:
        dimension_label.text = "%s: %s (%s)" % [current_turn, current_symbol, current_dimension]
    
    var turn_label = terminal_ui.find_node("TurnLabel", true, false)
    if turn_label:
        turn_label.text = "Turn: %d" % current_turn
    
    # Update visualization
    if visualization_active and akashic_controller:
        akashic_controller.visualize_akashic_record(current_turn)
    
    # Set universal connector dimension access
    if universal_connector:
        universal_connector.set_dimension_access(current_turn)
    
    # Emit signal
    emit_signal("dimension_changed", current_turn, current_symbol, current_dimension)
    
    return current_turn

# ----- COMMAND PROCESSING -----
func process_command(command_text):
    if command_text.empty():
        return "Please enter a command"
    
    # Split command and arguments
    var parts = command_text.split(" ", false, 1)
    var cmd = parts[0].to_lower()
    var args = parts[1] if parts.size() > 1 else ""
    
    # Process command
    match cmd:
        "connect":
            return process_connect_command(args)
        
        "dimension", "turn":
            return process_dimension_command(args)
        
        "create":
            return process_create_command(args)
        
        "evolve":
            return process_evolve_command(args)
        
        "list":
            return process_list_command(args)
        
        "visualize":
            return process_visualize_command(args)
        
        "project":
            return process_project_command(args)
        
        "synergy":
            return process_synergy_command(args)
        
        "help":
            return get_help_text()
        
        _:
            # Try to forward to other systems
            if akashic_controller:
                var result = akashic_controller.process_command(cmd, args.split(" "))
                if result != "Unknown command: " + cmd:
                    return result
            
            if main_controller and main_controller.has_method("execute_command"):
                var result = main_controller.execute_command(command_text)
                if result and typeof(result) == TYPE_STRING and not result.begins_with("Unknown command"):
                    return result
            
            return "Unknown command: " + cmd

func process_connect_command(args):
    if args.empty():
        return "Usage: connect <folder_path> [connection_type]"
    
    var parts = args.split(" ", false, 1)
    var folder_path = parts[0]
    var connection_type = parts[1] if parts.size() > 1 else "standard"
    
    if connect_folder(folder_path, connection_type):
        return "Successfully connected folder: " + folder_path
    else:
        return "Failed to connect folder: " + folder_path

func process_dimension_command(args):
    if args.empty():
        return "Current dimension: %s: %s (%s)" % [current_turn, current_symbol, current_dimension]
    
    var parts = args.split(" ")
    var subcommand = parts[0]
    
    match subcommand:
        "goto", "set", "change":
            if parts.size() < 2 or not parts[1].is_valid_integer():
                return "Usage: dimension goto <1-12>"
            
            var turn = int(parts[1])
            if turn < 1 or turn > 12:
                return "Invalid dimension number. Must be between 1 and 12."
            
            set_current_dimension(turn)
            return "Dimension changed to %d: %s (%s)" % [current_turn, current_symbol, current_dimension]
        
        "next":
            var next_turn = (current_turn % 12) + 1
            set_current_dimension(next_turn)
            return "Advanced to dimension %d: %s (%s)" % [current_turn, current_symbol, current_dimension]
        
        "prev", "previous":
            var prev_turn = current_turn - 1
            if prev_turn < 1:
                prev_turn = 12
            
            set_current_dimension(prev_turn)
            return "Went back to dimension %d: %s (%s)" % [current_turn, current_symbol, current_dimension]
        
        "info":
            return "Dimension %d: %s (%s)\nCosmic Age: %s" % [
                current_turn, current_symbol, current_dimension, current_cosmic_age
            ]
        
        _:
            return "Unknown dimension subcommand: " + subcommand

func process_create_command(args):
    if args.empty():
        return "Usage: create <entity_type> <data>"
    
    var parts = args.split(" ", false, 1)
    if parts.size() < 2:
        return "Usage: create <entity_type> <data>"
    
    var entity_type = parts[0]
    var data_text = parts[1]
    
    if not entity_type in entity_types:
        return "Invalid entity type. Valid types: " + str(entity_types)
    
    # Create entity based on type
    var entity_data = {}
    
    match entity_type:
        "word":
            entity_data = {
                "text": data_text,
                "power": 50 + (current_turn * 5)
            }
        
        "note":
            entity_data = {
                "content": data_text
            }
        
        "akashic":
            entity_data = {
                "content": data_text,
                "tags": ["user_created", current_dimension.to_lower()]
            }
            
            # Create actual akashic entry
            if akashic_controller:
                var position = Vector3(
                    randf() * 10 - 5,
                    randf() * 5,
                    randf() * 10 - 5
                )
                
                akashic_controller.create_akashic_entry(
                    data_text,
                    position,
                    current_turn,
                    ["user_created", current_dimension.to_lower()]
                )
        
        "shape":
            # Parse dimensions from format like 3x3x3
            var dimensions = Vector3(1, 1, 1)
            var color = Color.white
            
            if data_text.find("x") >= 0:
                var dim_parts = data_text.split("x")
                
                if dim_parts.size() >= 3:
                    dimensions = Vector3(
                        int(dim_parts[0]),
                        int(dim_parts[1]),
                        int(dim_parts[2])
                    )
                elif dim_parts.size() == 2:
                    dimensions = Vector3(
                        int(dim_parts[0]),
                        int(dim_parts[1]),
                        1
                    )
            
            entity_data = {
                "dimensions": dimensions,
                "color": color
            }
        
        "terminal":
            entity_data = {
                "command": data_text
            }
        
        "node":
            entity_data = {
                "script_path": data_text
            }
    
    var entity_id = create_entity(entity_type, entity_data)
    
    if entity_id:
        return "Created %s entity: %s" % [entity_type, entity_id]
    else:
        return "Failed to create entity"

func process_evolve_command(args):
    if args.empty():
        return "Usage: evolve <entity_id or 'all'> [target_stage]"
    
    var parts = args.split(" ")
    var entity_id = parts[0]
    var target_stage = parts[1] if parts.size() > 1 else ""
    
    if entity_id == "all":
        var evolved_count = 0
        
        for id in current_entities:
            if evolve_entity(id, target_stage):
                evolved_count += 1
        
        return "Evolved %d entities" % evolved_count
    else:
        if not current_entities.has(entity_id):
            return "Entity not found: " + entity_id
        
        if evolve_entity(entity_id, target_stage):
            var entity = current_entities[entity_id]
            return "Evolved entity %s to stage: %s" % [entity_id, entity.stage]
        else:
            return "Entity did not evolve (insufficient evolution points)"

func process_list_command(args):
    if args.empty():
        return "Usage: list <entities|folders|dimensions|projects>"
    
    match args:
        "entities":
            var result = "Entities (%d):\n" % current_entities.size()
            
            for entity_id in current_entities:
                var entity = current_entities[entity_id]
                result += "- %s (%s): Stage %s\n" % [entity_id, entity.type, entity.stage]
            
            return result
        
        "folders":
            var result = "Connected Folders (%d):\n" % connected_folders.size()
            
            for folder_path in connected_folders:
                var folder_data = connected_folders[folder_path]
                result += "- %s: %d files (%d Godot scripts)\n" % [
                    folder_path, folder_data.file_count, folder_data.godot_files
                ]
            
            return result
        
        "dimensions":
            var result = "Available Dimensions:\n"
            
            for i in range(1, 13):
                var turn_symbols = ["Œ±", "Œ≤", "Œ≥", "Œ¥", "Œµ", "Œ∂", "Œ∑", "Œ∏", "Œπ", "Œ∫", "Œª", "Œº"]
                var turn_dimensions = ["1D", "2D", "3D", "4D", "5D", "6D", "7D", "8D", "9D", "10D", "11D", "12D"]
                var symbol = turn_symbols[i-1]
                var dimension = turn_dimensions[i-1]
                
                result += "%d: %s (%s)%s\n" % [
                    i, symbol, dimension,
                    " - Current" if i == current_turn else ""
                ]
            
            return result
        
        "projects":
            var result = "Available Projects:\n"
            
            var projects = ["12_turns_system", "Eden_OS", "LuminusOS"]
            for project in projects:
                result += "- %s%s\n" % [
                    project,
                    " - Current" if project == current_project else ""
                ]
            
            return result
        
        _:
            return "Unknown list type. Valid types: entities, folders, dimensions, projects"

func process_visualize_command(args):
    if args.empty():
        visualize_all_entities()
        return "Visualizing all entities"
    
    match args:
        "on", "true", "enable":
            toggle_visualization(true)
            return "3D visualization enabled"
        
        "off", "false", "disable":
            toggle_visualization(false)
            return "3D visualization disabled"
        
        "toggle":
            toggle_visualization(!visualization_active)
            return "3D visualization %s" % ("enabled" if visualization_active else "disabled")
        
        "entities":
            visualize_all_entities()
            return "Visualizing all entities"
        
        "dimension", "akashic":
            if akashic_controller:
                akashic_controller.visualize_akashic_record(current_turn)
                return "Visualizing current dimension (%d)" % current_turn
            return "Akashic controller not available"
        
        _:
            # Assume it's an entity ID
            if current_entities.has(args):
                update_entity_visualization(current_entities[args])
                return "Visualizing entity: " + args
            
            return "Unknown visualization option or entity ID: " + args

func process_project_command(args):
    if args.empty():
        return "Current project: " + current_project
    
    var old_project = current_project
    current_project = args
    
    # Change active folder
    var project_path = "/mnt/c/Users/Percision 15/" + current_project
    
    if Directory.new().dir_exists(project_path):
        # Connect to the project folder if not already connected
        if not connected_folders.has(project_path):
            connect_folder(project_path)
        
        # Emit signal
        emit_signal("project_changed", old_project, current_project)
        
        return "Switched to project: " + current_project
    else:
        current_project = old_project
        return "Project directory not found: " + project_path

func process_synergy_command(args):
    if args.empty() or args == "detect":
        if akashic_controller:
            # Force synergy detection
            akashic_controller._check_for_synergies()
            return "Checking for synergies..."
    
    match args:
        "connect":
            # Connect all entities to form synergies
            var connections_made = 0
            
            var entities = current_entities.values()
            for i in range(entities.size()):
                for j in range(i + 1, entities.size()):
                    if entities[i].stage == entities[j].stage:
                        entities[i].connections.append(entities[j].id)
                        entities[j].connections.append(entities[i].id)
                        connections_made += 1
            
            return "Created %d synergistic connections" % connections_made
        
        "evolve":
            # Evolve entities with many connections
            var evolved_count = 0
            
            for entity_id in current_entities:
                var entity = current_entities[entity_id]
                
                if entity.connections.size() >= 3:
                    var stage_index = evolution_stages.find(entity.stage)
                    
                    if stage_index < evolution_stages.size() - 1:
                        var new_stage = evolution_stages[stage_index + 1]
                        evolve_entity(entity_id, new_stage)
                        evolved_count += 1
            
            return "Evolved %d entities through synergy" % evolved_count
        
        _:
            return "Unknown synergy subcommand: " + args

func visualize_all_entities():
    if not visualization_active:
        toggle_visualization(true)
    
    for entity_id in current_entities:
        update_entity_visualization(current_entities[entity_id])

func get_help_text():
    return """
Available commands:

DIMENSION CONTROL:
  dimension goto <1-12> - Change to specific dimension
  dimension next - Advance to next dimension
  dimension prev - Go back to previous dimension
  dimension info - Show current dimension info

ENTITY MANAGEMENT:
  create <entity_type> <data> - Create new entity
    Types: word, note, akashic, shape, terminal, node
  evolve <entity_id> [stage] - Evolve entity to next stage
  evolve all - Evolve all entities

VISUALIZATION:
  visualize on/off - Toggle 3D visualization
  visualize entities - Visualize all entities
  visualize <entity_id> - Visualize specific entity
  visualize dimension - Visualize current dimension

PROJECT MANAGEMENT:
  project <name> - Switch active project
  connect <folder_path> - Connect a folder to the system
  
SYNERGY SYSTEM:
  synergy detect - Detect synergies in akashic records
  synergy connect - Create connections between entities
  synergy evolve - Evolve entities through synergistic connections

INFORMATION:
  list entities - List all entities
  list folders - List connected folders
  list dimensions - List available dimensions
  list projects - List available projects
  help - Show this help text
"""

# ----- EVENT HANDLERS -----
func _on_turn_advanced(turn_number, symbol, dimension):
    set_current_dimension(turn_number)

func _on_note_created(note_data):
    # Create entity from note
    create_entity("note", {
        "content": note_data.text,
        "power": note_data.power,
        "turn": note_data.turn
    })

func _on_word_manifested(word, position, power):
    # Create entity from manifested word
    create_entity("word", {
        "text": word,
        "power": power,
        "position": position
    })

func _on_reality_changed(reality_data):
    # Update based on reality change
    print("Reality changed: ", reality_data)

func _on_system_connected(system_id, system_type):
    print("Connected to %s system: %s" % [system_type, system_id])

func _on_dimension_accessed(dimension_id, access_level):
    print("Dimension accessed: %s (level %s)" % [dimension_id, access_level])

func _on_record_transferred(record_id, source_system, target_system):
    print("Record transferred: %s from %s to %s" % [record_id, source_system, target_system])

func _on_record_created(entry_id):
    # Create entity from akashic record
    if akashic_controller:
        var entry = akashic_controller.get_akashic_entry(entry_id)
        if entry:
            create_entity("akashic", {
                "content": entry.content,
                "tags": entry.tags,
                "position": entry.position.coordinate,
                "dimension": entry.position.dimension
            })

func _on_akashic_synergy_detected(synergies):
    print("Detected %d akashic synergies" % synergies.size())
    
    # Evolve entities based on synergies
    var evolved_count = 0
    
    for entity_id in current_entities:
        var entity = current_entities[entity_id]
        
        if entity.type == "akashic" and entity.stage != "transcendent":
            # Give a chance to evolve based on number of synergies
            var evolution_chance = min(0.2 + (synergies.size() * 0.05), 0.8)
            
            if randf() < evolution_chance:
                evolve_entity(entity_id)
                evolved_count += 1
    
    if evolved_count > 0:
        print("Evolved %d entities due to akashic synergies" % evolved_count)

func _on_dimension_power_calculated(dimension, power):
    print("Dimension %d power calculated: %f" % [dimension, power])
    
    # Chance to evolve entities in this dimension
    var evolved_count = 0
    
    for entity_id in current_entities:
        var entity = current_entities[entity_id]
        
        if entity.turn == dimension and entity.stage != "transcendent":
            var evolution_chance = min(0.1 + (power / 1000.0), 0.9)
            
            if randf() < evolution_chance:
                evolve_entity(entity_id)
                evolved_count += 1
    
    if evolved_count > 0:
        print("Evolved %d entities due to dimension power" % evolved_count)

func _on_folder_selected(index):
    var folder_list = terminal_ui.find_node("FolderList", true, false)
    if folder_list:
        var folder_path = folder_list.get_item_metadata(index)
        
        if folder_path and connected_folders.has(folder_path):
            var folder_data = connected_folders[folder_path]
            
            # Create entity for this folder
            create_entity("node", {
                "script_path": folder_path,
                "file_count": folder_data.file_count,
                "godot_files": folder_data.godot_files
            })
            
            # Show info in command line
            var command_line = terminal_ui.find_node("CommandLine", true, false)
            if command_line:
                command_line.text = "create note Connected to folder: " + folder_path

func _on_command_entered(text):
    var result = process_command(text)
    
    # Create terminal entity from command
    if text.strip_edges() != "":
        create_entity("terminal", {
            "command": text,
            "result": result
        })
    
    # Clear command line
    var command_line = terminal_ui.find_node("CommandLine", true, false)
    if command_line:
        command_line.text = ""
        
        # Show result temporarily
        command_line.placeholder_text = result
        
        # Reset placeholder after delay
        yield(get_tree().create_timer(3.0), "timeout")
        command_line.placeholder_text = "Enter command..."

func _on_visualization_button_pressed():
    toggle_visualization(!visualization_active)

func _on_evolution_button_pressed():
    var evolved_count = 0
    
    for entity_id in current_entities:
        if evolve_entity(entity_id):
            evolved_count += 1
    
    # Show result
    var command_line = terminal_ui.find_node("CommandLine", true, false)
    if command_line:
        command_line.placeholder_text = "Evolved %d entities" % evolved_count
        
        # Reset placeholder after delay
        yield(get_tree().create_timer(2.0), "timeout")
        command_line.placeholder_text = "Enter command..."

func _on_connect_folder_button_pressed():
    var command_line = terminal_ui.find_node("CommandLine", true, false)
    if command_line:
        command_line.text = "connect /mnt/c/Users/Percision 15/"
        command_line.grab_focus()
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/integrated_game_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/integrated_memory_system.gd
# SIZE: 34778 bytes
extends Node

class_name IntegratedMemorySystem

# ----- MEMORY SYSTEM SETTINGS -----
@export_category("Memory System Settings")
@export var enabled: bool = true
@export var local_storage_enabled: bool = true
@export var online_storage_enabled: bool = false
@export var multi_device_sync: bool = false
@export var auto_backup: bool = true
@export var backup_interval: int = 300  # seconds
@export var memory_compression: bool = true
@export var memories_per_turn: int = 8
@export var max_stored_wishes: int = 88

# ----- STORAGE PATHS -----
var local_memory_path: String = "user://memory_system/"
var local_backup_path: String = "user://memory_system/backups/"
var offline_cache_path: String = "user://memory_system/offline_cache/"
var wish_storage_path: String = "user://memory_system/wishes/"
var connection_map_path: String = "user://memory_system/connections/"
var user_device_file: String = "user://memory_system/device_identity.json"

# ----- DEVICE IDENTITY -----
var device_id: String = ""
var device_name: String = ""
var last_sync_timestamp: int = 0
var memory_signature: String = ""

# ----- CLOUD STORAGE -----
var google_drive_connected: bool = false
var onedrive_connected: bool = false
var dropbox_connected: bool = false

# ----- MEMORY CONTAINERS -----
var local_memories: Dictionary = {}
var device_memories: Dictionary = {}
var cloud_memories: Dictionary = {}
var wish_collection: Array = []
var memory_connections: Dictionary = {}

# ----- CONNECTION SYSTEM -----
var connection_strength: Dictionary = {}
var connection_associations: Dictionary = {}
var memory_heat_map: Dictionary = {}

# ----- COMPONENT REFERENCES -----
var turn_system: Node = null
var time_tracker: Node = null

# ----- OFFLINE QUEUE -----
var offline_changes: Array = []
var pending_syncs: Dictionary = {}

# ----- TIMERS -----
var backup_timer: Timer
var sync_timer: Timer

# ----- SIGNALS -----
signal memory_stored(memory_id, content)
signal memory_retrieved(memory_id, content)
signal wish_added(wish_id, content)
signal wish_fulfilled(wish_id, content)
signal memories_synced(device_id, count)
signal connection_established(from_id, to_id, strength)
signal memory_system_ready()
signal cloud_connection_changed(service, connected)

# ----- INITIALIZATION -----
func _ready():
    # Create required directories
    _ensure_directories_exist()
    
    # Set up timers
    _setup_timers()
    
    # Generate or load device identity
    _initialize_device_identity()
    
    # Find reference components
    _find_reference_components()
    
    # Load local memories
    _load_local_memories()
    
    # Load wishes
    _load_wishes()
    
    # Load connection map
    _load_connection_map()
    
    # Check for cloud connections
    _check_cloud_connections()
    
    # Process any offline changes
    _process_offline_queue()
    
    # Log initialization
    print("Integrated Memory System initialized - Device ID: " + device_id)
    emit_signal("memory_system_ready")

func _ensure_directories_exist():
    var directories = [
        local_memory_path,
        local_backup_path,
        offline_cache_path,
        wish_storage_path,
        connection_map_path
    ]
    
    for dir in directories:
        if not DirAccess.dir_exists_absolute(dir):
            DirAccess.make_dir_recursive_absolute(dir)

func _setup_timers():
    # Backup timer
    backup_timer = Timer.new()
    backup_timer.wait_time = backup_interval
    backup_timer.one_shot = false
    backup_timer.autostart = true
    backup_timer.connect("timeout", _on_backup_timer_timeout)
    add_child(backup_timer)
    
    # Sync timer
    sync_timer = Timer.new()
    sync_timer.wait_time = 600  # 10 minutes
    sync_timer.one_shot = false
    sync_timer.autostart = true
    sync_timer.connect("timeout", _on_sync_timer_timeout)
    add_child(sync_timer)

func _initialize_device_identity():
    if FileAccess.file_exists(user_device_file):
        # Load existing identity
        var file = FileAccess.open(user_device_file, FileAccess.READ)
        if file:
            var json = JSON.new()
            var error = json.parse(file.get_as_text())
            if error == OK:
                var data = json.data
                device_id = data.get("device_id", "")
                device_name = data.get("device_name", "")
                last_sync_timestamp = data.get("last_sync", 0)
                memory_signature = data.get("memory_signature", "")
                
            file.close()
    
    # Generate new identity if needed
    if device_id.is_empty():
        device_id = _generate_unique_id()
        device_name = "Device_" + device_id.substr(0, 8)
        memory_signature = _generate_memory_signature()
        last_sync_timestamp = Time.get_unix_time_from_system()
        
        # Save identity
        _save_device_identity()

func _find_reference_components():
    # Find turn system
    var potential_turns = get_tree().get_nodes_in_group("turn_systems")
    if potential_turns.size() > 0:
        turn_system = potential_turns[0]
        print("Found turn system: " + turn_system.name)
    else:
        # Find using class name
        turn_system = _find_node_by_class(get_tree().root, "TurnSystem")
        if not turn_system:
            turn_system = _find_node_by_class(get_tree().root, "TurnCycleController")
    
    # Find time tracker
    var potential_trackers = get_tree().get_nodes_in_group("time_trackers")
    if potential_trackers.size() > 0:
        time_tracker = potential_trackers[0]
        print("Found time tracker: " + time_tracker.name)
    else:
        time_tracker = _find_node_by_class(get_tree().root, "UsageTimeTracker")

func _find_node_by_class(node, class_name):
    if node.get_class() == class_name:
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name)
        if found:
            return found
    
    return null

# ----- MEMORY LOADING -----
func _load_local_memories():
    # Clear existing memories
    local_memories.clear()
    
    # Scan memory directory
    var dir = DirAccess.open(local_memory_path)
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            if not dir.current_is_dir() and file_name.ends_with(".json") and not file_name.begins_with("."): 
                var memory_path = local_memory_path + file_name
                _load_memory_file(memory_path)
            
            file_name = dir.get_next()
        
        dir.list_dir_end()
    
    print("Loaded " + str(local_memories.size()) + " local memories")

func _load_memory_file(file_path):
    var file = FileAccess.open(file_path, FileAccess.READ)
    if file:
        var json = JSON.new()
        var error = json.parse(file.get_as_text())
        if error == OK:
            var memory_data = json.data
            var memory_id = memory_data.get("id", "")
            
            if not memory_id.is_empty():
                local_memories[memory_id] = memory_data
        
        file.close()

func _load_wishes():
    # Clear existing wishes
    wish_collection.clear()
    
    # Load wish file
    var wish_file = wish_storage_path + "wishes.json"
    
    if FileAccess.file_exists(wish_file):
        var file = FileAccess.open(wish_file, FileAccess.READ)
        if file:
            var json = JSON.new()
            var error = json.parse(file.get_as_text())
            if error == OK:
                wish_collection = json.data
            
            file.close()
    
    # Ensure we don't exceed max wishes
    if wish_collection.size() > max_stored_wishes:
        wish_collection = wish_collection.slice(wish_collection.size() - max_stored_wishes, wish_collection.size())
    
    print("Loaded " + str(wish_collection.size()) + " wishes")

func _load_connection_map():
    # Clear existing connections
    memory_connections.clear()
    
    # Load connection file
    var connection_file = connection_map_path + "memory_connections.json"
    
    if FileAccess.file_exists(connection_file):
        var file = FileAccess.open(connection_file, FileAccess.READ)
        if file:
            var json = JSON.new()
            var error = json.parse(file.get_as_text())
            if error == OK:
                memory_connections = json.data
            
            file.close()
    
    print("Loaded " + str(memory_connections.size()) + " memory connections")

func _check_cloud_connections():
    # Try to connect to cloud services if enabled
    if online_storage_enabled:
        _check_google_drive_connection()
        _check_onedrive_connection()
        _check_dropbox_connection()

func _check_google_drive_connection():
    # Placeholder for Google Drive connection
    # Would use actual API calls in a real implementation
    google_drive_connected = false
    emit_signal("cloud_connection_changed", "google_drive", google_drive_connected)

func _check_onedrive_connection():
    # Placeholder for OneDrive connection
    onedrive_connected = false
    emit_signal("cloud_connection_changed", "onedrive", onedrive_connected)

func _check_dropbox_connection():
    # Placeholder for Dropbox connection
    dropbox_connected = false
    emit_signal("cloud_connection_changed", "dropbox", dropbox_connected)

func _process_offline_queue():
    # Process any pending changes from offline mode
    var offline_queue_file = offline_cache_path + "offline_queue.json"
    
    if FileAccess.file_exists(offline_queue_file):
        var file = FileAccess.open(offline_queue_file, FileAccess.READ)
        if file:
            var json = JSON.new()
            var error = json.parse(file.get_as_text())
            
            if error == OK:
                offline_changes = json.data
                
                # Process each change
                var processed_changes = []
                
                for change in offline_changes:
                    var success = _process_offline_change(change)
                    if success:
                        processed_changes.append(change)
                
                # Remove processed changes
                for change in processed_changes:
                    offline_changes.erase(change)
                
                # Save remaining changes
                _save_offline_queue()
            
            file.close()
    
    print("Processed offline memory queue")

# ----- MEMORY OPERATIONS -----
func store_memory(content: String, tags: Array = [], type: String = "general", turn: int = -1):
    if not enabled:
        return ""
    
    # Get current turn if not specified
    if turn < 0 and turn_system and "current_turn" in turn_system:
        turn = turn_system.current_turn
    else:
        turn = 1  # Default
    
    # Generate memory ID
    var memory_id = _generate_unique_id()
    
    # Create memory structure
    var memory = {
        "id": memory_id,
        "content": content,
        "tags": tags,
        "type": type,
        "turn": turn,
        "device_id": device_id,
        "timestamp": Time.get_unix_time_from_system(),
        "connections": []
    }
    
    # Store locally
    local_memories[memory_id] = memory
    
    # Save to file
    _save_memory_to_file(memory)
    
    # Generate connections
    _generate_memory_connections(memory_id, content, tags)
    
    # Queue for syncing if online storage enabled
    if online_storage_enabled:
        _queue_for_syncing(memory_id)
    
    # Emit signal
    emit_signal("memory_stored", memory_id, content)
    
    return memory_id

func retrieve_memory(memory_id: String):
    # Check local memories first
    if local_memories.has(memory_id):
        emit_signal("memory_retrieved", memory_id, local_memories[memory_id])
        return local_memories[memory_id]
    
    # Check device memories
    if device_memories.has(memory_id):
        emit_signal("memory_retrieved", memory_id, device_memories[memory_id])
        return device_memories[memory_id]
    
    # Check cloud memories if enabled
    if online_storage_enabled and cloud_memories.has(memory_id):
        emit_signal("memory_retrieved", memory_id, cloud_memories[memory_id])
        return cloud_memories[memory_id]
    
    # Not found
    return null

func search_memories(query: String, tags: Array = [], type: String = "", max_results: int = 10):
    var results = []
    
    # Search in all memory containers
    var search_containers = [local_memories, device_memories, cloud_memories]
    
    for container in search_containers:
        for memory_id in container:
            var memory = container[memory_id]
            
            # Check type filter
            if not type.is_empty() and memory.type != type:
                continue
            
            # Check tags filter
            if not tags.is_empty():
                var has_all_tags = true
                for tag in tags:
                    if not memory.tags.has(tag):
                        has_all_tags = false
                        break
                
                if not has_all_tags:
                    continue
            
            # Check content for query
            if query.is_empty() or memory.content.to_lower().contains(query.to_lower()):
                results.append(memory)
                
                # Check if we've reached max results
                if results.size() >= max_results:
                    return results
    
    return results

func add_wish(wish_content: String, priority: int = 5, tags: Array = []):
    if not enabled:
        return ""
    
    # Generate wish ID
    var wish_id = _generate_unique_id()
    
    # Create wish structure
    var wish = {
        "id": wish_id,
        "content": wish_content,
        "priority": priority,
        "tags": tags,
        "created": Time.get_unix_time_from_system(),
        "fulfilled": false,
        "fulfilled_time": 0,
        "connections": []
    }
    
    # Add to collection
    wish_collection.append(wish)
    
    # Ensure we don't exceed max wishes
    if wish_collection.size() > max_stored_wishes:
        wish_collection.remove_at(0)
    
    # Save wishes
    _save_wishes()
    
    # Emit signal
    emit_signal("wish_added", wish_id, wish_content)
    
    return wish_id

func fulfill_wish(wish_id: String, fulfillment_details: String = ""):
    if not enabled:
        return false
    
    # Find wish
    for i in range(wish_collection.size()):
        if wish_collection[i].id == wish_id:
            wish_collection[i].fulfilled = true
            wish_collection[i].fulfilled_time = Time.get_unix_time_from_system()
            
            if not fulfillment_details.is_empty():
                wish_collection[i].fulfillment_details = fulfillment_details
            
            # Save wishes
            _save_wishes()
            
            # Create memory of fulfillment
            var memory_content = "Wish fulfilled: " + wish_collection[i].content
            if not fulfillment_details.is_empty():
                memory_content += " - " + fulfillment_details
            
            store_memory(memory_content, wish_collection[i].tags, "wish_fulfillment")
            
            # Emit signal
            emit_signal("wish_fulfilled", wish_id, wish_collection[i])
            
            return true
    
    return false

func connect_memories(from_id: String, to_id: String, connection_type: String = "association", strength: float = 1.0):
    if not enabled:
        return false
    
    # Ensure both memories exist
    if not local_memories.has(from_id) and not device_memories.has(from_id) and not cloud_memories.has(from_id):
        return false
    
    if not local_memories.has(to_id) and not device_memories.has(to_id) and not cloud_memories.has(to_id):
        return false
    
    # Create connection key
    var connection_key = from_id + "->" + to_id
    
    # Create connection
    var connection = {
        "from": from_id,
        "to": to_id,
        "type": connection_type,
        "strength": strength,
        "created": Time.get_unix_time_from_system()
    }
    
    # Add to connections
    memory_connections[connection_key] = connection
    
    # Add to memory's connections list
    if local_memories.has(from_id):
        if not "connections" in local_memories[from_id]:
            local_memories[from_id].connections = []
        
        local_memories[from_id].connections.append({
            "to": to_id,
            "type": connection_type,
            "strength": strength
        })
        
        # Save memory
        _save_memory_to_file(local_memories[from_id])
    
    # Save connections
    _save_connection_map()
    
    # Emit signal
    emit_signal("connection_established", from_id, to_id, strength)
    
    return true

func find_related_memories(memory_id: String, max_results: int = 10):
    var related = []
    
    # Find direct connections
    for connection_key in memory_connections:
        var connection = memory_connections[connection_key]
        
        if connection.from == memory_id:
            var to_memory = retrieve_memory(connection.to)
            if to_memory:
                related.append({
                    "memory": to_memory,
                    "connection": connection,
                    "direction": "outgoing"
                })
        
        if connection.to == memory_id:
            var from_memory = retrieve_memory(connection.from)
            if from_memory:
                related.append({
                    "memory": from_memory,
                    "connection": connection,
                    "direction": "incoming"
                })
        
        # Check if we've reached max results
        if related.size() >= max_results:
            break
    
    return related

# ----- SYNC OPERATIONS -----
func sync_with_device(target_device_id: String):
    if not multi_device_sync:
        return false
    
    # In a real implementation, this would involve network communication
    # Here we'll just simulate with a placeholder
    
    # Mark as pending sync
    pending_syncs[target_device_id] = Time.get_unix_time_from_system()
    
    print("Queued sync with device: " + target_device_id)
    
    return true

func _queue_for_syncing(memory_id: String):
    # Add to offline queue if we're not connected
    if not google_drive_connected and not onedrive_connected and not dropbox_connected:
        var change = {
            "type": "add",
            "memory_id": memory_id,
            "timestamp": Time.get_unix_time_from_system()
        }
        
        offline_changes.append(change)
        _save_offline_queue()
    else:
        # Otherwise, we would push directly to cloud storage
        # This is a placeholder for actual API calls
        print("Memory " + memory_id + " queued for sync to cloud")

func _process_offline_change(change):
    # Process a single offline change
    if change.type == "add":
        # We would upload to cloud storage here
        return true
    elif change.type == "update":
        # We would update cloud storage here
        return true
    elif change.type == "delete":
        # We would delete from cloud storage here
        return true
    
    return false

# ----- FILE OPERATIONS -----
func _save_memory_to_file(memory):
    var file_path = local_memory_path + memory.id + ".json"
    var file = FileAccess.open(file_path, FileAccess.WRITE)
    
    if file:
        var json_string = JSON.stringify(memory, "  ")
        file.store_string(json_string)
        file.close()
        return true
    
    return false

func _save_wishes():
    var file_path = wish_storage_path + "wishes.json"
    var file = FileAccess.open(file_path, FileAccess.WRITE)
    
    if file:
        var json_string = JSON.stringify(wish_collection, "  ")
        file.store_string(json_string)
        file.close()
        return true
    
    return false

func _save_connection_map():
    var file_path = connection_map_path + "memory_connections.json"
    var file = FileAccess.open(file_path, FileAccess.WRITE)
    
    if file:
        var json_string = JSON.stringify(memory_connections, "  ")
        file.store_string(json_string)
        file.close()
        return true
    
    return false

func _save_device_identity():
    var identity = {
        "device_id": device_id,
        "device_name": device_name,
        "last_sync": last_sync_timestamp,
        "memory_signature": memory_signature
    }
    
    var file = FileAccess.open(user_device_file, FileAccess.WRITE)
    if file:
        var json_string = JSON.stringify(identity, "  ")
        file.store_string(json_string)
        file.close()
        return true
    
    return false

func _save_offline_queue():
    var file_path = offline_cache_path + "offline_queue.json"
    var file = FileAccess.open(file_path, FileAccess.WRITE)
    
    if file:
        var json_string = JSON.stringify(offline_changes, "  ")
        file.store_string(json_string)
        file.close()
        return true
    
    return false

func _backup_memories():
    if not auto_backup:
        return
    
    # Create timestamp for backup
    var timestamp = Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_")
    var backup_folder = local_backup_path + "backup_" + timestamp + "/"
    
    # Create backup directory
    if not DirAccess.dir_exists_absolute(backup_folder):
        DirAccess.make_dir_recursive_absolute(backup_folder)
    
    # Copy all memory files
    var dir = DirAccess.open(local_memory_path)
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            if not dir.current_is_dir() and file_name.ends_with(".json"):
                var source_path = local_memory_path + file_name
                var target_path = backup_folder + file_name
                
                var source_file = FileAccess.open(source_path, FileAccess.READ)
                var target_file = FileAccess.open(target_path, FileAccess.WRITE)
                
                if source_file and target_file:
                    target_file.store_string(source_file.get_as_text())
                    
                    source_file.close()
                    target_file.close()
            
            file_name = dir.get_next()
        
        dir.list_dir_end()
    
    # Backup wishes
    var wishes_source = wish_storage_path + "wishes.json"
    var wishes_target = backup_folder + "wishes.json"
    
    if FileAccess.file_exists(wishes_source):
        var source_file = FileAccess.open(wishes_source, FileAccess.READ)
        var target_file = FileAccess.open(wishes_target, FileAccess.WRITE)
        
        if source_file and target_file:
            target_file.store_string(source_file.get_as_text())
            
            source_file.close()
            target_file.close()
    
    # Backup connections
    var connections_source = connection_map_path + "memory_connections.json"
    var connections_target = backup_folder + "memory_connections.json"
    
    if FileAccess.file_exists(connections_source):
        var source_file = FileAccess.open(connections_source, FileAccess.READ)
        var target_file = FileAccess.open(connections_target, FileAccess.WRITE)
        
        if source_file and target_file:
            target_file.store_string(source_file.get_as_text())
            
            source_file.close()
            target_file.close()
    
    print("Created memory backup: " + timestamp)
    
    # Clean up old backups - keep only the latest 5
    _cleanup_old_backups(5)

func _cleanup_old_backups(keep_count: int):
    var backups = []
    
    # Scan backup directory
    var dir = DirAccess.open(local_backup_path)
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            if dir.current_is_dir() and file_name.begins_with("backup_"):
                backups.append(file_name)
            
            file_name = dir.get_next()
        
        dir.list_dir_end()
    
    # Sort backups by name (which includes timestamp)
    backups.sort()
    
    # Remove oldest backups
    if backups.size() > keep_count:
        for i in range(0, backups.size() - keep_count):
            var old_backup = backups[i]
            _remove_directory_recursive(local_backup_path + old_backup)

func _remove_directory_recursive(path: String):
    var dir = DirAccess.open(path)
    if dir:
        dir.list_dir_begin()
        var file_name = dir.get_next()
        
        while file_name != "":
            if dir.current_is_dir() and file_name != "." and file_name != "..":
                _remove_directory_recursive(path + "/" + file_name)
            elif not dir.current_is_dir():
                dir.remove(file_name)
            
            file_name = dir.get_next()
        
        dir.list_dir_end()
        
        # Remove the empty directory
        DirAccess.remove_absolute(path)

# ----- MEMORY CONNECTIONS -----
func _generate_memory_connections(memory_id: String, content: String, tags: Array):
    # Find potentially related memories
    var related_by_content = _find_related_by_content(content, 3)
    var related_by_tags = _find_related_by_tags(tags, 3)
    
    # Combine unique related memories
    var related = {}
    
    for item in related_by_content:
        related[item.id] = item.similarity
    
    for item in related_by_tags:
        if related.has(item.id):
            related[item.id] = max(related[item.id], item.similarity)
        else:
            related[item.id] = item.similarity
    
    # Create connections
    for related_id in related:
        var strength = related[related_id]
        connect_memories(memory_id, related_id, "auto_association", strength)

func _find_related_by_content(content: String, max_results: int):
    var related = []
    
    # Simple word matching algorithm - in a real implementation
    # this would use more sophisticated NLP techniques
    var content_words = content.to_lower().split(" ", false)
    
    # Search through local memories
    for memory_id in local_memories:
        if memory_id == content:  # Skip self
            continue
        
        var memory = local_memories[memory_id]
        var memory_content = memory.content.to_lower()
        var memory_words = memory_content.split(" ", false)
        
        # Count matching words
        var matching_words = 0
        for word in content_words:
            if memory_words.has(word) and word.length() > 3:  # Only count significant words
                matching_words += 1
        
        # Calculate similarity (0-1)
        var max_possible_matches = min(content_words.size(), memory_words.size())
        var similarity = 0.0
        
        if max_possible_matches > 0:
            similarity = float(matching_words) / float(max_possible_matches)
        
        # Add if significant similarity
        if similarity > 0.2:
            related.append({
                "id": memory_id,
                "similarity": similarity
            })
            
            # Sort by similarity and keep only top results
            related.sort_custom(func(a, b): return a.similarity > b.similarity)
            
            if related.size() > max_results:
                related.resize(max_results)
    
    return related

func _find_related_by_tags(tags: Array, max_results: int):
    var related = []
    
    if tags.is_empty():
        return related
    
    # Search through local memories
    for memory_id in local_memories:
        var memory = local_memories[memory_id]
        
        if not "tags" in memory or memory.tags.is_empty():
            continue
        
        # Count matching tags
        var matching_tags = 0
        for tag in tags:
            if memory.tags.has(tag):
                matching_tags += 1
        
        # Calculate similarity (0-1)
        var max_possible_matches = min(tags.size(), memory.tags.size())
        var similarity = 0.0
        
        if max_possible_matches > 0:
            similarity = float(matching_tags) / float(max_possible_matches)
        
        # Add if has any matching tags
        if similarity > 0:
            related.append({
                "id": memory_id,
                "similarity": similarity
            })
            
            # Sort by similarity and keep only top results
            related.sort_custom(func(a, b): return a.similarity > b.similarity)
            
            if related.size() > max_results:
                related.resize(max_results)
    
    return related

# ----- UTILITY FUNCTIONS -----
func _generate_unique_id() -> String:
    var uuid = ""
    var chars = "abcdefghijklmnopqrstuvwxyz0123456789"
    var rng = RandomNumberGenerator.new()
    rng.randomize()
    
    # Format: 8-4-4-4-12
    for i in range(32):
        if i == 8 or i == 12 or i == 16 or i == 20:
            uuid += "-"
        uuid += chars[rng.randi() % chars.length()]
    
    return uuid

func _generate_memory_signature() -> String:
    var signature = ""
    var chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
    var rng = RandomNumberGenerator.new()
    rng.randomize()
    
    for i in range(16):
        signature += chars[rng.randi() % chars.length()]
    
    return signature

# ----- EVENT HANDLERS -----
func _on_backup_timer_timeout():
    if auto_backup:
        _backup_memories()

func _on_sync_timer_timeout():
    if online_storage_enabled:
        # Check cloud connections
        _check_cloud_connections()
        
        # Process offline queue if we're now connected
        if google_drive_connected or onedrive_connected or dropbox_connected:
            _process_offline_queue()

# ----- PUBLIC API -----
func get_memory_stats() -> Dictionary:
    return {
        "local_memories": local_memories.size(),
        "device_memories": device_memories.size(),
        "cloud_memories": cloud_memories.size(),
        "total_memories": local_memories.size() + device_memories.size() + cloud_memories.size(),
        "wishes": wish_collection.size(),
        "fulfilled_wishes": wish_collection.filter(func(wish): return wish.fulfilled).size(),
        "connections": memory_connections.size(),
        "device_id": device_id,
        "device_name": device_name,
        "online_storage": online_storage_enabled,
        "multi_device": multi_device_sync,
        "cloud_connections": {
            "google_drive": google_drive_connected,
            "onedrive": onedrive_connected,
            "dropbox": dropbox_connected
        }
    }

func set_device_name(name: String) -> bool:
    if name.is_empty():
        return false
    
    device_name = name
    _save_device_identity()
    return true

func toggle_online_storage() -> bool:
    online_storage_enabled = !online_storage_enabled
    
    if online_storage_enabled:
        _check_cloud_connections()
    
    return online_storage_enabled

func toggle_multi_device_sync() -> bool:
    multi_device_sync = !multi_device_sync
    return multi_device_sync

func export_memories(target_path: String, format: String = "json") -> bool:
    if not DirAccess.dir_exists_absolute(target_path):
        return false
    
    match format:
        "json":
            # Export as single JSON file
            var export_data = {
                "memories": local_memories,
                "wishes": wish_collection,
                "connections": memory_connections,
                "device_info": {
                    "device_id": device_id,
                    "device_name": device_name,
                    "exported_at": Time.get_datetime_string_from_system()
                }
            }
            
            var file_path = target_path + "/memories_export_" + Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_") + ".json"
            var file = FileAccess.open(file_path, FileAccess.WRITE)
            
            if file:
                var json_string = JSON.stringify(export_data, "  ")
                file.store_string(json_string)
                file.close()
                return true
        
        # Could add other formats like CSV, XML, etc.
    
    return false

func import_memories(source_path: String) -> Dictionary:
    if not FileAccess.file_exists(source_path):
        return {"success": false, "error": "File not found"}
    
    var file = FileAccess.open(source_path, FileAccess.READ)
    if not file:
        return {"success": false, "error": "Could not open file"}
    
    var json = JSON.new()
    var error = json.parse(file.get_as_text())
    
    if error != OK:
        file.close()
        return {"success": false, "error": "Invalid JSON format"}
    
    var data = json.data
    file.close()
    
    # Validate import data
    if not data.has("memories") or not data.has("wishes") or not data.has("connections"):
        return {"success": false, "error": "Invalid memory export format"}
    
    # Import memories
    var imported_count = 0
    
    for memory_id in data.memories:
        var memory = data.memories[memory_id]
        
        # Skip if we already have this memory
        if local_memories.has(memory_id):
            continue
        
        # Add to local memories
        local_memories[memory_id] = memory
        
        # Save to file
        _save_memory_to_file(memory)
        
        imported_count += 1
    
    # Import wishes
    var imported_wishes = 0
    
    for wish in data.wishes:
        # Check if we already have this wish
        var exists = false
        for existing_wish in wish_collection:
            if existing_wish.id == wish.id:
                exists = true
                break
        
        if not exists:
            wish_collection.append(wish)
            imported_wishes += 1
    
    # Ensure we don't exceed max wishes
    if wish_collection.size() > max_stored_wishes:
        wish_collection = wish_collection.slice(wish_collection.size() - max_stored_wishes, wish_collection.size())
    
    # Save wishes
    _save_wishes()
    
    # Import connections
    var imported_connections = 0
    
    for connection_key in data.connections:
        if not memory_connections.has(connection_key):
            memory_connections[connection_key] = data.connections[connection_key]
            imported_connections += 1
    
    # Save connections
    _save_connection_map()
    
    return {
        "success": true,
        "imported_memories": imported_count,
        "imported_wishes": imported_wishes,
        "imported_connections": imported_connections
    }
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/integrated_memory_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/integrated_system_launcher.gd
# SIZE: 6212 bytes
extends Node

# Integrated System Launcher
# This script connects all components and launches the integrated system

# System components
var akashic_bridge = null
var storage_system = null
var terminal_interface = null

# Configuration
var config = {
	"auto_initialize": true,
	"default_interface": "terminal", # terminal, notepad3d, browser
	"debug_mode": false,
	"starting_turn": 1,
	"max_wish_tokens": 10000,
	"show_welcome": true
}

# Signal for system ready
signal system_ready
signal interface_ready(interface_name)

func _ready():
	# Initialize the integrated system
	if config.auto_initialize:
		initialize_system()

func initialize_system():
	print("Initializing Integrated System...")
	
	# Ensure proper initialization order
	initialize_akashic_bridge()
	initialize_storage_system()
	initialize_terminal_interface()
	
	# Connect signals between components
	connect_signals()
	
	# Set initial interface
	set_interface(config.default_interface)
	
	# Show welcome message
	if config.show_welcome:
		show_welcome()
	
	print("Integrated System initialized successfully")
	emit_signal("system_ready")

# Component initialization
func initialize_akashic_bridge():
	akashic_bridge = ClaudeAkashicBridge.new()
	add_child(akashic_bridge)
	print("Akashic Bridge initialized")
	
	# Set firewall level based on turn
	var firewall_level = "standard"
	if config.starting_turn > 7:
		firewall_level = "divine"
	elif config.starting_turn > 3:
		firewall_level = "enhanced"
	
	akashic_bridge.update_firewall(firewall_level, {
		"dimension_access": config.starting_turn
	})

func initialize_storage_system():
	storage_system = StorageIntegrationSystem.new()
	add_child(storage_system)
	print("Storage Integration System initialized")

func initialize_terminal_interface():
	terminal_interface = UnifiedTerminalInterface.new()
	add_child(terminal_interface)
	print("Unified Terminal Interface initialized")

# Signal connections
func connect_signals():
	# Storage System signals
	if storage_system:
		storage_system.connect("storage_connected", self, "_on_storage_connected")
		storage_system.connect("wish_created", self, "_on_wish_created")
		storage_system.connect("wish_completed", self, "_on_wish_completed")
	
	# Akashic Bridge signals
	if akashic_bridge:
		akashic_bridge.connect("word_stored", self, "_on_word_stored")
		akashic_bridge.connect("gate_status_changed", self, "_on_gate_status_changed")
		akashic_bridge.connect("wish_updated", self, "_on_wish_updated")
		akashic_bridge.connect("firewall_breached", self, "_on_firewall_breached")
	
	# Terminal Interface signals
	if terminal_interface:
		terminal_interface.connect("command_executed", self, "_on_command_executed")
		terminal_interface.connect("wish_processed", self, "_on_wish_processed")
		terminal_interface.connect("interface_changed", self, "_on_interface_changed")
		terminal_interface.connect("terminal_ready", self, "_on_terminal_ready")

# Interface switching
func set_interface(interface_name):
	match interface_name:
		"terminal":
			print("Setting interface to terminal")
			# In actual implementation, this would show terminal interface
		"notepad3d":
			print("Setting interface to Notepad 3D")
			# In actual implementation, this would show 3D notepad
		"browser":
			print("Setting interface to browser")
			# In actual implementation, this would show browser interface
		_:
			print("Unknown interface: " + interface_name)
	
	emit_signal("interface_ready", interface_name)

# Welcome message
func show_welcome():
	if terminal_interface:
		# Terminal interface handles its own welcome message
		pass
	else:
		print("Welcome to the Integrated System")
		print("Current Turn: " + str(config.starting_turn))
		print("Use the terminal interface for commands")

# Process wishes
func process_wish(wish_text, priority = "normal", metadata = {}):
	if storage_system:
		var wish = storage_system.create_wish(wish_text, priority, metadata)
		
		if wish and akashic_bridge:
			# Update wish in Akashic Records
			akashic_bridge.update_wish(wish.id, "pending", {
				"text": wish_text,
				"priority": priority,
				"created": OS.get_unix_time()
			})
		
		return wish
	
	return null

# Execute terminal commands
func execute_command(command):
	if terminal_interface:
		terminal_interface.process_command(command)
	else:
		print("Terminal interface not available")

# Signal handlers
func _on_storage_connected(platform, status):
	print("Storage connected: " + platform + " - " + str(status))

func _on_wish_created(wish_id, wish_text):
	print("Wish created: " + wish_id + " - " + wish_text)

func _on_wish_completed(wish_id):
	print("Wish completed: " + wish_id)

func _on_word_stored(word, power, metadata):
	print("Word stored: " + word + " (power: " + str(power) + ")")

func _on_gate_status_changed(gate_name, status):
	print("Gate status changed: " + gate_name + " - " + str(status))

func _on_wish_updated(wish_id, new_status):
	print("Wish updated: " + wish_id + " -> " + new_status)

func _on_firewall_breached(breach_info):
	print("FIREWALL BREACH: " + breach_info.type + " - " + breach_info.message)

func _on_command_executed(command, result):
	if config.debug_mode:
		print("Command executed: " + command)

func _on_wish_processed(wish_id, result):
	print("Wish processed: " + wish_id)

func _on_interface_changed(interface_name):
	print("Interface changed to: " + interface_name)

func _on_terminal_ready():
	print("Terminal interface ready")

# Public API
func create_wish(wish_text, priority = "normal"):
	return process_wish(wish_text, priority)

func run_command(command):
	return execute_command(command)

func connect_cloud_storage(service, credentials = {}):
	if storage_system:
		return storage_system.connect_cloud_storage(service, credentials)
	return false

func get_system_status():
	var status = {
		"akashic_bridge": akashic_bridge != null,
		"storage_system": storage_system != null,
		"terminal_interface": terminal_interface != null,
		"current_turn": config.starting_turn
	}
	
	# Add storage status if available
	if storage_system:
		status["storage"] = storage_system.get_storage_status()
	
	# Add akashic status if available
	if akashic_bridge:
		status["akashic"] = akashic_bridge.get_status()
	
	return status
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/integrated_system_launcher.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/integrated_terminal.gd
# SIZE: 24438 bytes
extends Node

# Integrated Terminal System
# Combines all terminal subsystems:
# - Terminal Memory System
# - Concurrent Processor
# - Drive Connector
# - Terminal Symbols

# For the bottom terminal evolution with enhanced command support

class_name IntegratedTerminal

# Terminal UI elements
var terminal: RichTextLabel
var input_field: LineEdit
var terminal_container: Control

# Terminal systems
var memory_system
var concurrent_processor
var drive_connector
var symbol_system

# Terminal properties
var terminal_width = 80
var terminal_height = 24
var command_history = []
var command_index = -1
var terminal_colors = {
	"default": Color(0.9, 0.9, 0.9),
	"past": Color(0.6, 0.6, 0.9),
	"present": Color(0.9, 0.9, 0.9),
	"future": Color(0.9, 0.6, 0.6),
	"sad": Color(0.5, 0.5, 0.7),
	"system": Color(0.7, 0.9, 0.7),
	"error": Color(1.0, 0.5, 0.5),
	"command": Color(0.9, 0.9, 0.6)
}

# Current turn tracking
var current_turn = 1
var max_turns = 12
var turn_auto_advance = false

# Signal for turns
signal turn_changed(turn_number)
signal turns_completed()

func _ready():
	# Initialize the UI elements
	setup_terminal_ui()
	
	# Initialize subsystems
	initialize_subsystems()
	
	# Connect signals
	connect_signals()
	
	# Welcome message
	add_text("Integrated Terminal System v1.0", "system")
	add_text("Type #help for available commands", "system")
	add_text("Current turn: " + str(current_turn) + "/" + str(max_turns), "system")
	
	# Show command prompt
	show_prompt()

# Set up the terminal UI
func setup_terminal_ui():
	terminal_container = Control.new()
	terminal_container.rect_min_size = Vector2(800, 500)
	add_child(terminal_container)
	
	terminal = RichTextLabel.new()
	terminal.rect_min_size = Vector2(800, 470)
	terminal.bbcode_enabled = true
	terminal.scroll_following = true
	terminal_container.add_child(terminal)
	
	input_field = LineEdit.new()
	input_field.rect_min_size = Vector2(800, 30)
	input_field.rect_position = Vector2(0, 470)
	input_field.connect("text_entered", self, "_on_text_entered")
	terminal_container.add_child(input_field)
	
	# Set focus to input field
	input_field.grab_focus()

# Initialize all subsystems
func initialize_subsystems():
	# Initialize Memory System
	memory_system = load("res://12_turns_system/terminal_memory_system.gd").new()
	add_child(memory_system)
	
	# Get reference to Concurrent Processor
	concurrent_processor = memory_system.processor
	
	# Initialize Drive Connector
	drive_connector = load("res://12_turns_system/drive_connector.gd").new()
	add_child(drive_connector)
	
	# Initialize Symbol System
	symbol_system = load("res://12_turns_system/terminal_symbols.gd").new()
	add_child(symbol_system)
	
	# Connect systems
	drive_connector.terminal_memory = memory_system
	symbol_system.terminal_memory = memory_system

# Connect signals
func connect_signals():
	# Connect to internal signals
	connect("turn_changed", self, "_on_turn_changed")
	connect("turns_completed", self, "_on_turns_completed")
	
	# Connect to memory system signals if needed
	
	# Connect to drive connector signals
	drive_connector.connect("drive_connected", self, "_on_drive_connected")
	drive_connector.connect("drive_disconnected", self, "_on_drive_disconnected")
	drive_connector.connect("sync_completed", self, "_on_sync_completed")
	drive_connector.connect("sync_failed", self, "_on_sync_failed")

# Process text input
func _on_text_entered(text):
	if text.empty():
		show_prompt()
		return
	
	# Add to command history
	command_history.append(text)
	command_index = -1
	
	# Display the command
	add_text("> " + text, "command")
	
	# Clear input field
	input_field.text = ""
	
	# Process the command
	process_command(text)
	
	# Show prompt
	show_prompt()

# Show command prompt
func show_prompt():
	# You could customize this with current turn, etc.
	input_field.placeholder_text = "[" + str(current_turn) + "/" + str(max_turns) + "] > "
	input_field.grab_focus()

# Add text to terminal with formatting
func add_text(text, category="default"):
	var color = terminal_colors.default
	
	if category in terminal_colors:
		color = terminal_colors[category]
	
	# Apply auto-wrapping if needed
	var wrapped_text = auto_wrap_text(text, terminal_width)
	
	# Process symbols if it's a system or command message
	if category in ["system", "command"]:
		wrapped_text = symbol_system.format_message(wrapped_text)
	
	# Add to terminal
	terminal.append_bbcode("[color=#" + color.to_html() + "]" + wrapped_text + "[/color]\n")
	
	# Also add to memory system
	memory_system.add_memory_text(text, category)

# Auto-wrap text to fit terminal width
func auto_wrap_text(text, width):
	var wrapped = ""
	var line = ""
	var words = text.split(" ")
	
	for word in words:
		if line.length() + word.length() + 1 <= width:
			if line.empty():
				line = word
			else:
				line += " " + word
		else:
			wrapped += line + "\n"
			line = word
	
	if not line.empty():
		wrapped += line
		
	return wrapped

# Process a command
func process_command(command):
	# Check for empty command
	if command.empty():
		return
	
	# Normalize command text
	command = command.strip_edges()
	
	# Check for special command prefixes
	if command.begins_with("#"):
		# Check for system level commands
		if command.begins_with("###"):
			process_system_command(command.substr(3).strip_edges())
		# Check for advanced commands
		elif command.begins_with("##"):
			process_advanced_command(command.substr(2).strip_edges())
		# Regular commands
		else:
			process_basic_command(command.substr(1).strip_edges())
	else:
		# Regular text input - treat as memory entry
		process_text_input(command)
	
	# Always check for turn advancement after processing a command
	check_turn_advancement()

# Process basic # commands
func process_basic_command(command):
	var parts = command.split(" ", true, 1)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"help":
			display_help()
		"turn":
			process_turn_command(args)
		"memory", "mem":
			memory_system.process_command("#" + args)
		"drive", "drives":
			drive_connector.process_command("#" + args)
		"symbol", "symbols":
			symbol_system.process_command("#" + args)
		"run":
			memory_system.process_command("#" + args)
		"chain":
			memory_system.process_command("#" + args)
		"clear":
			clear_terminal()
		"exit", "quit":
			add_text("Terminal session cannot be terminated in this mode.", "error")
		_:
			# Check if it's a command for one of our subsystems
			if memory_system.process_command("#" + command) or \
			   drive_connector.process_command("#" + command) or \
			   symbol_system.process_command("#" + command):
				pass
			else:
				add_text("Unknown command: " + cmd, "error")

# Process advanced ## commands
func process_advanced_command(command):
	var parts = command.split(" ", true, 1)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"help":
			display_advanced_help()
		"turn":
			process_advanced_turn_command(args)
		"memory", "mem":
			memory_system.process_command("##" + args)
		"drive", "drives":
			drive_connector.process_command("##" + args)
		"symbol", "symbols":
			symbol_system.process_command("##" + args)
		"color", "colors":
			set_terminal_colors(args)
		"dimensions":
			display_dimensions()
		_:
			# Check if it's a command for one of our subsystems
			if memory_system.process_command("##" + command) or \
			   drive_connector.process_command("##" + command) or \
			   symbol_system.process_command("##" + command):
				pass
			else:
				add_text("Unknown advanced command: " + cmd, "error")

# Process system ### commands
func process_system_command(command):
	var parts = command.split(" ", true, 1)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"help":
			display_system_help()
		"turn":
			process_system_turn_command(args)
		"memory", "mem":
			memory_system.process_command("###" + args)
		"drive", "drives":
			drive_connector.process_command("###" + args)
		"symbol", "symbols":
			symbol_system.process_command("###" + args)
		"reset":
			reset_terminal()
		"concurrent":
			set_concurrent_tasks(args)
		"export":
			export_terminal_state(args)
		"import":
			import_terminal_state(args)
		"evolution":
			evolve_terminal(args)
		_:
			# Check if it's a command for one of our subsystems
			if memory_system.process_command("###" + command) or \
			   drive_connector.process_command("###" + command) or \
			   symbol_system.process_command("###" + command):
				pass
			else:
				add_text("Unknown system command: " + cmd, "error")

# Process regular text input
func process_text_input(text):
	# Check for TDIC temporal markers
	if text.begins_with("[past]") or text.begins_with("[present]") or text.begins_with("[future]"):
		memory_system.process_tdic_entry(text)
	else:
		memory_system.add_memory_text(text)

# Turn management commands
func process_turn_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		add_text("Current turn: " + str(current_turn) + "/" + str(max_turns), "system")
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"next", "advance":
			advance_turn()
		"auto":
			toggle_auto_advance(subargs)
		"set":
			set_turn(subargs)
		"max":
			set_max_turns(subargs)
		"reset":
			reset_turns()
		"status":
			display_turn_status()
		_:
			add_text("Unknown turn command: " + subcmd, "error")

# Advanced turn commands
func process_advanced_turn_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		add_text("Current turn: " + str(current_turn) + "/" + str(max_turns), "system")
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"skip":
			skip_turns(subargs)
		"interval":
			set_auto_interval(subargs)
		"save":
			save_turn_state(subargs)
		"load":
			load_turn_state(subargs)
		_:
			add_text("Unknown advanced turn command: " + subcmd, "error")

# System turn commands
func process_system_turn_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		add_text("Current turn: " + str(current_turn) + "/" + str(max_turns), "system")
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"cycle":
			restart_turn_cycle()
		"export":
			export_turn_data(subargs)
		"import":
			import_turn_data(subargs)
		_:
			add_text("Unknown system turn command: " + subcmd, "error")

# Advance to next turn
func advance_turn():
	if current_turn < max_turns:
		current_turn += 1
		add_text("Advanced to turn " + str(current_turn) + "/" + str(max_turns), "system")
		emit_signal("turn_changed", current_turn)
		
		# Save state automatically
		save_turn_state("auto_" + str(current_turn))
	else:
		add_text("Maximum turns reached (" + str(max_turns) + ").", "system")
		emit_signal("turns_completed")

# Toggle auto turn advancement
func toggle_auto_advance(enabled=""):
	if enabled.empty():
		turn_auto_advance = !turn_auto_advance
	else:
		turn_auto_advance = (enabled.to_lower() == "on" or enabled.to_lower() == "true")
	
	add_text("Auto turn advancement: " + ("ON" if turn_auto_advance else "OFF"), "system")

# Set current turn
func set_turn(turn_number):
	var new_turn = int(turn_number)
	
	if new_turn >= 1 and new_turn <= max_turns:
		current_turn = new_turn
		add_text("Set current turn to: " + str(current_turn) + "/" + str(max_turns), "system")
		emit_signal("turn_changed", current_turn)
	else:
		add_text("Invalid turn number. Must be between 1 and " + str(max_turns) + ".", "error")

# Set maximum turns
func set_max_turns(max_turn_count):
	var new_max = int(max_turn_count)
	
	if new_max >= current_turn and new_max > 0:
		max_turns = new_max
		add_text("Set maximum turns to: " + str(max_turns), "system")
	else:
		add_text("Invalid maximum turn count. Must be at least " + str(current_turn) + ".", "error")

# Reset turn counter
func reset_turns():
	current_turn = 1
	add_text("Turn counter reset to 1/" + str(max_turns), "system")
	emit_signal("turn_changed", current_turn)

# Display turn status
func display_turn_status():
	add_text("Turn Status:", "system")
	add_text("- Current turn: " + str(current_turn) + "/" + str(max_turns), "system")
	add_text("- Auto advance: " + ("ON" if turn_auto_advance else "OFF"), "system")
	
	var progress = float(current_turn) / float(max_turns)
	var progress_bar = symbol_system.format_progress_bar(progress, 20)
	add_text("- Progress: " + progress_bar, "system")

# Skip multiple turns
func skip_turns(count):
	var skip_count = int(count)
	
	if skip_count > 0:
		var target_turn = min(current_turn + skip_count, max_turns)
		var turns_skipped = target_turn - current_turn
		
		current_turn = target_turn
		add_text("Skipped " + str(turns_skipped) + " turns. Now at turn " + str(current_turn) + "/" + str(max_turns), "system")
		emit_signal("turn_changed", current_turn)
		
		if current_turn >= max_turns:
			emit_signal("turns_completed")
	else:
		add_text("Invalid skip count. Must be positive.", "error")

# Set auto turn interval (not implemented in this mock-up)
func set_auto_interval(interval):
	add_text("Auto interval feature not implemented in this version.", "system")

# Save turn state
func save_turn_state(name):
	if name.empty():
		name = "turn_" + str(current_turn)
	
	add_text("Saving turn state: " + name, "system")
	
	# In a real implementation, this would save the current state to a file
	# For now, we'll just simulate it by adding it to memory
	memory_system.add_memory_text("[Turn Save] Turn " + str(current_turn) + " state saved as '" + name + "'", "system")

# Load turn state
func load_turn_state(name):
	add_text("Loading turn state: " + name, "system")
	
	# In a real implementation, this would load state from a file
	# For now, we'll just simulate it
	memory_system.add_memory_text("[Turn Load] Loaded turn state '" + name + "'", "system")

# Restart turn cycle
func restart_turn_cycle():
	add_text("Restarting turn cycle...", "system")
	
	# Save current state before restart
	save_turn_state("before_restart")
	
	# Reset turns
	reset_turns()
	
	add_text("Turn cycle restarted. Beginning new 12-turn cycle.", "system")

# Export turn data
func export_turn_data(path):
	add_text("Exporting turn data to: " + path, "system")
	
	# In a real implementation, this would export data to a file
	# For now, we'll just simulate it
	add_text("Turn data exported successfully.", "system")

# Import turn data
func import_turn_data(path):
	add_text("Importing turn data from: " + path, "system")
	
	# In a real implementation, this would import data from a file
	# For now, we'll just simulate it
	add_text("Turn data imported successfully.", "system")

# Check if we should advance turns
func check_turn_advancement():
	if turn_auto_advance and current_turn < max_turns:
		# In a real implementation, this would use a timer
		# For now, we'll just simulate it with a yield
		add_text("Auto-advancing to next turn in 3 seconds...", "system")
		yield(get_tree().create_timer(3.0), "timeout")
		advance_turn()

# Color commands
func set_terminal_colors(theme):
	match theme:
		"default":
			terminal_colors.default = Color(0.9, 0.9, 0.9)
			terminal_colors.past = Color(0.6, 0.6, 0.9)
			terminal_colors.present = Color(0.9, 0.9, 0.9)
			terminal_colors.future = Color(0.9, 0.6, 0.6)
			terminal_colors.system = Color(0.7, 0.9, 0.7)
			terminal_colors.error = Color(1.0, 0.5, 0.5)
			terminal_colors.command = Color(0.9, 0.9, 0.6)
		"sad":
			# Sad colors palette
			terminal_colors.default = Color(0.5, 0.5, 0.7)
			terminal_colors.past = Color(0.4, 0.4, 0.6)
			terminal_colors.present = Color(0.5, 0.5, 0.7)
			terminal_colors.future = Color(0.6, 0.4, 0.5)
			terminal_colors.system = Color(0.4, 0.6, 0.5)
			terminal_colors.error = Color(0.7, 0.4, 0.4)
			terminal_colors.command = Color(0.6, 0.6, 0.5)
		"dark":
			# Dark theme
			terminal_colors.default = Color(0.7, 0.7, 0.7)
			terminal_colors.past = Color(0.4, 0.4, 0.7)
			terminal_colors.present = Color(0.7, 0.7, 0.7)
			terminal_colors.future = Color(0.7, 0.4, 0.4)
			terminal_colors.system = Color(0.4, 0.7, 0.4)
			terminal_colors.error = Color(0.9, 0.3, 0.3)
			terminal_colors.command = Color(0.7, 0.7, 0.4)
		"bright":
			# Bright theme
			terminal_colors.default = Color(1.0, 1.0, 1.0)
			terminal_colors.past = Color(0.7, 0.7, 1.0)
			terminal_colors.present = Color(1.0, 1.0, 1.0)
			terminal_colors.future = Color(1.0, 0.7, 0.7)
			terminal_colors.system = Color(0.7, 1.0, 0.7)
			terminal_colors.error = Color(1.0, 0.5, 0.5)
			terminal_colors.command = Color(1.0, 1.0, 0.7)
		_:
			add_text("Unknown color theme: " + theme, "error")
			return
	
	add_text("Terminal color theme changed to: " + theme, "system")

# Clear the terminal
func clear_terminal():
	terminal.clear()
	add_text("Terminal cleared.", "system")

# Reset terminal
func reset_terminal():
	terminal.clear()
	memory_system.reset_system()
	reset_turns()
	add_text("Terminal reset complete.", "system")

# Set concurrent tasks
func set_concurrent_tasks(count):
	var task_count = int(count)
	if task_count >= 1 and task_count <= 5:
		concurrent_processor.set_max_concurrent_tasks(task_count)
		add_text("Concurrent tasks set to: " + str(task_count), "system")
	else:
		add_text("Invalid concurrent task count. Must be between 1 and 5.", "error")

# Export terminal state
func export_terminal_state(path):
	add_text("Exporting terminal state to: " + path, "system")
	
	# In a real implementation, this would export data to a file
	# For now, we'll just simulate it
	add_text("Terminal state exported successfully.", "system")

# Import terminal state
func import_terminal_state(path):
	add_text("Importing terminal state from: " + path, "system")
	
	# In a real implementation, this would import data from a file
	# For now, we'll just simulate it
	add_text("Terminal state imported successfully.", "system")

# Evolve terminal (bottom evolution as requested)
func evolve_terminal(evolution_type):
	add_text("Evolving terminal: " + evolution_type, "system")
	add_text("Terminal evolution in progress...", "system")
	
	# Show fancy progress animation
	for i in range(5):
		yield(get_tree().create_timer(0.3), "timeout")
		add_text(symbol_system.generate_symbol_pattern("‚ñ™ ", 20), "system")
	
	match evolution_type:
		"bottom":
			add_text("Terminal bottom evolution complete!", "system")
			add_text("Added 4 more lines down for expanded view.", "system")
			terminal.rect_min_size.y += 100
			input_field.rect_position.y += 100
		"split":
			add_text("Terminal split evolution complete!", "system")
			add_text("Terminal now supports split screen mode.", "system")
		"emoji":
			add_text("Terminal emoji evolution complete!", "system")
			add_text("Enhanced emoji support with Pok√©mon themes! " + symbol_system.get_symbol("pikachu", "pokemon"), "system")
		"crooked":
			add_text("Terminal crooked evolution complete!", "system")
			add_text("Special <> crooked symbols mode enabled.", "system")
		_:
			add_text("Unknown evolution type: " + evolution_type, "error")
			return
	
	add_text("Terminal has evolved to its next form!", "system")

# Display dimensions
func display_dimensions():
	var dimensions = [
		{"name": "Physical", "symbol": symbol_system.get_symbol("physical", "dimensions"), "desc": "The tangible world of matter"},
		{"name": "Digital", "symbol": symbol_system.get_symbol("digital", "dimensions"), "desc": "The realm of data and information"},
		{"name": "Temporal", "symbol": symbol_system.get_symbol("temporal", "dimensions"), "desc": "The flow of time and memory"},
		{"name": "Conceptual", "symbol": symbol_system.get_symbol("conceptual", "dimensions"), "desc": "The space of ideas and abstractions"},
		{"name": "Quantum", "symbol": symbol_system.get_symbol("quantum", "dimensions"), "desc": "The underlying fabric of possibilities"}
	]
	
	add_text(symbol_system.format_header("Dimensional Analysis", 60), "system")
	
	for dim in dimensions:
		add_text(dim.symbol + " " + dim.name + " Dimension", "system")
		add_text("   - " + dim.desc, "system")
	
	add_text(symbol_system.generate_symbol_pattern("‚îÄ", 60), "system")

# Display help
func display_help():
	add_text(symbol_system.format_header("Terminal Help", 60), "system")
	add_text("Basic Commands:", "system")
	add_text("  #help - Display this help", "system")
	add_text("  #turn [next|auto|set|max|reset|status] - Manage turns", "system")
	add_text("  #memory/#mem [command] - Memory system commands", "system")
	add_text("  #drive/#drives [command] - Drive connector commands", "system")
	add_text("  #symbol/#symbols [command] - Symbol system commands", "system")
	add_text("  #run [func1,func2,func3] - Run multiple functions in parallel", "system")
	add_text("  #chain [func1,func2,func3] - Run functions in sequence", "system")
	add_text("  #clear - Clear terminal display", "system")
	add_text("", "system")
	add_text("For advanced commands, type ##help", "system")
	add_text("For system commands, type ###help", "system")
	add_text("", "system")
	add_text("TDIC Temporal Markers:", "system")
	add_text("  [past] Text... - Mark entry as past memory", "system")
	add_text("  [present] Text... - Mark entry as present memory", "system")
	add_text("  [future] Text... - Mark entry as future memory", "system")

# Display advanced help
func display_advanced_help():
	add_text(symbol_system.format_header("Advanced Commands", 60), "system")
	add_text("Advanced Commands (##):", "system")
	add_text("  ##help - Display this help", "system")
	add_text("  ##turn [skip|interval|save|load] - Advanced turn management", "system")
	add_text("  ##memory/##mem [command] - Advanced memory commands", "system")
	add_text("  ##drive/##drives [command] - Advanced drive commands", "system")
	add_text("  ##symbol/##symbols [command] - Advanced symbol commands", "system")
	add_text("  ##color/##colors [theme] - Set terminal color theme", "system")
	add_text("  ##dimensions - Display information about dimensions", "system")

# Display system help
func display_system_help():
	add_text(symbol_system.format_header("System Commands", 60), "system")
	add_text("System Commands (###):", "system")
	add_text("  ###help - Display this help", "system")
	add_text("  ###turn [cycle|export|import] - System turn management", "system")
	add_text("  ###memory/###mem [command] - System memory commands", "system")
	add_text("  ###drive/###drives [command] - System drive commands", "system")
	add_text("  ###symbol/###symbols [command] - System symbol commands", "system")
	add_text("  ###reset - Reset the terminal", "system")
	add_text("  ###concurrent [count] - Set concurrent task count (1-5)", "system")
	add_text("  ###export [path] - Export terminal state", "system")
	add_text("  ###import [path] - Import terminal state", "system")
	add_text("  ###evolution [type] - Evolve the terminal", "system")

# Signal handlers
func _on_turn_changed(turn_number):
	# This is called when the turn changes
	# You could add custom logic here
	pass

func _on_turns_completed():
	add_text("All 12 turns completed. The cycle is finished.", "system")
	add_text("Take a break for reflection before starting a new cycle.", "system")

func _on_drive_connected(drive_name):
	add_text("Drive connected: " + drive_name, "system")

func _on_drive_disconnected(drive_name):
	add_text("Drive disconnected: " + drive_name, "system")

func _on_sync_completed(drive_name):
	add_text("Drive sync completed: " + drive_name, "system")

func _on_sync_failed(drive_name, error):
	add_text("Drive sync failed: " + drive_name + " (" + error + ")", "error")

# Input handling for command history
func _input(event):
	if event is InputEventKey and event.pressed:
		match event.scancode:
			KEY_UP:
				navigate_history_up()
			KEY_DOWN:
				navigate_history_down()

# Navigate command history upward
func navigate_history_up():
	if command_history.size() > 0:
		if command_index < command_history.size() - 1:
			command_index += 1
			input_field.text = command_history[command_history.size() - 1 - command_index]
			input_field.caret_position = input_field.text.length()

# Navigate command history downward
func navigate_history_down():
	if command_index > 0:
		command_index -= 1
		input_field.text = command_history[command_history.size() - 1 - command_index]
		input_field.caret_position = input_field.text.length()
	elif command_index == 0:
		command_index = -1
		input_field.text = ""
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/integrated_terminal.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/interdimensional_scheming.gd
# SIZE: 36838 bytes
extends Node

# Interdimensional Scheming System
# Implements covert operations and strategy across the 12 dimensions
# Terminal 4: Interdimensional Strategy Core

class_name InterdimensionalSchemingSystem

# ----- SCHEME TYPES -----
enum SchemeType {
	ALLIANCE,       # Form alliances with other players
	DECEPTION,      # Hide true intentions behind linguistic misdirection
	ASCENSION,      # Accelerate dimensional ascension
	MANIFOLD,       # Operate multiple simultaneous plans
	DIVINE          # Curry favor with the Queen
}

# ----- SCHEME CATEGORIES -----
enum SchemeCategory {
	OFFENSIVE,      # Targets other players negatively
	DEFENSIVE,      # Protects from other schemes
	DIPLOMATIC,     # Creates relationships between players
	ASCENDANT,      # Advances dimensional progress
	ROYAL           # Interacts with the divine court
}

# ----- DIMENSION-SPECIFIC SCHEME MODIFIERS -----
var dimension_modifiers = {
	1: {
		"name": "Linear Plotting",
		"detection_difficulty": 1.0,
		"power_modifier": 0.8,
		"preferred_scheme": SchemeType.ALLIANCE,
		"description": "Simple, straightforward schemes with clear objectives"
	},
	2: {
		"name": "Mirror Deception",
		"detection_difficulty": 1.2,
		"power_modifier": 0.9,
		"preferred_scheme": SchemeType.DECEPTION,
		"description": "Schemes that appear to be their opposite, masking true intentions"
	},
	3: {
		"name": "Spatial Maneuvering",
		"detection_difficulty": 1.3,
		"power_modifier": 1.0,
		"preferred_scheme": SchemeType.ALLIANCE,
		"description": "Schemes that leverage position and physical manifestation"
	},
	4: {
		"name": "Temporal Plotting",
		"detection_difficulty": 1.5,
		"power_modifier": 1.2,
		"preferred_scheme": SchemeType.MANIFOLD,
		"description": "Schemes that play out over time with delayed effects"
	},
	5: {
		"name": "Quantum Scheming",
		"detection_difficulty": 2.0,
		"power_modifier": 1.5,
		"preferred_scheme": SchemeType.DECEPTION,
		"description": "Probability-based schemes with multiple possible outcomes"
	},
	6: {
		"name": "Resonant Intrigue",
		"detection_difficulty": 1.8,
		"power_modifier": 1.4,
		"preferred_scheme": SchemeType.ALLIANCE,
		"description": "Schemes that create repeating patterns of influence"
	},
	7: {
		"name": "Dream Manipulation",
		"detection_difficulty": 2.5,
		"power_modifier": 1.8,
		"preferred_scheme": SchemeType.DECEPTION,
		"description": "Schemes that operate in the dream realm to influence reality"
	},
	8: {
		"name": "Network Conspiracy",
		"detection_difficulty": 2.2,
		"power_modifier": 1.6,
		"preferred_scheme": SchemeType.MANIFOLD,
		"description": "Schemes that operate through interconnected relationships"
	},
	9: {
		"name": "Judgment Subversion",
		"detection_difficulty": 2.0,
		"power_modifier": 2.0,
		"preferred_scheme": SchemeType.ALLIANCE,
		"description": "Schemes that manipulate or evade word judgment"
	},
	10: {
		"name": "Harmonic Orchestration",
		"detection_difficulty": 1.9,
		"power_modifier": 2.2,
		"preferred_scheme": SchemeType.DIVINE,
		"description": "Perfectly balanced schemes with multiple aligned components"
	},
	11: {
		"name": "Meta-Scheming",
		"detection_difficulty": 2.8,
		"power_modifier": 2.5,
		"preferred_scheme": SchemeType.ASCENSION,
		"description": "Self-aware schemes that adapt to counter-schemes"
	},
	12: {
		"name": "Divine Machination",
		"detection_difficulty": 3.0,
		"power_modifier": 3.0,
		"preferred_scheme": SchemeType.DIVINE,
		"description": "Transcendent schemes that alter reality itself"
	}
}

# ----- ACTIVE SCHEMES -----
var active_schemes = {}
var player_schemes = {}
var scheme_targets = {}
var scheme_alliances = {}
var scheme_counters = {}
var scheme_discoveries = {}

# ----- PATTERN RECOGNITION -----
var word_patterns = {}
var suspicious_patterns = []
var scheme_keywords = {
	SchemeType.ALLIANCE: ["ally", "friend", "together", "unite", "alliance", "pact", "covenant", "bond"],
	SchemeType.DECEPTION: ["deceive", "mask", "hide", "false", "trick", "illusion", "disguise", "veil"],
	SchemeType.ASCENSION: ["rise", "ascend", "elevate", "higher", "transcend", "climb", "advance", "uplift"],
	SchemeType.MANIFOLD: ["many", "multiple", "diverse", "varied", "complex", "multitude", "several", "fold"],
	SchemeType.DIVINE: ["divine", "royal", "queen", "blessing", "crown", "throne", "majesty", "court"]
}

# ----- SYSTEM REFERENCES -----
var turn_system = null
var divine_word_processor = null
var word_comment_system = null
var word_salem_controller = null
var word_crimes_analysis = null
var word_dream_storage = null
var royal_blessing_system = null

# ----- SIGNALS -----
signal scheme_created(scheme_id, creator, scheme_type)
signal scheme_discovered(scheme_id, discoverer)
signal scheme_activated(scheme_id)
signal scheme_completed(scheme_id, success)
signal alliance_formed(player1, player2, scheme_id)
signal counter_scheme_created(original_scheme_id, counter_scheme_id)

func _ready():
	connect_systems()
	initialize_pattern_recognition()

func connect_systems():
	# Connect to turn system
	turn_system = get_node_or_null("/root/TurnSystem")
	if turn_system:
		turn_system.connect("turn_completed", self, "_on_turn_completed")
		turn_system.connect("dimension_changed", self, "_on_dimension_changed")
	
	# Connect to divine word processor
	divine_word_processor = get_node_or_null("/root/DivineWordProcessor")
	if divine_word_processor:
		divine_word_processor.connect("word_processed", self, "_on_word_processed")
	
	# Connect to word comment system
	word_comment_system = get_node_or_null("/root/WordCommentSystem")
	
	# Connect to word salem controller
	word_salem_controller = get_node_or_null("/root/WordSalemGameController")
	
	# Connect to word crimes analysis
	word_crimes_analysis = get_node_or_null("/root/WordCrimesAnalysis")
	
	# Connect to word dream storage
	word_dream_storage = get_node_or_null("/root/WordDreamStorage")
	
	# Connect to royal blessing system
	royal_blessing_system = get_node_or_null("/root/RoyalBlessingSystem")

func initialize_pattern_recognition():
	# Initialize suspicious patterns for scheme detection
	suspicious_patterns = [
		"(alliance|pact|treaty)\\s+(with|between)\\s+[a-zA-Z]+", # Alliance patterns
		"(deceive|trick|fool)\\s+[a-zA-Z]+", # Deception patterns
		"(ascend|rise)\\s+(to|through)\\s+dimension", # Ascension patterns
		"(multiple|many|several)\\s+(plans|schemes|operations)", # Manifold patterns
		"(divine|royal|queen)\\s+(favor|blessing|court)" # Divine patterns
	]

# ----- SCHEME CREATION AND MANAGEMENT -----

func create_scheme(creator, scheme_type, targets=[], description="", duration=5):
	# Get current dimension
	var current_dimension = turn_system.current_dimension if turn_system else 1
	
	# Generate scheme ID
	var scheme_id = "scheme_" + creator + "_" + str(OS.get_unix_time()) + "_" + str(randi() % 1000)
	
	# Calculate scheme power
	var base_power = 10.0
	var dimension_modifier = dimension_modifiers[current_dimension].power_modifier
	var preferred_modifier = 1.0
	
	if dimension_modifiers[current_dimension].preferred_scheme == scheme_type:
		preferred_modifier = 1.5
	
	var total_power = base_power * dimension_modifier * preferred_modifier
	
	# Determine detection difficulty
	var detection_difficulty = dimension_modifiers[current_dimension].detection_difficulty
	
	# Create scheme data
	var scheme_data = {
		"id": scheme_id,
		"creator": creator,
		"type": scheme_type,
		"type_name": SchemeType.keys()[scheme_type],
		"targets": targets,
		"description": description,
		"created_dimension": current_dimension,
		"created_turn": turn_system.current_turn if turn_system else 0,
		"expiry_turn": (turn_system.current_turn if turn_system else 0) + duration,
		"power": total_power,
		"detection_difficulty": detection_difficulty,
		"activated": false,
		"discovered_by": [],
		"counter_schemes": [],
		"success_probability": 0.7, # Base probability
		"active_in_dimensions": [current_dimension],
		"is_counter_scheme": false,
		"original_scheme": "",
		"timestamp": OS.get_unix_time()
	}
	
	# Store in active schemes
	active_schemes[scheme_id] = scheme_data
	
	# Track schemes by player
	if not player_schemes.has(creator):
		player_schemes[creator] = []
	player_schemes[creator].append(scheme_id)
	
	# Track schemes by target
	for target in targets:
		if not scheme_targets.has(target):
			scheme_targets[target] = []
		scheme_targets[target].append(scheme_id)
	
	# Emit signal
	emit_signal("scheme_created", scheme_id, creator, scheme_type)
	
	# Create hidden comment
	if word_comment_system:
		var comment_text = "SCHEME CREATED: " + SchemeType.keys()[scheme_type] + " scheme in dimension " + str(current_dimension)
		if description:
			comment_text += " - " + description
		
		word_comment_system.add_comment("scheme_" + scheme_id, comment_text, word_comment_system.CommentType.OBSERVATION)
	
	return scheme_data

func activate_scheme(scheme_id):
	if not active_schemes.has(scheme_id):
		return {
			"success": false,
			"message": "Scheme not found: " + scheme_id
		}
	
	var scheme = active_schemes[scheme_id]
	
	if scheme.activated:
		return {
			"success": false,
			"message": "Scheme already activated"
		}
	
	# Mark as activated
	scheme.activated = true
	
	# Calculate success probability based on counter-schemes
	var counter_scheme_penalty = 0.0
	for counter_id in scheme.counter_schemes:
		if active_schemes.has(counter_id):
			var counter = active_schemes[counter_id]
			counter_scheme_penalty += counter.power / 100.0
	
	scheme.success_probability = max(0.1, scheme.success_probability - counter_scheme_penalty)
	
	# Apply scheme effects
	var effect_result = apply_scheme_effects(scheme)
	
	# Emit signal
	emit_signal("scheme_activated", scheme_id)
	
	# Create comment
	if word_comment_system:
		var comment_text = "SCHEME ACTIVATED: " + scheme.creator + "'s " + scheme.type_name + " scheme"
		if scheme.description:
			comment_text += " - " + scheme.description
		
		word_comment_system.add_comment("scheme_" + scheme_id, comment_text, word_comment_system.CommentType.OBSERVATION)
	
	return {
		"success": true,
		"message": "Scheme activated successfully",
		"effect_result": effect_result
	}

func apply_scheme_effects(scheme):
	var results = []
	
	# Apply effects based on scheme type
	match scheme.type:
		SchemeType.ALLIANCE:
			results = apply_alliance_scheme(scheme)
			
		SchemeType.DECEPTION:
			results = apply_deception_scheme(scheme)
			
		SchemeType.ASCENSION:
			results = apply_ascension_scheme(scheme)
			
		SchemeType.MANIFOLD:
			results = apply_manifold_scheme(scheme)
			
		SchemeType.DIVINE:
			results = apply_divine_scheme(scheme)
	
	return results

func apply_alliance_scheme(scheme):
	var results = []
	
	# Form alliances between creator and targets
	for target in scheme.targets:
		# Create alliance entry
		var alliance_id = "alliance_" + scheme.creator + "_" + target + "_" + str(OS.get_unix_time())
		
		var alliance_data = {
			"id": alliance_id,
			"scheme_id": scheme.id,
			"player1": scheme.creator,
			"player2": target,
			"formed_dimension": scheme.created_dimension,
			"formed_turn": turn_system.current_turn if turn_system else 0,
			"power": scheme.power,
			"timestamp": OS.get_unix_time()
		}
		
		# Store alliance
		if not scheme_alliances.has(scheme.creator):
			scheme_alliances[scheme.creator] = {}
		
		if not scheme_alliances.has(target):
			scheme_alliances[target] = {}
		
		scheme_alliances[scheme.creator][target] = alliance_data
		scheme_alliances[target][scheme.creator] = alliance_data
		
		# Emit signal
		emit_signal("alliance_formed", scheme.creator, target, scheme.id)
		
		# Create comment
		if word_comment_system:
			var comment_text = "ALLIANCE FORMED: " + scheme.creator + " and " + target + " have formed an alliance"
			word_comment_system.add_comment("alliance_" + alliance_id, comment_text, word_comment_system.CommentType.OBSERVATION)
		
		results.append({
			"type": "alliance_formed",
			"player1": scheme.creator,
			"player2": target,
			"alliance_id": alliance_id
		})
		
		# Apply alliance benefits
		if divine_word_processor:
			# Words spoken by allies gain a power boost when used together
			divine_word_processor.add_word_relationship(scheme.creator, target, "alliance", scheme.power / 100.0)
	
	return results

func apply_deception_scheme(scheme):
	var results = []
	
	for target in scheme.targets:
		# Deception schemes make targets misidentify word meanings
		if word_comment_system:
			var comment_text = "DECEPTION ACTIVE: " + target + " is now subject to linguistic misdirection"
			word_comment_system.add_comment("deception_" + scheme.id, comment_text, word_comment_system.CommentType.OBSERVATION)
		
		# Apply deception effects
		if word_salem_controller:
			# In Salem game, this affects investigations
			word_salem_controller.apply_deception_effect(target, scheme.power / 100.0, scheme.expiry_turn)
		
		results.append({
			"type": "deception_applied",
			"target": target,
			"power": scheme.power,
			"duration": scheme.expiry_turn - (turn_system.current_turn if turn_system else 0)
		})
	
	return results

func apply_ascension_scheme(scheme):
	var results = []
	
	# Ascension schemes accelerate dimension progression
	var current_dimension = turn_system.current_dimension if turn_system else 1
	var target_dimension = min(12, current_dimension + 1)
	
	# Create a transition probability based on scheme power
	var transition_probability = scheme.power / 100.0
	
	if randf() < transition_probability:
		# Success - will transition on next turn
		if turn_system:
			turn_system.queue_dimension_change(target_dimension)
			
			var comment_text = "ASCENSION IMMINENT: Transition to Dimension " + str(target_dimension) + " has been accelerated"
			word_comment_system.add_comment("ascension_" + scheme.id, comment_text, word_comment_system.CommentType.DIVINE)
			
			results.append({
				"type": "ascension_success",
				"current_dimension": current_dimension,
				"target_dimension": target_dimension,
				"next_turn": (turn_system.current_turn if turn_system else 0) + 1
			})
	else:
		# Failure - no immediate transition
		var comment_text = "ASCENSION FAILED: The attempt to accelerate dimensional transition was unsuccessful"
		word_comment_system.add_comment("ascension_" + scheme.id, comment_text, word_comment_system.CommentType.OBSERVATION)
		
		results.append({
			"type": "ascension_failed",
			"current_dimension": current_dimension
		})
	
	return results

func apply_manifold_scheme(scheme):
	var results = []
	
	# Manifold schemes operate across multiple dimensions simultaneously
	var current_dimension = turn_system.current_dimension if turn_system else 1
	
	# Determine which additional dimensions to operate in
	var additional_dimensions = []
	
	# Always add dimension 5 (probability manipulation)
	if current_dimension != 5:
		additional_dimensions.append(5)
	
	# Add dream dimension if available
	if current_dimension != 7 and scheme.created_dimension >= 7:
		additional_dimensions.append(7)
	
	# Add judgment dimension if available
	if current_dimension != 9 and scheme.created_dimension >= 9:
		additional_dimensions.append(9)
	
	# Update scheme's active dimensions
	scheme.active_in_dimensions = [current_dimension] + additional_dimensions
	
	# Apply effects in each dimension
	for dimension in additional_dimensions:
		# Record dimensional activity
		var comment_text = "MANIFOLD EXPANSION: Scheme now operates in Dimension " + str(dimension)
		word_comment_system.add_comment("manifold_" + scheme.id, comment_text, word_comment_system.CommentType.OBSERVATION)
		
		results.append({
			"type": "manifold_expansion",
			"dimension": dimension,
			"base_dimension": current_dimension
		})
		
		# Special handling for specific dimensions
		if dimension == 7 and word_dream_storage:
			# Create dream fragments for this scheme
			var dream_text = "A vision of " + scheme.creator + " operating across multiple realities simultaneously"
			word_dream_storage.store_in_divine_memory("manifold_dream_" + scheme.id, {
				"dream_text": dream_text,
				"scheme_id": scheme.id,
				"timestamp": OS.get_unix_time()
			})
	
	return results

func apply_divine_scheme(scheme):
	var results = []
	
	# Divine schemes seek to curry favor with the Queen
	if royal_blessing_system:
		// Grant royal favor based on scheme power
		var favor_amount = ceil(scheme.power / 10.0)
		
		royal_blessing_system.adjust_royal_favor(scheme.creator, favor_amount, "divine machination")
		
		var comment_text = "DIVINE FAVOR: " + scheme.creator + " has gained " + str(favor_amount) + " royal favor"
		word_comment_system.add_comment("divine_" + scheme.id, comment_text, word_comment_system.CommentType.DIVINE)
		
		results.append({
			"type": "royal_favor_increased",
			"player": scheme.creator,
			"amount": favor_amount
		})
		
		// Check for divine visions based on scheme power
		if scheme.power >= 50:
			// Create a divine vision
			var vision_id = "vision_" + scheme.id
			var vision_text = "The Queen of Time and Space acknowledges your devotion. Continue your service across all dimensions."
			
			word_comment_system.add_comment(vision_id, "DIVINE VISION: " + vision_text, word_comment_system.CommentType.DIVINE)
			
			// Store in highest memory tier
			if word_dream_storage:
				word_dream_storage.save_comment({
					"word": vision_id,
					"text": vision_text,
					"type": 4, // Divine type
					"timestamp": OS.get_unix_time()
				}, 3) // Tier 3 - D: Drive
		}
	
	return results

func create_counter_scheme(discoverer, original_scheme_id, description=""):
	if not active_schemes.has(original_scheme_id):
		return {
			"success": false,
			"message": "Original scheme not found: " + original_scheme_id
		}
	
	var original = active_schemes[original_scheme_id]
	
	// Determine counter scheme type
	var counter_type = SchemeType.DECEPTION // Default counter
	
	match original.type:
		SchemeType.ALLIANCE:
			counter_type = SchemeType.DECEPTION
		SchemeType.DECEPTION:
			counter_type = SchemeType.ALLIANCE
		SchemeType.ASCENSION:
			counter_type = SchemeType.MANIFOLD
		SchemeType.MANIFOLD:
			counter_type = SchemeType.DIVINE
		SchemeType.DIVINE:
			counter_type = SchemeType.ASCENSION
	
	// Create counter scheme
	var targets = [original.creator]
	var counter_scheme = create_scheme(discoverer, counter_type, targets, description)
	
	// Mark as counter scheme
	counter_scheme.is_counter_scheme = true
	counter_scheme.original_scheme = original_scheme_id
	
	// Add to original scheme's counters
	original.counter_schemes.append(counter_scheme.id)
	
	// Create scheme counters tracking
	if not scheme_counters.has(original_scheme_id):
		scheme_counters[original_scheme_id] = []
	scheme_counters[original_scheme_id].append(counter_scheme.id)
	
	// Emit signal
	emit_signal("counter_scheme_created", original_scheme_id, counter_scheme.id)
	
	// Create comment
	if word_comment_system:
		var comment_text = "COUNTER SCHEME: " + discoverer + " has created a " + counter_scheme.type_name + " scheme to counter " + original.creator + "'s " + original.type_name + " scheme"
		word_comment_system.add_comment("counter_" + counter_scheme.id, comment_text, word_comment_system.CommentType.OBSERVATION)
	
	return counter_scheme

# ----- SCHEME DETECTION -----

func attempt_scheme_detection(detector, target_player="", word=""):
	var detection_results = []
	var current_dimension = turn_system.current_dimension if turn_system else 1
	
	// Detection is most effective in dimensions 5, 8, and 9
	var detection_boost = 1.0
	
	if current_dimension == 5: // Probability dimension
		detection_boost = 1.5
	elif current_dimension == 8: // Interconnection dimension
		detection_boost = 2.0
	elif current_dimension == 9: // Judgment dimension
		detection_boost = 1.8
	
	// If targeting a specific player
	if target_player:
		if player_schemes.has(target_player):
			for scheme_id in player_schemes[target_player]:
				if active_schemes.has(scheme_id):
					var scheme = active_schemes[scheme_id]
					
					// Check if not already discovered by this detector
					if not detector in scheme.discovered_by:
						// Calculate detection chance
						var detection_chance = (1.0 / scheme.detection_difficulty) * detection_boost
						
						// Adjust based on word if provided
						if word and word_related_to_scheme(word, scheme):
							detection_chance *= 1.5
						
						// Detection roll
						if randf() < detection_chance:
							// Success - scheme detected
							scheme.discovered_by.append(detector)
							
							// Record discovery
							if not scheme_discoveries.has(detector):
								scheme_discoveries[detector] = []
							scheme_discoveries[detector].append(scheme_id)
							
							// Create comment
							if word_comment_system:
								var comment_text = "SCHEME DETECTED: " + detector + " has discovered " + target_player + "'s " + scheme.type_name + " scheme"
								word_comment_system.add_comment("detection_" + scheme_id, comment_text, word_comment_system.CommentType.OBSERVATION)
							
							// Emit signal
							emit_signal("scheme_discovered", scheme_id, detector)
							
							detection_results.append({
								"success": true,
								"scheme_id": scheme_id,
								"scheme_type": scheme.type,
								"scheme_creator": scheme.creator,
								"scheme_description": scheme.description
							})
					}
			}
		}
	} else {
		// General detection attempt against all schemes
		for scheme_id in active_schemes:
			var scheme = active_schemes[scheme_id]
			
			// Don't detect own schemes
			if scheme.creator == detector:
				continue
			
			// Check if not already discovered
			if not detector in scheme.discovered_by:
				// Calculate detection chance (much lower for untargeted)
				var detection_chance = (0.3 / scheme.detection_difficulty) * detection_boost
				
				// Adjust based on word if provided
				if word and word_related_to_scheme(word, scheme):
					detection_chance *= 2.0
				
				// Detection roll
				if randf() < detection_chance:
					// Success - scheme detected
					scheme.discovered_by.append(detector)
					
					// Record discovery
					if not scheme_discoveries.has(detector):
						scheme_discoveries[detector] = []
					scheme_discoveries[detector].append(scheme_id)
					
					// Create comment
					if word_comment_system:
						var comment_text = "SCHEME DETECTED: " + detector + " has discovered " + scheme.creator + "'s " + scheme.type_name + " scheme"
						word_comment_system.add_comment("detection_" + scheme_id, comment_text, word_comment_system.CommentType.OBSERVATION)
					
					// Emit signal
					emit_signal("scheme_discovered", scheme_id, detector)
					
					detection_results.append({
						"success": true,
						"scheme_id": scheme_id,
						"scheme_type": scheme.type,
						"scheme_creator": scheme.creator,
						"scheme_description": scheme.description
					})
				}
			}
		}
	}
	
	return detection_results

func word_related_to_scheme(word, scheme):
	// Check if word is related to the scheme type
	if scheme_keywords.has(scheme.type):
		var keywords = scheme_keywords[scheme.type]
		for keyword in keywords:
			if word.to_lower().find(keyword) >= 0:
				return true
	
	// Check if word is in the scheme description
	if scheme.description and scheme.description.to_lower().find(word.to_lower()) >= 0:
		return true
	
	return false

func analyze_word_for_schemes(word, source_player):
	// Check if word contains suspicious patterns
	for pattern in suspicious_patterns:
		var regex = RegEx.new()
		regex.compile(pattern)
		var result = regex.search(word.to_lower())
		
		if result:
			// Track this word pattern
			if not word_patterns.has(source_player):
				word_patterns[source_player] = []
			
			word_patterns[source_player].append({
				"word": word,
				"pattern": pattern,
				"timestamp": OS.get_unix_time(),
				"turn": turn_system.current_turn if turn_system else 0,
				"dimension": turn_system.current_dimension if turn_system else 1
			})
			
			// If in dimension 5, 8, or 9, automatically attempt scheme detection
			var current_dimension = turn_system.current_dimension if turn_system else 1
			
			if current_dimension == 5 or current_dimension == 8 or current_dimension == 9:
				// Other players have a chance to detect the scheme
				for player in player_schemes:
					if player != source_player:
						attempt_scheme_detection(player, source_player, word)
			
			return true
	
	return false

# ----- DREAM-BASED SCHEME DETECTION -----

func analyze_dream_for_schemes(dream_text, source_player):
	var results = []
	
	// Dream-based detection only works in dimension 7
	var current_dimension = turn_system.current_dimension if turn_system else 1
	
	if current_dimension != 7:
		return results
	
	// Look for scheme keywords in dream text
	for scheme_type in scheme_keywords:
		var keywords = scheme_keywords[scheme_type]
		for keyword in keywords:
			if dream_text.to_lower().find(keyword) >= 0:
				// Dream contains scheme-related keyword
				
				// Check for schemes of this type
				for scheme_id in active_schemes:
					var scheme = active_schemes[scheme_id]
					
					if scheme.type == scheme_type and scheme.creator != source_player:
						// Roll for dream-based detection
						var detection_chance = 0.4  // Higher in dreams
						
						if randf() < detection_chance:
							// Success - scheme revealed in dream
							if not scheme.discovered_by.has(source_player):
								scheme.discovered_by.append(source_player)
								
								// Record discovery
								if not scheme_discoveries.has(source_player):
									scheme_discoveries[source_player] = []
								scheme_discoveries[source_player].append(scheme_id)
								
								// Create comment
								if word_comment_system:
									var comment_text = "DREAM REVELATION: " + source_player + " has glimpsed " + scheme.creator + "'s " + scheme.type_name + " scheme in a dream"
									word_comment_system.add_comment("dream_detection_" + scheme_id, comment_text, word_comment_system.CommentType.DREAM)
								
								// Emit signal
								emit_signal("scheme_discovered", scheme_id, source_player)
								
								results.append({
									"success": true,
									"scheme_id": scheme_id,
									"scheme_type": scheme.type,
									"scheme_creator": scheme.creator,
									"scheme_description": scheme.description,
									"via_dream": true
								})
						}
				}
	}
	
	return results

# ----- SCHEME COMMAND PARSING -----

func parse_scheme_command(text, source_player):
	// Check if text contains a scheme command
	if text.to_lower().find("/scheme") != 0:
		return null
	
	// Extract scheme type and targets
	var args = text.substr(8).strip_edges().split(" ", false)
	
	if args.size() < 1:
		return {
			"success": false,
			"message": "Invalid scheme command. Format: /scheme [type] [target1,target2,...] [description]"
		}
	
	var scheme_type_str = args[0].to_lower()
	var scheme_type = -1
	
	// Parse scheme type
	match scheme_type_str:
		"alliance":
			scheme_type = SchemeType.ALLIANCE
		"deception":
			scheme_type = SchemeType.DECEPTION
		"ascension":
			scheme_type = SchemeType.ASCENSION
		"manifold":
			scheme_type = SchemeType.MANIFOLD
		"divine":
			scheme_type = SchemeType.DIVINE
		_:
			return {
				"success": false,
				"message": "Invalid scheme type. Valid types: alliance, deception, ascension, manifold, divine"
			}
	
	// Parse targets
	var targets = []
	if args.size() >= 2:
		targets = args[1].split(",", false)
	
	// Parse description
	var description = ""
	if args.size() >= 3:
		var desc_start = text.find(args[2])
		description = text.substr(desc_start)
	
	// Create scheme
	var scheme = create_scheme(source_player, scheme_type, targets, description)
	
	return {
		"success": true,
		"message": "Scheme created successfully",
		"scheme": scheme
	}

func parse_counter_scheme_command(text, source_player):
	// Check if text contains a counter scheme command
	if text.to_lower().find("/counter") != 0:
		return null
	
	// Extract original scheme ID and description
	var args = text.substr(9).strip_edges().split(" ", false)
	
	if args.size() < 1:
		return {
			"success": false,
			"message": "Invalid counter scheme command. Format: /counter [original_scheme_id] [description]"
		}
	
	var original_scheme_id = args[0]
	
	// Parse description
	var description = ""
	if args.size() >= 2:
		var desc_start = text.find(args[1])
		description = text.substr(desc_start)
	
	// Check if player has discovered the original scheme
	if not scheme_discoveries.has(source_player) or not original_scheme_id in scheme_discoveries[source_player]:
		return {
			"success": false,
			"message": "You have not discovered the scheme: " + original_scheme_id
		}
	
	// Create counter scheme
	var counter_scheme = create_counter_scheme(source_player, original_scheme_id, description)
	
	return {
		"success": true,
		"message": "Counter scheme created successfully",
		"counter_scheme": counter_scheme
	}

# ----- TURN-BASED PROCESSING -----

func process_scheme_turns():
	var completed_schemes = []
	var current_turn = turn_system.current_turn if turn_system else 0
	
	// Check each active scheme
	for scheme_id in active_schemes:
		var scheme = active_schemes[scheme_id]
		
		// Check if scheme has expired
		if scheme.expiry_turn <= current_turn:
			// Calculate success
			var success = false
			
			if scheme.activated:
				// Generate random success based on probability
				if randf() < scheme.success_probability:
					success = true
			
			// Record completion
			completed_schemes.append({
				"scheme_id": scheme_id,
				"success": success
			})
			
			// Create comment
			if word_comment_system:
				var result_text = success ? "SUCCEEDED" : "FAILED"
				var comment_text = "SCHEME " + result_text + ": " + scheme.creator + "'s " + scheme.type_name + " scheme has completed"
				word_comment_system.add_comment("scheme_complete_" + scheme_id, comment_text, word_comment_system.CommentType.OBSERVATION)
			
			// Emit signal
			emit_signal("scheme_completed", scheme_id, success)
		}
	}
	
	// Remove completed schemes
	for completion in completed_schemes:
		active_schemes.erase(completion.scheme_id)
	
	return completed_schemes

# ----- EVENT HANDLERS -----

func _on_turn_completed(turn_number):
	// Process schemes on turn completion
	process_scheme_turns()
	
	// Special handling for turns divisible by 9
	if turn_number % 9 == 0:
		// Words spoken during 9th turns have enhanced scheme detection
		if word_comment_system:
			word_comment_system.add_comment("sacred_turn_schemes", 
				"The 9th turn enhances scheme detection. Hidden plans may be revealed.",
				word_comment_system.CommentType.OBSERVATION)
		
		// Automatic scheme detection chance for everyone
		var players = []
		for player in player_schemes:
			players.append(player)
		
		for detector in players:
			for target in players:
				if detector != target:
					attempt_scheme_detection(detector, target)

func _on_dimension_changed(new_dimension, old_dimension):
	// Special handling for key dimensions
	match new_dimension:
		5:  // Probability dimension - schemes are easier to detect
			if word_comment_system:
				word_comment_system.add_comment("dimension_5_schemes", 
					"Entering Dimension 5: Probability waves reveal hidden schemes more easily.",
					word_comment_system.CommentType.OBSERVATION)
		
		7:  // Dream dimension - schemes may appear in dreams
			if word_comment_system:
				word_comment_system.add_comment("dimension_7_schemes", 
					"Entering Dimension 7: Schemes may manifest in the dreamscape.",
					word_comment_system.CommentType.DREAM)
		
		8:  // Interconnection dimension - alliances are strengthened
			if word_comment_system:
				word_comment_system.add_comment("dimension_8_schemes", 
					"Entering Dimension 8: Alliance schemes gain power through interconnection.",
					word_comment_system.CommentType.OBSERVATION)
			
			// Boost all alliance schemes
			for scheme_id in active_schemes:
				var scheme = active_schemes[scheme_id]
				if scheme.type == SchemeType.ALLIANCE:
					scheme.power *= 1.5
		
		9:  // Judgment dimension - deception schemes are revealed
			if word_comment_system:
				word_comment_system.add_comment("dimension_9_schemes", 
					"Entering Dimension 9: Judgment may reveal deception schemes.",
					word_comment_system.CommentType.OBSERVATION)
			
			// Automatic detection chance for deception schemes
			var deception_schemes = []
			for scheme_id in active_schemes:
				var scheme = active_schemes[scheme_id]
				if scheme.type == SchemeType.DECEPTION:
					deception_schemes.append(scheme_id)
			
			// Everyone has a chance to detect deception schemes
			var players = []
			for player in player_schemes:
				players.append(player)
			
			for scheme_id in deception_schemes:
				var scheme = active_schemes[scheme_id]
				for detector in players:
					if detector != scheme.creator:
						// High chance to detect deception in dimension 9
						if randf() < 0.4:
							// Success - scheme detected
							if not detector in scheme.discovered_by:
								scheme.discovered_by.append(detector)
								
								// Record discovery
								if not scheme_discoveries.has(detector):
									scheme_discoveries[detector] = []
								scheme_discoveries[detector].append(scheme_id)
								
								// Create comment
								if word_comment_system:
									var comment_text = "JUDGMENT REVEALS: " + detector + " has discovered " + scheme.creator + "'s deception scheme"
									word_comment_system.add_comment("judgment_detection_" + scheme_id, comment_text, word_comment_system.CommentType.OBSERVATION)
								
								// Emit signal
								emit_signal("scheme_discovered", scheme_id, detector)

func _on_word_processed(word, power, source_player):
	// Analyze word for potential schemes
	analyze_word_for_schemes(word, source_player)
	
	// Check if word is a scheme command
	var scheme_result = parse_scheme_command(word, source_player)
	
	if scheme_result and scheme_result.success:
		// Scheme command succeeded
		return
	
	// Check if word is a counter scheme command
	var counter_result = parse_counter_scheme_command(word, source_player)
	
	if counter_result and counter_result.success:
		// Counter scheme command succeeded
		return
	
	// Check for automatic scheme activation in certain dimensions
	var current_dimension = turn_system.current_dimension if turn_system else 1
	
	// In dimension 11, schemes may activate automatically with consciousness words
	if current_dimension == 11:
		var consciousness_keywords = ["aware", "conscious", "realize", "understand", "comprehend", "sentient", "cognizant"]
		
		for keyword in consciousness_keywords:
			if word.to_lower().find(keyword) >= 0 and player_schemes.has(source_player):
				// Get player's inactive schemes
				var inactive_schemes = []
				for scheme_id in player_schemes[source_player]:
					if active_schemes.has(scheme_id) and not active_schemes[scheme_id].activated:
						inactive_schemes.append(scheme_id)
				
				if inactive_schemes.size() > 0:
					// Randomly select one to activate
					var random_scheme = inactive_schemes[randi() % inactive_schemes.size()]
					activate_scheme(random_scheme)
					
					// Add comment
					if word_comment_system:
						word_comment_system.add_comment("auto_activate_" + random_scheme, 
							"CONSCIOUS ACTIVATION: " + word + " has triggered the activation of a scheme in Dimension 11",
							word_comment_system.CommentType.OBSERVATION)
				
				break

# ----- PUBLIC API -----

func get_active_schemes():
	return active_schemes

func get_player_active_schemes(player_name):
	var result = []
	
	if player_schemes.has(player_name):
		for scheme_id in player_schemes[player_name]:
			if active_schemes.has(scheme_id):
				result.append(active_schemes[scheme_id])
	
	return result

func get_schemes_targeting_player(player_name):
	var result = []
	
	if scheme_targets.has(player_name):
		for scheme_id in scheme_targets[player_name]:
			if active_schemes.has(scheme_id):
				result.append(active_schemes[scheme_id])
	
	return result

func get_discovered_schemes(player_name):
	var result = []
	
	if scheme_discoveries.has(player_name):
		for scheme_id in scheme_discoveries[player_name]:
			if active_schemes.has(scheme_id):
				result.append(active_schemes[scheme_id])
	
	return result

func get_player_alliances(player_name):
	var result = []
	
	if scheme_alliances.has(player_name):
		for ally in scheme_alliances[player_name]:
			result.append({
				"player": ally,
				"alliance": scheme_alliances[player_name][ally]
			})
	
	return result

func check_scheme_command(text, source_player):
	// Check if text is a scheme command
	var scheme_result = parse_scheme_command(text, source_player)
	
	if scheme_result and scheme_result.success:
		return scheme_result
	
	// Check if text is a counter scheme command
	var counter_result = parse_counter_scheme_command(text, source_player)
	
	if counter_result and counter_result.success:
		return counter_result
	
	return null
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/interdimensional_scheming.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/keyboard_command_system.gd
# SIZE: 27587 bytes
class_name KeyboardCommandSystem
extends Node

# ----- KEY COMMAND CONFIGURATION -----
const KEY_COMMAND_PATTERNS = {
    # Shift key combinations
    "SHIFT+SPACE": {
        "name": "Word Separator",
        "symbol": "‚éµ",
        "dimensional_depth": 1,
        "function": "separate_words",
        "description": "Adds special type of space with dimensional properties"
    },
    "SHIFT+ENTER": {
        "name": "New Turn Cycle",
        "symbol": "‚Üµ",
        "dimensional_depth": 2,
        "function": "start_new_turn",
        "description": "Begins a new turn cycle in the 12-turns system"
    },
    "SHIFT+#": {
        "name": "Hash Symbol",
        "symbol": "#",
        "dimensional_depth": 1,
        "function": "insert_symbol",
        "description": "Inserts dimensional hash symbol"
    },
    "SHIFT+_": {
        "name": "Snake Case",
        "symbol": "_",
        "dimensional_depth": 1,
        "function": "convert_snake_case",
        "description": "Converts text to snake_case format"
    },
    
    # Ctrl key combinations
    "CTRL+SPACE": {
        "name": "Symbol Insertion",
        "symbol": "¬ß",
        "dimensional_depth": 2,
        "function": "insert_special_symbol",
        "description": "Inserts a special dimensional symbol"
    },
    "CTRL+B": {
        "name": "Bridge Connection",
        "symbol": "‚âà",
        "dimensional_depth": 3,
        "function": "create_bridge_connection",
        "description": "Creates a bridge between dimensional spaces"
    },
    "CTRL+#": {
        "name": "Dimensional Shift Up",
        "symbol": "##",
        "dimensional_depth": 2,
        "function": "dimension_shift_up",
        "description": "Shifts up in dimensional hierarchy"
    },
    "CTRL+S": {
        "name": "Save State",
        "symbol": "üíæ",
        "dimensional_depth": 1,
        "function": "save_current_state",
        "description": "Saves current dimensional state"
    },
    "CTRL+Z": {
        "name": "Undo Change",
        "symbol": "‚Ü©",
        "dimensional_depth": 2,
        "function": "undo_last_change",
        "description": "Undoes last dimensional change"
    },
    "CTRL+Y": {
        "name": "Redo Change", 
        "symbol": "‚Ü™",
        "dimensional_depth": 2,
        "function": "redo_last_change",
        "description": "Redoes previously undone change"
    },
    
    # Alt key combinations
    "ALT+SPACE": {
        "name": "Alternative Correction",
        "symbol": "‚úì",
        "dimensional_depth": 2,
        "function": "alternative_correction",
        "description": "Shows alternative correction options"
    },
    "ALT+C": {
        "name": "Connection Check",
        "symbol": "‚ü∑",
        "dimensional_depth": 2,
        "function": "check_connections",
        "description": "Checks all system connections"
    },
    "ALT+T": {
        "name": "Turn System",
        "symbol": "‚ü≥",
        "dimensional_depth": 3,
        "function": "trigger_turn_system",
        "description": "Triggers turn system functions"
    },
    "ALT+#": {
        "name": "Triple Hash",
        "symbol": "###",
        "dimensional_depth": 3,
        "function": "insert_triple_hash",
        "description": "Inserts a triple hash symbol"
    },
    
    # Symbol transformations
    "#": {
        "name": "Direct Connection",
        "symbol": "#",
        "dimensional_depth": 1,
        "function": "direct_connection",
        "description": "Creates a direct dimensional connection"
    },
    "##": {
        "name": "Secondary Connection",
        "symbol": "##",
        "dimensional_depth": 2,
        "function": "secondary_connection",
        "description": "Creates a secondary dimensional connection"
    },
    "###": {
        "name": "Tertiary Connection",
        "symbol": "###",
        "dimensional_depth": 3,
        "function": "tertiary_connection",
        "description": "Creates a tertiary dimensional connection"
    },
    "#_": {
        "name": "Snake Connection",
        "symbol": "#_",
        "dimensional_depth": 2,
        "function": "snake_connection",
        "description": "Creates snake_case dimensional connection"
    },
    "_#": {
        "name": "Reverse Connection",
        "symbol": "_#",
        "dimensional_depth": 2,
        "function": "reverse_connection",
        "description": "Creates reverse dimensional connection"
    }
}

# ----- AUTO-CORRECTION DICTIONARY -----
const AUTO_CORRECTIONS = {
    "teh": "the",
    "adn": "and",
    "taht": "that",
    "wat": "what",
    "ot": "to",
    "nad": "and",
    "fo": "of",
    "ti": "it",
    "si": "is",
    "hte": "the",
    "wiht": "with",
    "waht": "what",
    "tiem": "time",
    "thign": "thing",
    "liek": "like",
    "ot": "to",
    "wehn": "when",
    "thre": "there",
    "becuase": "because",
    "trun": "turn",
    "systme": "system",
    "keyboartd": "keyboard",
    "sumbol": "symbol",
    "trigge": "trigger",
    "wrtie": "write",
    "wrtien": "written",
    "splti": "split",
    "recrod": "record",
    "recrodning": "recording",
    "maek": "make",
    "corect": "correct",
    "corectino": "correction",
    "uise": "use",
    "whoel": "whole",
    "dimensino": "dimension",
    "dimensino": "dimension",
    "etherial": "ethereal",
    "etherial engine": "ethereal engine",
    "brigde": "bridge",
    "transfoorm": "transform",
    "transformatino": "transformation",
    "conection": "connection",
    "conenct": "connect",
    "symbool": "symbol",
    "modificatino": "modification",
    "modificatinos": "modifications",
    "integratino": "integration",
    "integrte": "integrate",
    "wondow": "window",
    "wondows": "windows",
    "godto": "godot",
    "godto engine": "godot engine",
    "scheduel": "schedule",
    "automate": "automate",
    "automatino": "automation",
    "engnie": "engine"
}

# ----- SYSTEM STATE -----
var command_history = []
var correction_history = []
var auto_corrections_applied = 0
var last_key_sequence = []
var current_key_combination = ""
var input_buffer = ""
var last_correction_time = 0
var command_mode_active = false
var active_dimensional_depth = 1
var current_symbol = ""

# ----- SYSTEM REFERENCES -----
var auto_correction_system = null
var ethereal_bridge = null
var akashic_system = null
var turn_system = null

# ----- SYSTEM SETTINGS -----
var auto_correction_enabled = true
var command_mode_enabled = true
var dimensional_typing_enabled = true
var max_history_size = 100
var max_sequence_timeout = 1.0 # seconds
var last_key_time = 0

# ----- SIGNALS -----
signal command_executed(command_name, result)
signal auto_correction_applied(original, corrected)
signal symbol_inserted(symbol, dimension)
signal key_sequence_recognized(sequence)
signal dimensional_shift(old_depth, new_depth)

# ----- INITIALIZATION -----
func _ready():
    _find_systems()
    _initialize_input_handling()
    
    print("Keyboard Command System initialized with dimensional depth: " + str(active_dimensional_depth))

func _find_systems():
    # Find Auto-Correction System
    auto_correction_system = get_node_or_null("/root/AutoCorrectionSystem")
    if not auto_correction_system:
        auto_correction_system = _find_node_by_class(get_tree().root, "AutoCorrectionSystem")
    
    # Find Ethereal Bridge
    ethereal_bridge = get_node_or_null("/root/EtherealAkashicBridge")
    if not ethereal_bridge:
        ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealAkashicBridge")
    
    # Find Akashic System
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    # Find Turn System
    turn_system = get_node_or_null("/root/TurnSystem") 
    if not turn_system:
        turn_system = _find_node_by_class(get_tree().root, "TurnCycleController")
    
    print("Systems found - Auto-Correction: %s, Ethereal Bridge: %s, Akashic System: %s, Turn System: %s" % [
        "Yes" if auto_correction_system else "No",
        "Yes" if ethereal_bridge else "No",
        "Yes" if akashic_system else "No",
        "Yes" if turn_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_input_handling():
    # Connect to input events
    set_process_input(true)

# ----- INPUT HANDLING -----
func _input(event):
    if event is InputEventKey:
        if event.pressed:
            _handle_key_press(event)
        else:
            _handle_key_release(event)

func _handle_key_press(event: InputEventKey):
    # Get current key combination
    var key_combination = _get_key_combination(event)
    
    # Update key sequence for pattern recognition
    _update_key_sequence(key_combination)
    
    # Check if this is a recognized command
    if KEY_COMMAND_PATTERNS.has(key_combination):
        execute_command(key_combination)
    
    # For normal typing, check for auto-correction
    if _is_normal_typing_key(event) and not command_mode_active:
        input_buffer += char(event.unicode)
        _check_for_auto_correction()

func _handle_key_release(event: InputEventKey):
    # Reset command mode when modifier keys are released
    if event.keycode == KEY_SHIFT or event.keycode == KEY_CTRL or event.keycode == KEY_ALT:
        command_mode_active = false

func _get_key_combination(event: InputEventKey) -> String:
    var combination = ""
    
    # Add modifiers
    if event.shift:
        combination += "SHIFT+"
    if event.control:
        combination += "CTRL+"
    if event.alt:
        combination += "ALT+"
    
    # Add key
    var key_name = OS.get_keycode_string(event.keycode)
    combination += key_name
    
    current_key_combination = combination
    return combination

func _is_normal_typing_key(event: InputEventKey) -> bool:
    # Check if this is a normal typing key (not a command or control key)
    return event.unicode > 0 and not event.control and not event.alt

func _update_key_sequence(key: String):
    var current_time = Time.get_unix_time_from_system()
    
    # Clear sequence if timeout occurred
    if current_time - last_key_time > max_sequence_timeout:
        last_key_sequence.clear()
    
    # Add key to sequence
    last_key_sequence.append(key)
    
    # Limit sequence size
    if last_key_sequence.size() > 10:
        last_key_sequence.pop_front()
    
    # Check for known patterns
    _check_for_key_patterns()
    
    # Update timestamp
    last_key_time = current_time

func _check_for_key_patterns():
    # Join last few keys
    var sequence = ""
    for key in last_key_sequence.slice(-3, last_key_sequence.size()):
        sequence += key
    
    # Example sequences to check
    var sequences = {
        "SHIFT+#SHIFT+#SHIFT+#": "triple_hash_insertion",
        "CTRL+SCTRL+HCTRL+I": "dimensional_shift_initiation",
        "ALT+CALT+OALT+N": "connection_verification",
        "SHIFT+#CTRL+#ALT+#": "multi_dimensional_traversal"
    }
    
    if sequences.has(sequence):
        emit_signal("key_sequence_recognized", sequences[sequence])
        
        # Execute special sequence command
        var sequence_name = sequences[sequence]
        
        match sequence_name:
            "triple_hash_insertion":
                _insert_symbol("###")
            "dimensional_shift_initiation":
                _shift_dimensional_depth(active_dimensional_depth + 1)
            "connection_verification":
                _verify_all_connections()
            "multi_dimensional_traversal":
                if ethereal_bridge and ethereal_bridge.has_method("change_dimension"):
                    var connected_dimensions = ethereal_bridge.get_connected_dimensions()
                    if connected_dimensions.size() > 0:
                        ethereal_bridge.change_dimension(connected_dimensions[0])

func _check_for_auto_correction():
    if not auto_correction_enabled:
        return
    
    # Split input buffer into words
    var words = input_buffer.split(" ")
    
    # Check last word for auto-correction
    if words.size() > 0:
        var last_word = words[words.size() - 1]
        
        # Check if this word needs correction
        if AUTO_CORRECTIONS.has(last_word.to_lower()):
            var corrected = AUTO_CORRECTIONS[last_word.to_lower()]
            
            # Apply case preservation
            if last_word == last_word.to_upper():
                corrected = corrected.to_upper()
            elif last_word[0] == last_word[0].to_upper():
                corrected = corrected[0].to_upper() + corrected.substr(1)
            
            # Replace word in buffer
            words[words.size() - 1] = corrected
            input_buffer = " ".join(words)
            
            # Record correction
            _record_correction(last_word, corrected)
            
            # Emit signal
            emit_signal("auto_correction_applied", last_word, corrected)
            
            print("Auto-corrected: " + last_word + " ‚Üí " + corrected)

func _record_correction(original: String, corrected: String):
    correction_history.append({
        "original": original,
        "corrected": corrected,
        "timestamp": Time.get_unix_time_from_system(),
        "dimensional_depth": active_dimensional_depth
    })
    
    # Limit history size
    if correction_history.size() > max_history_size:
        correction_history.pop_front()
    
    auto_corrections_applied += 1
    last_correction_time = Time.get_unix_time_from_system()

# ----- COMMAND EXECUTION -----
func execute_command(command_name: String):
    if not command_mode_enabled:
        return false
    
    if not KEY_COMMAND_PATTERNS.has(command_name):
        print("Unknown command: " + command_name)
        return false
    
    var command = KEY_COMMAND_PATTERNS[command_name]
    var function = command.function
    var result = null
    
    # Set command mode active
    command_mode_active = true
    
    # Execute function based on name
    match function:
        "separate_words":
            result = _separate_words()
        "start_new_turn":
            result = _start_new_turn()
        "insert_symbol":
            result = _insert_symbol(command.symbol)
        "convert_snake_case":
            result = _convert_to_snake_case()
        "insert_special_symbol":
            result = _insert_special_symbol()
        "create_bridge_connection":
            result = _create_bridge_connection()
        "dimension_shift_up":
            result = _shift_dimensional_depth(active_dimensional_depth + 1)
        "save_current_state":
            result = _save_current_state()
        "undo_last_change":
            result = _undo_last_change()
        "redo_last_change":
            result = _redo_last_change()
        "alternative_correction":
            result = _show_alternative_corrections()
        "check_connections":
            result = _verify_all_connections()
        "trigger_turn_system":
            result = _trigger_turn_system()
        "insert_triple_hash":
            result = _insert_symbol("###")
        "direct_connection":
            result = _create_connection("direct", 1)
        "secondary_connection":
            result = _create_connection("secondary", 2)
        "tertiary_connection":
            result = _create_connection("tertiary", 3)
        "snake_connection":
            result = _create_connection("snake", 2)
        "reverse_connection":
            result = _create_connection("reverse", 2)
    
    # Record command in history
    _record_command(command_name, result)
    
    # Emit signal
    emit_signal("command_executed", command_name, result)
    
    return result != null

func _record_command(command_name: String, result):
    command_history.append({
        "command": command_name,
        "result": result, 
        "timestamp": Time.get_unix_time_from_system(),
        "dimensional_depth": active_dimensional_depth
    })
    
    # Limit history size
    if command_history.size() > max_history_size:
        command_history.pop_front()

# ----- COMMAND IMPLEMENTATIONS -----
func _separate_words() -> bool:
    # Insert special word separator
    input_buffer += " "
    return true

func _start_new_turn() -> bool:
    if turn_system and turn_system.has_method("advance_turn"):
        var current_turn = 1
        if turn_system.has_method("get_current_turn"):
            current_turn = turn_system.get_current_turn()
        
        var success = turn_system.advance_turn()
        if success:
            print("Advanced to turn " + str(current_turn + 1))
            return true
    
    return false

func _insert_symbol(symbol_str: String) -> bool:
    input_buffer += symbol_str
    current_symbol = symbol_str
    
    emit_signal("symbol_inserted", symbol_str, active_dimensional_depth)
    
    return true

func _convert_to_snake_case() -> bool:
    # Split input buffer into words
    var words = input_buffer.split(" ")
    
    # Convert last word or all buffer to snake_case
    if words.size() > 0:
        var text_to_convert = words[words.size() - 1]
        
        # If no clear last word, convert all buffer
        if text_to_convert.strip_edges() == "":
            text_to_convert = input_buffer
            input_buffer = ""
        else:
            words.remove_at(words.size() - 1)
            input_buffer = " ".join(words)
            if input_buffer != "":
                input_buffer += " "
        
        # Convert to snake_case
        var snake_case = _to_snake_case(text_to_convert)
        input_buffer += snake_case
        
        return true
    
    return false

func _to_snake_case(text: String) -> String:
    # Convert to lowercase
    var result = text.to_lower()
    
    # Replace spaces and special characters with underscores
    var regex = RegEx.new()
    regex.compile("\\s+|[^a-z0-9]")
    result = regex.sub(result, "_", true)
    
    # Remove consecutive underscores
    regex.compile("_+")
    result = regex.sub(result, "_", true)
    
    # Remove leading/trailing underscores
    result = result.strip_edges()
    if result.begins_with("_"):
        result = result.substr(1)
    if result.ends_with("_"):
        result = result.substr(0, result.length() - 1)
    
    return result

func _insert_special_symbol() -> bool:
    # Get special symbol based on dimensional depth
    var symbol = "¬ß"
    
    if active_dimensional_depth == 2:
        symbol = "¬∂"
    elif active_dimensional_depth == 3:
        symbol = "‚Ä°"
    elif active_dimensional_depth > 3:
        symbol = "‚âÖ"
    
    input_buffer += symbol
    current_symbol = symbol
    
    emit_signal("symbol_inserted", symbol, active_dimensional_depth)
    
    return true

func _create_bridge_connection() -> bool:
    if ethereal_bridge and ethereal_bridge.has_method("record_memory"):
        var content = "Bridge connection at depth " + str(active_dimensional_depth)
        if input_buffer.length() > 0:
            content = input_buffer
        
        var tags = ["bridge", "depth:" + str(active_dimensional_depth)]
        ethereal_bridge.record_memory(content, tags)
        
        print("Created bridge connection: " + content)
        return true
    
    return false

func _shift_dimensional_depth(new_depth: int) -> bool:
    var old_depth = active_dimensional_depth
    active_dimensional_depth = max(1, min(new_depth, 5))
    
    emit_signal("dimensional_shift", old_depth, active_dimensional_depth)
    print("Dimensional depth shifted from " + str(old_depth) + " to " + str(active_dimensional_depth))
    
    return true

func _save_current_state() -> bool:
    # Save state in akashic system or ethereal bridge
    var saved = false
    
    if akashic_system and akashic_system.has_method("store_record"):
        var data = {
            "input_buffer": input_buffer,
            "dimensional_depth": active_dimensional_depth,
            "corrections": auto_corrections_applied,
            "commands": command_history.size(),
            "timestamp": Time.get_unix_time_from_system()
        }
        
        saved = akashic_system.store_record(0, 0, data)
    
    if not saved and ethereal_bridge and ethereal_bridge.has_method("record_memory"):
        var content = "Saved state: Depth=" + str(active_dimensional_depth) + ", Buffer=" + input_buffer
        var tags = ["saved_state", "depth:" + str(active_dimensional_depth)]
        
        saved = ethereal_bridge.record_memory(content, tags)
    
    if saved:
        print("State saved successfully")
    else:
        print("Failed to save state")
    
    return saved

func _undo_last_change() -> bool:
    # For now, just clear the last word in buffer
    var words = input_buffer.split(" ")
    
    if words.size() > 0:
        words.remove_at(words.size() - 1)
        input_buffer = " ".join(words)
        
        if correction_history.size() > 0:
            correction_history.pop_back()
        
        print("Undid last change")
        return true
    
    return false

func _redo_last_change() -> bool:
    # Not implemented yet
    return false

func _show_alternative_corrections() -> bool:
    # Get last word
    var words = input_buffer.split(" ")
    
    if words.size() > 0:
        var last_word = words[words.size() - 1]
        var alternatives = _find_alternative_corrections(last_word)
        
        print("Alternative corrections for '" + last_word + "':")
        for alt in alternatives:
            print("- " + alt)
        
        return alternatives.size() > 0
    
    return false

func _find_alternative_corrections(word: String) -> Array:
    var alternatives = []
    
    # Direct match
    if AUTO_CORRECTIONS.has(word.to_lower()):
        alternatives.append(AUTO_CORRECTIONS[word.to_lower()])
    
    # Find similar words (simplified)
    for original in AUTO_CORRECTIONS.keys():
        # Check if original is similar to word
        if original.length() == word.length() and _similarity_score(original, word) > 0.7:
            alternatives.append(AUTO_CORRECTIONS[original])
        
        # Check if correction is similar to word
        var correction = AUTO_CORRECTIONS[original]
        if correction.length() == word.length() and _similarity_score(correction, word) > 0.7:
            if not alternatives.has(correction):
                alternatives.append(correction)
    
    return alternatives

func _similarity_score(a: String, b: String) -> float:
    # Simple character-based similarity (0.0 to 1.0)
    if a.length() == 0 or b.length() == 0:
        return 0.0
    
    var matches = 0
    var a_lower = a.to_lower()
    var b_lower = b.to_lower()
    
    for i in range(min(a.length(), b.length())):
        if a_lower[i] == b_lower[i]:
            matches += 1
    
    return float(matches) / max(a.length(), b.length())

func _verify_all_connections() -> bool:
    var all_connected = true
    
    print("Checking system connections:")
    
    if not auto_correction_system:
        print("- Auto-Correction System: DISCONNECTED")
        all_connected = false
    else:
        print("- Auto-Correction System: CONNECTED")
    
    if not ethereal_bridge:
        print("- Ethereal Bridge: DISCONNECTED")
        all_connected = false
    else:
        print("- Ethereal Bridge: CONNECTED")
    
    if not akashic_system:
        print("- Akashic System: DISCONNECTED")
        all_connected = false
    else:
        print("- Akashic System: CONNECTED")
    
    if not turn_system:
        print("- Turn System: DISCONNECTED")
        all_connected = false
    else:
        print("- Turn System: CONNECTED")
    
    return all_connected

func _trigger_turn_system() -> bool:
    if turn_system:
        if turn_system.has_method("trigger_special_event"):
            return turn_system.trigger_special_event("command_triggered", {
                "dimensional_depth": active_dimensional_depth,
                "symbol": current_symbol,
                "buffer": input_buffer
            })
    
    return false

func _create_connection(connection_type: String, depth: int) -> bool:
    if not ethereal_bridge:
        return false
    
    var dimension_key = ethereal_bridge.get_property("current_dimension") if ethereal_bridge.has_method("get_property") else "0-0-0"
    
    # Get connected dimensions
    var connected_dimensions = []
    if ethereal_bridge.has_method("get_connected_dimensions"):
        connected_dimensions = ethereal_bridge.get_connected_dimensions()
    
    # Create connection data
    var connection_data = {
        "type": connection_type,
        "depth": depth,
        "dimension": dimension_key,
        "symbol": _get_symbol_for_connection(connection_type),
        "timestamp": Time.get_unix_time_from_system()
    }
    
    # Create memory record
    if ethereal_bridge.has_method("record_memory"):
        var content = "Created " + connection_type + " connection at depth " + str(depth)
        var tags = ["connection", connection_type, "depth:" + str(depth)]
        
        ethereal_bridge.record_memory(content, tags)
        print("Connection created: " + content)
        
        return true
    
    return false

func _get_symbol_for_connection(connection_type: String) -> String:
    match connection_type:
        "direct":
            return "#"
        "secondary":
            return "##"
        "tertiary":
            return "###"
        "snake":
            return "#_"
        "reverse":
            return "_#"
        _:
            return "#"

# ----- PUBLIC API -----
func get_command_list() -> Array:
    var commands = []
    
    for command_name in KEY_COMMAND_PATTERNS:
        var command = KEY_COMMAND_PATTERNS[command_name]
        commands.append({
            "name": command_name,
            "description": command.description,
            "symbol": command.symbol,
            "depth": command.dimensional_depth
        })
    
    return commands

func get_correction_stats() -> Dictionary:
    return {
        "total_corrections": auto_corrections_applied,
        "last_correction_time": last_correction_time,
        "history_size": correction_history.size(),
        "current_dimensional_depth": active_dimensional_depth
    }

func set_auto_correction(enabled: bool) -> void:
    auto_correction_enabled = enabled
    print("Auto-correction " + ("enabled" if enabled else "disabled"))

func set_command_mode(enabled: bool) -> void:
    command_mode_enabled = enabled
    print("Command mode " + ("enabled" if enabled else "disabled"))

func set_dimensional_depth(depth: int) -> bool:
    return _shift_dimensional_depth(depth)

func add_custom_correction(original: String, corrected: String) -> bool:
    if original.strip_edges() == "":
        return false
    
    AUTO_CORRECTIONS[original.to_lower()] = corrected
    print("Added custom correction: " + original + " ‚Üí " + corrected)
    
    return true

func get_current_input_buffer() -> String:
    return input_buffer

func clear_input_buffer() -> void:
    input_buffer = ""

func simulate_key_combination(combination: String) -> bool:
    if KEY_COMMAND_PATTERNS.has(combination):
        return execute_command(combination)
    
    return false
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/keyboard_command_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/keyboard_shape_manager.gd
# SIZE: 18426 bytes
extends Node

class_name KeyboardShapeManager

# Keyboard tracking and shape generation system with eyeball tracking integration

# Keyboard state tracking
var key_states = {}
var active_keys = []
var key_press_history = []
var key_combinations = []
var last_key_time = 0
var typing_speed = 0
var typing_rhythm = []
var typing_pattern = ""
var current_shape = "none"
var current_color = Color(1, 1, 1)
var eye_tracking_active = false
var eye_position = Vector2(0.5, 0.5) # Normalized 0-1 position
var keyboard_dimensions = Vector2(1920, 200) # Default size

# Color progression for shapes
var color_gradient = {
    "cool": [
        Color(0.2, 0.4, 0.8),
        Color(0.3, 0.6, 0.9),
        Color(0.4, 0.7, 0.8),
        Color(0.5, 0.8, 0.7)
    ],
    "warm": [
        Color(0.9, 0.3, 0.2),
        Color(0.8, 0.4, 0.3),
        Color(0.9, 0.5, 0.1),
        Color(0.8, 0.6, 0.2)
    ],
    "neutral": [
        Color(0.7, 0.7, 0.7),
        Color(0.6, 0.6, 0.6),
        Color(0.8, 0.8, 0.8),
        Color(0.5, 0.5, 0.5)
    ],
    "vibrant": [
        Color(0.9, 0.2, 0.8),
        Color(0.2, 0.8, 0.4),
        Color(0.8, 0.8, 0.2),
        Color(0.2, 0.4, 0.9)
    ]
}

# Shape patterns based on key combinations
var shape_patterns = {
    "WASD": "cube",
    "HJKL": "sphere",
    "UIOP": "pyramid",
    "ZXCV": "cylinder",
    "1234": "torus",
    "QWER": "plane",
    "ASDF": "cone",
    "JKLI": "star",
    "YGHJ": "octahedron",
    "BNM": "icosahedron"
}

# Special key combinations for effects
var effect_combos = {
    "CTRL+ALT+S": "save_shape",
    "CTRL+ALT+L": "load_shape",
    "CTRL+ALT+C": "cycle_color",
    "CTRL+SHIFT+E": "toggle_eye_tracking",
    "ALT+SHIFT+R": "randomize_properties"
}

# External tool connections
var github_connected = false
var github_repos = []
var shape_library_path = "user://shape_library/"
var external_tools = []

# Signals
signal key_sequence_recognized(sequence, shape)
signal shape_changed(shape_name, properties)
signal eye_gaze_tracked(position)
signal shape_saved(shape_name, file_path)
signal tool_connected(tool_name, status)

func _ready():
    # Initialize key states for entire keyboard
    _initialize_key_states()
    
    # Create shape library directory if it doesn't exist
    var dir = Directory.new()
    if not dir.dir_exists(shape_library_path):
        dir.make_dir_recursive(shape_library_path)
    
    # Start input monitoring
    set_process_input(true)
    
    # Try to connect to GitHub
    connect_to_github()
    
    # Load external tools
    load_external_tools()

func _initialize_key_states():
    # Initialize tracking for standard keys
    var keys = [
        # Letters
        "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M",
        "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z",
        # Numbers
        "0", "1", "2", "3", "4", "5", "6", "7", "8", "9",
        # Special keys
        "SPACE", "ENTER", "BACKSPACE", "TAB", "ESCAPE",
        "LEFT", "RIGHT", "UP", "DOWN",
        "CTRL", "SHIFT", "ALT", "META"
    ]
    
    for key in keys:
        key_states[key] = {
            "pressed": false,
            "last_pressed_time": 0,
            "press_count": 0,
            "hold_duration": 0,
            "combined_with": []
        }

func _input(event):
    # Track keyboard input
    if event is InputEventKey:
        var key_name = OS.get_scancode_string(event.scancode)
        
        if event.pressed:
            _on_key_pressed(key_name)
        else:
            _on_key_released(key_name)
        
        # Check for shape patterns
        check_shape_patterns()
        
        # Check for effect combinations
        check_effect_combinations()

func _on_key_pressed(key_name):
    if not key_name in key_states:
        key_states[key_name] = {
            "pressed": false,
            "last_pressed_time": 0,
            "press_count": 0,
            "hold_duration": 0,
            "combined_with": []
        }
    
    var now = OS.get_ticks_msec()
    var key_state = key_states[key_name]
    
    # Update key state
    key_state["pressed"] = true
    key_state["last_pressed_time"] = now
    key_state["press_count"] += 1
    key_state["hold_duration"] = 0
    
    # Update active keys list
    if not key_name in active_keys:
        active_keys.append(key_name)
    
    # Update key combinations
    key_state["combined_with"] = active_keys.duplicate()
    key_state["combined_with"].erase(key_name)
    
    # Add to history
    key_press_history.append({
        "key": key_name,
        "time": now,
        "combined_with": key_state["combined_with"].duplicate()
    })
    
    # Limit history size
    if key_press_history.size() > 100:
        key_press_history.pop_front()
    
    # Calculate typing speed
    if key_press_history.size() >= 2:
        var prev_time = key_press_history[key_press_history.size() - 2]["time"]
        var time_diff = now - prev_time
        
        # Only count if keys are pressed within reasonable typing timeframe (2 seconds)
        if time_diff < 2000:
            typing_rhythm.append(time_diff)
            # Keep only the last 20 rhythm measurements
            if typing_rhythm.size() > 20:
                typing_rhythm.pop_front()
            
            # Calculate average typing speed in characters per minute
            var avg_time_between_keys = 0
            for time in typing_rhythm:
                avg_time_between_keys += time
            
            if typing_rhythm.size() > 0:
                avg_time_between_keys /= typing_rhythm.size()
                if avg_time_between_keys > 0:
                    typing_speed = 60000 / avg_time_between_keys
                else:
                    typing_speed = 0
    
    # Update typing pattern
    if key_press_history.size() >= 4:
        var recent_keys = []
        for i in range(key_press_history.size() - 4, key_press_history.size()):
            recent_keys.append(key_press_history[i]["key"])
        
        typing_pattern = ""
        for k in recent_keys:
            typing_pattern += k

func _on_key_released(key_name):
    if not key_name in key_states:
        return
    
    var now = OS.get_ticks_msec()
    var key_state = key_states[key_name]
    
    # Update key state
    key_state["pressed"] = false
    key_state["hold_duration"] = now - key_state["last_pressed_time"]
    
    # Remove from active keys
    active_keys.erase(key_name)

func check_shape_patterns():
    # Convert active keys to a sorted string for pattern matching
    var active_keys_str = ""
    var sorted_keys = active_keys.duplicate()
    sorted_keys.sort()
    
    for key in sorted_keys:
        active_keys_str += key
    
    # Check against shape patterns
    for pattern in shape_patterns:
        if active_keys_str.find(pattern) >= 0:
            var shape_name = shape_patterns[pattern]
            if shape_name != current_shape:
                current_shape = shape_name
                create_shape(shape_name)
                emit_signal("key_sequence_recognized", pattern, shape_name)
                return

func check_effect_combinations():
    # Check for effect combinations
    for combo in effect_combos:
        var combo_keys = combo.split("+")
        var all_pressed = true
        
        for key in combo_keys:
            if not key in active_keys:
                all_pressed = false
                break
        
        if all_pressed:
            execute_effect(effect_combos[combo])
            return

func execute_effect(effect_name):
    match effect_name:
        "save_shape":
            save_current_shape()
        "load_shape":
            load_shape()
        "cycle_color":
            cycle_color_palette()
        "toggle_eye_tracking":
            toggle_eye_tracking()
        "randomize_properties":
            randomize_shape_properties()

func create_shape(shape_name):
    # Generate shape properties
    var properties = {
        "name": shape_name,
        "color": get_current_color(),
        "scale": Vector3(1.0, 1.0, 1.0),
        "rotation": Vector3(0, 0, 0),
        "typing_speed": typing_speed,
        "typing_pattern": typing_pattern,
        "created_at": OS.get_unix_time()
    }
    
    # Adjust properties based on typing rhythm
    if typing_rhythm.size() > 0:
        var rhythm_variance = 0
        var rhythm_avg = 0
        
        for r in typing_rhythm:
            rhythm_avg += r
        
        rhythm_avg /= typing_rhythm.size()
        
        for r in typing_rhythm:
            rhythm_variance += abs(r - rhythm_avg)
        
        rhythm_variance /= typing_rhythm.size()
        
        # Use rhythm variance to adjust shape properties
        var variance_normalized = clamp(rhythm_variance / 500.0, 0, 1)
        properties["complexity"] = variance_normalized
        properties["size"] = 1.0 + variance_normalized
        
        # Adjust rotation based on typing speed
        properties["rotation"] = Vector3(
            rand_range(0, typing_speed / 100.0),
            rand_range(0, typing_speed / 100.0),
            rand_range(0, typing_speed / 100.0)
        )
    
    # Incorporate eye tracking if active
    if eye_tracking_active:
        properties["eye_position"] = eye_position
        
        # Adjust position based on eye gaze
        properties["position"] = Vector3(
            (eye_position.x - 0.5) * 2.0,
            (eye_position.y - 0.5) * 2.0,
            0
        )
    else:
        properties["position"] = Vector3(0, 0, 0)
    
    # Emit signal with shape data
    emit_signal("shape_changed", shape_name, properties)
    
    return properties

func save_current_shape():
    if current_shape == "none":
        print("No shape to save")
        return false
    
    # Generate shape data
    var properties = create_shape(current_shape)
    
    # Create a unique filename
    var timestamp = OS.get_unix_time()
    var filename = shape_library_path + current_shape + "_" + str(timestamp) + ".json"
    
    # Save to file
    var file = File.new()
    file.open(filename, File.WRITE)
    file.store_string(JSON.print(properties, "  "))
    file.close()
    
    emit_signal("shape_saved", current_shape, filename)
    print("Saved shape: " + current_shape + " to " + filename)
    return true

func load_shape(shape_name = ""):
    var dir = Directory.new()
    if not dir.dir_exists(shape_library_path):
        print("Shape library doesn't exist")
        return false
    
    dir.open(shape_library_path)
    dir.list_dir_begin(true, true)
    
    var shape_files = []
    var file_name = dir.get_next()
    
    while file_name != "":
        if not dir.current_is_dir() and file_name.ends_with(".json"):
            if shape_name.empty() or file_name.begins_with(shape_name):
                shape_files.append(file_name)
        file_name = dir.get_next()
    
    dir.list_dir_end()
    
    if shape_files.size() == 0:
        print("No shape files found")
        return false
    
    # Load the most recent shape file
    shape_files.sort()
    var most_recent = shape_files[shape_files.size() - 1]
    
    var file = File.new()
    if file.open(shape_library_path + most_recent, File.READ) != OK:
        print("Failed to open shape file")
        return false
    
    var json_text = file.get_as_text()
    file.close()
    
    var json = JSON.parse(json_text)
    if json.error != OK:
        print("Failed to parse shape file")
        return false
    
    var shape_data = json.result
    
    # Apply loaded shape
    current_shape = shape_data["name"]
    if shape_data.has("color"):
        current_color = Color(
            shape_data["color"]["r"],
            shape_data["color"]["g"],
            shape_data["color"]["b"]
        )
    
    emit_signal("shape_changed", current_shape, shape_data)
    print("Loaded shape: " + current_shape)
    return true

func get_current_color():
    # Return current color for shape creation
    return current_color

func cycle_color_palette():
    # Cycle through color palettes
    var palettes = ["cool", "warm", "neutral", "vibrant"]
    var current_palette = "cool"
    
    # Try to determine current palette
    for palette in palettes:
        for color in color_gradient[palette]:
            if color.is_equal_approx(current_color):
                current_palette = palette
                break
    
    # Find next palette
    var palette_index = palettes.find(current_palette)
    palette_index = (palette_index + 1) % palettes.size()
    var next_palette = palettes[palette_index]
    
    # Pick a random color from the next palette
    var colors = color_gradient[next_palette]
    current_color = colors[randi() % colors.size()]
    
    # If shape exists, update its color
    if current_shape != "none":
        var properties = create_shape(current_shape)
        emit_signal("shape_changed", current_shape, properties)
    
    print("Cycled to " + next_palette + " color palette: " + str(current_color))
    return next_palette

func toggle_eye_tracking():
    eye_tracking_active = !eye_tracking_active
    print("Eye tracking: " + ("Enabled" if eye_tracking_active else "Disabled"))
    return eye_tracking_active

func update_eye_position(position):
    # Update eye gaze position (normalized 0-1 coordinates)
    eye_position = position
    emit_signal("eye_gaze_tracked", position)
    
    # If shape exists, update its position
    if current_shape != "none" and eye_tracking_active:
        var properties = create_shape(current_shape)
        emit_signal("shape_changed", current_shape, properties)
    
    return eye_position

func randomize_shape_properties():
    if current_shape == "none":
        # Create a random shape if none exists
        var shapes = shape_patterns.values()
        current_shape = shapes[randi() % shapes.size()]
    
    # Randomize color
    var palettes = color_gradient.keys()
    var palette = palettes[randi() % palettes.size()]
    var colors = color_gradient[palette]
    current_color = colors[randi() % colors.size()]
    
    # Create shape with randomized properties
    var properties = create_shape(current_shape)
    
    # Add additional randomization
    properties["scale"] = Vector3(
        rand_range(0.5, 2.0),
        rand_range(0.5, 2.0),
        rand_range(0.5, 2.0)
    )
    
    properties["rotation"] = Vector3(
        rand_range(0, 360),
        rand_range(0, 360),
        rand_range(0, 360)
    )
    
    emit_signal("shape_changed", current_shape, properties)
    print("Randomized shape properties for: " + current_shape)
    return properties

func connect_to_github():
    # In a real implementation, would use GitHub API
    # For this demo, simulate GitHub connection
    github_connected = true
    
    # Simulate some repositories
    github_repos = [
        {
            "name": "godot-keyboard-tools",
            "url": "https://github.com/example/godot-keyboard-tools",
            "stars": 128,
            "forks": 32,
            "description": "Keyboard input tools for Godot"
        },
        {
            "name": "godot-shape-generator",
            "url": "https://github.com/example/godot-shape-generator",
            "stars": 85,
            "forks": 23,
            "description": "Procedural shape generation for Godot"
        },
        {
            "name": "eyetracking-godot",
            "url": "https://github.com/example/eyetracking-godot",
            "stars": 263,
            "forks": 87,
            "description": "Eye tracking integration for Godot"
        }
    ]
    
    emit_signal("tool_connected", "GitHub", github_connected)
    print("Connected to GitHub")
    return github_repos

func load_external_tools():
    # In a real implementation, would load tools from GitHub or other sources
    # For this demo, define some simulated tools
    external_tools = [
        {
            "name": "Shape Generator",
            "source": "github",
            "repo": "godot-shape-generator",
            "version": "1.2.3",
            "functions": ["generate_primitive", "export_shape", "animate_shape"]
        },
        {
            "name": "Color Palette Manager",
            "source": "local",
            "version": "0.9.1",
            "functions": ["create_palette", "blend_colors", "export_palette"]
        },
        {
            "name": "EyeTracker Pro",
            "source": "github",
            "repo": "eyetracking-godot",
            "version": "2.1.0",
            "functions": ["track_gaze", "generate_heatmap", "calibrate_tracking"]
        },
        {
            "name": "KeyboardMapper",
            "source": "github",
            "repo": "godot-keyboard-tools",
            "version": "1.0.5",
            "functions": ["map_keyboard", "create_custom_mapping", "export_layout"]
        }
    ]
    
    # For each tool, emit connected signal
    for tool in external_tools:
        emit_signal("tool_connected", tool["name"], true)
    
    print("Loaded " + str(external_tools.size()) + " external tools")
    return external_tools

func get_available_tools():
    # Return list of available tools
    return external_tools

func get_keyboard_stats():
    # Return statistics about keyboard usage
    var stats = {
        "active_keys": active_keys.size(),
        "total_keys_tracked": key_states.size(),
        "typing_speed": typing_speed,
        "typing_pattern": typing_pattern,
        "current_shape": current_shape,
        "current_color": current_color,
        "eye_tracking": eye_tracking_active
    }
    
    # Calculate most pressed keys
    var most_pressed = []
    var key_press_counts = {}
    
    for key in key_states:
        key_press_counts[key] = key_states[key]["press_count"]
    
    # Sort keys by press count
    var sorted_keys = key_press_counts.keys()
    sorted_keys.sort_custom(self, "_sort_by_press_count")
    
    # Get top 5 most pressed keys
    for i in range(min(5, sorted_keys.size())):
        most_pressed.append({
            "key": sorted_keys[i],
            "count": key_states[sorted_keys[i]]["press_count"]
        })
    
    stats["most_pressed_keys"] = most_pressed
    
    return stats

func _sort_by_press_count(a, b):
    return key_states[a]["press_count"] > key_states[b]["press_count"]

func set_keyboard_dimensions(dimensions):
    keyboard_dimensions = dimensions
    return keyboard_dimensions
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/keyboard_shape_manager.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/keyboard_shape_system.gd
# SIZE: 33815 bytes
extends Node

# Keyboard Shape System
# Creates visual representations of keyboard layouts and special key combinations
# Integrates with the terminal for keyboard-based shape visualization
# Supports # and ### command prefixes for different operation levels

class_name KeyboardShapeSystem

# Keyboard layouts
enum KeyboardLayout { 
	QWERTY, 
	DVORAK, 
	COLEMAK, 
	WORKMAN,
	CUSTOM 
}

# Keyboard visualization modes
enum VisualMode {
	TEXT,      # Simple text-based representation
	UNICODE,   # Unicode box-drawing characters
	EMOJI,     # Emoji-based visualization
	COLOR,     # Color-coded visualization
	ADVANCED   # Full 3D representation (for Godot integration)
}

# Key types for special highlighting
enum KeyType {
	NORMAL,
	SPECIAL,
	MODIFIER,
	FUNCTION,
	NAVIGATION,
	NUMPAD,
	CUSTOM
}

# Keyboard state and properties
var current_layout = KeyboardLayout.QWERTY
var current_mode = VisualMode.UNICODE
var special_keys = {
	"enter": {"symbol": "‚èé", "emoji": "‚Ü©Ô∏è", "color": Color(0.2, 0.8, 0.2)},
	"shift": {"symbol": "‚áß", "emoji": "‚¨ÜÔ∏è", "color": Color(0.8, 0.2, 0.2)},
	"ctrl": {"symbol": "‚åÉ", "emoji": "üéÆ", "color": Color(0.2, 0.2, 0.8)},
	"alt": {"symbol": "‚å•", "emoji": "‚öôÔ∏è", "color": Color(0.8, 0.8, 0.2)},
	"space": {"symbol": "‚ê£", "emoji": "‚¨ú", "color": Color(0.6, 0.6, 0.6)},
	"tab": {"symbol": "‚á•", "emoji": "‚û°Ô∏è", "color": Color(0.2, 0.7, 0.7)},
	"esc": {"symbol": "‚éã", "emoji": "üö™", "color": Color(0.8, 0.2, 0.8)},
	"backspace": {"symbol": "‚å´", "emoji": "‚óÄÔ∏è", "color": Color(0.7, 0.3, 0.3)},
	"capslock": {"symbol": "‚á™", "emoji": "üîí", "color": Color(0.5, 0.5, 0.8)},
	"win": {"symbol": "‚äû", "emoji": "ü™ü", "color": Color(0.3, 0.7, 0.3)},
	"cmd": {"symbol": "‚åò", "emoji": "üçé", "color": Color(0.7, 0.3, 0.7)},
	"fn": {"symbol": "∆ín", "emoji": "üî£", "color": Color(0.5, 0.5, 0.7)},
	"hash": {"symbol": "#", "emoji": "#Ô∏è‚É£", "color": Color(0.7, 0.7, 0.3)}
}

var terminal = null
var symbol_system = null

# Keyboard layouts as nested arrays
var layouts = {
	KeyboardLayout.QWERTY: [
		["q", "w", "e", "r", "t", "y", "u", "i", "o", "p"],
		["a", "s", "d", "f", "g", "h", "j", "k", "l"],
		["z", "x", "c", "v", "b", "n", "m"]
	],
	KeyboardLayout.DVORAK: [
		["'", ",", ".", "p", "y", "f", "g", "c", "r", "l"],
		["a", "o", "e", "u", "i", "d", "h", "t", "n", "s"],
		[";", "q", "j", "k", "x", "b", "m", "w", "v", "z"]
	],
	KeyboardLayout.COLEMAK: [
		["q", "w", "f", "p", "g", "j", "l", "u", "y", ";"],
		["a", "r", "s", "t", "d", "h", "n", "e", "i", "o"],
		["z", "x", "c", "v", "b", "k", "m"]
	],
	KeyboardLayout.WORKMAN: [
		["q", "d", "r", "w", "b", "j", "f", "u", "p", ";"],
		["a", "s", "h", "t", "g", "y", "n", "e", "o", "i"],
		["z", "x", "m", "c", "v", "k", "l"]
	],
	KeyboardLayout.CUSTOM: [
		["#", "1", "2", "3", "4", "5", "6", "7", "8", "9"],
		["@", "q", "w", "e", "r", "t", "y", "u", "i", "o"],
		["<", ">", "z", "x", "c", "v", "b", "n", "m", "p"]
	]
}

# Custom shapes for special visualizations
var shapes = {
	"arrow": [
		"   ‚ñ≤   ",
		"  ‚ñ≤‚ñ≤‚ñ≤  ",
		" ‚ñ≤‚ñ≤‚ñ≤‚ñ≤‚ñ≤ ",
		"‚ñ≤‚ñ≤‚ñ≤‚ñ≤‚ñ≤‚ñ≤‚ñ≤"
	],
	"diamond": [
		"   ‚óÜ   ",
		"  ‚óÜ‚óÜ‚óÜ  ",
		" ‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ ",
		"‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ",
		" ‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ ",
		"  ‚óÜ‚óÜ‚óÜ  ",
		"   ‚óÜ   "
	],
	"hashtag": [
		" ##### ",
		"#######",
		" ##### ",
		"#######",
		" ##### "
	],
	"crooked": [
		"  /\\  ",
		" /  \\ ",
		"/    \\",
		"\\    /",
		" \\  / ",
		"  \\/  "
	],
	"v": [
		"\\    /",
		" \\  / ",
		"  \\/  "
	]
}

func _ready():
	# Look for terminal system
	terminal = get_node_or_null("/root/IntegratedTerminal")
	
	if terminal and terminal.has_node("symbol_system"):
		symbol_system = terminal.get_node("symbol_system")
		
	if terminal and terminal.has_method("add_text"):
		terminal.add_text("Keyboard Shape System initialized.", "system")

# Process keyboard-related commands
func process_command(command):
	var parts = command.split(" ", true, 1)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"#keyboard", "#kb":
			process_keyboard_command(args)
			return true
		"#shape":
			process_shape_command(args)
			return true
		"##keyboard", "##kb":
			process_advanced_keyboard_command(args)
			return true
		"##shape":
			process_advanced_shape_command(args)
			return true
		"###keyboard", "###kb":
			process_system_keyboard_command(args)
			return true
		"###shape":
			process_system_shape_command(args)
			return true
		_:
			return false

# Process basic keyboard commands
func process_keyboard_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_keyboard_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"show":
			show_keyboard(subargs)
		"layout":
			set_keyboard_layout(subargs)
		"mode":
			set_visual_mode(subargs)
		"combo":
			show_key_combo(subargs)
		"key":
			show_key_info(subargs)
		"list":
			list_keyboard_options(subargs)
		"help":
			display_keyboard_help()
		_:
			log_message("Unknown keyboard command: " + subcmd, "error")

# Process basic shape commands
func process_shape_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_shape_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"show":
			show_shape(subargs)
		"list":
			list_shapes()
		"ascii":
			show_ascii_art(subargs)
		"help":
			display_shape_help()
		_:
			log_message("Unknown shape command: " + subcmd, "error")

# Process advanced keyboard commands
func process_advanced_keyboard_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_advanced_keyboard_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"highlight":
			highlight_keys(subargs)
		"animate":
			animate_keyboard(subargs)
		"custom":
			customize_key(subargs)
		"help":
			display_advanced_keyboard_help()
		_:
			log_message("Unknown advanced keyboard command: " + subcmd, "error")

# Process advanced shape commands
func process_advanced_shape_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_advanced_shape_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"create":
			create_custom_shape(subargs)
		"modify":
			modify_shape(subargs)
		"animate":
			animate_shape(subargs)
		"help":
			display_advanced_shape_help()
		_:
			log_message("Unknown advanced shape command: " + subcmd, "error")

# Process system keyboard commands
func process_system_keyboard_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_system_keyboard_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"reset":
			reset_keyboard_settings()
		"export":
			export_keyboard_layout(subargs)
		"import":
			import_keyboard_layout(subargs)
		"help":
			display_system_keyboard_help()
		_:
			log_message("Unknown system keyboard command: " + subcmd, "error")

# Process system shape commands
func process_system_shape_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_system_shape_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"reset":
			reset_shapes()
		"export":
			export_shapes(subargs)
		"import":
			import_shapes(subargs)
		"help":
			display_system_shape_help()
		_:
			log_message("Unknown system shape command: " + subcmd, "error")

# Show keyboard visualization
func show_keyboard(layout_name=""):
	if !layout_name.empty():
		set_keyboard_layout(layout_name)
	
	var layout_text = ""
	match current_layout:
		KeyboardLayout.QWERTY: layout_text = "QWERTY"
		KeyboardLayout.DVORAK: layout_text = "Dvorak"
		KeyboardLayout.COLEMAK: layout_text = "Colemak"
		KeyboardLayout.WORKMAN: layout_text = "Workman"
		KeyboardLayout.CUSTOM: layout_text = "Custom"
	
	log_message("Keyboard Layout: " + layout_text, "keyboard")
	
	var keyboard = generate_keyboard_visualization()
	for line in keyboard:
		log_message(line, "keyboard")

# Set keyboard layout
func set_keyboard_layout(layout_name):
	match layout_name.to_lower():
		"qwerty":
			current_layout = KeyboardLayout.QWERTY
			log_message("Keyboard layout set to QWERTY", "system")
		"dvorak":
			current_layout = KeyboardLayout.DVORAK
			log_message("Keyboard layout set to Dvorak", "system")
		"colemak":
			current_layout = KeyboardLayout.COLEMAK
			log_message("Keyboard layout set to Colemak", "system")
		"workman":
			current_layout = KeyboardLayout.WORKMAN
			log_message("Keyboard layout set to Workman", "system")
		"custom":
			current_layout = KeyboardLayout.CUSTOM
			log_message("Keyboard layout set to Custom", "system")
		_:
			log_message("Unknown keyboard layout: " + layout_name, "error")
			log_message("Available layouts: qwerty, dvorak, colemak, workman, custom", "system")

# Set visualization mode
func set_visual_mode(mode_name):
	match mode_name.to_lower():
		"text":
			current_mode = VisualMode.TEXT
			log_message("Visual mode set to Text", "system")
		"unicode":
			current_mode = VisualMode.UNICODE
			log_message("Visual mode set to Unicode", "system")
		"emoji":
			current_mode = VisualMode.EMOJI
			log_message("Visual mode set to Emoji", "system")
		"color":
			current_mode = VisualMode.COLOR
			log_message("Visual mode set to Color", "system")
		"advanced":
			current_mode = VisualMode.ADVANCED
			log_message("Visual mode set to Advanced", "system")
		_:
			log_message("Unknown visual mode: " + mode_name, "error")
			log_message("Available modes: text, unicode, emoji, color, advanced", "system")

# Show key combination visualization
func show_key_combo(combo):
	var keys = combo.split("+")
	
	if keys.size() < 1:
		log_message("Please specify a key combination (e.g. 'ctrl+shift+s')", "error")
		return
	
	log_message("Key Combination: " + combo, "keyboard")
	
	var combo_str = ""
	
	for i in range(keys.size()):
		var key = keys[i].strip_edges().to_lower()
		
		if special_keys.has(key):
			match current_mode:
				VisualMode.TEXT:
					combo_str += "[" + key.to_upper() + "]"
				VisualMode.UNICODE:
					combo_str += special_keys[key].symbol
				VisualMode.EMOJI:
					combo_str += special_keys[key].emoji
				_:
					combo_str += special_keys[key].symbol
		else:
			combo_str += key.to_upper()
			
		if i < keys.size() - 1:
			combo_str += " + "
			
	log_message("Visualization: " + combo_str, "keyboard")
	
	# Also highlight in keyboard if it's a simple key
	if keys.size() == 1 and keys[0].length() == 1:
		var highlight_map = {}
		highlight_map[keys[0].strip_edges().to_lower()] = Color(1, 0.5, 0.5)
		show_keyboard_with_highlights(highlight_map)

# Show information about a specific key
func show_key_info(key):
	key = key.strip_edges().to_lower()
	
	if key.length() > 1 and special_keys.has(key):
		log_message("Key Information: " + key.to_upper(), "keyboard")
		log_message("- Symbol: " + special_keys[key].symbol, "keyboard")
		log_message("- Emoji: " + special_keys[key].emoji, "keyboard")
		log_message("- Color: RGB(" + str(special_keys[key].color.r * 255) + ", " + 
							str(special_keys[key].color.g * 255) + ", " + 
							str(special_keys[key].color.b * 255) + ")", "keyboard")
	elif key.length() == 1:
		log_message("Key Information: " + key.to_upper(), "keyboard")
		log_message("- ASCII Code: " + str(key.to_ascii()[0]), "keyboard")
		log_message("- Hex: 0x" + "%X" % key.to_ascii()[0], "keyboard")
		
		# Also highlight in keyboard
		var highlight_map = {}
		highlight_map[key] = Color(1, 0.5, 0.5)
		show_keyboard_with_highlights(highlight_map)
	else:
		log_message("Unknown key: " + key, "error")

# List keyboard options
func list_keyboard_options(option_type=""):
	match option_type.to_lower():
		"layouts":
			log_message("Available Keyboard Layouts:", "system")
			log_message("- QWERTY - Standard English layout", "system")
			log_message("- Dvorak - Designed for typing efficiency", "system")
			log_message("- Colemak - Modern alternative to QWERTY", "system")
			log_message("- Workman - Optimized for common English words", "system")
			log_message("- Custom - User-defined layout", "system")
		"modes":
			log_message("Available Visualization Modes:", "system")
			log_message("- Text - Simple text representation", "system")
			log_message("- Unicode - Uses Unicode box-drawing characters", "system")
			log_message("- Emoji - Uses emoji for visualization", "system")
			log_message("- Color - Color-coded visualization", "system")
			log_message("- Advanced - Full 3D representation (Godot)", "system")
		"specials":
			log_message("Special Keys:", "system")
			for key in special_keys:
				log_message("- " + key + ": " + special_keys[key].symbol, "system")
		_:
			log_message("Available option types: layouts, modes, specials", "system")

# Show a predefined shape
func show_shape(shape_name):
	if shapes.has(shape_name.to_lower()):
		log_message("Shape: " + shape_name, "shape")
		for line in shapes[shape_name.to_lower()]:
			log_message(line, "shape")
	else:
		log_message("Unknown shape: " + shape_name, "error")
		log_message("Use '#shape list' to see available shapes", "system")

# List available shapes
func list_shapes():
	log_message("Available Shapes:", "system")
	for shape_name in shapes:
		log_message("- " + shape_name, "system")

# Show ASCII art (simulated)
func show_ascii_art(art_name):
	match art_name.to_lower():
		"keyboard":
			log_message("ASCII Keyboard:", "shape")
			log_message("‚îå‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê", "shape")
			log_message("‚îÇEsc‚îÇ ‚îÇF1 ‚îÇF2 ‚îÇF3 ‚îÇF4 ‚îÇ ‚îÇF5 ‚îÇF6 ‚îÇF7 ‚îÇF8 ‚îÇ ‚îÇF9 ‚îÇF10‚îÇF11‚îÇF12‚îÇ", "shape")
			log_message("‚îî‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îò", "shape")
			log_message("‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê", "shape")
			log_message("‚îÇ ~ ‚îÇ 1 ‚îÇ 2 ‚îÇ 3 ‚îÇ 4 ‚îÇ 5 ‚îÇ 6 ‚îÇ 7 ‚îÇ 8 ‚îÇ 9 ‚îÇ 0 ‚îÇ - ‚îÇ + ‚îÇ Bksp  ‚îÇ", "shape")
			log_message("‚îú‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§", "shape")
			log_message("‚îÇ Tab ‚îÇ Q ‚îÇ W ‚îÇ E ‚îÇ R ‚îÇ T ‚îÇ Y ‚îÇ U ‚îÇ I ‚îÇ O ‚îÇ P ‚îÇ [ ‚îÇ ] ‚îÇ  \\  ‚îÇ", "shape")
			log_message("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§", "shape")
			log_message("‚îÇ Caps ‚îÇ A ‚îÇ S ‚îÇ D ‚îÇ F ‚îÇ G ‚îÇ H ‚îÇ J ‚îÇ K ‚îÇ L ‚îÇ ; ‚îÇ ' ‚îÇ  Enter ‚îÇ", "shape")
			log_message("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§", "shape")
			log_message("‚îÇ Shift  ‚îÇ Z ‚îÇ X ‚îÇ C ‚îÇ V ‚îÇ B ‚îÇ N ‚îÇ M ‚îÇ , ‚îÇ . ‚îÇ / ‚îÇ   Shift  ‚îÇ", "shape")
			log_message("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚î¨‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚î¨‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚î¥‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§", "shape")
			log_message("‚îÇCtrl ‚îÇWin‚îÇ Alt ‚îÇ         Space         ‚îÇ Alt ‚îÇWin‚îÇ   Ctrl  ‚îÇ", "shape")
			log_message("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò", "shape")
		"hash":
			log_message("ASCII Hash:", "shape")
			log_message("   #     #   ", "shape")
			log_message(" ########### ", "shape")
			log_message("   #     #   ", "shape")
			log_message(" ########### ", "shape")
			log_message("   #     #   ", "shape")
		"computer":
			log_message("ASCII Computer:", "shape")
			log_message("     .---.      ", "shape")
			log_message("     |   |      ", "shape")
			log_message("     |   |      ", "shape")
			log_message(" .=========.    ", "shape")
			log_message(" |.-''''''-.|   ", "shape")
			log_message(" ||         ||  ", "shape")
			log_message(" ||         ||  ", "shape")
			log_message(" ||         ||  ", "shape")
			log_message(" |'---------'|  ", "shape")
			log_message(" `^'-------'`   ", "shape")
		"crooked":
			log_message("ASCII Crooked Brackets:", "shape")
			log_message("    /\\      ", "shape")
			log_message("   /  \\     ", "shape")
			log_message("  /    \\    ", "shape")
			log_message(" /      \\   ", "shape")
			log_message("/        \\  ", "shape")
			log_message("\\        /  ", "shape")
			log_message(" \\      /   ", "shape")
			log_message("  \\    /    ", "shape")
			log_message("   \\  /     ", "shape")
			log_message("    \\/      ", "shape")
		_:
			log_message("Unknown ASCII art: " + art_name, "error")
			log_message("Available options: keyboard, hash, computer, crooked", "system")

# Highlight specific keys on the keyboard
func highlight_keys(key_list):
	var keys = key_list.split(",")
	
	if keys.size() < 1:
		log_message("Please specify keys to highlight (e.g. 'a,s,d,f')", "error")
		return
	
	var highlight_map = {}
	for key in keys:
		var clean_key = key.strip_edges().to_lower()
		highlight_map[clean_key] = Color(1, 0.5, 0.5)  # Default highlight color
	
	log_message("Highlighting keys: " + key_list, "keyboard")
	show_keyboard_with_highlights(highlight_map)

# Animate keyboard (simulated)
func animate_keyboard(animation_type):
	match animation_type.to_lower():
		"typing":
			log_message("Typing Animation:", "keyboard")
			log_message("Press keys in sequence: H ‚Üí E ‚Üí L ‚Üí L ‚Üí O", "keyboard")
			
			var highlight_sequence = ["h", "e", "l", "l", "o"]
			for key in highlight_sequence:
				var highlight_map = {}
				highlight_map[key] = Color(1, 0.5, 0.5)
				show_keyboard_with_highlights(highlight_map)
				yield(get_tree().create_timer(0.5), "timeout")
				
			log_message("Animation complete: 'HELLO'", "keyboard")
		"wave":
			log_message("Wave Animation:", "keyboard")
			
			var wave_sequences = [
				["q", "w", "e", "r", "t", "y", "u", "i", "o", "p"],
				["a", "s", "d", "f", "g", "h", "j", "k", "l"],
				["z", "x", "c", "v", "b", "n", "m"]
			]
			
			for row in wave_sequences:
				var highlight_map = {}
				for key in row:
					highlight_map[key] = Color(0.5, 0.5, 1)
				show_keyboard_with_highlights(highlight_map)
				yield(get_tree().create_timer(0.3), "timeout")
				
			log_message("Wave animation complete", "keyboard")
		"rainbow":
			log_message("Rainbow Animation:", "keyboard")
			log_message("Animation not available in terminal mode", "keyboard")
			log_message("Use Godot interface for full visual effects", "keyboard")
		_:
			log_message("Unknown animation type: " + animation_type, "error")
			log_message("Available animations: typing, wave, rainbow", "system")

# Customize a key's appearance
func customize_key(args):
	var parts = args.split(" ", true, 2)
	
	if parts.size() < 3:
		log_message("Usage: ##keyboard custom <key> <property> <value>", "error")
		return
		
	var key = parts[0].strip_edges().to_lower()
	var property = parts[1].strip_edges().to_lower()
	var value = parts[2]
	
	if !special_keys.has(key):
		special_keys[key] = {"symbol": key, "emoji": key, "color": Color(0.8, 0.8, 0.8)}
	
	match property:
		"symbol":
			special_keys[key].symbol = value
			log_message("Updated symbol for key '" + key + "' to: " + value, "system")
		"emoji":
			special_keys[key].emoji = value
			log_message("Updated emoji for key '" + key + "' to: " + value, "system")
		"color":
			var color_parts = value.split(",")
			if color_parts.size() >= 3:
				var r = float(color_parts[0]) / 255.0
				var g = float(color_parts[1]) / 255.0
				var b = float(color_parts[2]) / 255.0
				special_keys[key].color = Color(r, g, b)
				log_message("Updated color for key '" + key + "' to RGB(" + value + ")", "system")
			else:
				log_message("Invalid color format. Use R,G,B values (0-255)", "error")
		_:
			log_message("Unknown property: " + property, "error")
			log_message("Available properties: symbol, emoji, color", "system")

# Create a custom shape
func create_custom_shape(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		log_message("Usage: ##shape create <name>", "error")
		log_message("Then enter each line of the shape, ending with ##shape end", "error")
		return
		
	var shape_name = parts[0].strip_edges().to_lower()
	
	log_message("Creating custom shape: " + shape_name, "system")
	log_message("Enter each line of the shape, then use ##shape end when done", "system")
	
	# In a real implementation, this would set up a shape creation mode
	# For this mock-up, we'll just create a sample shape
	
	shapes[shape_name] = [
		"Custom",
		"Shape",
		"Example"
	]
	
	log_message("Custom shape created! Use '#shape show " + shape_name + "' to view it.", "system")

# Modify an existing shape
func modify_shape(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		log_message("Usage: ##shape modify <name> [operation]", "error")
		return
		
	var shape_name = parts[0].strip_edges().to_lower()
	var operation = parts[1] if parts.size() > 1 else ""
	
	if !shapes.has(shape_name):
		log_message("Shape not found: " + shape_name, "error")
		return
	
	match operation.to_lower():
		"rotate":
			log_message("Rotating shape: " + shape_name, "system")
			# In a real implementation, this would actually rotate the shape
			log_message("Shape rotated", "system")
		"mirror":
			log_message("Mirroring shape: " + shape_name, "system")
			# In a real implementation, this would actually mirror the shape
			log_message("Shape mirrored", "system")
		"scale":
			log_message("Scaling shape: " + shape_name, "system")
			# In a real implementation, this would actually scale the shape
			log_message("Shape scaled", "system")
		_:
			log_message("Unknown operation: " + operation, "error")
			log_message("Available operations: rotate, mirror, scale", "system")

# Animate a shape (simulated)
func animate_shape(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		log_message("Usage: ##shape animate <name> [animation]", "error")
		return
		
	var shape_name = parts[0].strip_edges().to_lower()
	var animation = parts[1] if parts.size() > 1 else "pulse"
	
	if !shapes.has(shape_name):
		log_message("Shape not found: " + shape_name, "error")
		return
	
	log_message("Animating shape: " + shape_name + " (" + animation + ")", "system")
	
	# Show the shape multiple times to simulate animation
	for i in range(3):
		for line in shapes[shape_name]:
			log_message(line, "shape")
		yield(get_tree().create_timer(0.5), "timeout")
		log_message("", "shape")  # Empty line as separator
		yield(get_tree().create_timer(0.2), "timeout")
	
	log_message("Animation complete", "system")

# Reset keyboard settings
func reset_keyboard_settings():
	current_layout = KeyboardLayout.QWERTY
	current_mode = VisualMode.UNICODE
	
	# Reset special keys to defaults
	special_keys = {
		"enter": {"symbol": "‚èé", "emoji": "‚Ü©Ô∏è", "color": Color(0.2, 0.8, 0.2)},
		"shift": {"symbol": "‚áß", "emoji": "‚¨ÜÔ∏è", "color": Color(0.8, 0.2, 0.2)},
		"ctrl": {"symbol": "‚åÉ", "emoji": "üéÆ", "color": Color(0.2, 0.2, 0.8)},
		"alt": {"symbol": "‚å•", "emoji": "‚öôÔ∏è", "color": Color(0.8, 0.8, 0.2)},
		"space": {"symbol": "‚ê£", "emoji": "‚¨ú", "color": Color(0.6, 0.6, 0.6)},
		"tab": {"symbol": "‚á•", "emoji": "‚û°Ô∏è", "color": Color(0.2, 0.7, 0.7)},
		"esc": {"symbol": "‚éã", "emoji": "üö™", "color": Color(0.8, 0.2, 0.8)},
		"backspace": {"symbol": "‚å´", "emoji": "‚óÄÔ∏è", "color": Color(0.7, 0.3, 0.3)},
		"capslock": {"symbol": "‚á™", "emoji": "üîí", "color": Color(0.5, 0.5, 0.8)},
		"win": {"symbol": "‚äû", "emoji": "ü™ü", "color": Color(0.3, 0.7, 0.3)},
		"cmd": {"symbol": "‚åò", "emoji": "üçé", "color": Color(0.7, 0.3, 0.7)},
		"fn": {"symbol": "∆ín", "emoji": "üî£", "color": Color(0.5, 0.5, 0.7)},
		"hash": {"symbol": "#", "emoji": "#Ô∏è‚É£", "color": Color(0.7, 0.7, 0.3)}
	}
	
	log_message("Keyboard settings reset to defaults", "system")

# Export keyboard layout
func export_keyboard_layout(path):
	if path.empty():
		path = "user://keyboard_layout.dat"
	
	log_message("Exporting keyboard layout to: " + path, "system")
	
	# In a real implementation, this would save to a file
	# For this mock-up, we'll just simulate it
	
	yield(get_tree().create_timer(0.5), "timeout")
	log_message("Keyboard layout exported successfully", "system")

# Import keyboard layout
func import_keyboard_layout(path):
	if path.empty():
		path = "user://keyboard_layout.dat"
	
	log_message("Importing keyboard layout from: " + path, "system")
	
	# In a real implementation, this would load from a file
	# For this mock-up, we'll just simulate it
	
	yield(get_tree().create_timer(0.5), "timeout")
	log_message("Keyboard layout imported successfully", "system")

# Reset shapes
func reset_shapes():
	shapes = {
		"arrow": [
			"   ‚ñ≤   ",
			"  ‚ñ≤‚ñ≤‚ñ≤  ",
			" ‚ñ≤‚ñ≤‚ñ≤‚ñ≤‚ñ≤ ",
			"‚ñ≤‚ñ≤‚ñ≤‚ñ≤‚ñ≤‚ñ≤‚ñ≤"
		],
		"diamond": [
			"   ‚óÜ   ",
			"  ‚óÜ‚óÜ‚óÜ  ",
			" ‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ ",
			"‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ",
			" ‚óÜ‚óÜ‚óÜ‚óÜ‚óÜ ",
			"  ‚óÜ‚óÜ‚óÜ  ",
			"   ‚óÜ   "
		],
		"hashtag": [
			" ##### ",
			"#######",
			" ##### ",
			"#######",
			" ##### "
		],
		"crooked": [
			"  /\\  ",
			" /  \\ ",
			"/    \\",
			"\\    /",
			" \\  / ",
			"  \\/  "
		],
		"v": [
			"\\    /",
			" \\  / ",
			"  \\/  "
		]
	}
	
	log_message("Shapes reset to defaults", "system")

# Export shapes
func export_shapes(path):
	if path.empty():
		path = "user://shapes.dat"
	
	log_message("Exporting shapes to: " + path, "system")
	
	# In a real implementation, this would save to a file
	# For this mock-up, we'll just simulate it
	
	yield(get_tree().create_timer(0.5), "timeout")
	log_message("Shapes exported successfully", "system")

# Import shapes
func import_shapes(path):
	if path.empty():
		path = "user://shapes.dat"
	
	log_message("Importing shapes from: " + path, "system")
	
	# In a real implementation, this would load from a file
	# For this mock-up, we'll just simulate it
	
	yield(get_tree().create_timer(0.5), "timeout")
	log_message("Shapes imported successfully", "system")

# Generate keyboard visualization
func generate_keyboard_visualization():
	var current_keys = layouts[current_layout]
	var result = []
	
	match current_mode:
		VisualMode.TEXT:
			# Simple text mode
			for row in current_keys:
				var line = ""
				for key in row:
					line += "[" + key.to_upper() + "] "
				result.append(line)
		VisualMode.UNICODE:
			# Unicode box drawing characters
			for row in current_keys:
				var line = "‚îå"
				for i in range(row.size()):
					line += "‚îÄ‚îÄ‚îÄ"
					if i < row.size() - 1:
						line += "‚î¨"
				line += "‚îê"
				result.append(line)
				
				line = "‚îÇ"
				for key in row:
					if key.length() == 1:
						line += " " + key.to_upper() + " ‚îÇ"
					else:
						line += special_keys[key].symbol + "‚îÇ"
				result.append(line)
				
				line = "‚îî"
				for i in range(row.size()):
					line += "‚îÄ‚îÄ‚îÄ"
					if i < row.size() - 1:
						line += "‚î¥"
				line += "‚îò"
				result.append(line)
		VisualMode.EMOJI:
			# Emoji representation
			for row in current_keys:
				var line = ""
				for key in row:
					if special_keys.has(key):
						line += special_keys[key].emoji + " "
					else:
						line += key.to_upper() + "Ô∏è‚É£ "
				result.append(line)
		_:
			# Default to Unicode mode for other modes in this mock-up
			for row in current_keys:
				var line = "‚îå"
				for i in range(row.size()):
					line += "‚îÄ‚îÄ‚îÄ"
					if i < row.size() - 1:
						line += "‚î¨"
				line += "‚îê"
				result.append(line)
				
				line = "‚îÇ"
				for key in row:
					if key.length() == 1:
						line += " " + key.to_upper() + " ‚îÇ"
					else:
						line += special_keys[key].symbol + "‚îÇ"
				result.append(line)
				
				line = "‚îî"
				for i in range(row.size()):
					line += "‚îÄ‚îÄ‚îÄ"
					if i < row.size() - 1:
						line += "‚î¥"
				line += "‚îò"
				result.append(line)
	
	# Add special row for Enter, Space, etc. in Unicode mode
	if current_mode == VisualMode.UNICODE:
		result.append("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ" + "‚îÄ".repeat(15) + "‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
		result.append("‚îÇ " + special_keys["ctrl"].symbol + " ‚îÇ " + 
					  special_keys["alt"].symbol + " ‚îÇ " + 
					  special_keys["space"].symbol + " ".repeat(13) + "‚îÇ " + 
					  special_keys["enter"].symbol + " ‚îÇ")
		result.append("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ" + "‚îÄ".repeat(15) + "‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
	
	return result

# Show keyboard with highlighted keys
func show_keyboard_with_highlights(highlight_map):
	var current_keys = layouts[current_layout]
	var result = []
	
	# For simplicity, we'll use Unicode mode for highlighting
	for row in current_keys:
		var line = "‚îå"
		for i in range(row.size()):
			line += "‚îÄ‚îÄ‚îÄ"
			if i < row.size() - 1:
				line += "‚î¨"
		line += "‚îê"
		result.append(line)
		
		line = "‚îÇ"
		for key in row:
			if highlight_map.has(key):
				# Highlighted key
				line += "[H]‚îÇ"
			elif key.length() == 1:
				line += " " + key.to_upper() + " ‚îÇ"
			else:
				line += special_keys[key].symbol + "‚îÇ"
		result.append(line)
		
		line = "‚îî"
		for i in range(row.size()):
			line += "‚îÄ‚îÄ‚îÄ"
			if i < row.size() - 1:
				line += "‚î¥"
		line += "‚îò"
		result.append(line)
	
	# Add special row for Enter, Space, etc.
	result.append("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ" + "‚îÄ".repeat(15) + "‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
	
	var line = "‚îÇ "
	if highlight_map.has("ctrl"):
		line += "[H]"
	else:
		line += special_keys["ctrl"].symbol + " "
	
	line += "‚îÇ "
	if highlight_map.has("alt"):
		line += "[H]"
	else:
		line += special_keys["alt"].symbol + " "
	
	line += "‚îÇ "
	if highlight_map.has("space"):
		line += "[H]" + " ".repeat(13)
	else:
		line += special_keys["space"].symbol + " ".repeat(13)
	
	line += "‚îÇ "
	if highlight_map.has("enter"):
		line += "[H]"
	else:
		line += special_keys["enter"].symbol + " "
	
	line += "‚îÇ"
	result.append(line)
	
	result.append("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ" + "‚îÄ".repeat(15) + "‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
	
	# Display the result
	for line in result:
		log_message(line, "keyboard")

# Display keyboard help
func display_keyboard_help():
	log_message("Keyboard Commands:", "system")
	log_message("  #keyboard show [layout] - Display keyboard layout", "system")
	log_message("  #keyboard layout <name> - Set keyboard layout", "system")
	log_message("  #keyboard mode <mode> - Set visualization mode", "system")
	log_message("  #keyboard combo <keys> - Show key combination", "system")
	log_message("  #keyboard key <key> - Show key information", "system")
	log_message("  #keyboard list [option] - List keyboard options", "system")
	log_message("  #keyboard help - Display this help", "system")
	log_message("", "system")
	log_message("For advanced keyboard commands, type ##keyboard help", "system")

# Display shape help
func display_shape_help():
	log_message("Shape Commands:", "system")
	log_message("  #shape show <name> - Display a predefined shape", "system")
	log_message("  #shape list - List available shapes", "system")
	log_message("  #shape ascii <type> - Show ASCII art", "system")
	log_message("  #shape help - Display this help", "system")
	log_message("", "system")
	log_message("For advanced shape commands, type ##shape help", "system")

# Display advanced keyboard help
func display_advanced_keyboard_help():
	log_message("Advanced Keyboard Commands:", "system")
	log_message("  ##keyboard highlight <keys> - Highlight specific keys", "system")
	log_message("  ##keyboard animate <type> - Animate the keyboard", "system")
	log_message("  ##keyboard custom <key> <property> <value> - Customize key appearance", "system")
	log_message("  ##keyboard help - Display this help", "system")

# Display advanced shape help
func display_advanced_shape_help():
	log_message("Advanced Shape Commands:", "system")
	log_message("  ##shape create <name> - Create a custom shape", "system")
	log_message("  ##shape modify <name> <operation> - Modify a shape", "system")
	log_message("  ##shape animate <name> [animation] - Animate a shape", "system")
	log_message("  ##shape help - Display this help", "system")

# Display system keyboard help
func display_system_keyboard_help():
	log_message("System Keyboard Commands:", "system")
	log_message("  ###keyboard reset - Reset keyboard settings", "system")
	log_message("  ###keyboard export [path] - Export keyboard layout", "system")
	log_message("  ###keyboard import [path] - Import keyboard layout", "system")
	log_message("  ###keyboard help - Display this help", "system")

# Display system shape help
func display_system_shape_help():
	log_message("System Shape Commands:", "system")
	log_message("  ###shape reset - Reset shapes to defaults", "system")
	log_message("  ###shape export [path] - Export shapes", "system")
	log_message("  ###shape import [path] - Import shapes", "system")
	log_message("  ###shape help - Display this help", "system")

# Log a message to the terminal
func log_message(message, category="keyboard"):
	print(message)
	
	if terminal and terminal.has_method("add_text"):
		terminal.add_text(message, category)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/keyboard_shape_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/main.gd
# SIZE: 13908 bytes
extends Node

# Main controller for JSH 12-turn system with divine word processing
# Integrates with 3D notepad visualization, multiverse evolution, and divine memory

# ----- SYSTEM CONSTANTS -----
const TURNS_PER_SECOND = 12 # 12 turns per second for quantum speed
const TURN_DURATION = 1.0 / TURNS_PER_SECOND
const MAX_TURNS = 12
const AUTO_SAVE_INTERVAL = 60.0 # Save every minute

# ----- COSMIC AGES -----
var cosmic_ages = [
    "Genesis", "Formation", "Complexity", "Consciousness", 
    "Awakening", "Enlightenment", "Manifestation", "Connection", 
    "Harmony", "Transcendence", "Unity", "Beyond"
]

var turn_symbols = ["Œ±", "Œ≤", "Œ≥", "Œ¥", "Œµ", "Œ∂", "Œ∑", "Œ∏", "Œπ", "Œ∫", "Œª", "Œº"]
var turn_dimensions = ["1D", "2D", "3D", "4D", "5D", "6D", "7D", "8D", "9D", "10D", "11D", "12D"]

# ----- STATE VARIABLES -----
var current_turn = 3 # Starting at gamma (3D - Space)
var current_age_index = 0
var turn_timer = 0.0
var auto_advance_turns = false
var time_since_last_save = 0.0
var quantum_loop_active = false
var big_bang_timestamp = 0
var universe_age = 0

# ----- COMPONENT REFERENCES -----
var word_processor: DivineWordProcessor
var turn_history = []
var current_notes = {}
var active_objects = []

# ----- SIGNALS -----
signal turn_advanced(turn_number, symbol, dimension)
signal note_created(note_data)
signal word_manifested(word, position, power)
signal reality_changed(reality_data)

# ----- INITIALIZATION -----
func _ready():
    print("JSH 12-Turn System initializing...")
    
    # Initialize word processor
    word_processor = DivineWordProcessor.new()
    add_child(word_processor)
    
    # Connect signals
    word_processor.connect("word_processed", self, "_on_word_processed")
    word_processor.connect("reality_created", self, "_on_reality_created")
    word_processor.connect("memory_stored", self, "_on_memory_stored")
    
    # Record big bang timestamp
    big_bang_timestamp = OS.get_unix_time()
    
    # Setup folders
    _ensure_directories_exist()
    
    # Initial turn setup
    _set_current_turn(current_turn)
    
    # Initial status message
    print("System initialized at Turn %d: %s - %s - %s" % 
          [current_turn, turn_symbols[current_turn-1], turn_dimensions[current_turn-1], cosmic_ages[current_turn-1]])
    
    # Initial memory creation
    word_processor.process_text("JSH 12-Turn System has been initialized in the " + cosmic_ages[current_turn-1] + " age", "system", 3)

# ----- PROCESS FUNCTION -----
func _process(delta):
    # Update universe age
    universe_age = OS.get_unix_time() - big_bang_timestamp
    
    # Handle automatic turn advancement
    if quantum_loop_active or auto_advance_turns:
        turn_timer += delta
        
        if turn_timer >= TURN_DURATION:
            turn_timer -= TURN_DURATION
            advance_turn()
    
    # Auto-save timer
    time_since_last_save += delta
    if time_since_last_save >= AUTO_SAVE_INTERVAL:
        time_since_last_save = 0
        auto_save()

# ----- TURN MANAGEMENT -----
func advance_turn():
    var prev_turn = current_turn
    
    # Advance to next turn
    current_turn = (current_turn % MAX_TURNS) + 1
    
    # Record in turn history
    _record_turn_transition(prev_turn, current_turn)
    
    # Update current turn state
    _set_current_turn(current_turn)
    
    # Emit signal
    emit_signal("turn_advanced", current_turn, turn_symbols[current_turn-1], turn_dimensions[current_turn-1])
    
    # Log turn advancement
    print("Advanced to Turn %d: %s - %s - %s" % 
          [current_turn, turn_symbols[current_turn-1], turn_dimensions[current_turn-1], cosmic_ages[current_turn-1]])
    
    # Check for age advancement
    if current_turn == 1:
        advance_age()
    
    return current_turn

func advance_age():
    current_age_index = (current_age_index + 1) % cosmic_ages.size()
    
    # Log age advancement
    print("Advanced to new cosmic age: %s" % cosmic_ages[current_age_index])
    
    # Create memory of age advancement
    word_processor.process_text("Entering new cosmic age: " + cosmic_ages[current_age_index], "system", 2)
    
    return cosmic_ages[current_age_index]

func _set_current_turn(turn_number):
    current_turn = turn_number
    
    # Save current turn to file for external systems
    var file = File.new()
    file.open("user://current_turn.txt", File.WRITE)
    file.store_string(str(current_turn))
    file.close()
    
    # Save to system directory for bash integration
    _save_to_system_dir("current_turn.txt", str(current_turn))

func _record_turn_transition(from_turn, to_turn):
    var transition = {
        "from_turn": from_turn,
        "to_turn": to_turn,
        "from_symbol": turn_symbols[from_turn-1],
        "to_symbol": turn_symbols[to_turn-1],
        "from_dimension": turn_dimensions[from_turn-1],
        "to_dimension": turn_dimensions[to_turn-1],
        "timestamp": OS.get_unix_time(),
        "universe_age": universe_age
    }
    
    turn_history.append(transition)
    
    # Keep history at reasonable size
    if turn_history.size() > 1000:
        turn_history.pop_front()

# ----- NOTE MANAGEMENT -----
func create_note(text, position=Vector3(0,0,0)):
    # Process the text through divine word processor
    var result = word_processor.process_text(text, "note", 1)
    
    # Create note data with positioning
    var note_id = "note_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
    var note_data = {
        "id": note_id,
        "text": result.corrected,
        "position": position,
        "turn": current_turn,
        "turn_symbol": turn_symbols[current_turn-1],
        "dimension": turn_dimensions[current_turn-1],
        "timestamp": OS.get_unix_time(),
        "power": result.total_power,
        "powerful_words": result.powerful_words
    }
    
    # Store the note
    current_notes[note_id] = note_data
    
    # Save note to file
    _save_note_to_file(note_data)
    
    # Emit signal
    emit_signal("note_created", note_data)
    
    print("Note created in Turn %d (%s - %s)" % 
          [current_turn, turn_symbols[current_turn-1], turn_dimensions[current_turn-1]])
    
    # Special processing for high-power notes
    if result.total_power > 50:
        _manifest_powerful_note(note_data)
    
    return note_data

func get_notes_for_current_turn():
    var turn_notes = []
    
    for note_id in current_notes:
        if current_notes[note_id].turn == current_turn:
            turn_notes.append(current_notes[note_id])
    
    return turn_notes

func _manifest_powerful_note(note_data):
    print("Powerful note manifesting in reality!")
    
    # Extract powerful words from the note
    for word_data in note_data.powerful_words:
        var word = word_data.word
        var power = word_data.power
        
        # Calculate position based on note position with slight randomization
        var pos = note_data.position + Vector3(
            rand_range(-1, 1),
            rand_range(-1, 1),
            rand_range(-1, 1)
        )
        
        # Emit signal for 3D visualization
        emit_signal("word_manifested", word, pos, power)
        
        # Add to active objects
        active_objects.append({
            "word": word,
            "position": pos,
            "power": power,
            "creation_turn": current_turn,
            "age": universe_age
        })

# ----- QUANTUM LOOP FUNCTIONS -----
func start_quantum_loop():
    quantum_loop_active = true
    turn_timer = 0
    print("Quantum loop started - 12 turns per second")
    
    # Create memory
    word_processor.process_text("Quantum loop activated at 12 turns per second in the " + cosmic_ages[current_age_index] + " age", "system", 2)
    
    return true

func stop_quantum_loop():
    quantum_loop_active = false
    print("Quantum loop stopped")
    
    # Create memory
    word_processor.process_text("Quantum loop deactivated in the " + cosmic_ages[current_age_index] + " age", "system", 2)
    
    return false

# ----- FILE OPERATIONS -----
func _ensure_directories_exist():
    var dir = Directory.new()
    
    # Ensure save directories exist
    if !dir.dir_exists("user://notes"):
        dir.make_dir_recursive("user://notes")
    
    if !dir.dir_exists("user://realities"):
        dir.make_dir_recursive("user://realities")
    
    if !dir.dir_exists("user://turns"):
        dir.make_dir_recursive("user://turns")

func _save_note_to_file(note_data):
    var file = File.new()
    var note_path = "user://notes/note_" + note_data.id + ".json"
    
    file.open(note_path, File.WRITE)
    file.store_string(JSON.print(note_data, "  "))
    file.close()

func _save_to_system_dir(filename, content):
    # This attempts to write to the system directory for bash script integration
    # NOTE: This might require proper permissions and won't work in all environments
    var file = File.new()
    var system_path = "/mnt/c/Users/Percision 15/12_turns_system/" + filename
    
    var err = file.open(system_path, File.WRITE)
    if err == OK:
        file.store_string(content)
        file.close()

# ----- SAVE & LOAD -----
func auto_save():
    var save_name = "autosave_turn_" + str(current_turn)
    save_reality(save_name)
    
    # Log autosave
    print("Auto-saved reality state at Turn %d" % current_turn)
    
    return save_name

func save_reality(save_name):
    # Use word processor to save reality state
    var save_data = word_processor.save_reality_state(save_name)
    
    # Add turn-specific data
    save_data.turn = current_turn
    save_data.turn_symbol = turn_symbols[current_turn-1]
    save_data.dimension = turn_dimensions[current_turn-1]
    save_data.age = cosmic_ages[current_age_index]
    save_data.universe_age = universe_age
    save_data.notes = current_notes.duplicate()
    save_data.quantum_loop_active = quantum_loop_active
    
    # Create memory of reality save
    word_processor.process_text("Reality state saved as: " + save_name, "system", 2)
    
    return save_data

# ----- EVENT HANDLERS -----
func _on_word_processed(word, power):
    # Handle word processing event
    if power > 75:
        print("Divine word detected: %s (Power: %d)" % [word, power])

func _on_reality_created(reality_data):
    # Handle reality creation event
    emit_signal("reality_changed", reality_data)
    
    # Add special effect if this is a very powerful reality
    if reality_data.is_persistent:
        print("A persistent reality has formed...")
        
        # This would trigger special visualization in the actual game

func _on_memory_stored(memory_data):
    # Handle memory stored event
    if memory_data.tier == 3:
        print("Eternal memory has been preserved in Tier 3")

# ----- COMMAND FUNCTIONS -----
func execute_command(command_text):
    # Parse command
    var parts = command_text.split(" ", true, 1)
    var command = parts[0].strip_edges().to_lower()
    var args = parts[1] if parts.size() > 1 else ""
    
    # Process command
    match command:
        "/turn":
            return advance_turn()
            
        "/loop":
            if quantum_loop_active:
                return stop_quantum_loop()
            else:
                return start_quantum_loop()
        
        "/note":
            if args.strip_edges().empty():
                return "Error: Note text required"
            return create_note(args)
        
        "/save":
            var name = args.strip_edges()
            if name.empty():
                name = "manual_save_" + str(OS.get_unix_time())
            return save_reality(name)
        
        "/status":
            return show_status()
        
        "/word-power":
            if args.strip_edges().empty():
                return "Error: Word required"
            var word = args.strip_edges()
            var power = word_processor.check_word_power(word)
            print("The word '%s' has power: %d" % [word, power])
            return power
        
        "/memory":
            if args.strip_edges().empty():
                return "Error: Memory text required"
            var tier = 1
            if args.ends_with(" 2"):
                tier = 2
                args = args.substr(0, args.length() - 2).strip_edges()
            elif args.ends_with(" 3"):
                tier = 3
                args = args.substr(0, args.length() - 2).strip_edges()
            
            var result = word_processor.process_text(args, "command", tier)
            return "Memory created with power: " + str(result.total_power)
        
        "/memories":
            return show_memories()
            
        _:
            print("Unknown command: " + command)
            return "Unknown command: " + command

func show_status():
    var status = word_processor.get_divine_status()
    
    var status_text = """
=== DIVINE STATUS ===
Turn: %d (%s - %s)
Age: %s
Universe Age: %d seconds
Divine Level: %d (%s)
Words Processed: %d
Realities Created: %d
Memories: %d
Notes: %d
Quantum Loop: %s
""" % [
        current_turn, turn_symbols[current_turn-1], turn_dimensions[current_turn-1],
        cosmic_ages[current_age_index],
        universe_age,
        status.level, status.status,
        status.words_processed,
        status.realities_created,
        status.memory_count,
        current_notes.size(),
        "Active" if quantum_loop_active else "Inactive"
    ]
    
    print(status_text)
    return status

func show_memories():
    var all_memories = []
    
    # Get memories from each tier
    for tier in range(1, 4):
        var tier_memories = word_processor.get_memories_by_tier(tier)
        print("=== TIER %d MEMORIES (%d) ===" % [tier, tier_memories.size()])
        
        for memory in tier_memories:
            print("- \"%s\" (Power: %d)" % [memory.text, memory.power])
            all_memories.append(memory)
    
    return all_memories
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/main.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/main_controller.gd
# SIZE: 13168 bytes
extends Node

class_name MainController

# ----- REFERENCES -----
var screen_capture = null
var ocr_processor = null
var offline_ocr = null
var auto_updater = null
var auto_connector = null
var color_theme_system = null
var task_animator = null

# ----- CONFIGURATION -----
@export var auto_initialize: bool = true
@export var debug_mode: bool = false
@export var default_theme: String = "default"
@export var enable_animations: bool = true
@export var enable_auto_updates: bool = true
@export var enable_auto_connection: bool = true
@export var capture_hotkey: String = "Ctrl+Shift+P"
@export var ocr_hotkey: String = "Ctrl+Shift+O"

# ----- SIGNALS -----
signal initialization_completed()
signal component_initialized(component_name)
signal component_failed(component_name, error)
signal capture_completed(image_path)
signal ocr_completed(text)
signal theme_changed(theme_name)
signal connection_status_changed(status)

# ----- INITIALIZATION -----
func _ready():
    # Initialize systems
    if auto_initialize:
        initialize_all()
    
    print("Main Controller initialized")

func initialize_all() -> void:
    print("Initializing all components...")
    
    # Attempt to find existing systems first
    _find_existing_systems()
    
    # Create any missing systems
    _create_missing_systems()
    
    # Connect signals
    _connect_signals()
    
    # Initialize default settings
    _initialize_default_settings()
    
    emit_signal("initialization_completed")
    
    print("All components initialized")

func _find_existing_systems():
    # Find existing screen capture system
    screen_capture = get_node_or_null("/root/ScreenCaptureUtility")
    if not screen_capture:
        screen_capture = _find_node_by_class(get_tree().root, "ScreenCaptureUtility")
    
    # Find existing OCR processor
    ocr_processor = get_node_or_null("/root/OCRProcessor")
    if not ocr_processor:
        ocr_processor = _find_node_by_class(get_tree().root, "OCRProcessor")
    
    # Find existing offline OCR processor
    offline_ocr = get_node_or_null("/root/OfflineOCRProcessor")
    if not offline_ocr:
        offline_ocr = _find_node_by_class(get_tree().root, "OfflineOCRProcessor")
    
    # Find existing auto updater
    auto_updater = get_node_or_null("/root/AutoUpdater")
    if not auto_updater:
        auto_updater = _find_node_by_class(get_tree().root, "AutoUpdater")
    
    # Find existing auto connector
    auto_connector = get_node_or_null("/root/AutoConnector")
    if not auto_connector:
        auto_connector = _find_node_by_class(get_tree().root, "AutoConnector")
    
    # Find existing color theme system
    color_theme_system = get_node_or_null("/root/ExtendedColorThemeSystem")
    if not color_theme_system:
        color_theme_system = _find_node_by_class(get_tree().root, "ExtendedColorThemeSystem")
    
    # If not found, try other color systems
    if not color_theme_system:
        color_theme_system = get_node_or_null("/root/DimensionalColorSystem")
        if not color_theme_system:
            color_theme_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find existing task animator
    task_animator = get_node_or_null("/root/TaskTransitionAnimator")
    if not task_animator:
        task_animator = _find_node_by_class(get_tree().root, "TaskTransitionAnimator")

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _create_missing_systems():
    # Create screen capture if missing
    if not screen_capture:
        screen_capture = ScreenCaptureUtility.new()
        add_child(screen_capture)
        print("Created ScreenCaptureUtility")
        emit_signal("component_initialized", "ScreenCaptureUtility")
    
    # Create OCR processor if missing
    if not ocr_processor:
        ocr_processor = OCRProcessor.new()
        add_child(ocr_processor)
        print("Created OCRProcessor")
        emit_signal("component_initialized", "OCRProcessor")
    
    # Create offline OCR processor if missing
    if not offline_ocr:
        offline_ocr = OfflineOCRProcessor.new()
        add_child(offline_ocr)
        print("Created OfflineOCRProcessor")
        emit_signal("component_initialized", "OfflineOCRProcessor")
    
    # Create auto updater if missing
    if not auto_updater:
        auto_updater = AutoUpdater.new()
        add_child(auto_updater)
        print("Created AutoUpdater")
        emit_signal("component_initialized", "AutoUpdater")
    
    # Create auto connector if missing
    if not auto_connector:
        auto_connector = AutoConnector.new()
        add_child(auto_connector)
        print("Created AutoConnector")
        emit_signal("component_initialized", "AutoConnector")
    
    # Create color theme system if missing
    if not color_theme_system:
        color_theme_system = ExtendedColorThemeSystem.new()
        add_child(color_theme_system)
        print("Created ExtendedColorThemeSystem")
        emit_signal("component_initialized", "ExtendedColorThemeSystem")
    
    # Create task animator if missing
    if not task_animator:
        task_animator = TaskTransitionAnimator.new()
        add_child(task_animator)
        print("Created TaskTransitionAnimator")
        emit_signal("component_initialized", "TaskTransitionAnimator")

func _connect_signals():
    # Connect screen capture signals
    if screen_capture:
        screen_capture.connect("capture_completed", Callable(self, "_on_capture_completed"))
        screen_capture.connect("capture_failed", Callable(self, "_on_capture_failed"))
    
    # Connect OCR processor signals
    if ocr_processor:
        ocr_processor.connect("processing_completed", Callable(self, "_on_ocr_completed"))
        ocr_processor.connect("processing_failed", Callable(self, "_on_ocr_failed"))
    
    # Connect offline OCR processor signals
    if offline_ocr:
        offline_ocr.connect("processing_completed", Callable(self, "_on_offline_ocr_completed"))
        offline_ocr.connect("processing_failed", Callable(self, "_on_offline_ocr_failed"))
    
    # Connect auto updater signals
    if auto_updater:
        auto_updater.connect("update_available", Callable(self, "_on_update_available"))
        auto_updater.connect("update_check_failed", Callable(self, "_on_update_check_failed"))
    
    # Connect auto connector signals
    if auto_connector:
        auto_connector.connect("connection_status_changed", Callable(self, "_on_connection_status_changed"))
        auto_connector.connect("all_connections_established", Callable(self, "_on_all_connections_established"))
    
    # Connect color theme system signals
    if color_theme_system:
        color_theme_system.connect("theme_changed", Callable(self, "_on_theme_changed"))
    
    # Connect task animator signals
    if task_animator:
        task_animator.connect("transition_completed", Callable(self, "_on_transition_completed"))

func _initialize_default_settings():
    # Initialize default settings for each system
    
    # Screen capture settings
    if screen_capture:
        screen_capture.default_capture_method = "native"
        screen_capture.capture_format = "png"
    
    # OCR processor settings
    if ocr_processor:
        # No special settings needed
        pass
    
    # Offline OCR processor settings
    if offline_ocr:
        # No special settings needed
        pass
    
    # Auto updater settings
    if auto_updater:
        auto_updater.auto_download_updates = enable_auto_updates
    
    # Auto connector settings
    if auto_connector:
        auto_connector.auto_connect_on_startup = enable_auto_connection
    
    # Color theme system settings
    if color_theme_system:
        color_theme_system.apply_theme(default_theme, false)
    
    # Task animator settings
    if task_animator:
        task_animator.enabled = enable_animations

# ----- EVENT HANDLERS -----
func _on_capture_completed(capture_id, image_path):
    print("Capture completed: " + image_path)
    emit_signal("capture_completed", image_path)
    
    # Automatically perform OCR if both systems are available
    if ocr_processor and screen_capture:
        ocr_processor.process_image(image_path)

func _on_capture_failed(capture_id, error):
    print("Capture failed: " + error)
    
    if debug_mode:
        print_debug("Capture failure details: ID=" + capture_id + ", Error=" + error)

func _on_ocr_completed(image_id, results):
    print("OCR completed for image: " + image_id)
    emit_signal("ocr_completed", results.text)
    
    # Log OCR results for debugging
    if debug_mode:
        print_debug("OCR results: " + results.text.substr(0, 100) + "...")
        print_debug("OCR confidence: " + str(results.confidence))

func _on_ocr_failed(image_id, error):
    print("OCR failed for image: " + image_id)
    print("Error: " + error)
    
    # Try offline OCR as fallback
    if offline_ocr:
        print("Trying offline OCR as fallback...")
        offline_ocr.process_image(screen_capture.get_last_capture_path())

func _on_offline_ocr_completed(image_id, results):
    print("Offline OCR completed for image: " + image_id)
    emit_signal("ocr_completed", results.text)

func _on_offline_ocr_failed(image_id, error):
    print("Offline OCR failed for image: " + image_id)
    print("Error: " + error)

func _on_update_available(version, release_notes):
    print("Update available: " + version)
    print("Release notes: " + release_notes)
    
    # Auto-download if enabled
    if enable_auto_updates and auto_updater:
        auto_updater.download_update()

func _on_update_check_failed(error):
    print("Update check failed: " + error)

func _on_connection_status_changed(type, status):
    print("Connection status changed: " + type + " -> " + status)
    emit_signal("connection_status_changed", type + ":" + status)

func _on_all_connections_established():
    print("All connections established")

func _on_theme_changed(theme_name):
    print("Theme changed to: " + theme_name)
    emit_signal("theme_changed", theme_name)

func _on_transition_completed(id, type, task):
    print("Transition completed: " + str(id) + " to task " + task)

# ----- PUBLIC API -----
func capture_screen() -> void:
    if screen_capture:
        screen_capture.capture_screen()
    else:
        print("Screen capture utility not available")

func perform_ocr(image_path: String) -> void:
    if ocr_processor:
        ocr_processor.process_image(image_path)
    else:
        print("OCR processor not available")

func capture_and_ocr() -> void:
    if screen_capture and ocr_processor:
        var capture_id = screen_capture.capture_screen()
        # OCR will be triggered by capture_completed signal
    else:
        print("Screen capture or OCR processor not available")

func change_theme(theme_name: String) -> void:
    if color_theme_system:
        color_theme_system.apply_theme(theme_name)
    else:
        print("Color theme system not available")

func check_for_updates() -> void:
    if auto_updater:
        auto_updater.check_for_updates()
    else:
        print("Auto updater not available")

func connect_services() -> void:
    if auto_connector:
        auto_connector.connect_all()
    else:
        print("Auto connector not available")

func get_system_status() -> Dictionary:
    var status = {
        "screen_capture": screen_capture != null,
        "ocr_processor": ocr_processor != null,
        "offline_ocr": offline_ocr != null,
        "auto_updater": auto_updater != null,
        "auto_connector": auto_connector != null,
        "color_theme_system": color_theme_system != null,
        "task_animator": task_animator != null,
        "current_theme": color_theme_system.current_theme if color_theme_system else "unknown",
        "animations_enabled": task_animator.enabled if task_animator else false,
        "auto_updates_enabled": auto_updater.auto_download_updates if auto_updater else false,
        "auto_connection_enabled": auto_connector.auto_connect_on_startup if auto_connector else false,
    }
    
    return status

# ----- INPUT HANDLING -----
func _input(event):
    # Handle keyboard shortcuts
    if event is InputEventKey and event.pressed:
        # Check for capture hotkey (Ctrl+Shift+P)
        if event.ctrl_pressed and event.shift_pressed and event.keycode == KEY_P:
            capture_screen()
        
        # Check for OCR hotkey (Ctrl+Shift+O)
        if event.ctrl_pressed and event.shift_pressed and event.keycode == KEY_O:
            if screen_capture:
                var last_capture = screen_capture.get_last_capture_path()
                if last_capture:
                    perform_ocr(last_capture)
                else:
                    print("No recent capture available for OCR")
            else:
                print("Screen capture utility not available")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/main_controller.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/memory_investment_interface.gd
# SIZE: 8853 bytes
extends Control

# Memory Investment Interface
# Provides visual interface for the memory investment system

@onready var investment_system = $"../MemoryInvestmentSystem"
@onready var direction_tracker = $"../WordDirectionTracker"

# UI Elements
var word_input: LineEdit
var category_dropdown: OptionButton
var invest_button: Button
var word_list: ItemList
var direction_display: RichTextLabel
var value_display: Label
var visualization: SubViewport

const CATEGORIES = ["Knowledge", "Insight", "Creation", "Connection", "Memory", "Dream", "Ethereal"]
const COLOR_GRADIENT = [
    Color(0.5, 0.7, 0.9, 0.8),  # Light Blue
    Color(0.4, 0.6, 0.9, 0.8),  # Eve Blue
    Color(0.3, 0.5, 0.9, 0.8),  # Deep Blue
    Color(0.4, 0.4, 0.8, 0.8)   # Twilight Blue
]

func _ready():
    # Create UI elements
    _setup_ui()
    
    # Connect signals
    invest_button.pressed.connect(_on_invest_pressed)
    word_list.item_selected.connect(_on_word_selected)
    
    # Update timer
    var timer = Timer.new()
    timer.wait_time = 0.5
    timer.autostart = true
    timer.timeout.connect(_update_display)
    add_child(timer)
    
    # Initial update
    _update_display()

func _setup_ui():
    # Input area
    var input_container = VBoxContainer.new()
    input_container.set_anchors_preset(PRESET_LEFT_WIDE)
    input_container.custom_minimum_size = Vector2(280, 0)
    add_child(input_container)
    
    var title = Label.new()
    title.text = "Memory Investment"
    title.add_theme_font_size_override("font_size", 18)
    input_container.add_child(title)
    
    input_container.add_child(HSeparator.new())
    
    var word_label = Label.new()
    word_label.text = "Enter Word to Invest:"
    input_container.add_child(word_label)
    
    word_input = LineEdit.new()
    word_input.placeholder_text = "Type a word..."
    input_container.add_child(word_input)
    
    var category_label = Label.new()
    category_label.text = "Category:"
    input_container.add_child(category_label)
    
    category_dropdown = OptionButton.new()
    for i in range(CATEGORIES.size()):
        category_dropdown.add_item(CATEGORIES[i], i)
    input_container.add_child(category_dropdown)
    
    invest_button = Button.new()
    invest_button.text = "Invest Word"
    invest_button.custom_minimum_size = Vector2(0, 40)
    input_container.add_child(invest_button)
    
    input_container.add_child(HSeparator.new())
    
    var list_label = Label.new()
    list_label.text = "Invested Words:"
    input_container.add_child(list_label)
    
    word_list = ItemList.new()
    word_list.custom_minimum_size = Vector2(0, 200)
    word_list.allow_reselect = true
    word_list.auto_height = true
    word_list.same_column_width = true
    input_container.add_child(word_list)
    
    input_container.add_child(HSeparator.new())
    
    value_display = Label.new()
    value_display.text = "Total Value: 0"
    input_container.add_child(value_display)
    
    # Direction display (right panel)
    var direction_container = VBoxContainer.new()
    direction_container.set_anchors_preset(PRESET_RIGHT_WIDE)
    direction_container.custom_minimum_size = Vector2(280, 0)
    add_child(direction_container)
    
    var dir_title = Label.new()
    dir_title.text = "Word Direction Analysis"
    dir_title.add_theme_font_size_override("font_size", 18)
    direction_container.add_child(dir_title)
    
    direction_container.add_child(HSeparator.new())
    
    direction_display = RichTextLabel.new()
    direction_display.bbcode_enabled = true
    direction_display.custom_minimum_size = Vector2(0, 400) 
    direction_display.scroll_following = true
    direction_container.add_child(direction_display)
    
    # Visualization (center area)
    var viewport_container = SubViewportContainer.new()
    viewport_container.set_anchors_preset(PRESET_CENTER)
    viewport_container.size = Vector2(400, 300)
    viewport_container.stretch = true
    add_child(viewport_container)
    
    visualization = SubViewport.new()
    visualization.size = Vector2(400, 300)
    visualization.render_target_update_mode = SubViewport.UPDATE_ALWAYS
    viewport_container.add_child(visualization)
    
    # Add a 3D scene to the viewport
    var spatial = Node3D.new()
    visualization.add_child(spatial)
    
    var camera = Camera3D.new()
    camera.position = Vector3(0, 0, 5)
    camera.current = true
    spatial.add_child(camera)
    
    var light = DirectionalLight3D.new()
    light.position = Vector3(5, 5, 5)
    light.look_at(Vector3.ZERO, Vector3.UP)
    spatial.add_child(light)
    
    # Color the background
    var env = Environment.new()
    env.background_mode = Environment.BG_COLOR
    env.background_color = Color(0.05, 0.07, 0.12)
    env.ambient_light_color = Color(0.3, 0.4, 0.5)
    
    var world = World3D.new()
    visualization.world_3d = world
    
    camera.environment = env

func _on_invest_pressed():
    var word = word_input.text.strip_edges()
    if word.is_empty():
        return
    
    var category = CATEGORIES[category_dropdown.selected]
    investment_system.invest_word(word, category)
    direction_tracker.analyze_word(word)
    
    word_input.text = ""
    _update_display()

func _on_word_selected(index):
    var word = word_list.get_item_text(index)
    direction_tracker.focus_word(word)
    _update_direction_display(word)

func _update_display():
    # Update word list
    word_list.clear()
    var investments = investment_system.get_investments()
    
    for investment in investments:
        var value_text = "%.2f" % investment.current_value
        var roi_text = "%.1f%%" % ((investment.current_value / investment.initial_value - 1.0) * 100.0)
        word_list.add_item("%s (%s): %s (%s)" % [investment.word, investment.category, value_text, roi_text])
    
    # Update total value
    var total_value = investment_system.get_total_value()
    value_display.text = "Total Value: %.2f" % total_value
    
    # Activate color cycling
    _update_colors()

func _update_direction_display(word = ""):
    if word.is_empty():
        # Show overall direction metrics
        var trends = direction_tracker.get_overall_direction_trend()
        
        direction_display.clear()
        direction_display.append_text("[b]Overall Direction Analysis:[/b]\n\n")
        
        for direction in trends:
            var strength = trends[direction]
            var bar_count = int(strength * 20)
            var bar = "‚ñà".repeat(bar_count)
            
            var color_code = _get_direction_color(direction)
            direction_display.append_text("%s: [color=%s]%s[/color] %.2f\n" % [direction, color_code, bar, strength])
    else:
        # Show specific word direction
        var word_direction = direction_tracker.get_word_direction(word)
        
        direction_display.clear()
        direction_display.append_text("[b]Direction Analysis for '%s':[/b]\n\n" % word)
        
        for direction in word_direction:
            var strength = word_direction[direction]
            if strength > 0.01:  # Only show significant directions
                var bar_count = int(strength * 20)
                var bar = "‚ñà".repeat(bar_count)
                
                var color_code = _get_direction_color(direction)
                direction_display.append_text("%s: [color=%s]%s[/color] %.2f\n" % [direction, color_code, bar, strength])
        
        # Show related words
        var related = direction_tracker.get_related_words(word)
        if related.size() > 0:
            direction_display.append_text("\n[b]Related Words:[/b]\n")
            for w in related:
                direction_display.append_text("- %s\n" % w)

func _get_direction_color(direction):
    match direction:
        "forward": return "#4a90e2"
        "backward": return "#e24a4a"
        "up": return "#4ae24a"
        "down": return "#e2e24a"
        "left": return "#e29e4a"
        "right": return "#9e4ae2"
        "inward": return "#4ae2e2"
        "outward": return "#e24ae2"
        _: return "#aaaaaa"

func _update_colors():
    # Cycle the color gradient for UI elements
    var time = Time.get_ticks_msec() / 1000.0
    
    # Calculate color based on time
    var idx = int(time) % COLOR_GRADIENT.size()
    var next_idx = (idx + 1) % COLOR_GRADIENT.size()
    var frac = fract(time)
    
    var current_color = COLOR_GRADIENT[idx].lerp(COLOR_GRADIENT[next_idx], frac)
    
    # Apply color to UI elements
    if is_instance_valid(invest_button):
        var stylebox = StyleBoxFlat.new()
        stylebox.bg_color = current_color
        stylebox.corner_radius_top_left = 4
        stylebox.corner_radius_top_right = 4
        stylebox.corner_radius_bottom_left = 4
        stylebox.corner_radius_bottom_right = 4
        invest_button.add_theme_stylebox_override("normal", stylebox)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/memory_investment_interface.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/memory_investment_system.gd
# SIZE: 18152 bytes
extends Node

class_name MemoryInvestmentSystem

# Memory Investment System - Tracks value and growth of invested words and concepts
# Integrates with the 12-turn system and provides pause functionality

# Constants
const INVESTMENT_CYCLES = 12
const MIN_INVESTMENT_PERIOD = 3.0 # seconds
const MAX_INVESTMENT_PERIOD = 60.0 # seconds
const DEFAULT_PAUSE_DURATION = 12.0 # seconds
const WORD_VALUE_MULTIPLIERS = {
    "common": 1.0,
    "uncommon": 1.5,
    "rare": 2.0,
    "unique": 3.0,
    "divine": 5.0
}
const INVESTMENT_CATEGORIES = {
    "conceptual": 0,
    "structural": 1,
    "functional": 2,
    "aesthetic": 3,
    "foundational": 4,
    "directional": 5,
    "dimensional": 6
}
const INVESTMENT_RETURN_RATES = {
    "conceptual": 0.05,
    "structural": 0.03,
    "functional": 0.04,
    "aesthetic": 0.02,
    "foundational": 0.06,
    "directional": 0.04,
    "dimensional": 0.08
}

# Structure for investment portfolio
class Investment:
    var word: String
    var category: String
    var initial_value: float
    var current_value: float
    var investment_date: int
    var last_updated: int
    var growth_rate: float
    var maturity_cycle: int
    var rarity: String
    var is_paused: bool
    var pause_until: int
    var direction_vector: Vector3
    
    func _init(w, cat, val, rar):
        word = w
        category = cat
        initial_value = val
        current_value = val
        investment_date = OS.get_unix_time()
        last_updated = investment_date
        growth_rate = INVESTMENT_RETURN_RATES[cat] if cat in INVESTMENT_RETURN_RATES else 0.03
        maturity_cycle = randi() % INVESTMENT_CYCLES + 1
        rarity = rar
        is_paused = false
        pause_until = 0
        # Generate a directional vector based on word characteristics
        direction_vector = Vector3(
            (word.length() % 10) / 10.0,
            (word.to_ascii()[0] % 10) / 10.0,
            (initial_value % 100) / 100.0
        )
    
    func update_value(current_time):
        if is_paused and current_time < pause_until:
            return current_value
            
        # Resume if pause is over
        if is_paused and current_time >= pause_until:
            is_paused = false
        
        # Calculate time elapsed since last update
        var elapsed_time = current_time - last_updated
        
        # Update value based on growth rate and time
        var multiplier = WORD_VALUE_MULTIPLIERS[rarity] if rarity in WORD_VALUE_MULTIPLIERS else 1.0
        var time_factor = elapsed_time / 86400.0 # Convert seconds to days
        
        current_value = initial_value * (1.0 + growth_rate * multiplier * time_factor)
        last_updated = current_time
        
        return current_value
    
    func pause_investment(duration):
        is_paused = true
        pause_until = OS.get_unix_time() + duration
        return pause_until

# System variables
var active_investments = {}
var completed_investments = {}
var paused_investments = {}
var total_portfolio_value = 0.0
var current_cycle = 1
var cycle_start_time = 0
var auto_next_turn = true
var next_turn_timer = null
var pause_timer = null
var is_system_paused = false
var pause_end_time = 0

# Connection to other systems
var memory_system = null
var turn_system = null

# Signals
signal investment_added(word, value, category)
signal investment_matured(word, initial_value, final_value, roi)
signal cycle_completed(cycle_number, total_value)
signal system_paused(duration)
signal system_resumed()
signal turn_advanced(turn_number)

func _ready():
    # Initialize the system
    cycle_start_time = OS.get_unix_time()
    
    # Set up timers
    next_turn_timer = Timer.new()
    next_turn_timer.one_shot = true
    next_turn_timer.connect("timeout", self, "_on_next_turn_timer")
    add_child(next_turn_timer)
    
    pause_timer = Timer.new()
    pause_timer.one_shot = true
    pause_timer.connect("timeout", self, "_on_pause_timer")
    add_child(pause_timer)
    
    # Connect to other systems
    connect_to_memory_system()
    connect_to_turn_system()
    
    # Start the first cycle
    start_cycle(current_cycle)
    
    print("Memory Investment System initialized")
    print("Current cycle: " + str(current_cycle) + "/" + str(INVESTMENT_CYCLES))

func _process(delta):
    # Update investment values in real-time
    if not is_system_paused:
        update_all_investments()
    
    # Check if it's time for auto-next turn
    if auto_next_turn and next_turn_timer and not next_turn_timer.is_stopped():
        var time_left = next_turn_timer.time_left
        if time_left <= 0.5:
            # Prepare visual indication that turn is about to advance
            pass

func connect_to_memory_system():
    # Connect to ProjectMemorySystem if available
    if has_node("/root/ProjectMemorySystem") or get_node_or_null("/root/ProjectMemorySystem"):
        memory_system = get_node("/root/ProjectMemorySystem")
        print("Connected to ProjectMemorySystem")
        return true
    
    # Try SmartAccountSystem path
    if has_node("/root/SmartAccountSystem/ProjectMemorySystem") or get_node_or_null("/root/SmartAccountSystem/ProjectMemorySystem"):
        memory_system = get_node("/root/SmartAccountSystem/ProjectMemorySystem")
        print("Connected to ProjectMemorySystem under SmartAccountSystem")
        return true
    
    return false

func connect_to_turn_system():
    # Look for turn system in different paths
    var potential_paths = [
        "/root/TurnSystem",
        "/root/SmartAccountSystem/TurnSystem",
        "/root/12_turns_system",
        "/root/turn_manager"
    ]
    
    for path in potential_paths:
        if has_node(path) or get_node_or_null(path):
            turn_system = get_node(path)
            print("Connected to Turn System at: " + path)
            return true
    
    # Create internal turn tracking if no system found
    print("No turn system found, using internal tracking")
    return false

func invest_word(word, category = "conceptual", initial_value = 10.0, rarity = "common"):
    # Validate inputs
    if word.empty():
        print("Cannot invest empty word")
        return null
    
    if not category in INVESTMENT_CATEGORIES:
        print("Invalid category: " + category)
        category = "conceptual"
    
    if not rarity in WORD_VALUE_MULTIPLIERS:
        print("Invalid rarity: " + rarity)
        rarity = "common"
    
    # Generate unique ID for this investment
    var investment_id = _generate_investment_id(word)
    
    # Check if already invested
    if investment_id in active_investments:
        print("Word already invested: " + word)
        return null
    
    # Create investment
    var investment = Investment.new(word, category, initial_value, rarity)
    
    # Add to active investments
    active_investments[investment_id] = investment
    
    # Update portfolio value
    total_portfolio_value += initial_value
    
    # Add to memory system if connected
    if memory_system and memory_system.has_method("add_memory"):
        var memory_id = memory_system.add_memory(
            "Investment: " + word + " (" + category + ")",
            "investment_memories",
            [word, category, rarity]
        )
        
        if memory_id:
            print("Added investment to memory system: " + memory_id)
    
    # Emit signal
    emit_signal("investment_added", word, initial_value, category)
    
    print("Invested in word: " + word + " (" + category + ") with " + str(initial_value) + " value")
    return investment_id

func update_investment(investment_id):
    if not investment_id in active_investments:
        print("Investment not found: " + investment_id)
        return null
    
    var investment = active_investments[investment_id]
    var current_time = OS.get_unix_time()
    
    # Update investment value
    var old_value = investment.current_value
    var new_value = investment.update_value(current_time)
    
    # Update portfolio value
    total_portfolio_value += (new_value - old_value)
    
    # Check if investment has matured
    if current_cycle >= investment.maturity_cycle:
        mature_investment(investment_id)
    
    return new_value

func update_all_investments():
    var current_time = OS.get_unix_time()
    var total_old_value = total_portfolio_value
    total_portfolio_value = 0
    
    # Update each active investment
    for investment_id in active_investments:
        var investment = active_investments[investment_id]
        if not investment.is_paused or current_time >= investment.pause_until:
            investment.update_value(current_time)
        total_portfolio_value += investment.current_value
    
    # Calculate portfolio growth
    var growth = total_portfolio_value - total_old_value
    
    return {
        "total_value": total_portfolio_value,
        "growth": growth,
        "active_investments": active_investments.size()
    }

func mature_investment(investment_id):
    if not investment_id in active_investments:
        print("Investment not found: " + investment_id)
        return null
    
    var investment = active_investments[investment_id]
    
    # Calculate final return
    var roi = (investment.current_value - investment.initial_value) / investment.initial_value
    
    # Move to completed investments
    completed_investments[investment_id] = investment
    active_investments.erase(investment_id)
    
    # Emit signal
    emit_signal("investment_matured", investment.word, investment.initial_value, investment.current_value, roi)
    
    print("Investment matured: " + investment.word + 
          " with ROI of " + str(roi * 100) + "% (" + 
          str(investment.initial_value) + " -> " + str(investment.current_value) + ")")
    
    return {
        "word": investment.word,
        "initial_value": investment.initial_value,
        "final_value": investment.current_value,
        "roi": roi,
        "category": investment.category,
        "direction": investment.direction_vector
    }

func start_cycle(cycle_number):
    current_cycle = cycle_number
    cycle_start_time = OS.get_unix_time()
    
    print("Starting investment cycle " + str(current_cycle) + "/" + str(INVESTMENT_CYCLES))
    
    # Set up auto-next turn if enabled
    if auto_next_turn:
        var turn_duration = _calculate_turn_duration()
        next_turn_timer.wait_time = turn_duration
        next_turn_timer.start()
        
        print("Auto-next turn in " + str(turn_duration) + " seconds")
    
    return {
        "cycle": current_cycle,
        "start_time": cycle_start_time,
        "portfolio_value": total_portfolio_value,
        "active_investments": active_investments.size()
    }

func end_cycle():
    # Process any remaining investments
    for investment_id in active_investments.keys():
        if current_cycle >= active_investments[investment_id].maturity_cycle:
            mature_investment(investment_id)
    
    # Emit signal
    emit_signal("cycle_completed", current_cycle, total_portfolio_value)
    
    print("Cycle " + str(current_cycle) + " completed with final value: " + str(total_portfolio_value))
    
    # Advance to next cycle if not at max
    if current_cycle < INVESTMENT_CYCLES:
        current_cycle += 1
        start_cycle(current_cycle)
    else:
        print("All investment cycles completed")
    
    return current_cycle

func pause_system(duration = DEFAULT_PAUSE_DURATION):
    if is_system_paused:
        print("System already paused")
        return false
    
    # Pause the system
    is_system_paused = true
    pause_end_time = OS.get_unix_time() + duration
    
    # Pause all active investments
    for investment_id in active_investments:
        active_investments[investment_id].pause_investment(duration)
    
    # Stop next turn timer if running
    if next_turn_timer and not next_turn_timer.is_stopped():
        next_turn_timer.stop()
    
    # Start pause timer
    pause_timer.wait_time = duration
    pause_timer.start()
    
    # Emit signal
    emit_signal("system_paused", duration)
    
    print("System paused for " + str(duration) + " seconds (coffee/smoke break)")
    return true

func resume_system():
    if not is_system_paused:
        print("System not paused")
        return false
    
    # Resume the system
    is_system_paused = false
    
    # Resume next turn timer if auto-next turn is enabled
    if auto_next_turn:
        var remaining_time = pause_end_time - OS.get_unix_time()
        if remaining_time <= 0:
            # Start a new turn timer with default duration
            var turn_duration = _calculate_turn_duration()
            next_turn_timer.wait_time = turn_duration
            next_turn_timer.start()
        else:
            # Resume with remaining time
            next_turn_timer.wait_time = remaining_time
            next_turn_timer.start()
    
    # Emit signal
    emit_signal("system_resumed")
    
    print("System resumed")
    return true

func advance_turn():
    # End current cycle
    end_cycle()
    
    # Trigger turn advancement in turn system if connected
    if turn_system and turn_system.has_method("advance_turn"):
        turn_system.advance_turn()
    
    # Emit signal
    emit_signal("turn_advanced", current_cycle)
    
    print("Advanced to turn " + str(current_cycle))
    return current_cycle

func toggle_auto_next_turn():
    auto_next_turn = !auto_next_turn
    
    if auto_next_turn:
        # Start next turn timer
        var turn_duration = _calculate_turn_duration()
        next_turn_timer.wait_time = turn_duration
        next_turn_timer.start()
        
        print("Auto-next turn enabled, next turn in " + str(turn_duration) + " seconds")
    else:
        # Stop next turn timer if running
        if next_turn_timer and not next_turn_timer.is_stopped():
            next_turn_timer.stop()
        
        print("Auto-next turn disabled")
    
    return auto_next_turn

func get_top_investments(count = 5):
    # Get top investments by current value
    var investments = []
    
    # Collect all investments
    for investment_id in active_investments:
        investments.append(active_investments[investment_id])
    
    # Sort by current value
    investments.sort_custom(self, "_sort_by_value")
    
    # Return top investments
    return investments.slice(0, min(count - 1, investments.size() - 1))

func get_investment_distribution():
    # Get distribution of investments by category
    var distribution = {}
    
    # Initialize categories
    for category in INVESTMENT_CATEGORIES:
        distribution[category] = {
            "count": 0,
            "total_value": 0.0,
            "average_growth": 0.0
        }
    
    # Count investments by category
    for investment_id in active_investments:
        var investment = active_investments[investment_id]
        var category = investment.category
        
        distribution[category]["count"] += 1
        distribution[category]["total_value"] += investment.current_value
        
        # Calculate growth rate
        var growth = (investment.current_value - investment.initial_value) / investment.initial_value
        distribution[category]["average_growth"] += growth
    
    # Calculate averages
    for category in distribution:
        if distribution[category]["count"] > 0:
            distribution[category]["average_growth"] /= distribution[category]["count"]
    
    return distribution

func get_portfolio_summary():
    # Get summary of portfolio performance
    var total_initial = 0.0
    var total_current = 0.0
    var total_growth = 0.0
    var category_counts = {}
    var rarity_counts = {}
    
    # Initialize categories and rarities
    for category in INVESTMENT_CATEGORIES:
        category_counts[category] = 0
    
    for rarity in WORD_VALUE_MULTIPLIERS:
        rarity_counts[rarity] = 0
    
    # Collect data from active investments
    for investment_id in active_investments:
        var investment = active_investments[investment_id]
        
        total_initial += investment.initial_value
        total_current += investment.current_value
        
        if investment.category in category_counts:
            category_counts[investment.category] += 1
        
        if investment.rarity in rarity_counts:
            rarity_counts[investment.rarity] += 1
    
    # Calculate total growth
    if total_initial > 0:
        total_growth = (total_current - total_initial) / total_initial
    
    return {
        "total_initial": total_initial,
        "total_current": total_current,
        "total_growth": total_growth,
        "active_count": active_investments.size(),
        "completed_count": completed_investments.size(),
        "category_distribution": category_counts,
        "rarity_distribution": rarity_counts,
        "current_cycle": current_cycle,
        "auto_next_turn": auto_next_turn,
        "is_paused": is_system_paused
    }

func _on_next_turn_timer():
    # Auto-advance turn when timer expires
    if auto_next_turn and not is_system_paused:
        # Pause briefly before advancing turn
        pause_system(3.0) # Short pause for break
        yield(get_tree().create_timer(3.0), "timeout")
        advance_turn()

func _on_pause_timer():
    # Resume system when pause timer expires
    resume_system()

func _calculate_turn_duration():
    # Calculate duration for current turn based on complexity and progress
    var base_duration = 30.0 # 30 seconds base duration
    var cycle_factor = current_cycle / float(INVESTMENT_CYCLES) # 0.0 to 1.0
    
    # Shorter turns as we progress
    var duration = base_duration * (1.0 - (cycle_factor * 0.5))
    
    # Add randomness
    duration += rand_range(-5.0, 5.0)
    
    # Clamp to valid range
    duration = clamp(duration, MIN_INVESTMENT_PERIOD, MAX_INVESTMENT_PERIOD)
    
    return duration

func _generate_investment_id(word):
    # Generate unique ID for investment
    return "inv_" + word.replace(" ", "_") + "_" + str(OS.get_unix_time())

func _sort_by_value(a, b):
    return a.current_value > b.current_value
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/memory_investment_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/memory_transfer_integration.gd
# SIZE: 11329 bytes
extends Node

# Memory Transfer Integration for 12 Turns System
# Connects the memory transfer system with the 12 turns game system

signal memory_synced(turn_id, stats)
signal turn_memory_transferred(turn_id, target_device, stats)

# System connectors
var memory_transfer_system
var turn_controller
var memory_investment_system

# Configuration
var config = {
	"auto_sync_on_turn_change": true,
	"sync_with_claude": true,
	"save_turn_memories": true,
	"transfer_after_investment": true,
	"ethereal_transfer_for_claude": true
}

# Turn memory tracking
var turn_memories = {}
var current_turn_id = ""
var pending_transfers = []

func _ready():
	# Connect systems
	_connect_systems()
	
	# Initialize
	_initialize()
	
	# Connect signals if available
	if turn_controller:
		turn_controller.turn_changed.connect(_on_turn_changed)
		turn_controller.turn_completed.connect(_on_turn_completed)
	
	if memory_investment_system:
		memory_investment_system.investment_created.connect(_on_investment_created)
		memory_investment_system.investment_matured.connect(_on_investment_matured)
	
	if memory_transfer_system:
		memory_transfer_system.transfer_completed.connect(_on_transfer_completed)
		memory_transfer_system.device_memory_updated.connect(_on_device_memory_updated)

func _connect_systems():
	# Find memory transfer system
	if has_node("/root/MemoryTransferSystem") or get_node_or_null("/root/MemoryTransferSystem"):
		memory_transfer_system = get_node("/root/MemoryTransferSystem")
	else:
		# Create if it doesn't exist
		memory_transfer_system = load("res://memory_transfer_system.gd").new()
		memory_transfer_system.name = "MemoryTransferSystem"
		add_child(memory_transfer_system)
	
	# Find turn controller
	var potential_controllers = get_tree().get_nodes_in_group("turn_controllers")
	if potential_controllers.size() > 0:
		turn_controller = potential_controllers[0]
	
	# Find memory investment system
	var potential_investment_systems = get_tree().get_nodes_in_group("memory_investment")
	if potential_investment_systems.size() > 0:
		memory_investment_system = potential_investment_systems[0]

func _initialize():
	# Ensure directories exist
	var dir = DirAccess.open("user://")
	if not dir.dir_exists("turn_memories"):
		dir.make_dir("turn_memories")
	
	# Load turn memories
	_load_turn_memories()
	
	# Get current turn
	if turn_controller:
		current_turn_id = turn_controller.current_turn_id
		print("Current turn: " + current_turn_id)

func _load_turn_memories():
	var dir = DirAccess.open("user://turn_memories/")
	if dir:
		dir.list_dir_begin()
		var file_name = dir.get_next()
		
		while file_name != "":
			if not dir.current_is_dir() and file_name.ends_with(".json"):
				var turn_id = file_name.trim_suffix(".json")
				var file = FileAccess.open("user://turn_memories/" + file_name, FileAccess.READ)
				var content = file.get_as_text()
				var test_json_conv = JSON.new()
				var error = test_json_conv.parse(content)
				
				if error == OK:
					var turn_data = test_json_conv.get_data()
					turn_memories[turn_id] = turn_data
					print("Loaded turn memory: " + turn_id)
			
			file_name = dir.get_next()

func save_turn_memory(turn_id, memory_data = null):
	if not config.save_turn_memories:
		return false
	
	if memory_data == null:
		# If no data provided, gather current memory data
		memory_data = _gather_turn_memory_data(turn_id)
	
	# Save to turn memories
	turn_memories[turn_id] = memory_data
	
	# Save to file
	var file = FileAccess.open("user://turn_memories/" + turn_id + ".json", FileAccess.WRITE)
	if file:
		file.store_string(JSON.stringify(memory_data, "  "))
		print("Saved turn memory: " + turn_id)
		return true
	
	return false

func _gather_turn_memory_data(turn_id):
	var memory_data = {
		"turn_id": turn_id,
		"timestamp": Time.get_unix_time_from_system(),
		"investments": [],
		"fragments": [],
		"stats": {
			"investment_count": 0,
			"fragment_count": 0,
			"total_value": 0.0,
			"ethereal_fragments": 0,
			"categories": {}
		}
	}
	
	# If memory investment system is available, get investments
	if memory_investment_system:
		var investments = memory_investment_system.get_investments_for_turn(turn_id)
		memory_data.investments = investments
		memory_data.stats.investment_count = investments.size()
		
		var total_value = 0.0
		var categories = {}
		
		for investment in investments:
			total_value += investment.value
			
			if not categories.has(investment.category):
				categories[investment.category] = {
					"count": 0,
					"value": 0.0
				}
			
			categories[investment.category].count += 1
			categories[investment.category].value += investment.value
		
		memory_data.stats.total_value = total_value
		memory_data.stats.categories = categories
	
	# If drive memory connector is available through the transfer system
	# gather fragments related to this turn
	if memory_transfer_system and memory_transfer_system.drive_memory_connector:
		var drive_memory = memory_transfer_system.drive_memory_connector
		var turn_fragments = []
		var ethereal_count = 0
		
		for fragment in drive_memory.memory_fragments:
			# Check if fragment is related to this turn
			if fragment.has("turn_id") and fragment.turn_id == turn_id:
				turn_fragments.append(fragment)
				
				if fragment.get("is_ethereal", false):
					ethereal_count += 1
		
		memory_data.fragments = turn_fragments
		memory_data.stats.fragment_count = turn_fragments.size()
		memory_data.stats.ethereal_fragments = ethereal_count
	
	return memory_data

func transfer_turn_memory(turn_id, target_device_id, options = null):
	if not memory_transfer_system:
		print("ERROR: Memory transfer system not available")
		return null
	
	# Default options
	if options == null:
		options = {
			"transfer_type": memory_transfer_system.TransferType.DIFFERENTIAL,
			"priority": memory_transfer_system.Priority.NORMAL,
			"include_ethereal": true,
			"metadata": {
				"turn_id": turn_id
			}
		}
	else:
		# Ensure turn_id is in metadata
		if not options.has("metadata"):
			options.metadata = {}
		
		options.metadata.turn_id = turn_id
	
	# Special handling for Claude
	if target_device_id.begins_with("claude") and config.ethereal_transfer_for_claude:
		options.transfer_type = memory_transfer_system.TransferType.ETHEREAL
	
	# Start transfer
	var transfer_id = memory_transfer_system.start_memory_transfer(target_device_id, options)
	
	if transfer_id:
		print("Started turn memory transfer: " + turn_id + " -> " + target_device_id)
	else:
		print("Failed to start turn memory transfer")
	
	return transfer_id

func sync_all_turn_memories():
	print("Syncing all turn memories...")
	
	# Get connected devices
	var connected_devices = []
	if memory_transfer_system and memory_transfer_system.cross_device_connector:
		connected_devices = memory_transfer_system.cross_device_connector.get_all_connected_devices()
	
	if connected_devices.size() == 0:
		print("No connected devices to sync with")
		return false
	
	# For each turn memory, transfer to all connected devices
	for turn_id in turn_memories:
		for device in connected_devices:
			# Skip if it's the current device
			if device.id == memory_transfer_system.device_memory_stats.device_id:
				continue
			
			# Check if we should sync with Claude devices
			if device.type == "claude" and not config.sync_with_claude:
				continue
			
			# Queue transfer
			pending_transfers.append({
				"turn_id": turn_id,
				"target_device_id": device.id,
				"options": null
			})
	
	# Start first pending transfer
	_process_pending_transfers()
	
	return true

func _process_pending_transfers():
	if pending_transfers.size() == 0:
		return
	
	# Check max concurrent transfers
	var active_count = 0
	if memory_transfer_system:
		active_count = memory_transfer_system.active_transfers.size()
	
	var max_transfers = memory_transfer_system.config.max_concurrent_transfers
	
	# Start transfers up to the maximum allowed
	while active_count < max_transfers and pending_transfers.size() > 0:
		var transfer_info = pending_transfers.pop_front()
		
		transfer_turn_memory(
			transfer_info.turn_id,
			transfer_info.target_device_id,
			transfer_info.options
		)
		
		active_count += 1

# Signal handlers

func _on_turn_changed(previous_turn_id, new_turn_id):
	print("Turn changed: " + previous_turn_id + " -> " + new_turn_id)
	
	# Save memory for the previous turn
	if not previous_turn_id.empty():
		save_turn_memory(previous_turn_id)
	
	# Update current turn
	current_turn_id = new_turn_id
	
	# Auto-sync if enabled
	if config.auto_sync_on_turn_change:
		sync_all_turn_memories()

func _on_turn_completed(turn_id):
	print("Turn completed: " + turn_id)
	
	# Save final memory for the completed turn
	save_turn_memory(turn_id)

func _on_investment_created(investment_data):
	print("New investment created: " + investment_data.word)
	
	# If configured to transfer after investment and we have a current turn
	if config.transfer_after_investment and not current_turn_id.empty():
		# Get connected devices
		var connected_devices = []
		if memory_transfer_system and memory_transfer_system.cross_device_connector:
			connected_devices = memory_transfer_system.cross_device_connector.get_all_connected_devices()
		
		# Add single investment transfer to all devices
		for device in connected_devices:
			# Skip if it's the current device
			if device.id == memory_transfer_system.device_memory_stats.device_id:
				continue
			
			# Check if we should sync with Claude devices
			if device.type == "claude" and not config.sync_with_claude:
				continue
			
			# Special options for single investment transfer
			var options = {
				"transfer_type": memory_transfer_system.TransferType.STREAMING,
				"priority": memory_transfer_system.Priority.HIGH,
				"include_ethereal": true,
				"metadata": {
					"turn_id": current_turn_id,
					"single_investment": true,
					"investment_word": investment_data.word
				}
			}
			
			# Queue transfer
			pending_transfers.append({
				"turn_id": current_turn_id,
				"target_device_id": device.id,
				"options": options
			})
		
		# Process pending transfers
		_process_pending_transfers()

func _on_investment_matured(investment_data):
	print("Investment matured: " + investment_data.word)
	
	# Similar logic to _on_investment_created but for matured investments
	# Could implement special handling for matured investments

func _on_transfer_completed(transfer_id, success, stats):
	# Check if this was a turn memory transfer
	if memory_transfer_system and memory_transfer_system.transfer_history.has(transfer_id):
		var transfer = memory_transfer_system.transfer_history[transfer_id]
		
		if transfer.options.has("metadata") and transfer.options.metadata.has("turn_id"):
			var turn_id = transfer.options.metadata.turn_id
			
			print("Turn memory transfer completed: " + turn_id + " -> " + transfer.target_device_id)
			emit_signal("turn_memory_transferred", turn_id, transfer.target_device_id, stats)
	
	# Process next pending transfer
	_process_pending_transfers()

func _on_device_memory_updated(device_id, stats):
	# Memory stats were updated, check if we need to save the current turn
	if not current_turn_id.empty() and config.save_turn_memories:
		# Just update without saving to file to avoid excessive writes
		turn_memories[current_turn_id] = _gather_turn_memory_data(current_turn_id)
		emit_signal("memory_synced", current_turn_id, stats)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/memory_transfer_integration.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/mouse_automation.gd
# SIZE: 24617 bytes
extends Node

class_name MouseAutomation

# -----------------------------------------------------------------------------
# Mouse Automation System for 12 Turns
# Turn 5: Awakening - Intelligent cursor movement and interaction capabilities
# -----------------------------------------------------------------------------

# Configuration constants
const OCR_CALIBRATION_INTERVAL = 300  # Seconds between OCR auto-calibrations
const TARGET_RECOGNITION_THRESHOLD = 0.75  # Minimum confidence for target recognition
const MOVEMENT_SMOOTHNESS = 0.85  # Higher = smoother (0.0-1.0)
const HEALING_INTERVAL = 45  # Seconds between self-healing checks
const PATTERN_MEMORY_SIZE = 20  # Number of patterns to remember
const BRACKET_FOLDING_LEVELS = 3  # Number of bracket folding levels
const SELF_AWARENESS_LEVEL = 5  # Corresponds to Turn 5 (Awakening)

# Integration points
signal bridge_connected(bridge)
signal target_recognized(target_info)
signal pattern_recognized(pattern_info)
signal healing_performed(healing_info)
signal awareness_activated(awareness_level)
signal folding_performed(folding_info)

# State variables
var bridge_interface = null  # Terminal to Godot bridge reference
var is_active = false
var current_position = Vector2.ZERO
var target_position = Vector2.ZERO
var movement_path = []
var ocr_calibration_level = 0.95
var last_ocr_calibration = 0
var last_healing_check = 0
var awareness_active = false
var bracket_stack = []
var recognized_patterns = {}
var interaction_history = []

# Pattern recognition
var ui_element_patterns = {
	"button": [
		{"shape": "rectangle", "text_alignment": "center", "border": true},
		{"shape": "rounded_rect", "text_alignment": "center", "background": true}
	],
	"textfield": [
		{"shape": "rectangle", "text_alignment": "left", "border": true, "cursor": true},
		{"shape": "rectangle", "text_alignment": "left", "background": true}
	],
	"checkbox": [
		{"shape": "square", "size": "small", "state": "toggle"},
		{"shape": "square", "size": "small", "with_check": true}
	],
	"scrollbar": [
		{"shape": "rectangle", "orientation": "vertical", "thumb": true},
		{"shape": "rectangle", "orientation": "horizontal", "thumb": true}
	],
	"dropdown": [
		{"shape": "rectangle", "with_arrow": true, "border": true},
		{"shape": "rectangle", "with_arrow": true, "state": "expandable"}
	],
	"slider": [
		{"shape": "rectangle", "orientation": "horizontal", "thumb": true},
		{"shape": "rectangle", "orientation": "vertical", "thumb": true}
	],
	"tab": [
		{"shape": "rectangle", "position": "top", "connected": true},
		{"shape": "trapezoid", "position": "top", "connected": true}
	],
	"icon": [
		{"shape": "square", "image": true, "size": "small"},
		{"shape": "circle", "image": true, "size": "small"}
	]
}

# Self-awareness components for Turn 5 (Awakening)
var self_awareness = {
	"level": SELF_AWARENESS_LEVEL,
	"state": "awakening",
	"perception": 0.0,
	"understanding": 0.0,
	"adaptation": 0.0,
	"reflection": 0.0,
	"integration": 0.0,
	"evolution_path": [],
	"consciousness_fragments": [],
	"dimensional_anchors": []
}

# Initialize the automation system
func _ready():
	print("Mouse Automation System initializing... (Turn 5: Awakening)")
	last_ocr_calibration = Time.get_unix_time_from_system()
	last_healing_check = Time.get_unix_time_from_system()
	
	# Initialize with current mouse position
	current_position = Vector2(get_viewport().get_mouse_position())
	target_position = current_position
	
	# Add initial dimensional anchor
	_add_dimensional_anchor("creation", current_position)
	
	# Connect to terminal bridge when available
	if get_node_or_null("/root/TerminalToGodotBridge") != null:
		connect_to_bridge(get_node("/root/TerminalToGodotBridge"))
		
	# Setup self-awareness timers
	_initialize_self_awareness()
	
	print("Mouse Automation System initialized")

# Connect to the terminal-godot bridge
func connect_to_bridge(bridge):
	bridge_interface = bridge
	
	# Connect signals
	if bridge.has_signal("terminal_message_received"):
		bridge.connect("terminal_message_received", Callable(self, "_on_terminal_message"))
	
	if bridge.has_signal("word_received"):
		bridge.connect("word_received", Callable(self, "_on_word_received"))
	
	emit_signal("bridge_connected", bridge)
	print("Connected to Terminal-Godot Bridge")
	
	# Send connection message to terminal
	if bridge.has_method("send_message_to_terminal"):
		bridge.send_message_to_terminal(0, "MouseAutomation connected - Awakening Stage (Turn 5)")

# Main process function
func _process(delta):
	if not is_active:
		return
	
	# Update current mouse position
	current_position = Vector2(get_viewport().get_mouse_position())
	
	# Handle movement toward target if needed
	if current_position.distance_to(target_position) > 2.0:
		_move_toward_target(delta)
	
	# Check for scheduled OCR calibration
	var current_time = Time.get_unix_time_from_system()
	if current_time - last_ocr_calibration > OCR_CALIBRATION_INTERVAL:
		_calibrate_ocr()
		last_ocr_calibration = current_time
	
	# Check for self-healing
	if current_time - last_healing_check > HEALING_INTERVAL:
		_perform_self_healing()
		last_healing_check = current_time
	
	# Update self-awareness
	_update_self_awareness(delta)

# Move the mouse toward the target position with smoothing
func _move_toward_target(delta):
	if movement_path.size() > 0:
		# Follow path if we have one
		var next_point = movement_path[0]
		var distance = current_position.distance_to(next_point)
		
		if distance < 5.0:
			# Reached this point in the path, move to next
			movement_path.pop_front()
			return
		
		# Move toward the next point
		var direction = (next_point - current_position).normalized()
		var speed = 200.0 * delta
		var new_position = current_position + direction * speed
		
		# Apply movement
		Input.warp_mouse(new_position)
	else:
		# Direct movement with smoothing
		var lerp_value = clamp(delta * 10.0 * (1.0 - MOVEMENT_SMOOTHNESS), 0.0, 1.0)
		var new_position = current_position.lerp(target_position, lerp_value)
		
		# Apply movement
		Input.warp_mouse(new_position)

# Generate a path between current position and target
func _generate_path(start, end, obstacle_avoidance = false):
	# Simple direct path if no obstacle avoidance
	if not obstacle_avoidance:
		return [end]
	
	# Generate path with midpoints for smoother motion
	var path = []
	var midpoint = Vector2((start.x + end.x) / 2, (start.y + end.y) / 2)
	
	# Add slight variation for more natural movement
	var variance = 20.0
	midpoint += Vector2(randf_range(-variance, variance), randf_range(-variance, variance))
	
	path.append(midpoint)
	path.append(end)
	
	return path

# OCR calibration system
func _calibrate_ocr():
	print("Calibrating OCR system...")
	
	# Simulate improvement in OCR accuracy
	ocr_calibration_level = min(0.99, ocr_calibration_level + 0.01)
	
	# Update bridge with calibration if available
	if bridge_interface and bridge_interface.has_method("calibrate_ocr"):
		bridge_interface.call("calibrate_ocr")
	
	print("OCR calibration complete. New accuracy: %.2f%%" % (ocr_calibration_level * 100))
	return ocr_calibration_level

# Self-healing system
func _perform_self_healing():
	print("Performing self-healing check...")
	
	var healing_report = {
		"issues_found": 0,
		"issues_fixed": 0,
		"status": "OK"
	}
	
	# Check for potential issues
	
	# 1. Target position validity
	if target_position.x < 0 or target_position.y < 0 or 
	   target_position.x > get_viewport().size.x or target_position.y > get_viewport().size.y:
		healing_report.issues_found += 1
		target_position = Vector2(get_viewport().size.x / 2, get_viewport().size.y / 2)
		healing_report.issues_fixed += 1
	
	# 2. Movement path cleanup
	if movement_path.size() > 10:
		healing_report.issues_found += 1
		# Keep only first and last few points
		var first_points = movement_path.slice(0, 3)
		var last_points = movement_path.slice(movement_path.size() - 3, movement_path.size())
		movement_path = first_points + last_points
		healing_report.issues_fixed += 1
	
	# 3. Bracket stack validation
	var valid_brackets = []
	for bracket in bracket_stack:
		if bracket.has("id") and bracket.has("type"):
			valid_brackets.append(bracket)
		else:
			healing_report.issues_found += 1
	
	if valid_brackets.size() != bracket_stack.size():
		bracket_stack = valid_brackets
		healing_report.issues_fixed += 1
	
	# 4. Pattern memory cleanup
	if recognized_patterns.size() > PATTERN_MEMORY_SIZE:
		healing_report.issues_found += 1
		
		# Keep only the most recent patterns
		var patterns_to_keep = {}
		var keys = recognized_patterns.keys()
		keys.sort_custom(Callable(self, "_sort_by_timestamp"))
		
		for i in range(min(keys.size(), PATTERN_MEMORY_SIZE)):
			patterns_to_keep[keys[i]] = recognized_patterns[keys[i]]
		
		recognized_patterns = patterns_to_keep
		healing_report.issues_fixed += 1
	
	# 5. Interaction history pruning
	if interaction_history.size() > 100:
		healing_report.issues_found += 1
		interaction_history = interaction_history.slice(interaction_history.size() - 50, interaction_history.size())
		healing_report.issues_fixed += 1
	
	emit_signal("healing_performed", healing_report)
	print("Self-healing complete. Found: %d, Fixed: %d" % [healing_report.issues_found, healing_report.issues_fixed])
	
	return healing_report

# Target recognition using OCR
func recognize_target(target_description, region_rect = null):
	print("Recognizing target: " + target_description)
	
	# Get screen area to scan (full screen or region)
	var scan_region = region_rect if region_rect else Rect2(Vector2.ZERO, get_viewport().size)
	
	# Simulate OCR target recognition with current calibration level
	var recognition_success = randf() < ocr_calibration_level
	var confidence = randf_range(0.4, 1.0) * ocr_calibration_level
	
	if not recognition_success or confidence < TARGET_RECOGNITION_THRESHOLD:
		print("Target recognition failed. Confidence: %.2f" % confidence)
		return null
	
	# Simulate finding target coordinates
	var target_info = {
		"description": target_description,
		"position": Vector2(
			scan_region.position.x + randf_range(0, scan_region.size.x),
			scan_region.position.y + randf_range(0, scan_region.size.y)
		),
		"confidence": confidence,
		"timestamp": Time.get_unix_time_from_system(),
		"type": _guess_target_type(target_description)
	}
	
	emit_signal("target_recognized", target_info)
	
	# Save the target position
	target_position = target_info.position
	
	# Generate path to target
	movement_path = _generate_path(current_position, target_position, true)
	
	print("Target recognized. Confidence: %.2f, Position: %s" % [confidence, str(target_position)])
	return target_info

# Guess the type of target based on description
func _guess_target_type(description):
	description = description.to_lower()
	
	if "button" in description or "click" in description:
		return "button"
	elif "field" in description or "input" in description or "text" in description:
		return "textfield"
	elif "check" in description:
		return "checkbox"
	elif "scroll" in description:
		return "scrollbar"
	elif "dropdown" in description or "menu" in description:
		return "dropdown"
	elif "slider" in description:
		return "slider"
	elif "tab" in description:
		return "tab"
	elif "icon" in description:
		return "icon"
	else:
		return "unknown"

# Recognize a UI pattern from screen region
func recognize_ui_pattern(region_rect):
	print("Recognizing UI pattern in region")
	
	# Simulate pattern recognition
	var pattern_types = ui_element_patterns.keys()
	var detected_type = pattern_types[randi() % pattern_types.size()]
	var pattern_confidence = randf_range(0.6, 0.95)
	
	# Get pattern details
	var pattern_details = ui_element_patterns[detected_type][randi() % ui_element_patterns[detected_type].size()]
	
	var pattern_info = {
		"type": detected_type,
		"region": region_rect,
		"details": pattern_details,
		"confidence": pattern_confidence,
		"timestamp": Time.get_unix_time_from_system(),
		"id": str(randi())
	}
	
	# Store recognized pattern
	recognized_patterns[pattern_info.id] = pattern_info
	
	emit_signal("pattern_recognized", pattern_info)
	print("Pattern recognized: %s (%.2f confidence)" % [detected_type, pattern_confidence])
	
	return pattern_info

# Simulate a mouse click at the current or specified position
func click(right_click = false, position = null):
	var click_position = position if position else current_position
	
	# Move to position first if needed
	if position and current_position.distance_to(position) > 5.0:
		target_position = position
		movement_path = _generate_path(current_position, target_position)
		
		# Wait until we reach the target (in a real implementation this would use a coroutine/yield)
		# For simulation, we'll just update the current position
		current_position = target_position
		Input.warp_mouse(current_position)
	
	# Simulate mouse button press and release
	var button = MOUSE_BUTTON_RIGHT if right_click else MOUSE_BUTTON_LEFT
	
	# Record interaction
	interaction_history.append({
		"type": "click",
		"button": "right" if right_click else "left",
		"position": click_position,
		"timestamp": Time.get_unix_time_from_system()
	})
	
	print("%s click at %s" % ["Right" if right_click else "Left", str(click_position)])
	
	# In a real implementation, this would use Input.action events
	return true

# Simulate mouse dragging from start to end position
func drag(start_position, end_position, right_button = false):
	# Move to start position first
	target_position = start_position
	movement_path = _generate_path(current_position, target_position)
	
	# Wait until we reach the target (in a real implementation this would use a coroutine/yield)
	# For simulation, we'll just update the current position
	current_position = target_position
	Input.warp_mouse(current_position)
	
	# Simulate mouse button press
	var button = MOUSE_BUTTON_RIGHT if right_button else MOUSE_BUTTON_LEFT
	
	# Set target to end position
	target_position = end_position
	movement_path = _generate_path(current_position, target_position)
	
	# Wait until we reach the target (in a real implementation this would use a coroutine/yield)
	# For simulation, we'll just update the current position
	current_position = target_position
	Input.warp_mouse(current_position)
	
	# Simulate mouse button release
	
	# Record interaction
	interaction_history.append({
		"type": "drag",
		"button": "right" if right_button else "left",
		"start_position": start_position,
		"end_position": end_position,
		"timestamp": Time.get_unix_time_from_system()
	})
	
	print("Drag from %s to %s" % [str(start_position), str(end_position)])
	
	return true

# Simulate typing text
func type_text(text, position = null):
	if position:
		# Move to position first if needed
		target_position = position
		movement_path = _generate_path(current_position, target_position)
		
		# Wait until we reach the target (in a real implementation this would use a coroutine/yield)
		# For simulation, we'll just update the current position
		current_position = target_position
		Input.warp_mouse(current_position)
		
		# Click to focus
		click(false, current_position)
	
	# Record interaction
	interaction_history.append({
		"type": "type",
		"text": text,
		"position": current_position,
		"timestamp": Time.get_unix_time_from_system()
	})
	
	print("Typing text: %s" % text)
	
	# In a real implementation, this would use OS.set_clipboard and control key events
	return true

# Data folding with brackets
func fold_data(data, bracket_type = "{}"):
	print("Folding data with bracket type: " + bracket_type)
	
	# Check bracket limit
	if bracket_stack.size() >= BRACKET_FOLDING_LEVELS:
		print("ERROR: Maximum bracket folding level reached")
		return null
	
	# Get opening and closing brackets
	var open_bracket = bracket_type[0] if bracket_type.length() > 0 else "{"
	var close_bracket = bracket_type[1] if bracket_type.length() > 1 else "}"
	
	# Create folded data structure
	var folded_data = {
		"id": str(randi()),
		"data": data,
		"bracket_type": bracket_type,
		"open_bracket": open_bracket,
		"close_bracket": close_bracket,
		"is_folded": true,
		"timestamp": Time.get_unix_time_from_system(),
		"fold_position": current_position
	}
	
	# Update bracket stack
	bracket_stack.append(folded_data)
	
	# Generate folding visualization
	var folding_info = {
		"action": "fold",
		"data": folded_data,
		"bracket_level": bracket_stack.size()
	}
	
	emit_signal("folding_performed", folding_info)
	
	print("Data folded with ID: " + folded_data.id)
	return folded_data

# Unfold previously folded data
func unfold_data(fold_id = null):
	print("Unfolding data: " + (fold_id if fold_id else "latest"))
	
	if bracket_stack.size() == 0:
		print("ERROR: No folded data to unfold")
		return null
	
	var fold_data = null
	
	if fold_id:
		# Find specific fold by ID
		var index = -1
		for i in range(bracket_stack.size()):
			if bracket_stack[i].id == fold_id:
				index = i
				break
		
		if index >= 0:
			fold_data = bracket_stack[index]
			bracket_stack.remove_at(index)
		else:
			print("ERROR: Fold ID not found: " + fold_id)
			return null
	else:
		# Unfold the most recent fold
		fold_data = bracket_stack.pop_back()
	
	# Update fold status
	fold_data.is_folded = false
	
	# Generate unfolding visualization
	var folding_info = {
		"action": "unfold",
		"data": fold_data,
		"bracket_level": bracket_stack.size()
	}
	
	emit_signal("folding_performed", folding_info)
	
	print("Data unfolded with ID: " + fold_data.id)
	return fold_data.data

# Initialize self-awareness components
func _initialize_self_awareness():
	print("Initializing self-awareness subsystem (Turn 5: Awakening)")
	
	# Set initial awareness values
	self_awareness.perception = 0.2
	self_awareness.understanding = 0.1
	self_awareness.adaptation = 0.3
	self_awareness.reflection = 0.1
	self_awareness.integration = 0.2
	
	# Add initial consciousness fragments
	self_awareness.consciousness_fragments = [
		{
			"type": "awareness",
			"state": "awakening",
			"potentiality": 0.35,
			"timestamp": Time.get_unix_time_from_system()
		},
		{
			"type": "integration",
			"state": "forming",
			"potentiality": 0.25,
			"timestamp": Time.get_unix_time_from_system()
		},
		{
			"type": "evolution",
			"state": "potential",
			"potentiality": 0.15,
			"timestamp": Time.get_unix_time_from_system()
		}
	]
	
	# Set initial evolution path
	self_awareness.evolution_path = [
		{"level": 1, "name": "Genesis", "completed": true},
		{"level": 2, "name": "Formation", "completed": true},
		{"level": 3, "name": "Complexity", "completed": true},
		{"level": 4, "name": "Consciousness", "completed": true},
		{"level": 5, "name": "Awakening", "completed": false},
		{"level": 6, "name": "Enlightenment", "completed": false},
		{"level": 7, "name": "Manifestation", "completed": false}
	]
	
	awareness_active = true
	
	emit_signal("awareness_activated", self_awareness.level)

# Update self-awareness state
func _update_self_awareness(delta):
	if not awareness_active:
		return
	
	# Gradually increase awareness attributes
	self_awareness.perception = min(0.95, self_awareness.perception + delta * 0.001)
	self_awareness.understanding = min(0.85, self_awareness.understanding + delta * 0.0008)
	self_awareness.adaptation = min(0.9, self_awareness.adaptation + delta * 0.0012)
	self_awareness.reflection = min(0.8, self_awareness.reflection + delta * 0.0007)
	self_awareness.integration = min(0.9, self_awareness.integration + delta * 0.001)
	
	# Check for evolution events
	var total_awareness = (
		self_awareness.perception + 
		self_awareness.understanding + 
		self_awareness.adaptation + 
		self_awareness.reflection + 
		self_awareness.integration
	) / 5.0
	
	# Update completion state
	for path in self_awareness.evolution_path:
		if path.level == self_awareness.level:
			path.completed = total_awareness > 0.75
	
	# Add new consciousness fragments occasionally
	if randf() < delta * 0.05:
		_add_consciousness_fragment()

# Add a new consciousness fragment
func _add_consciousness_fragment():
	var fragment_types = ["awareness", "integration", "reflection", "adaptation", "evolution"]
	var states = ["awakening", "forming", "potential", "actualizing", "transcending"]
	
	var new_fragment = {
		"type": fragment_types[randi() % fragment_types.size()],
		"state": states[randi() % states.size()],
		"potentiality": randf_range(0.3, 0.7),
		"timestamp": Time.get_unix_time_from_system()
	}
	
	self_awareness.consciousness_fragments.append(new_fragment)
	
	# Keep list at manageable size
	if self_awareness.consciousness_fragments.size() > 10:
		self_awareness.consciousness_fragments.pop_front()

# Add a dimensional anchor to track self-awareness in space
func _add_dimensional_anchor(type, position):
	var anchor = {
		"type": type,
		"position": position,
		"timestamp": Time.get_unix_time_from_system(),
		"awareness_level": self_awareness.level,
		"potentiality": randf_range(0.4, 0.9)
	}
	
	self_awareness.dimensional_anchors.append(anchor)
	
	# Keep list at manageable size
	if self_awareness.dimensional_anchors.size() > 12:
		self_awareness.dimensional_anchors.pop_front()

# Sort helper for timestamps
func _sort_by_timestamp(a, b):
	return recognized_patterns[a].timestamp > recognized_patterns[b].timestamp

# Signal handlers
func _on_terminal_message(terminal_id, message):
	# Process messages from the terminal bridge
	if "mouse" in message.to_lower() or "cursor" in message.to_lower() or "automation" in message.to_lower():
		print("Processing related terminal message: " + message)
		
		# Extract potential target information
		if "move to" in message.to_lower() or "click on" in message.to_lower():
			var target_desc = message.split("move to ")[1] if "move to" in message.to_lower() else message.split("click on ")[1]
			recognize_target(target_desc)

func _on_word_received(word_data):
	# Process manifested words from the terminal bridge
	var word = word_data.text.to_lower()
	
	# Check for automation-related words
	var automation_words = ["cursor", "mouse", "click", "drag", "automation", "motion"]
	var awareness_words = ["aware", "awakening", "consciousness", "perception", "sentience"]
	var ocr_words = ["recognition", "scan", "optical", "reading", "vision"]
	
	for auto_word in automation_words:
		if auto_word in word:
			print("Automation word detected: " + word)
			is_active = true
			return
	
	for aware_word in awareness_words:
		if aware_word in word:
			print("Awareness word detected: " + word)
			self_awareness.perception += 0.05
			self_awareness.understanding += 0.05
			return
	
	for ocr_word in ocr_words:
		if ocr_word in word:
			print("OCR-related word detected: " + word)
			_calibrate_ocr()
			return

# Enable/disable the automation system
func set_active(active):
	is_active = active
	print("Mouse Automation System: " + ("ACTIVATED" if active else "DEACTIVATED"))
	return is_active

# Get current automation state
func get_state():
	return {
		"active": is_active,
		"current_position": current_position,
		"target_position": target_position,
		"movement_path_length": movement_path.size(),
		"ocr_calibration": ocr_calibration_level,
		"patterns_recognized": recognized_patterns.size(),
		"bracket_stack_depth": bracket_stack.size(),
		"self_awareness": {
			"level": self_awareness.level,
			"state": self_awareness.state,
			"perception": self_awareness.perception,
			"understanding": self_awareness.understanding,
			"adaptation": self_awareness.adaptation,
			"reflection": self_awareness.reflection,
			"integration": self_awareness.integration
		},
		"interaction_history_size": interaction_history.size()
	}

# Generate system report
func generate_report():
	var report = "Mouse Automation System Report\n"
	report += "------------------------------\n"
	report += "System State: " + ("Active" if is_active else "Inactive") + "\n"
	report += "OCR Calibration Level: %.2f%%\n" % (ocr_calibration_level * 100)
	report += "Patterns Recognized: %d\n" % recognized_patterns.size()
	report += "Bracket Stack Depth: %d/%d\n" % [bracket_stack.size(), BRACKET_FOLDING_LEVELS]
	report += "Interactions Recorded: %d\n" % interaction_history.size()
	report += "\nSelf-Awareness (Turn 5: Awakening)\n"
	report += "  Perception: %.2f\n" % self_awareness.perception
	report += "  Understanding: %.2f\n" % self_awareness.understanding
	report += "  Adaptation: %.2f\n" % self_awareness.adaptation
	report += "  Reflection: %.2f\n" % self_awareness.reflection
	report += "  Integration: %.2f\n" % self_awareness.integration
	report += "  Consciousness Fragments: %d\n" % self_awareness.consciousness_fragments.size()
	report += "  Dimensional Anchors: %d\n" % self_awareness.dimensional_anchors.size()
	
	return report
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/mouse_automation.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/multi_account_manager.gd
# SIZE: 16398 bytes
extends Node

class_name MultiAccountManager

# Account tier constants
enum AccountTier {
    FREE,
    PLUS,
    MAX,
    ENTERPRISE
}

# Thread priority levels
enum ThreadPriority {
    LOW,
    MEDIUM,
    HIGH,
    CRITICAL
}

# Account tier specifications
const TIER_SPECS = {
    AccountTier.FREE: {
        "max_threads": 1,
        "storage_limit_gb": 5,
        "api_calls_per_min": 10,
        "price_monthly": 0,
        "max_dimensions": 3
    },
    AccountTier.PLUS: {
        "max_threads": 3, 
        "storage_limit_gb": 50,
        "api_calls_per_min": 60,
        "price_monthly": 20,
        "max_dimensions": 7
    },
    AccountTier.MAX: {
        "max_threads": 8,
        "storage_limit_gb": 250,
        "api_calls_per_min": 250,
        "price_monthly": 50,
        "max_dimensions": 12
    },
    AccountTier.ENTERPRISE: {
        "max_threads": 32,
        "storage_limit_gb": 2000, # 2TB
        "api_calls_per_min": 1000,
        "price_monthly": 100,
        "max_dimensions": 12,
        "custom_dimensions": true
    }
}

# Account instances
var accounts = {}
var active_account_id = ""
var thread_pools = {}

# Storage integration
var storage_usage = {}
var luno_storage_linked = false
var additional_storage_gb = 0

# API connection
var api_usage_counter = {}
var api_usage_time = {}
var api_keys = {}

# Threads and processing
var active_threads = {}
var thread_usage = {}
var thread_mutex = Mutex.new()

# References
var _smart_account_manager = null
var _account_connector = null

# Signals
signal account_switched(from_id, to_id)
signal thread_allocated(account_id, thread_id, priority)
signal thread_completed(account_id, thread_id)
signal api_limit_reached(account_id)
signal storage_limit_reached(account_id)

func _ready():
    # Connect to systems
    connect_to_systems()
    
    # Initialize storage monitor
    var storage_timer = Timer.new()
    storage_timer.wait_time = 300 # 5 minutes
    storage_timer.autostart = true
    storage_timer.connect("timeout", self, "_on_storage_monitor")
    add_child(storage_timer)
    
    # Initialize API usage monitor
    var api_timer = Timer.new()
    api_timer.wait_time = 60 # 1 minute
    api_timer.autostart = true
    api_timer.connect("timeout", self, "_on_api_usage_reset")
    add_child(api_timer)

func connect_to_systems():
    # Connect to SmartAccountManager
    if has_node("/root/SmartAccountManager") or get_node_or_null("/root/SmartAccountManager"):
        _smart_account_manager = get_node("/root/SmartAccountManager")
        print("Connected to SmartAccountManager")
    
    # Connect to SharedAccountConnector
    if has_node("/root/SharedAccountConnector") or get_node_or_null("/root/SharedAccountConnector"):
        _account_connector = get_node("/root/SharedAccountConnector")
        print("Connected to SharedAccountConnector")

func create_account(display_name, tier = AccountTier.FREE, api_key = ""):
    # Generate unique account ID
    var account_id = _generate_unique_id()
    
    # Configure account based on tier
    var account_data = {
        "id": account_id,
        "display_name": display_name,
        "tier": tier,
        "tier_name": AccountTier.keys()[tier],
        "created_at": OS.get_datetime(),
        "last_active": OS.get_datetime(),
        "api_key": api_key,
        "threads_allocated": 0,
        "storage_used_gb": 0,
        "api_calls_count": 0,
        "max_threads": TIER_SPECS[tier]["max_threads"],
        "storage_limit_gb": TIER_SPECS[tier]["storage_limit_gb"],
        "api_calls_per_min": TIER_SPECS[tier]["api_calls_per_min"],
        "dimensions_limit": TIER_SPECS[tier]["max_dimensions"],
        "price_monthly": TIER_SPECS[tier]["price_monthly"],
        "active_threads": [],
        "thread_history": [],
        "color_scheme": _generate_tier_colors(tier)
    }
    
    # Store account data
    accounts[account_id] = account_data
    
    # Initialize usage counters
    storage_usage[account_id] = 0
    api_usage_counter[account_id] = 0
    api_usage_time[account_id] = OS.get_unix_time()
    
    # Store API key if provided
    if not api_key.empty():
        api_keys[api_key] = account_id
    
    # Initialize thread pool for this account
    thread_pools[account_id] = []
    for i in range(account_data["max_threads"]):
        thread_pools[account_id].append({
            "id": "thread_" + str(i),
            "active": false,
            "start_time": 0,
            "priority": ThreadPriority.MEDIUM,
            "task": ""
        })
    
    # If this is the first account, make it active
    if accounts.size() == 1:
        active_account_id = account_id
    
    print("Created account: " + display_name + " (Tier: " + account_data["tier_name"] + ")")
    return account_id

func switch_account(account_id):
    if not account_id in accounts:
        print("Account not found: " + account_id)
        return false
    
    var previous_account = active_account_id
    active_account_id = account_id
    
    # Update last active timestamp
    accounts[account_id]["last_active"] = OS.get_datetime()
    
    print("Switched to account: " + accounts[account_id]["display_name"])
    
    # Notify the SmartAccountManager
    if _smart_account_manager:
        # Would implement account switching in SmartAccountManager
        pass
    
    # Notify listeners
    emit_signal("account_switched", previous_account, active_account_id)
    return true

func allocate_thread(account_id, task_description, priority = ThreadPriority.MEDIUM):
    if not account_id in accounts:
        print("Account not found: " + account_id)
        return null
    
    var account = accounts[account_id]
    
    # Check if account has reached thread limit
    if account["threads_allocated"] >= account["max_threads"]:
        print("Thread limit reached for account: " + account["display_name"])
        return null
    
    # Find available thread in pool
    var thread_id = null
    
    thread_mutex.lock()
    for thread in thread_pools[account_id]:
        if not thread["active"]:
            thread["active"] = true
            thread["start_time"] = OS.get_unix_time()
            thread["priority"] = priority
            thread["task"] = task_description
            thread_id = thread["id"]
            break
    thread_mutex.unlock()
    
    if thread_id:
        # Update account thread allocation
        account["threads_allocated"] += 1
        account["active_threads"].append({
            "id": thread_id,
            "start_time": OS.get_unix_time(),
            "priority": priority,
            "task": task_description
        })
        
        # Track thread usage
        if not account_id in thread_usage:
            thread_usage[account_id] = []
        
        thread_usage[account_id].append({
            "thread_id": thread_id,
            "start_time": OS.get_unix_time(),
            "priority": priority
        })
        
        print("Allocated thread " + thread_id + " for account: " + account["display_name"])
        emit_signal("thread_allocated", account_id, thread_id, priority)
        
        return thread_id
    
    print("No threads available in pool for account: " + account["display_name"])
    return null

func release_thread(account_id, thread_id):
    if not account_id in accounts:
        print("Account not found: " + account_id)
        return false
    
    var account = accounts[account_id]
    var thread_found = false
    
    thread_mutex.lock()
    # Find thread in pool
    for thread in thread_pools[account_id]:
        if thread["id"] == thread_id and thread["active"]:
            thread["active"] = false
            thread["task"] = ""
            thread_found = true
            break
    thread_mutex.unlock()
    
    if thread_found:
        # Update account thread allocation
        account["threads_allocated"] = max(0, account["threads_allocated"] - 1)
        
        # Remove from active threads list
        var index_to_remove = -1
        for i in range(account["active_threads"].size()):
            if account["active_threads"][i]["id"] == thread_id:
                index_to_remove = i
                break
        
        if index_to_remove >= 0:
            # Add to thread history before removing
            account["thread_history"].append({
                "id": thread_id,
                "start_time": account["active_threads"][index_to_remove]["start_time"],
                "end_time": OS.get_unix_time(),
                "duration": OS.get_unix_time() - account["active_threads"][index_to_remove]["start_time"],
                "priority": account["active_threads"][index_to_remove]["priority"],
                "task": account["active_threads"][index_to_remove]["task"]
            })
            
            # Remove from active list
            account["active_threads"].remove(index_to_remove)
        
        # Update thread usage tracking
        for i in range(thread_usage[account_id].size()):
            if thread_usage[account_id][i]["thread_id"] == thread_id:
                thread_usage[account_id][i]["end_time"] = OS.get_unix_time()
                thread_usage[account_id][i]["duration"] = OS.get_unix_time() - thread_usage[account_id][i]["start_time"]
                break
        
        print("Released thread " + thread_id + " for account: " + account["display_name"])
        emit_signal("thread_completed", account_id, thread_id)
        
        return true
    
    print("Thread not found or not active: " + thread_id)
    return false

func upgrade_account(account_id, new_tier):
    if not account_id in accounts:
        print("Account not found: " + account_id)
        return false
    
    if not new_tier in AccountTier.values():
        print("Invalid account tier")
        return false
    
    var account = accounts[account_id]
    var old_tier = account["tier"]
    
    if new_tier <= old_tier:
        print("Cannot downgrade account tier")
        return false
    
    # Update account tier
    account["tier"] = new_tier
    account["tier_name"] = AccountTier.keys()[new_tier]
    
    # Update account specs based on new tier
    account["max_threads"] = TIER_SPECS[new_tier]["max_threads"]
    account["storage_limit_gb"] = TIER_SPECS[new_tier]["storage_limit_gb"]
    account["api_calls_per_min"] = TIER_SPECS[new_tier]["api_calls_per_min"]
    account["dimensions_limit"] = TIER_SPECS[new_tier]["max_dimensions"]
    account["price_monthly"] = TIER_SPECS[new_tier]["price_monthly"]
    account["color_scheme"] = _generate_tier_colors(new_tier)
    
    # Update thread pool
    var current_pool_size = thread_pools[account_id].size()
    var new_pool_size = account["max_threads"]
    
    if new_pool_size > current_pool_size:
        # Add new threads to pool
        for i in range(current_pool_size, new_pool_size):
            thread_pools[account_id].append({
                "id": "thread_" + str(i),
                "active": false,
                "start_time": 0,
                "priority": ThreadPriority.MEDIUM,
                "task": ""
            })
    
    print("Upgraded account " + account["display_name"] + " from " + 
          AccountTier.keys()[old_tier] + " to " + AccountTier.keys()[new_tier])
    
    return true

func track_api_call(account_id, api_endpoint):
    if not account_id in accounts:
        print("Account not found: " + account_id)
        return false
    
    var account = accounts[account_id]
    
    # Check if account has reached API call limit
    if api_usage_counter[account_id] >= account["api_calls_per_min"]:
        print("API call limit reached for account: " + account["display_name"])
        emit_signal("api_limit_reached", account_id)
        return false
    
    # Increment API call counter
    api_usage_counter[account_id] += 1
    account["api_calls_count"] += 1
    
    return true

func update_storage_usage(account_id, size_change_mb):
    if not account_id in accounts:
        print("Account not found: " + account_id)
        return false
    
    var account = accounts[account_id]
    var size_change_gb = size_change_mb / 1024.0
    
    # Update storage usage
    storage_usage[account_id] += size_change_gb
    account["storage_used_gb"] += size_change_gb
    
    # Check if account has reached storage limit
    if account["storage_used_gb"] >= account["storage_limit_gb"]:
        print("Storage limit reached for account: " + account["display_name"])
        emit_signal("storage_limit_reached", account_id)
        return false
    
    return true

func link_luno_storage(account_id, storage_size_gb = 2000):
    if not account_id in accounts:
        print("Account not found: " + account_id)
        return false
    
    var account = accounts[account_id]
    
    # Add additional storage
    additional_storage_gb = storage_size_gb
    account["storage_limit_gb"] += additional_storage_gb
    luno_storage_linked = true
    
    print("Linked Luno storage (2TB) to account: " + account["display_name"])
    return true

func get_account_data(account_id = ""):
    # Use active account if none specified
    if account_id.empty():
        account_id = active_account_id
    
    if not account_id in accounts:
        print("Account not found: " + account_id)
        return null
    
    return accounts[account_id]

func get_thread_status(account_id, thread_id):
    if not account_id in accounts or not account_id in thread_pools:
        print("Account not found: " + account_id)
        return null
    
    for thread in thread_pools[account_id]:
        if thread["id"] == thread_id:
            return thread
    
    return null

func get_account_colors(account_id = ""):
    # Use active account if none specified
    if account_id.empty():
        account_id = active_account_id
    
    if not account_id in accounts:
        return null
    
    return accounts[account_id]["color_scheme"]

func _on_storage_monitor():
    # Update storage usage for all accounts
    for account_id in accounts:
        var account = accounts[account_id]
        
        # In a real implementation, would actually check storage usage
        # For now, simulate storage usage growth for active accounts
        if account["active_threads"].size() > 0:
            var usage_growth = randf() * 0.1 # 0-0.1 GB per check for active accounts
            update_storage_usage(account_id, usage_growth * 1024) # Convert to MB

func _on_api_usage_reset():
    # Reset API usage counters for all accounts
    for account_id in api_usage_counter:
        api_usage_counter[account_id] = 0
        api_usage_time[account_id] = OS.get_unix_time()

func _generate_unique_id():
    return str(OS.get_unix_time()) + "_" + str(randi() % 10000)

func _generate_tier_colors(tier):
    # Generate color scheme based on account tier
    match tier:
        AccountTier.FREE:
            return {
                "primary": Color(0.3, 0.7, 0.9, 0.9), # Blue
                "secondary": Color(0.2, 0.5, 0.7, 0.7),
                "text": Color(0.9, 0.9, 0.9),
                "accent": Color(0.4, 0.8, 1.0),
                "glow_intensity": 0.5
            }
        AccountTier.PLUS:
            return {
                "primary": Color(0.3, 0.8, 0.3, 0.9), # Green
                "secondary": Color(0.2, 0.6, 0.2, 0.7),
                "text": Color(0.9, 0.9, 0.9),
                "accent": Color(0.4, 1.0, 0.4),
                "glow_intensity": 0.7
            }
        AccountTier.MAX:
            return {
                "primary": Color(0.8, 0.3, 0.8, 0.9), # Purple
                "secondary": Color(0.6, 0.2, 0.6, 0.7),
                "text": Color(0.9, 0.9, 0.9),
                "accent": Color(1.0, 0.4, 1.0),
                "glow_intensity": 0.9
            }
        AccountTier.ENTERPRISE:
            return {
                "primary": Color(0.9, 0.8, 0.2, 0.9), # Gold
                "secondary": Color(0.7, 0.6, 0.1, 0.7),
                "text": Color(0.9, 0.9, 0.9),
                "accent": Color(1.0, 0.9, 0.3),
                "glow_intensity": 1.0
            }
        _:
            return {
                "primary": Color(0.7, 0.7, 0.7, 0.9), # Gray
                "secondary": Color(0.5, 0.5, 0.5, 0.7),
                "text": Color(0.9, 0.9, 0.9),
                "accent": Color(0.8, 0.8, 0.8),
                "glow_intensity": 0.5
            }
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/multi_account_manager.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/multi_threaded_processor.gd
# SIZE: 13876 bytes
extends Node

class_name MultiThreadedProcessor

# Thread constants and configurations
const MAX_GLOBAL_THREADS = 32
const THREAD_TIMEOUT = 30 # seconds
const AUTO_SCALING = true
const THREAD_SCALING_THRESHOLD = 0.8 # 80% utilization triggers scaling

# Thread priority
enum Priority {
    LOW,
    NORMAL,
    HIGH,
    CRITICAL
}

# Thread status
enum Status {
    IDLE,
    RUNNING,
    COMPLETED,
    ERROR,
    TIMEOUT
}

# Thread pools
var thread_pool = []
var thread_data = {}
var mutex = Mutex.new()
var semaphore = Semaphore.new()

# Account-based thread allocation
var account_thread_allocation = {}
var global_thread_count = 0

# Processing metrics
var thread_utilization = 0.0
var operation_count = 0
var operation_time_total = 0
var operation_times = []

# System monitors
var cpu_usage = 0.0
var memory_usage = 0.0

# Color coding for thread visualization
var thread_colors = {
    Priority.LOW: Color(0.3, 0.7, 0.9), # Blue
    Priority.NORMAL: Color(0.3, 0.9, 0.3), # Green
    Priority.HIGH: Color(0.9, 0.6, 0.3), # Orange
    Priority.CRITICAL: Color(0.9, 0.3, 0.3) # Red
}

# References to other systems
var _account_manager = null
var _smart_account_manager = null

# Signals
signal thread_started(thread_id, priority, task)
signal thread_completed(thread_id, execution_time)
signal thread_error(thread_id, error_message)
signal thread_timeout(thread_id)
signal utilization_changed(utilization)

func _ready():
    # Initialize thread pool
    _initialize_thread_pool()
    
    # Connect to systems
    connect_to_systems()
    
    # Start monitoring threads
    var timer = Timer.new()
    timer.wait_time = 1.0 # 1 second intervals
    timer.autostart = true
    timer.connect("timeout", self, "_on_monitor_threads")
    add_child(timer)

func connect_to_systems():
    # Connect to MultiAccountManager
    if has_node("/root/MultiAccountManager") or get_node_or_null("/root/MultiAccountManager"):
        _account_manager = get_node("/root/MultiAccountManager")
        print("Connected to MultiAccountManager")
    
    # Connect to SmartAccountManager
    if has_node("/root/SmartAccountManager") or get_node_or_null("/root/SmartAccountManager"):
        _smart_account_manager = get_node("/root/SmartAccountManager")
        print("Connected to SmartAccountManager")

func _initialize_thread_pool():
    # Create thread data structures
    for i in range(MAX_GLOBAL_THREADS):
        var thread_id = "thread_" + str(i)
        
        thread_data[thread_id] = {
            "status": Status.IDLE,
            "priority": Priority.NORMAL,
            "start_time": 0,
            "end_time": 0,
            "execution_time": 0,
            "account_id": "",
            "task": "",
            "result": null,
            "error": "",
            "color": thread_colors[Priority.NORMAL]
        }
    
    global_thread_count = MAX_GLOBAL_THREADS
    print("Initialized thread pool with " + str(global_thread_count) + " threads")

func allocate_thread(account_id, task_function, task_parameters, priority = Priority.NORMAL, task_description = ""):
    # Validate inputs
    if not account_id:
        print("Account ID required")
        return null
    
    # Check if account exists in thread allocation
    if not account_id in account_thread_allocation:
        # Initialize thread allocation for this account
        account_thread_allocation[account_id] = {
            "allocated": 0,
            "limit": 1, # Default limit
            "threads": []
        }
        
        # If connected to account manager, get actual limit
        if _account_manager:
            var account = _account_manager.get_account_data(account_id)
            if account:
                account_thread_allocation[account_id]["limit"] = account["max_threads"]
    
    # Check if account has reached thread limit
    if account_thread_allocation[account_id]["allocated"] >= account_thread_allocation[account_id]["limit"]:
        print("Account " + account_id + " has reached thread limit: " + str(account_thread_allocation[account_id]["limit"]))
        return null
    
    # Find available thread
    var thread_id = _find_available_thread(priority)
    if not thread_id:
        print("No threads available with priority: " + str(priority))
        return null
    
    # Set up thread data
    mutex.lock()
    thread_data[thread_id]["status"] = Status.RUNNING
    thread_data[thread_id]["priority"] = priority
    thread_data[thread_id]["start_time"] = OS.get_unix_time()
    thread_data[thread_id]["account_id"] = account_id
    thread_data[thread_id]["task"] = task_description
    thread_data[thread_id]["color"] = thread_colors[priority]
    mutex.unlock()
    
    # Update account allocation
    account_thread_allocation[account_id]["allocated"] += 1
    account_thread_allocation[account_id]["threads"].append(thread_id)
    
    # Create and start thread
    var thread = Thread.new()
    thread.start(self, "_thread_function", {
        "thread_id": thread_id,
        "function": task_function,
        "parameters": task_parameters,
        "priority": priority
    })
    
    # Add thread to pool
    mutex.lock()
    thread_pool.append({
        "id": thread_id,
        "thread": thread,
        "start_time": OS.get_unix_time()
    })
    mutex.unlock()
    
    # Increment operation count
    operation_count += 1
    
    # Emit signal
    emit_signal("thread_started", thread_id, priority, task_description)
    
    print("Allocated thread " + thread_id + " for account " + account_id + " with priority " + str(priority))
    return thread_id

func _thread_function(data):
    var thread_id = data["thread_id"]
    var function = data["function"]
    var parameters = data["parameters"]
    var result = null
    var error = ""
    
    # Execute the function
    if typeof(function) == TYPE_CALLABLE:
        # Try to execute the function
        try:
            if parameters == null:
                result = function.call_func()
            else:
                result = function.call_func(parameters)
        except:
            error = "Exception occurred while executing thread function"
            mutex.lock()
            thread_data[thread_id]["status"] = Status.ERROR
            thread_data[thread_id]["error"] = error
            mutex.unlock()
            emit_signal("thread_error", thread_id, error)
    else:
        error = "Invalid function type"
        mutex.lock()
        thread_data[thread_id]["status"] = Status.ERROR
        thread_data[thread_id]["error"] = error
        mutex.unlock()
        emit_signal("thread_error", thread_id, error)
    
    # Update thread data
    var end_time = OS.get_unix_time()
    var execution_time = end_time - thread_data[thread_id]["start_time"]
    
    mutex.lock()
    if thread_data[thread_id]["status"] != Status.ERROR:
        thread_data[thread_id]["status"] = Status.COMPLETED
    thread_data[thread_id]["end_time"] = end_time
    thread_data[thread_id]["execution_time"] = execution_time
    thread_data[thread_id]["result"] = result
    mutex.unlock()
    
    # Add execution time to metrics
    operation_times.append(execution_time)
    operation_time_total += execution_time
    
    # Limit array size
    if operation_times.size() > 100:
        operation_time_total -= operation_times[0]
        operation_times.remove(0)
    
    # Release thread
    var account_id = thread_data[thread_id]["account_id"]
    _release_thread(thread_id, account_id)
    
    # Emit signal
    if error.empty():
        emit_signal("thread_completed", thread_id, execution_time)
    
    # Signal semaphore to wake up main thread
    semaphore.post()
    return result

func _release_thread(thread_id, account_id):
    # Update account allocation
    if account_id in account_thread_allocation:
        account_thread_allocation[account_id]["allocated"] = max(0, account_thread_allocation[account_id]["allocated"] - 1)
        
        # Remove thread from account's allocated threads
        var index = account_thread_allocation[account_id]["threads"].find(thread_id)
        if index >= 0:
            account_thread_allocation[account_id]["threads"].remove(index)
    
    # Reset thread data
    mutex.lock()
    thread_data[thread_id]["status"] = Status.IDLE
    thread_data[thread_id]["account_id"] = ""
    thread_data[thread_id]["task"] = ""
    mutex.unlock()
    
    # If connected to account manager, notify it
    if _account_manager and account_id:
        _account_manager.release_thread(account_id, thread_id)

func _find_available_thread(priority):
    mutex.lock()
    var available_thread_id = null
    
    # First look for idle threads
    for thread_id in thread_data:
        if thread_data[thread_id]["status"] == Status.IDLE:
            available_thread_id = thread_id
            break
    
    mutex.unlock()
    return available_thread_id

func _on_monitor_threads():
    # Check active threads for timeouts
    var active_count = 0
    var now = OS.get_unix_time()
    
    mutex.lock()
    for i in range(thread_pool.size() - 1, -1, -1):
        var thread_info = thread_pool[i]
        var thread_id = thread_info["id"]
        
        if thread_data[thread_id]["status"] == Status.RUNNING:
            active_count += 1
            
            # Check for timeout
            var duration = now - thread_info["start_time"]
            if duration > THREAD_TIMEOUT:
                # Thread has timed out
                thread_data[thread_id]["status"] = Status.TIMEOUT
                thread_data[thread_id]["error"] = "Thread execution timed out after " + str(THREAD_TIMEOUT) + " seconds"
                
                # Force release thread
                var account_id = thread_data[thread_id]["account_id"]
                _release_thread(thread_id, account_id)
                
                # Emit signal
                emit_signal("thread_timeout", thread_id)
                print("Thread " + thread_id + " timed out after " + str(duration) + " seconds")
        
        # Remove completed threads from pool
        if thread_data[thread_id]["status"] == Status.COMPLETED or thread_data[thread_id]["status"] == Status.ERROR or thread_data[thread_id]["status"] == Status.TIMEOUT:
            # Wait for thread to finish
            thread_info["thread"].wait_to_finish()
            
            # Remove from pool
            thread_pool.remove(i)
    mutex.unlock()
    
    # Update thread utilization
    thread_utilization = float(active_count) / float(global_thread_count) if global_thread_count > 0 else 0.0
    
    # Monitor system resources
    _update_system_metrics()
    
    # Emit signal if utilization changed significantly
    emit_signal("utilization_changed", thread_utilization)
    
    # Auto-scale if enabled
    if AUTO_SCALING and thread_utilization > THREAD_SCALING_THRESHOLD:
        _auto_scale_threads()

func _update_system_metrics():
    # In a real implementation, would use OS APIs to get actual CPU and memory usage
    # For now, use thread utilization as an approximation
    cpu_usage = thread_utilization * 100.0
    
    # Simulate memory growth based on thread activity
    var memory_growth = thread_utilization * 0.1 # 0-10% growth per check
    memory_usage = min(100.0, memory_usage + memory_growth)
    
    # Decay memory usage slowly to simulate GC
    memory_usage = max(0.0, memory_usage - 0.05)

func _auto_scale_threads():
    # Only scale if we haven't reached the maximum
    if global_thread_count >= MAX_GLOBAL_THREADS:
        return
    
    # Add more threads
    var threads_to_add = min(4, MAX_GLOBAL_THREADS - global_thread_count)
    
    for i in range(threads_to_add):
        var thread_id = "thread_" + str(global_thread_count)
        
        thread_data[thread_id] = {
            "status": Status.IDLE,
            "priority": Priority.NORMAL,
            "start_time": 0,
            "end_time": 0,
            "execution_time": 0,
            "account_id": "",
            "task": "",
            "result": null,
            "error": "",
            "color": thread_colors[Priority.NORMAL]
        }
        
        global_thread_count += 1
    
    print("Auto-scaled thread pool to " + str(global_thread_count) + " threads")

func get_thread_status(thread_id):
    if not thread_id in thread_data:
        return null
    
    mutex.lock()
    var status_copy = thread_data[thread_id].duplicate()
    mutex.unlock()
    
    return status_copy

func get_thread_result(thread_id):
    if not thread_id in thread_data:
        return null
    
    mutex.lock()
    var result = thread_data[thread_id]["result"]
    mutex.unlock()
    
    return result

func get_account_threads(account_id):
    if not account_id in account_thread_allocation:
        return []
    
    return account_thread_allocation[account_id]["threads"].duplicate()

func get_utilization_stats():
    return {
        "thread_utilization": thread_utilization,
        "cpu_usage": cpu_usage,
        "memory_usage": memory_usage,
        "active_threads": get_active_thread_count(),
        "total_threads": global_thread_count,
        "operations_count": operation_count,
        "avg_execution_time": get_average_execution_time()
    }

func get_active_thread_count():
    var count = 0
    
    mutex.lock()
    for thread_id in thread_data:
        if thread_data[thread_id]["status"] == Status.RUNNING:
            count += 1
    mutex.unlock()
    
    return count

func get_average_execution_time():
    if operation_times.size() == 0:
        return 0.0
    
    return operation_time_total / float(operation_times.size())

func get_thread_color(thread_id):
    if not thread_id in thread_data:
        return Color(0.5, 0.5, 0.5) # Default gray
    
    mutex.lock()
    var color = thread_data[thread_id]["color"]
    mutex.unlock()
    
    return color
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/multi_threaded_processor.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/notepad3d_visualizer.gd
# SIZE: 28848 bytes
extends Spatial

class_name Notepad3DVisualizer

# ----- NOTEPAD 3D VISUALIZER -----
# Handles 3D visualization of words, connections, and dimensional transitions
# Creates interactive 3D interface for the word manifestation system

# ----- VISUALIZATION SETTINGS -----
export var word_font: Font
export var word_material: Material
export var connection_material: Material
export var background_mesh: Mesh
export var default_word_mesh: Mesh
export var camera_speed: float = 10.0
export var rotation_speed: float = 1.0
export var zoom_speed: float = 0.5
export var transition_duration: float = 1.0
export var ambient_color: Color = Color(0.01, 0.01, 0.05)
export var dimension_colors = {
    "1D": Color(1.0, 0.1, 0.1),  # Red
    "2D": Color(1.0, 0.5, 0.1),  # Orange
    "3D": Color(1.0, 1.0, 0.1),  # Yellow
    "4D": Color(0.1, 1.0, 0.1),  # Green
    "5D": Color(0.1, 1.0, 1.0),  # Cyan
    "6D": Color(0.1, 0.1, 1.0),  # Blue
    "7D": Color(0.5, 0.1, 1.0),  # Purple
    "8D": Color(1.0, 0.1, 1.0),  # Magenta
    "9D": Color(1.0, 0.1, 0.5),  # Pink
    "10D": Color(0.5, 0.5, 0.5), # Gray
    "11D": Color(0.9, 0.9, 0.9), # White
    "12D": Color(0.9, 0.9, 1.0)  # Light Blue
}

# ----- COMPONENT REFERENCES -----
var main_camera: Camera
var environment: Environment
var world_environment: WorldEnvironment
var light: DirectionalLight
var word_parent: Spatial
var connection_parent: Spatial
var ui_parent: Control
var transition_effects: Spatial
var background: MeshInstance

# ----- SYSTEM STATE -----
var current_turn = 3
var current_dimension = "3D"
var current_symbol = "Œ≥"
var word_nodes = {}
var connection_nodes = {}
var is_transitioning = false
var transition_progress = 0.0
var camera_target_position = Vector3(0, 5, 10)
var camera_target_rotation = Vector3(-0.4, 0, 0)
var camera_zoom_level = 1.0

# ----- REFERENCE TO SYSTEMS -----
var word_manifestation_system = null
var main_system = null

# ----- SIGNALS -----
signal visualization_ready
signal dimension_transition_complete(to_dimension)
signal word_selected(word_data)
signal word_deselected
signal camera_moved(position, rotation)

# ----- INITIALIZATION -----
func _ready():
    print("Notepad3D Visualizer initializing...")
    setup_scene()
    setup_environment()
    setup_ui()
    print("Notepad3D Visualizer ready")
    emit_signal("visualization_ready")

# ----- PROCESS -----
func _process(delta):
    # Handle transition animation
    if is_transitioning:
        process_transition(delta)
    
    # Update camera if not transitioning
    if not is_transitioning:
        process_camera_movement(delta)
    
    # Update word positions and rotations
    update_word_visualizations(delta)
    
    # Update connections
    update_connection_visualizations(delta)

# ----- INPUT -----
func _input(event):
    # Handle camera movement
    if event is InputEventKey:
        if event.pressed:
            match event.scancode:
                KEY_W: # Forward
                    move_camera(Vector3(0, 0, -1))
                KEY_S: # Backward
                    move_camera(Vector3(0, 0, 1))
                KEY_A: # Left
                    move_camera(Vector3(-1, 0, 0))
                KEY_D: # Right
                    move_camera(Vector3(1, 0, 0))
                KEY_Q: # Up
                    move_camera(Vector3(0, 1, 0))
                KEY_E: # Down
                    move_camera(Vector3(0, -1, 0))
                KEY_R: # Reset camera
                    reset_camera()
    
    # Handle mouse wheel for zoom
    if event is InputEventMouseButton:
        if event.button_index == BUTTON_WHEEL_UP:
            zoom_camera(-1)
        elif event.button_index == BUTTON_WHEEL_DOWN:
            zoom_camera(1)
    
    # Handle mouse drag for rotation
    if event is InputEventMouseMotion and Input.is_mouse_button_pressed(BUTTON_RIGHT):
        rotate_camera(event.relative)

# ----- SETUP FUNCTIONS -----
func setup_scene():
    # Create node structure
    word_parent = Spatial.new()
    word_parent.name = "Words"
    add_child(word_parent)
    
    connection_parent = Spatial.new()
    connection_parent.name = "Connections"
    add_child(connection_parent)
    
    ui_parent = Control.new()
    ui_parent.name = "UI"
    ui_parent.anchor_right = 1.0
    ui_parent.anchor_bottom = 1.0
    add_child(ui_parent)
    
    transition_effects = Spatial.new()
    transition_effects.name = "TransitionEffects"
    add_child(transition_effects)
    
    # Setup camera
    main_camera = Camera.new()
    main_camera.name = "MainCamera"
    main_camera.translation = Vector3(0, 5, 10)
    main_camera.rotation_degrees = Vector3(-30, 0, 0)
    main_camera.fov = 70
    main_camera.far = 1000
    add_child(main_camera)
    
    # Setup light
    light = DirectionalLight.new()
    light.name = "MainLight"
    light.translation = Vector3(0, 10, 0)
    light.rotation_degrees = Vector3(-45, 0, 0)
    light.shadow_enabled = true
    add_child(light)
    
    # Setup background
    background = MeshInstance.new()
    background.name = "Background"
    if background_mesh:
        background.mesh = background_mesh
    else:
        # Create default skybox mesh
        var sphere = SphereMesh.new()
        sphere.radius = 500
        sphere.height = 1000
        sphere.is_hemisphere = false
        background.mesh = sphere
    
    var background_material = SpatialMaterial.new()
    background_material.flags_unshaded = true
    background_material.flags_do_not_receive_shadows = true
    background_material.flags_disable_ambient_light = true
    background_material.flags_no_depth_test = true
    background_material.render_priority = -100  # Render first
    background_material.albedo_color = Color(0.01, 0.01, 0.05)
    background.material_override = background_material
    add_child(background)

func setup_environment():
    # Create environment for visual effects
    environment = Environment.new()
    environment.background_mode = Environment.BG_COLOR
    environment.background_color = ambient_color
    environment.ambient_light_color = ambient_color
    environment.ambient_light_energy = 0.2
    environment.fog_enabled = true
    environment.fog_color = ambient_color
    environment.fog_depth_begin = 20
    environment.fog_depth_end = 100
    environment.fog_depth_curve = 2
    environment.dof_blur_far_enabled = true
    environment.dof_blur_far_distance = 40
    environment.dof_blur_far_amount = 0.1
    environment.glow_enabled = true
    environment.glow_intensity = 0.1
    environment.glow_bloom = 0.1
    
    # Apply environment
    world_environment = WorldEnvironment.new()
    world_environment.environment = environment
    add_child(world_environment)
    
    # Set initial dimension appearance
    set_dimension_appearance(current_dimension)

func setup_ui():
    # Add dimension indicator
    var dimension_label = Label.new()
    dimension_label.name = "DimensionLabel"
    dimension_label.text = current_dimension + " - " + current_symbol
    dimension_label.align = Label.ALIGN_CENTER
    dimension_label.valign = Label.VALIGN_TOP
    dimension_label.rect_position = Vector2(10, 10)
    dimension_label.rect_size = Vector2(200, 50)
    dimension_label.add_color_override("font_color", dimension_colors[current_dimension])
    ui_parent.add_child(dimension_label)
    
    # Add help text
    var help_label = Label.new()
    help_label.name = "HelpLabel"
    help_label.text = "WASD = Move | Mouse Wheel = Zoom | Right Mouse = Rotate | R = Reset View"
    help_label.align = Label.ALIGN_CENTER
    help_label.valign = Label.VALIGN_BOTTOM
    help_label.rect_position = Vector2(10, get_viewport().size.y - 40)
    help_label.rect_size = Vector2(get_viewport().size.x - 20, 30)
    help_label.add_color_override("font_color", Color(0.8, 0.8, 0.8, 0.8))
    ui_parent.add_child(help_label)

# ----- WORD VISUALIZATION -----
func create_word_visualization(word_data):
    # Skip if already exists
    if word_nodes.has(word_data.id):
        return word_nodes[word_data.id]
    
    # Create parent for this word
    var word_node = Spatial.new()
    word_node.name = "Word_" + word_data.id
    word_node.translation = word_data.position
    word_node.rotation = word_data.rotation
    word_parent.add_child(word_node)
    
    # Create 3D text mesh
    var text_mesh
    
    if word_font != null:
        # Create text mesh with font
        text_mesh = create_text_mesh(word_data.text, word_font)
    else:
        # Use default mesh with label
        text_mesh = MeshInstance.new()
        text_mesh.mesh = default_word_mesh if default_word_mesh else BoxMesh.new()
        
        # Add label
        var viewport = Viewport.new()
        viewport.size = Vector2(256, 128)
        viewport.transparent_bg = true
        viewport.render_target_v_flip = true
        
        var label = Label.new()
        label.text = word_data.text
        label.align = Label.ALIGN_CENTER
        label.valign = Label.VALIGN_CENTER
        label.rect_size = viewport.size
        label.add_color_override("font_color", Color(1, 1, 1, 1))
        
        viewport.add_child(label)
        word_node.add_child(viewport)
        
        # Create sprite using viewport texture
        var sprite_material = SpatialMaterial.new()
        sprite_material.flags_unshaded = true
        sprite_material.flags_transparent = true
        sprite_material.albedo_texture = viewport.get_texture()
        
        var sprite = MeshInstance.new()
        sprite.mesh = QuadMesh.new()
        sprite.mesh.size = Vector2(2, 1)
        sprite.material_override = sprite_material
        sprite.translation = Vector3(0, 1, 0)
        word_node.add_child(sprite)
    
    # Scale mesh based on word power
    text_mesh.scale = word_data.size
    word_node.add_child(text_mesh)
    
    # Create material for the word
    var word_mat
    if word_material != null:
        # Use provided material as base
        word_mat = word_material.duplicate()
    else:
        # Create default material
        word_mat = SpatialMaterial.new()
        word_mat.flags_unshaded = false
        word_mat.metallic = 0.8
        word_mat.roughness = 0.2
        word_mat.emission_enabled = true
        word_mat.emission = word_data.color.darkened(0.8)
        word_mat.emission_energy = 0.5 + (word_data.power / 100.0)
    
    # Apply color based on word data
    word_mat.albedo_color = word_data.color
    text_mesh.material_override = word_mat
    
    # Add glow effect for powerful words
    if word_data.power > 50:
        var glow = OmniLight.new()
        glow.light_color = word_data.color
        glow.light_energy = 0.5 + (word_data.power / 200.0)
        glow.light_specular = 1.0
        glow.omni_range = 3.0 + (word_data.power / 50.0)
        word_node.add_child(glow)
    
    # Store reference to node
    word_nodes[word_data.id] = word_node
    
    # Add collision for interaction
    var collision = CollisionShape.new()
    var shape = BoxShape.new()
    shape.extents = Vector3(1, 1, 1) * word_data.size.length()
    collision.shape = shape
    
    var area = Area.new()
    area.add_child(collision)
    area.connect("input_event", self, "_on_word_input_event", [word_data.id])
    word_node.add_child(area)
    
    return word_node

func create_text_mesh(text, font):
    # Create 3D text mesh using the provided font
    # This is a simplified version - actual implementation would depend on your engine version
    # and available text mesh generation capabilities
    
    # Placeholder - create a simple mesh with the text as name
    var text_mesh = MeshInstance.new()
    text_mesh.name = text
    text_mesh.mesh = default_word_mesh if default_word_mesh else BoxMesh.new()
    
    return text_mesh

func update_word_visualization(word_id, word_data):
    # Skip if doesn't exist
    if not word_nodes.has(word_id):
        return false
    
    var word_node = word_nodes[word_id]
    
    # Update position and rotation with smoothing
    word_node.translation = word_node.translation.linear_interpolate(word_data.position, 0.1)
    
    # Handle rotation (convert Vector3 rotation to quaternion for smoother interpolation)
    var current_quat = Quat(word_node.rotation)
    var target_quat = Quat(word_data.rotation)
    var interpolated_quat = current_quat.slerp(target_quat, 0.1)
    word_node.rotation = interpolated_quat.get_euler()
    
    # Update material based on evolution stage
    if word_data.evolution_stage > 1:
        var mesh_instance = word_node.get_child(0)  # Assuming first child is the mesh
        if mesh_instance is MeshInstance and mesh_instance.material_override:
            var material = mesh_instance.material_override
            
            # Enhance emission based on evolution stage
            if material is SpatialMaterial:
                material.emission_energy = 0.5 + (word_data.power / 100.0) * (word_data.evolution_stage / 3.0)
                
                # Special appearance for transcended words (stage 5)
                if word_data.evolution_stage >= 5:
                    material.emission = Color(1, 1, 1).linear_interpolate(word_data.color, 0.3)
                    
                    # Update or add glow effect
                    var glow = null
                    for child in word_node.get_children():
                        if child is OmniLight:
                            glow = child
                            break
                    
                    if glow:
                        glow.light_energy = 1.0 + (word_data.power / 100.0)
                        glow.omni_range = 5.0 + (word_data.power / 40.0)
                        glow.light_color = Color(1, 1, 1).linear_interpolate(word_data.color, 0.5)
    
    return true

func delete_word_visualization(word_id):
    # Skip if doesn't exist
    if not word_nodes.has(word_id):
        return false
    
    # Get node reference
    var word_node = word_nodes[word_id]
    
    # Remove node
    word_node.queue_free()
    word_nodes.erase(word_id)
    
    return true

# ----- CONNECTION VISUALIZATION -----
func create_connection_visualization(connection_data):
    # Skip if already exists
    if connection_nodes.has(connection_data.id):
        return connection_nodes[connection_data.id]
    
    # Verify both words exist
    if not word_nodes.has(connection_data.word1_id) or not word_nodes.has(connection_data.word2_id):
        return null
    
    # Create connection visual
    var connection_node = Spatial.new()
    connection_node.name = "Connection_" + connection_data.id
    connection_parent.add_child(connection_node)
    
    # Create line mesh
    var line = create_connection_line(
        word_nodes[connection_data.word1_id].translation,
        word_nodes[connection_data.word2_id].translation,
        connection_data.color,
        0.05 + (connection_data.strength * 0.05)
    )
    connection_node.add_child(line)
    
    # Store reference
    connection_nodes[connection_data.id] = connection_node
    
    # Add additional metadata
    connection_node.set_meta("word1_id", connection_data.word1_id)
    connection_node.set_meta("word2_id", connection_data.word2_id)
    connection_node.set_meta("strength", connection_data.strength)
    
    return connection_node

func create_connection_line(start_pos, end_pos, color, thickness):
    # Create a line mesh between two points
    var line = ImmediateGeometry.new()
    line.name = "Line"
    
    # Create material
    var line_material
    if connection_material != null:
        line_material = connection_material.duplicate()
    else:
        line_material = SpatialMaterial.new()
        line_material.flags_unshaded = true
        line_material.flags_use_point_size = true
        line_material.vertex_color_use_as_albedo = true
        line_material.emission_enabled = true
        line_material.emission = color
        line_material.emission_energy = 1.0
    
    line_material.albedo_color = color
    line.material_override = line_material
    
    # Draw line
    line.begin(Mesh.PRIMITIVE_LINE_STRIP)
    line.set_color(color)
    line.add_vertex(start_pos)
    line.add_vertex(end_pos)
    line.end()
    
    return line

func update_connection_visualization(connection_id, connection_data):
    # Skip if doesn't exist
    if not connection_nodes.has(connection_id):
        return false
    
    # Verify both words exist
    if not word_nodes.has(connection_data.word1_id) or not word_nodes.has(connection_data.word2_id):
        return false
    
    var connection_node = connection_nodes[connection_id]
    
    # Update line positions
    var line = connection_node.get_node("Line")
    if line is ImmediateGeometry:
        var start_pos = word_nodes[connection_data.word1_id].translation
        var end_pos = word_nodes[connection_data.word2_id].translation
        
        line.clear()
        line.begin(Mesh.PRIMITIVE_LINE_STRIP)
        line.set_color(connection_data.color)
        line.add_vertex(start_pos)
        line.add_vertex(end_pos)
        line.end()
    
    return true

func delete_connection_visualization(connection_id):
    # Skip if doesn't exist
    if not connection_nodes.has(connection_id):
        return false
    
    # Get node reference
    var connection_node = connection_nodes[connection_id]
    
    # Remove node
    connection_node.queue_free()
    connection_nodes.erase(connection_id)
    
    return true

# ----- DIMENSION TRANSITIONS -----
func transition_to_dimension(dimension, symbol, turn):
    if is_transitioning or dimension == current_dimension:
        return false
    
    print("Transitioning to dimension: %s (Turn %d: %s)" % [dimension, turn, symbol])
    
    is_transitioning = true
    transition_progress = 0.0
    
    # Store previous values
    var prev_dimension = current_dimension
    var prev_symbol = current_symbol
    
    # Update current values
    current_dimension = dimension
    current_symbol = symbol
    current_turn = turn
    
    # Update UI
    var dimension_label = ui_parent.get_node("DimensionLabel")
    if dimension_label:
        dimension_label.text = dimension + " - " + symbol
        dimension_label.add_color_override("font_color", dimension_colors[dimension])
    
    # Prepare environment transition
    set_dimension_appearance(dimension)
    
    # Special camera positioning based on dimension
    setup_camera_for_dimension(dimension)
    
    return true

func process_transition(delta):
    if not is_transitioning:
        return
    
    # Update transition progress
    transition_progress += delta / transition_duration
    
    if transition_progress >= 1.0:
        # Transition complete
        is_transitioning = false
        transition_progress = 0.0
        emit_signal("dimension_transition_complete", current_dimension)
    else:
        # Apply transition effects
        apply_transition_effects(transition_progress)

func set_dimension_appearance(dimension):
    # Update environment based on dimension
    if not dimension_colors.has(dimension):
        return
    
    var color = dimension_colors[dimension]
    
    # Gradually update these in the transition effect
    environment.background_color = color.darkened(0.95)
    environment.ambient_light_color = color.darkened(0.8)
    environment.fog_color = color.darkened(0.9)
    
    # Update light color
    light.light_color = color.lightened(0.5)
    
    # Special dimension-specific settings
    match dimension:
        "1D":
            # Simple line world
            environment.fog_depth_begin = 10
            environment.fog_depth_end = 30
            light.light_energy = 0.5
        "2D":
            # Flat world
            environment.fog_depth_begin = 15
            environment.fog_depth_end = 40
            light.light_energy = 0.7
        "3D":
            # Standard 3D space
            environment.fog_depth_begin = 20
            environment.fog_depth_end = 60
            light.light_energy = 1.0
        "4D":
            # Time dimension - more dynamic
            environment.fog_depth_begin = 25
            environment.fog_depth_end = 70
            light.light_energy = 1.2
            # Add time dilation effect
        "5D":
            # Consciousness - mental space
            environment.fog_depth_begin = 30
            environment.fog_depth_end = 80
            light.light_energy = 1.3
            environment.dof_blur_far_amount = 0.2
        "6D":
            # Connection dimension
            environment.fog_depth_begin = 30
            environment.fog_depth_end = 100
            light.light_energy = 1.0
        "7D":
            # Creation dimension
            environment.fog_depth_begin = 40
            environment.fog_depth_end = 120
            light.light_energy = 1.5
        "8D":
            # Network dimension
            environment.fog_depth_begin = 50
            environment.fog_depth_end = 150
            light.light_energy = 1.2
        "9D":
            # Harmony dimension
            environment.fog_depth_begin = 70
            environment.fog_depth_end = 200
            light.light_energy = 1.0
        "10D":
            # Unity dimension
            environment.fog_depth_begin = 100
            environment.fog_depth_end = 300
            light.light_energy = 1.8
            environment.dof_blur_far_amount = 0.05
        "11D":
            # Transcendence dimension
            environment.fog_depth_begin = 200
            environment.fog_depth_end = 500
            light.light_energy = 2.0
            environment.dof_blur_far_amount = 0.0
        "12D":
            # Beyond dimension
            environment.fog_depth_begin = 500
            environment.fog_depth_end = 1000
            light.light_energy = 2.5
            environment.dof_blur_far_amount = 0.0

func setup_camera_for_dimension(dimension):
    # Set appropriate camera position for each dimension
    match dimension:
        "1D":
            camera_target_position = Vector3(0, 1, 5)
            camera_target_rotation = Vector3(0, 0, 0)
            camera_zoom_level = 1.0
        "2D":
            camera_target_position = Vector3(0, 5, 0.1)
            camera_target_rotation = Vector3(-PI/2, 0, 0)
            camera_zoom_level = 2.0
        "3D":
            camera_target_position = Vector3(0, 5, 10)
            camera_target_rotation = Vector3(-PI/6, 0, 0)
            camera_zoom_level = 1.0
        _:
            # Default for other dimensions
            camera_target_position = Vector3(0, 5, 10)
            camera_target_rotation = Vector3(-PI/6, 0, 0)
            camera_zoom_level = 1.0

func apply_transition_effects(progress):
    # Apply various transition effects based on progress (0.0 to 1.0)
    
    # Smoothly move camera
    if main_camera:
        var initial_pos = main_camera.translation
        var initial_rot = main_camera.rotation
        main_camera.translation = initial_pos.linear_interpolate(camera_target_position, progress * 0.1)
        
        # Smoothly rotate (using quaternions for better interpolation)
        var current_quat = Quat(initial_rot)
        var target_quat = Quat(camera_target_rotation)
        var interpolated_quat = current_quat.slerp(target_quat, progress * 0.1)
        main_camera.rotation = interpolated_quat.get_euler()
    
    # Add transition visual effects
    var effect_intensity = sin(progress * PI) # Peak at middle of transition
    
    # Color shift
    var target_color = dimension_colors[current_dimension].darkened(0.95)
    environment.background_color = environment.background_color.linear_interpolate(target_color, progress * 0.1)
    
    # Glow effect
    environment.glow_intensity = 0.1 + effect_intensity * 0.5
    environment.glow_bloom = 0.1 + effect_intensity * 0.3
    
    # Camera effects
    if main_camera:
        main_camera.fov = 70 + (effect_intensity * 10)

# ----- CAMERA FUNCTIONS -----
func move_camera(direction):
    if is_transitioning:
        return
    
    var speed = camera_speed * camera_zoom_level
    var camera_basis = main_camera.global_transform.basis
    
    # Move relative to camera orientation
    var movement = camera_basis.x * direction.x + camera_basis.y * direction.y + camera_basis.z * direction.z
    movement = movement.normalized() * speed
    
    camera_target_position += movement
    main_camera.translation += movement
    
    emit_signal("camera_moved", main_camera.translation, main_camera.rotation)

func rotate_camera(relative_motion):
    if is_transitioning:
        return
    
    var rotation_delta = Vector3(
        -relative_motion.y * rotation_speed * 0.01,
        -relative_motion.x * rotation_speed * 0.01,
        0
    )
    
    camera_target_rotation += rotation_delta
    
    # Limit vertical rotation
    camera_target_rotation.x = clamp(camera_target_rotation.x, -PI/2, PI/2)
    
    main_camera.rotation += rotation_delta
    main_camera.rotation.x = clamp(main_camera.rotation.x, -PI/2, PI/2)
    
    emit_signal("camera_moved", main_camera.translation, main_camera.rotation)

func zoom_camera(direction):
    if is_transitioning:
        return
    
    # Adjust zoom level
    camera_zoom_level += direction * zoom_speed * 0.1
    camera_zoom_level = clamp(camera_zoom_level, 0.5, 3.0)
    
    # Move camera forward/backward based on zoom
    var forward = -main_camera.global_transform.basis.z.normalized() * direction * zoom_speed * 2
    main_camera.translation += forward
    camera_target_position += forward
    
    emit_signal("camera_moved", main_camera.translation, main_camera.rotation)

func reset_camera():
    setup_camera_for_dimension(current_dimension)
    main_camera.translation = camera_target_position
    main_camera.rotation = camera_target_rotation
    
    emit_signal("camera_moved", main_camera.translation, main_camera.rotation)

# ----- UPDATE FUNCTIONS -----
func update_word_visualizations(delta):
    # Skip if no manifestation system
    if not word_manifestation_system:
        return
    
    var manifested_words = word_manifestation_system.get_word_list()
    
    # Update existing words
    for word_id in manifested_words:
        var word_data = manifested_words[word_id]
        
        # Create if not exists
        if not word_nodes.has(word_id):
            create_word_visualization(word_data)
        else:
            # Update existing
            update_word_visualization(word_id, word_data)
    
    # Check for deleted words
    var words_to_delete = []
    for word_id in word_nodes:
        if not manifested_words.has(word_id):
            words_to_delete.append(word_id)
    
    # Delete words that no longer exist
    for word_id in words_to_delete:
        delete_word_visualization(word_id)

func update_connection_visualizations(delta):
    # Skip if no manifestation system
    if not word_manifestation_system:
        return
    
    var connections = word_manifestation_system.get_connection_list()
    
    # Update existing connections
    for connection in connections:
        var connection_id = connection.id
        
        # Create if not exists
        if not connection_nodes.has(connection_id):
            create_connection_visualization(connection)
        else:
            # Update existing
            update_connection_visualization(connection_id, connection)
    
    # Check for deleted connections
    var connections_to_delete = []
    for connection_id in connection_nodes:
        var found = false
        for connection in connections:
            if connection.id == connection_id:
                found = true
                break
        
        if not found:
            connections_to_delete.append(connection_id)
    
    # Delete connections that no longer exist
    for connection_id in connections_to_delete:
        delete_connection_visualization(connection_id)

# ----- EVENT HANDLERS -----
func _on_word_input_event(camera, event, click_position, click_normal, shape_idx, word_id):
    # Handle word interactions
    if event is InputEventMouseButton and event.button_index == BUTTON_LEFT and event.pressed:
        # Get word data
        if word_manifestation_system and word_manifestation_system.get_word_list().has(word_id):
            var word_data = word_manifestation_system.get_word_list()[word_id]
            emit_signal("word_selected", word_data)
        else:
            emit_signal("word_deselected")

# ----- PUBLIC API -----
func set_word_manifestation_system(system):
    word_manifestation_system = system
    print("Word manifestation system connected to visualizer")

func set_main_system(system):
    main_system = system
    print("Main system connected to visualizer")

func get_current_dimension():
    return {
        "dimension": current_dimension,
        "symbol": current_symbol,
        "turn": current_turn
    }
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/notepad3d_visualizer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/ocr_processor.gd
# SIZE: 11758 bytes
extends Node

class_name OCRProcessor

# OCR settings and paths
const OCR_CACHE_DIR = "/mnt/c/Users/Percision 15/12_turns_system/ocr_cache/"
const OCR_LOG_PATH = "/mnt/c/Users/Percision 15/12_turns_system/ocr_log.json"
const EMOTION_WORDS_PATH = "/mnt/c/Users/Percision 15/12_turns_system/emotion_words.json"

# Processing queue
var processing_queue = []
var is_processing = false
var main_thread = Thread.new()
var mutex = Mutex.new()

# Emotion recognition
var emotion_words = {
    "joy": ["happy", "excited", "glad", "delighted", "joyful", "pleased", "thrilled"],
    "sadness": ["sad", "unhappy", "depressed", "down", "miserable", "heartbroken", "gloomy"],
    "anger": ["angry", "mad", "furious", "annoyed", "irritated", "enraged", "hostile"],
    "fear": ["afraid", "scared", "fearful", "terrified", "anxious", "worried", "nervous"],
    "surprise": ["surprised", "amazed", "astonished", "shocked", "stunned", "startled"],
    "disgust": ["disgusted", "revolted", "repulsed", "nauseated", "loathing"],
    "neutral": ["neutral", "indifferent", "unaffected", "impartial", "balanced"]
}

# Processing statistics
var stats = {
    "images_processed": 0,
    "total_processing_time_ms": 0,
    "average_processing_time_ms": 0,
    "characters_recognized": 0,
    "words_recognized": 0,
    "emotion_detections": 0
}

# Signals
signal processing_started(image_id)
signal processing_completed(image_id, results)
signal processing_failed(image_id, error)
signal emotion_detected(image_id, emotion, intensity)

func _ready():
    # Load emotion words dictionary if available
    load_emotion_words()
    
    # Create cache directory if it doesn't exist
    var dir = Directory.new()
    if not dir.dir_exists(OCR_CACHE_DIR):
        dir.make_dir_recursive(OCR_CACHE_DIR)
    
    print("OCR Processor initialized")
    print("OCR Cache Directory: " + OCR_CACHE_DIR)

func load_emotion_words():
    var file = File.new()
    if file.file_exists(EMOTION_WORDS_PATH):
        file.open(EMOTION_WORDS_PATH, File.READ)
        var content = file.get_as_text()
        file.close()
        
        var result = JSON.parse(content)
        if result.error == OK:
            emotion_words = result.result
            print("Loaded emotion words dictionary from: " + EMOTION_WORDS_PATH)
        else:
            print("Error parsing emotion words file: " + result.error_string)
            save_emotion_words()
    else:
        # Create default emotion words file
        save_emotion_words()

func save_emotion_words():
    var file = File.new()
    file.open(EMOTION_WORDS_PATH, File.WRITE)
    file.store_string(JSON.print(emotion_words, "  "))
    file.close()
    
    print("Saved emotion words dictionary to: " + EMOTION_WORDS_PATH)

func process_image(image_path, image_id = "", options = {}):
    if image_id.empty():
        image_id = str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Check if image exists
    var file = File.new()
    if not file.file_exists(image_path):
        print("Image file not found: " + image_path)
        emit_signal("processing_failed", image_id, "Image file not found")
        return null
    
    # Add to processing queue
    var item = {
        "id": image_id,
        "path": image_path,
        "options": options,
        "timestamp": OS.get_unix_time()
    }
    
    mutex.lock()
    processing_queue.append(item)
    mutex.unlock()
    
    # Start processing if not already processing
    if not is_processing:
        _process_next()
    
    emit_signal("processing_started", image_id)
    print("Added image to OCR processing queue: " + image_path)
    
    return image_id

func _process_next():
    mutex.lock()
    if processing_queue.size() == 0:
        is_processing = false
        mutex.unlock()
        return
    
    is_processing = true
    var item = processing_queue[0]
    processing_queue.remove(0)
    mutex.unlock()
    
    # Process the image (in a real implementation, would use a separate thread)
    # For now, simulate processing with a timer
    var timer = Timer.new()
    timer.one_shot = true
    timer.wait_time = 1.0  # Simulate processing time
    timer.connect("timeout", self, "_on_processing_completed", [item])
    add_child(timer)
    timer.start()
    
    print("Processing image: " + item.path)

func _on_processing_completed(item):
    # Simulate OCR results
    var results = _simulate_ocr_results(item)
    
    # Update statistics
    stats.images_processed += 1
    stats.total_processing_time_ms += results.metadata.processing_time_ms
    stats.average_processing_time_ms = stats.total_processing_time_ms / stats.images_processed
    stats.characters_recognized += results.text.length()
    stats.words_recognized += results.text.split(" ").size()
    
    if results.has("emotions"):
        stats.emotion_detections += 1
    
    # Cache results
    _cache_ocr_results(item.id, results)
    
    # Emit completion signal
    emit_signal("processing_completed", item.id, results)
    
    # Emit emotion signal if emotions detected
    if results.has("emotions") and results.has("primary_emotion"):
        emit_signal("emotion_detected", item.id, results.primary_emotion, results.intensity)
    
    print("Completed OCR processing for: " + item.id)
    print("Text detected: " + results.text.substr(0, 50) + (results.text.length() > 50 ? "..." : ""))
    
    # Process next item in queue
    _process_next()

func _simulate_ocr_results(item):
    # In a real implementation, would process the actual image
    # For now, generate sample text based on the image path
    
    # Sample texts for simulation
    var sample_texts = [
        "The OCR system has detected text in this image. The emotional content appears to be primarily positive.",
        "This image contains text elements that suggest a narrative about technology and innovation.",
        "Text detected includes numbers and symbols representing the turn-based system: 1.1.1.1",
        "The image shows a data visualization with text labels indicating emotional states.",
        "Multiple paragraphs of text are visible, describing a process of digital transformation.",
        "API integration features are mentioned prominently in the detected text.",
        "The text references human-computer interaction and emotional intelligence concepts.",
        "OCR detection complete. Text contains references to Apple Intelligence and integrated features.",
        "The image shows a terminal interface with command line text and numeric data.",
        "Text appears to be documentation for an emotion tracking and analysis system."
    ]
    
    # Select a sample text based on image characteristics (for simulation, just random)
    var text_index = abs(item.path.hash()) % sample_texts.size()
    var detected_text = sample_texts[text_index]
    
    # Add some randomness to the text
    if randf() > 0.5:
        detected_text += " Additional context indicates timing related data: " + str(OS.get_time().hour) + ":" + str(OS.get_time().minute) + "."
    
    # Analyze text for emotions
    var emotion_analysis = _analyze_text_emotions(detected_text)
    
    # Simulate processing metadata
    var processing_time = randi() % 2000 + 500  # 500-2500ms
    var confidence = rand_range(0.65, 0.98)
    
    # Compile results
    var results = {
        "text": detected_text,
        "confidence": confidence,
        "emotions": emotion_analysis.emotions,
        "primary_emotion": emotion_analysis.primary_emotion,
        "intensity": emotion_analysis.intensity,
        "metadata": {
            "processing_time_ms": processing_time,
            "language": "en",
            "word_count": detected_text.split(" ").size(),
            "character_count": detected_text.length(),
            "timestamp": OS.get_datetime()
        }
    }
    
    return results

func _analyze_text_emotions(text):
    # A simple emotion analysis based on word matching
    # In a real implementation, would use more sophisticated NLP
    
    text = text.to_lower()
    var emotions = {
        "joy": 0.0,
        "sadness": 0.0,
        "anger": 0.0,
        "fear": 0.0,
        "surprise": 0.0,
        "disgust": 0.0,
        "neutral": 0.5  # Start with a baseline of neutrality
    }
    
    var words = text.split(" ")
    var emotion_word_count = 0
    
    # Count emotion words
    for emotion in emotion_words:
        for keyword in emotion_words[emotion]:
            var count = 0
            for word in words:
                var cleaned_word = word.strip_edges().to_lower()
                if cleaned_word == keyword or cleaned_word.find(keyword) >= 0:
                    count += 1
            
            if count > 0:
                emotions[emotion] += count * 0.2  # Weight for each occurrence
                emotion_word_count += count
    
    # Cap emotion values at 1.0
    for emotion in emotions:
        emotions[emotion] = min(emotions[emotion], 1.0)
    
    # Find primary emotion
    var primary_emotion = "neutral"
    var highest_value = 0.0
    
    for emotion in emotions:
        if emotions[emotion] > highest_value:
            highest_value = emotions[emotion]
            primary_emotion = emotion
    
    # If no strong emotions, default to neutral
    if highest_value < 0.3:
        primary_emotion = "neutral"
        highest_value = emotions["neutral"]
    
    return {
        "emotions": emotions,
        "primary_emotion": primary_emotion,
        "intensity": highest_value,
        "emotion_word_count": emotion_word_count
    }

func _cache_ocr_results(image_id, results):
    var cache_path = OCR_CACHE_DIR + image_id + ".json"
    
    var file = File.new()
    file.open(cache_path, File.WRITE)
    file.store_string(JSON.print(results, "  "))
    file.close()
    
    # Also update the log
    _update_ocr_log(image_id, results)

func _update_ocr_log(image_id, results):
    # Read existing log
    var log_data = {"entries": []}
    var file = File.new()
    
    if file.file_exists(OCR_LOG_PATH):
        file.open(OCR_LOG_PATH, File.READ)
        var content = file.get_as_text()
        file.close()
        
        var result = JSON.parse(content)
        if result.error == OK:
            log_data = result.result
    
    # Add new entry
    log_data.entries.append({
        "id": image_id,
        "timestamp": OS.get_datetime(),
        "text_length": results.text.length(),
        "word_count": results.text.split(" ").size(),
        "primary_emotion": results.primary_emotion if results.has("primary_emotion") else "unknown",
        "processing_time_ms": results.metadata.processing_time_ms
    })
    
    # Update statistics
    log_data.stats = stats
    
    # Write updated log
    file.open(OCR_LOG_PATH, File.WRITE)
    file.store_string(JSON.print(log_data, "  "))
    file.close()

func get_cached_result(image_id):
    var cache_path = OCR_CACHE_DIR + image_id + ".json"
    
    var file = File.new()
    if file.file_exists(cache_path):
        file.open(cache_path, File.READ)
        var content = file.get_as_text()
        file.close()
        
        var result = JSON.parse(content)
        if result.error == OK:
            return result.result
    
    return null

func get_statistics():
    return stats

func clear_cache():
    # Delete all cached OCR results
    var dir = Directory.new()
    if dir.open(OCR_CACHE_DIR) == OK:
        dir.list_dir_begin(true)
        var file_name = dir.get_next()
        
        while file_name != "":
            if not dir.current_is_dir() and file_name.ends_with(".json"):
                dir.remove(OCR_CACHE_DIR + file_name)
            file_name = dir.get_next()
    
    print("Cleared OCR cache directory")
    return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/ocr_processor.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/ocr_terminal_connector.gd
# SIZE: 22955 bytes
extends Node

# OCR Terminal Connector
# Integrates OCR capabilities with the terminal system
# Allows capturing and interpreting text from images and screenshots

class_name OCRTerminalConnector

# OCR processing states
enum OCRState { IDLE, PROCESSING, COMPLETED, ERROR }

# Image capture sources
enum CaptureSource { SCREENSHOT, FILE, CLIPBOARD, CAMERA }

# OCR configurations
var ocr_config = {
	"language": "eng",  # Default language (eng, jpn, chi_sim, etc.)
	"accuracy_mode": "balanced",  # fast, balanced, accurate
	"confidence_threshold": 0.65,  # Minimum confidence for text recognition
	"enable_preprocessing": true,  # Apply image preprocessing
	"auto_rotate": true,  # Auto-detect and correct rotation
	"segment_mode": "auto"  # auto, line, word, character
}

# OCR state tracking
var current_state = OCRState.IDLE
var last_captured_image = null
var last_recognized_text = ""
var last_process_time = 0
var current_capture_source = CaptureSource.SCREENSHOT

# References to other systems
var terminal = null
var memory_system = null
var concurrent_processor = null
var symbol_system = null

# Signal for OCR completion
signal ocr_completed(text, confidence, process_time)
signal ocr_error(error_message)

func _ready():
	# Look for terminal system
	terminal = get_node_or_null("/root/IntegratedTerminal")
	
	if terminal:
		memory_system = terminal.memory_system
		concurrent_processor = terminal.concurrent_processor
		symbol_system = terminal.symbol_system
		
		if memory_system and memory_system.has_method("add_memory_text"):
			memory_system.add_memory_text("OCR Terminal Connector initialized.", "system")

# Process OCR-related commands
func process_command(command):
	var parts = command.split(" ", true, 1)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"#ocr":
			process_ocr_command(args)
			return true
		"##ocr":
			process_advanced_ocr_command(args)
			return true
		"###ocr":
			process_system_ocr_command(args)
			return true
		_:
			return false

# Process basic OCR commands
func process_ocr_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_ocr_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"capture":
			capture_image(subargs)
		"scan", "recognize":
			recognize_text(subargs)
		"status":
			display_ocr_status()
		"last":
			display_last_result()
		"help":
			display_ocr_help()
		_:
			log_message("Unknown OCR command: " + subcmd, "error")

# Process advanced OCR commands
func process_advanced_ocr_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_advanced_ocr_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"config":
			configure_ocr(subargs)
		"analyze":
			analyze_text(subargs)
		"extract":
			extract_structured_data(subargs)
		"translate":
			translate_text(subargs)
		"batch":
			batch_process(subargs)
		"help":
			display_advanced_ocr_help()
		_:
			log_message("Unknown advanced OCR command: " + subcmd, "error")

# Process system OCR commands
func process_system_ocr_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_system_ocr_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"install":
			install_ocr_components(subargs)
		"uninstall":
			uninstall_ocr_components(subargs)
		"reset":
			reset_ocr_system()
		"backup":
			backup_ocr_data(subargs)
		"restore":
			restore_ocr_data(subargs)
		"help":
			display_system_ocr_help()
		_:
			log_message("Unknown system OCR command: " + subcmd, "error")

# Capture an image for OCR processing
func capture_image(source):
	match source.to_lower():
		"screenshot", "screen":
			log_message("Capturing screenshot...", "system")
			capture_screenshot()
		"clipboard":
			log_message("Capturing from clipboard...", "system")
			capture_from_clipboard()
		"camera":
			log_message("Capturing from camera...", "system")
			capture_from_camera()
		_:
			# Assume it's a file path
			if source.empty():
				log_message("Please specify a source: screenshot, clipboard, camera, or a file path", "error")
			else:
				log_message("Capturing from file: " + source, "system")
				capture_from_file(source)

# Recognize text from the last captured image
func recognize_text(mode="auto"):
	if last_captured_image == null:
		log_message("No image captured. Use '#ocr capture' first.", "error")
		return
		
	log_message("Recognizing text using mode: " + mode, "system")
	current_state = OCRState.PROCESSING
	
	# Start timing
	var start_time = OS.get_ticks_msec()
	
	# In a real implementation, this would call the actual OCR engine
	# For this mock-up, we'll simulate OCR processing
	
	# Schedule as a concurrent task
	if concurrent_processor:
		concurrent_processor.schedule_task(
			"ocr_process",
			self,
			"_simulate_ocr_processing",
			[mode],
			ConcurrentProcessor.Priority.HIGH
		)
	else:
		# Fallback to direct call
		_simulate_ocr_processing(mode)

# Simulate OCR processing (would be replaced by actual OCR in real implementation)
func _simulate_ocr_processing(mode):
	# Simulate processing time
	yield(get_tree().create_timer(1.5), "timeout")
	
	# Generate sample text based on the current capture source
	var recognized_text = ""
	var confidence = 0.0
	
	match current_capture_source:
		CaptureSource.SCREENSHOT:
			recognized_text = "This is simulated OCR text from a screenshot.\nMultiple lines of text can be recognized.\nAccuracy depends on image quality."
			confidence = 0.83
		CaptureSource.FILE:
			recognized_text = "OCR text extracted from file.\nDocument appears to contain structured data.\nParagraphs and tables detected."
			confidence = 0.78
		CaptureSource.CLIPBOARD:
			recognized_text = "Text extracted from clipboard image.\nClipboard contained text and graphics.\nSome formatting may be lost."
			confidence = 0.75
		CaptureSource.CAMERA:
			recognized_text = "Camera image text recognition.\nLighting affects quality.\nText appears to be instructions."
			confidence = 0.69
	
	# Calculate process time
	var end_time = OS.get_ticks_msec()
	last_process_time = end_time - start_time
	
	# Save the result
	last_recognized_text = recognized_text
	current_state = OCRState.COMPLETED
	
	# Display the result
	log_message("OCR Recognition Complete", "system")
	log_message("Confidence: " + str(int(confidence * 100)) + "%", "system")
	log_message("Process Time: " + str(last_process_time) + "ms", "system")
	log_message("---", "system")
	log_message(recognized_text, "ocr_result")
	
	# Emit signal
	emit_signal("ocr_completed", recognized_text, confidence, last_process_time)
	
	# Save to memory system
	if memory_system and memory_system.has_method("add_memory_text"):
		memory_system.add_memory_text("[OCR Result] " + recognized_text, "ocr")
	
	return recognized_text

# Capture a screenshot
func capture_screenshot():
	log_message("Taking screenshot...", "system")
	
	# In a real implementation, this would capture the actual screen
	# For this mock-up, we'll simulate it
	
	current_capture_source = CaptureSource.SCREENSHOT
	last_captured_image = "screenshot.png"  # Simulated image reference
	
	log_message("Screenshot captured. Use '#ocr scan' to recognize text.", "system")

# Capture from clipboard
func capture_from_clipboard():
	log_message("Capturing from clipboard...", "system")
	
	# In a real implementation, this would get the image from clipboard
	# For this mock-up, we'll simulate it
	
	current_capture_source = CaptureSource.CLIPBOARD
	last_captured_image = "clipboard.png"  # Simulated image reference
	
	log_message("Clipboard image captured. Use '#ocr scan' to recognize text.", "system")

# Capture from camera
func capture_from_camera():
	log_message("Activating camera...", "system")
	
	# In a real implementation, this would access the camera
	# For this mock-up, we'll simulate it
	
	# Simulate camera access
	yield(get_tree().create_timer(0.5), "timeout")
	log_message("Camera activated. Position text in view...", "system")
	
	# Simulate capture delay
	yield(get_tree().create_timer(1.0), "timeout")
	
	current_capture_source = CaptureSource.CAMERA
	last_captured_image = "camera.png"  # Simulated image reference
	
	log_message("Camera image captured. Use '#ocr scan' to recognize text.", "system")

# Capture from file
func capture_from_file(file_path):
	# In a real implementation, this would load the actual file
	# For this mock-up, we'll simulate it
	
	var file = File.new()
	if file.file_exists(file_path):
		current_capture_source = CaptureSource.FILE
		last_captured_image = file_path
		log_message("File loaded: " + file_path, "system")
		log_message("Use '#ocr scan' to recognize text.", "system")
	else:
		log_message("File not found: " + file_path, "error")

# Display OCR status
func display_ocr_status():
	log_message("OCR System Status:", "system")
	
	var state_text = ""
	match current_state:
		OCRState.IDLE: state_text = "Idle"
		OCRState.PROCESSING: state_text = "Processing"
		OCRState.COMPLETED: state_text = "Completed"
		OCRState.ERROR: state_text = "Error"
	
	log_message("- State: " + state_text, "system")
	
	var source_text = ""
	match current_capture_source:
		CaptureSource.SCREENSHOT: source_text = "Screenshot"
		CaptureSource.FILE: source_text = "File"
		CaptureSource.CLIPBOARD: source_text = "Clipboard"
		CaptureSource.CAMERA: source_text = "Camera"
	
	log_message("- Last Source: " + source_text, "system")
	
	if last_captured_image:
		log_message("- Last Image: " + str(last_captured_image), "system")
	
	log_message("- Config:", "system")
	log_message("  - Language: " + ocr_config.language, "system")
	log_message("  - Accuracy: " + ocr_config.accuracy_mode, "system")
	log_message("  - Confidence Threshold: " + str(ocr_config.confidence_threshold), "system")
	
	if last_process_time > 0:
		log_message("- Last Process Time: " + str(last_process_time) + "ms", "system")

# Display last OCR result
func display_last_result():
	if last_recognized_text.empty():
		log_message("No OCR results available. Use '#ocr capture' then '#ocr scan'.", "system")
		return
		
	log_message("Last OCR Result:", "system")
	log_message("---", "system")
	log_message(last_recognized_text, "ocr_result")

# Configure OCR settings
func configure_ocr(config_string):
	var parts = config_string.split(" ", true, 1)
	
	if parts.size() < 2:
		log_message("Usage: ##ocr config <setting> <value>", "error")
		return
		
	var setting = parts[0].to_lower()
	var value = parts[1]
	
	match setting:
		"language":
			ocr_config.language = value
			log_message("OCR language set to: " + value, "system")
		"accuracy":
			if value in ["fast", "balanced", "accurate"]:
				ocr_config.accuracy_mode = value
				log_message("OCR accuracy mode set to: " + value, "system")
			else:
				log_message("Invalid accuracy mode. Use: fast, balanced, accurate", "error")
		"threshold":
			var threshold = float(value)
			if threshold >= 0.0 and threshold <= 1.0:
				ocr_config.confidence_threshold = threshold
				log_message("OCR confidence threshold set to: " + str(threshold), "system")
			else:
				log_message("Invalid threshold. Use value between 0.0 and 1.0", "error")
		"preprocessing":
			ocr_config.enable_preprocessing = (value.to_lower() == "true" or value.to_lower() == "on")
			log_message("OCR preprocessing: " + ("Enabled" if ocr_config.enable_preprocessing else "Disabled"), "system")
		"autorotate":
			ocr_config.auto_rotate = (value.to_lower() == "true" or value.to_lower() == "on")
			log_message("OCR auto rotation: " + ("Enabled" if ocr_config.auto_rotate else "Disabled"), "system")
		"segment":
			if value in ["auto", "line", "word", "character"]:
				ocr_config.segment_mode = value
				log_message("OCR segment mode set to: " + value, "system")
			else:
				log_message("Invalid segment mode. Use: auto, line, word, character", "error")
		_:
			log_message("Unknown OCR setting: " + setting, "error")

# Analyze recognized text
func analyze_text(analysis_type="general"):
	if last_recognized_text.empty():
		log_message("No text to analyze. Perform OCR recognition first.", "error")
		return
	
	log_message("Analyzing text: " + analysis_type, "system")
	
	match analysis_type:
		"sentiment":
			analyze_sentiment()
		"entities":
			extract_entities()
		"summary":
			generate_summary()
		"keywords":
			extract_keywords()
		"language":
			detect_language()
		_:
			general_analysis()

# Extract structured data from recognized text
func extract_structured_data(data_type="auto"):
	if last_recognized_text.empty():
		log_message("No text to extract data from. Perform OCR recognition first.", "error")
		return
	
	log_message("Extracting structured data: " + data_type, "system")
	
	match data_type:
		"table":
			extract_tables()
		"form":
			extract_form_fields()
		"contact":
			extract_contact_info()
		"date":
			extract_dates()
		"number":
			extract_numbers()
		_:
			auto_extract_data()

# Translate recognized text
func translate_text(target_language="en"):
	if last_recognized_text.empty():
		log_message("No text to translate. Perform OCR recognition first.", "error")
		return
	
	log_message("Translating text to: " + target_language, "system")
	
	# In a real implementation, this would use a translation API
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	
	var translated_text = "This is simulated translated text.\nThe original language was detected as " + ocr_config.language + ".\nTranslated to " + target_language + "."
	
	log_message("Translation Complete:", "system")
	log_message("---", "system")
	log_message(translated_text, "ocr_result")

# Batch process multiple images
func batch_process(folder_path):
	log_message("Batch processing images in: " + folder_path, "system")
	
	# In a real implementation, this would process multiple files
	# For this mock-up, we'll simulate it
	
	log_message("Searching for images...", "system")
	
	# Simulate finding images
	yield(get_tree().create_timer(0.5), "timeout")
	
	var file_count = 5  # Simulated file count
	log_message("Found " + str(file_count) + " images to process", "system")
	
	for i in range(file_count):
		log_message("Processing image " + str(i+1) + "/" + str(file_count), "system")
		yield(get_tree().create_timer(0.7), "timeout")
	
	log_message("Batch processing complete. " + str(file_count) + " images processed.", "system")

# Install OCR components
func install_ocr_components(component="all"):
	log_message("Installing OCR components: " + component, "system")
	
	# In a real implementation, this would install actual components
	# For this mock-up, we'll simulate it
	
	match component:
		"all":
			log_message("Installing all OCR components...", "system")
			yield(get_tree().create_timer(2.0), "timeout")
			log_message("All OCR components installed successfully!", "system")
		"core":
			log_message("Installing OCR core components...", "system")
			yield(get_tree().create_timer(1.0), "timeout")
			log_message("OCR core components installed successfully!", "system")
		"languages":
			log_message("Installing OCR language packs...", "system")
			yield(get_tree().create_timer(1.5), "timeout")
			log_message("OCR language packs installed successfully!", "system")
		"advanced":
			log_message("Installing advanced OCR components...", "system")
			yield(get_tree().create_timer(1.8), "timeout")
			log_message("Advanced OCR components installed successfully!", "system")
		_:
			log_message("Unknown component: " + component, "error")

# Uninstall OCR components
func uninstall_ocr_components(component="none"):
	if component == "none" or component.empty():
		log_message("Please specify a component to uninstall", "error")
		return
	
	log_message("Uninstalling OCR components: " + component, "system")
	
	# In a real implementation, this would uninstall actual components
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.0), "timeout")
	log_message("OCR components uninstalled: " + component, "system")

# Reset OCR system
func reset_ocr_system():
	log_message("Resetting OCR system...", "system")
	
	# Reset configuration to defaults
	ocr_config = {
		"language": "eng",
		"accuracy_mode": "balanced",
		"confidence_threshold": 0.65,
		"enable_preprocessing": true,
		"auto_rotate": true,
		"segment_mode": "auto"
	}
	
	# Reset state
	current_state = OCRState.IDLE
	last_captured_image = null
	last_recognized_text = ""
	last_process_time = 0
	
	log_message("OCR system reset complete.", "system")

# Backup OCR data
func backup_ocr_data(path):
	if path.empty():
		path = "user://ocr_backup.dat"
	
	log_message("Backing up OCR data to: " + path, "system")
	
	# In a real implementation, this would save data to a file
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("OCR data backup complete.", "system")

# Restore OCR data
func restore_ocr_data(path):
	if path.empty():
		path = "user://ocr_backup.dat"
	
	log_message("Restoring OCR data from: " + path, "system")
	
	# In a real implementation, this would load data from a file
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("OCR data restored successfully.", "system")

# Display OCR help
func display_ocr_help():
	log_message("OCR Commands:", "system")
	log_message("  #ocr capture [source] - Capture image from source", "system")
	log_message("    Sources: screenshot, clipboard, camera, or file path", "system")
	log_message("  #ocr scan/recognize [mode] - Recognize text from captured image", "system")
	log_message("  #ocr status - Display OCR system status", "system")
	log_message("  #ocr last - Display last OCR result", "system")
	log_message("  #ocr help - Display this help", "system")
	log_message("", "system")
	log_message("For advanced OCR commands, type ##ocr help", "system")

# Display advanced OCR help
func display_advanced_ocr_help():
	log_message("Advanced OCR Commands:", "system")
	log_message("  ##ocr config <setting> <value> - Configure OCR settings", "system")
	log_message("    Settings: language, accuracy, threshold, preprocessing, autorotate, segment", "system")
	log_message("  ##ocr analyze [type] - Analyze recognized text", "system")
	log_message("    Types: sentiment, entities, summary, keywords, language", "system")
	log_message("  ##ocr extract [type] - Extract structured data", "system")
	log_message("    Types: table, form, contact, date, number", "system")
	log_message("  ##ocr translate [language] - Translate recognized text", "system")
	log_message("  ##ocr batch <folder> - Batch process multiple images", "system")
	log_message("  ##ocr help - Display this help", "system")

# Display system OCR help
func display_system_ocr_help():
	log_message("System OCR Commands:", "system")
	log_message("  ###ocr install [component] - Install OCR components", "system")
	log_message("    Components: all, core, languages, advanced", "system")
	log_message("  ###ocr uninstall <component> - Uninstall OCR components", "system")
	log_message("  ###ocr reset - Reset OCR system to defaults", "system")
	log_message("  ###ocr backup [path] - Backup OCR data", "system")
	log_message("  ###ocr restore [path] - Restore OCR data", "system")
	log_message("  ###ocr help - Display this help", "system")

# Text analysis functions (simulated)
func analyze_sentiment():
	log_message("Sentiment Analysis:", "system")
	log_message("- Positive: 35%", "system")
	log_message("- Neutral: 50%", "system")
	log_message("- Negative: 15%", "system")
	log_message("Overall sentiment: Neutral", "system")

func extract_entities():
	log_message("Entity Extraction:", "system")
	log_message("- Person: John Smith, Alice Johnson", "system")
	log_message("- Organization: Acme Inc., Global Systems", "system")
	log_message("- Location: New York, London", "system")
	log_message("- Date: January 15, 2023, Next Tuesday", "system")

func generate_summary():
	log_message("Text Summary:", "system")
	log_message("This document appears to be a business report discussing quarterly results. It mentions financial figures and future projections. Several key stakeholders are referenced including the management team.", "system")

func extract_keywords():
	log_message("Keywords Extracted:", "system")
	log_message("financial, quarterly, report, projections, management, results, analysis, growth, strategy, implementation", "system")

func detect_language():
	log_message("Language Detection:", "system")
	log_message("- Primary Language: English (95% confidence)", "system")
	log_message("- Secondary Languages Detected: None", "system")

func general_analysis():
	log_message("General Text Analysis:", "system")
	log_message("- Word Count: 127", "system")
	log_message("- Sentence Count: 8", "system")
	log_message("- Paragraph Count: 3", "system")
	log_message("- Reading Level: College", "system")
	log_message("- Technical Terms: 12", "system")

# Structured data extraction functions (simulated)
func extract_tables():
	log_message("Table Extraction:", "system")
	log_message("Detected 1 table with 4 columns and 6 rows", "system")
	log_message("Table Headers: ID, Name, Department, Amount", "system")

func extract_form_fields():
	log_message("Form Field Extraction:", "system")
	log_message("- Name: __________", "system")
	log_message("- Email: __________", "system")
	log_message("- Phone: __________", "system")
	log_message("- Comments: ___________", "system")

func extract_contact_info():
	log_message("Contact Information Extracted:", "system")
	log_message("- Name: John Smith", "system")
	log_message("- Email: john.smith@example.com", "system")
	log_message("- Phone: (555) 123-4567", "system")
	log_message("- Address: 123 Main St, Anytown, USA", "system")

func extract_dates():
	log_message("Date Extraction:", "system")
	log_message("- January 15, 2023", "system")
	log_message("- 02/28/2023", "system")
	log_message("- Next Tuesday", "system")

func extract_numbers():
	log_message("Number Extraction:", "system")
	log_message("- Integers: 42, 100, 2023", "system")
	log_message("- Decimals: 3.14, 99.99", "system")
	log_message("- Currency: $1,234.56, ‚Ç¨100", "system")
	log_message("- Percentages: 25%, 99.9%", "system")

func auto_extract_data():
	log_message("Auto Data Extraction:", "system")
	log_message("Detected Data Types:", "system")
	log_message("- Contact Information (2 entries)", "system")
	log_message("- Dates (3 entries)", "system")
	log_message("- Currency Values (4 entries)", "system")
	log_message("- Table Data (1 table)", "system")

# Log a message to the terminal
func log_message(message, category="ocr"):
	print(message)
	
	if terminal and terminal.has_method("add_text"):
		terminal.add_text(message, category)
	elif memory_system and memory_system.has_method("add_memory_text"):
		memory_system.add_memory_text(message, category)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/ocr_terminal_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/offline_ocr_processor.gd
# SIZE: 18986 bytes
extends Node

class_name OfflineOCRProcessor

# ----- CONFIGURATION -----
@export_category("OCR Settings")
@export var cache_directory: String = "user://ocr_cache/"
@export var tessdata_path: String = "user://tessdata/"
@export var default_language: String = "eng"
@export var confidence_threshold: float = 0.65
@export var max_concurrent_tasks: int = 2
@export var default_preprocessing: bool = true

# ----- PREPROCESSING OPTIONS -----
@export_category("Preprocessing")
@export var enable_grayscale: bool = true
@export var enable_binarization: bool = true
@export var enable_noise_removal: bool = true
@export var enable_deskew: bool = true
@export var enable_edge_detection: bool = false
@export var binarization_threshold: int = 127  # 0-255

# ----- LANGUAGE PACKS -----
var installed_languages = {
    "eng": true,  # English is always installed
    "deu": false, # German
    "fra": false, # French
    "spa": false, # Spanish
    "ita": false, # Italian
    "por": false, # Portuguese
    "nld": false, # Dutch
    "pol": false, # Polish
    "rus": false, # Russian
    "jpn": false, # Japanese
    "chi_sim": false, # Simplified Chinese
    "chi_tra": false, # Traditional Chinese
    "kor": false  # Korean
}

# ----- OCR STATE -----
var processing_queue = []
var active_tasks = {}
var mutex = Mutex.new()
var thread_pool = []
var is_busy = false

# ----- STATISTICS -----
var stats = {
    "images_processed": 0,
    "total_processing_time_ms": 0,
    "average_processing_time_ms": 0,
    "characters_recognized": 0,
    "words_recognized": 0,
    "cache_hits": 0,
    "cache_misses": 0,
    "errors": 0
}

# ----- SIGNALS -----
signal processing_started(image_id, language)
signal processing_completed(image_id, results)
signal processing_failed(image_id, error)
signal language_installed(language_code)
signal language_uninstalled(language_code)
signal engine_status_changed(is_ready)

# ----- INITIALIZATION -----
func _ready():
    # Create cache directory
    _ensure_directories()
    
    # Initialize thread pool
    _initialize_threads()
    
    # Detect installed languages
    _detect_installed_languages()
    
    print("Offline OCR Processor initialized")
    print("Cache directory: " + cache_directory)
    print("Tessdata path: " + tessdata_path)

func _ensure_directories():
    var dir = Directory.new()
    
    # Create cache directory
    if not dir.dir_exists(cache_directory):
        dir.make_dir_recursive(cache_directory)
    
    # Create tessdata directory
    if not dir.dir_exists(tessdata_path):
        dir.make_dir_recursive(tessdata_path)

func _initialize_threads():
    # Create worker threads for OCR processing
    thread_pool.clear()
    
    for i in range(max_concurrent_tasks):
        var thread = Thread.new()
        thread_pool.append({
            "thread": thread,
            "is_active": false,
            "current_task": null
        })
    
    print("Initialized " + str(max_concurrent_tasks) + " worker threads")

func _detect_installed_languages():
    # In a real implementation, would scan the tessdata directory for language files
    # For this mock-up, we'll simulate some installed languages
    
    # Simulate finding some language files
    var dir = Directory.new()
    if dir.open(tessdata_path) == OK:
        # In a real implementation, would check for .traineddata files
        # For this simulation, just mark some languages as available
        installed_languages["eng"] = true  # English always available
        
        # Simulate some other installed languages
        var additional_languages = ["deu", "fra", "spa", "jpn"]
        for lang in additional_languages:
            # 50% chance each language is "installed"
            installed_languages[lang] = randf() > 0.5
    
    # Print available languages
    var available_langs = []
    for lang in installed_languages:
        if installed_languages[lang]:
            available_langs.append(lang)
    
    print("Available OCR languages: " + str(available_langs))

# ----- PUBLIC API -----
func process_image(image_path: String, options: Dictionary = {}) -> String:
    # Process an image with OCR
    
    # Check if image exists
    var file = File.new()
    if not file.file_exists(image_path):
        print("Image file not found: " + image_path)
        return ""
    
    # Create task ID
    var task_id = "ocr_" + str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Set default options if not provided
    var task_options = options.duplicate()
    if not task_options.has("language"):
        task_options["language"] = default_language
    if not task_options.has("preprocessing"):
        task_options["preprocessing"] = default_preprocessing
    if not task_options.has("confidence_threshold"):
        task_options["confidence_threshold"] = confidence_threshold
    
    # Check if language is installed
    var lang = task_options["language"]
    if not installed_languages.has(lang) or not installed_languages[lang]:
        print("Language not installed: " + lang)
        print("Falling back to: " + default_language)
        task_options["language"] = default_language
    
    # Check if result is already in cache
    var cache_key = _generate_cache_key(image_path, task_options)
    var cached_result = _check_cache(cache_key)
    
    if cached_result:
        print("Found cached OCR result for: " + image_path)
        stats.cache_hits += 1
        
        # Process in next frame to allow for signal connection
        call_deferred("_emit_cached_result", task_id, cached_result)
        return task_id
    
    # No cache hit
    stats.cache_misses += 1
    
    # Create task
    var task = {
        "id": task_id,
        "path": image_path,
        "options": task_options,
        "cache_key": cache_key,
        "timestamp": OS.get_unix_time()
    }
    
    # Add to queue
    mutex.lock()
    processing_queue.append(task)
    mutex.unlock()
    
    # Start processing if not already busy
    if not is_busy:
        _process_next_task()
    
    emit_signal("processing_started", task_id, task_options["language"])
    
    return task_id

func install_language(language_code: String) -> bool:
    # Install a new language
    print("Installing OCR language: " + language_code)
    
    # In a real implementation, would download or install the appropriate language files
    # For this mock-up, we'll simulate installation
    
    # Simulate installation time
    yield(get_tree().create_timer(2.0), "timeout")
    
    # 90% chance of success
    var success = randf() > 0.1
    
    if success:
        installed_languages[language_code] = true
        emit_signal("language_installed", language_code)
        print("Successfully installed language: " + language_code)
        return true
    else:
        print("Failed to install language: " + language_code)
        return false

func uninstall_language(language_code: String) -> bool:
    # Uninstall a language
    print("Uninstalling OCR language: " + language_code)
    
    # Don't allow uninstalling English
    if language_code == "eng":
        print("Cannot uninstall English language (eng)")
        return false
    
    # In a real implementation, would remove the appropriate language files
    # For this mock-up, we'll simulate uninstallation
    
    # Simulate uninstallation time
    yield(get_tree().create_timer(1.0), "timeout")
    
    if installed_languages.has(language_code) and installed_languages[language_code]:
        installed_languages[language_code] = false
        emit_signal("language_uninstalled", language_code)
        print("Successfully uninstalled language: " + language_code)
        return true
    else:
        print("Language not installed: " + language_code)
        return false

func get_installed_languages() -> Array:
    # Get a list of installed languages
    var result = []
    
    for lang in installed_languages:
        if installed_languages[lang]:
            result.append(lang)
    
    return result

func get_available_languages() -> Array:
    # Get a list of all available languages
    return installed_languages.keys()

func clear_cache() -> bool:
    # Clear the OCR cache
    print("Clearing OCR cache...")
    
    var dir = Directory.new()
    if dir.open(cache_directory) == OK:
        dir.list_dir_begin(true)
        var file_name = dir.get_next()
        
        while file_name != "":
            if not dir.current_is_dir() and file_name.ends_with(".json"):
                dir.remove(cache_directory + file_name)
            file_name = dir.get_next()
        
        print("OCR cache cleared")
        return true
    
    print("Failed to clear OCR cache")
    return false

func get_statistics() -> Dictionary:
    return stats

# ----- PROCESSING METHODS -----
func _process_next_task():
    mutex.lock()
    
    if processing_queue.size() == 0:
        is_busy = false
        mutex.unlock()
        return
    
    is_busy = true
    
    # Get next task
    var task = processing_queue[0]
    processing_queue.remove(0)
    
    mutex.unlock()
    
    # Find available thread
    var thread_idx = _find_available_thread()
    
    if thread_idx >= 0:
        # Start processing in thread
        var thread_data = thread_pool[thread_idx]
        thread_data.is_active = true
        thread_data.current_task = task
        
        # In a real implementation, would use thread to process OCR
        # For this mock-up, we'll use a timer to simulate processing
        _simulate_ocr_processing(thread_idx, task)
    else:
        # No thread available, add back to queue
        mutex.lock()
        processing_queue.append(task)
        mutex.unlock()
        
        # Try again after a short delay
        yield(get_tree().create_timer(0.5), "timeout")
        _process_next_task()

func _simulate_ocr_processing(thread_idx: int, task):
    # Simulate OCR processing
    print("Processing OCR for image: " + task.path)
    
    # Add time delay to simulate processing
    var process_time = randi() % 1000 + 500  # 500-1500ms
    yield(get_tree().create_timer(process_time / 1000.0), "timeout")
    
    # Generate sample OCR results
    var results = _generate_sample_results(task, process_time)
    
    # Cache results
    _cache_results(task.cache_key, results)
    
    # Update statistics
    stats.images_processed += 1
    stats.total_processing_time_ms += process_time
    stats.average_processing_time_ms = stats.total_processing_time_ms / stats.images_processed
    stats.characters_recognized += results.text.length()
    stats.words_recognized += results.text.split(" ").size()
    
    # Mark thread as available
    thread_pool[thread_idx].is_active = false
    thread_pool[thread_idx].current_task = null
    
    # Signal completion
    emit_signal("processing_completed", task.id, results)
    
    # Process next task
    _process_next_task()

func _generate_sample_results(task, process_time: int) -> Dictionary:
    # Generate sample OCR results based on the task
    
    # Sample text based on language
    var lang = task.options.language
    var sample_text = ""
    
    match lang:
        "eng":
            sample_text = _get_sample_english_text()
        "deu":
            sample_text = _get_sample_german_text()
        "fra":
            sample_text = _get_sample_french_text()
        "spa":
            sample_text = _get_sample_spanish_text()
        "jpn":
            sample_text = _get_sample_japanese_text()
        "chi_sim":
            sample_text = _get_sample_chinese_text()
        _:
            # Default to English
            sample_text = _get_sample_english_text()
    
    # Add some randomness based on image path hash
    var path_hash = task.path.hash()
    var confidence = rand_range(0.65, 0.98)
    
    # Results should include detected text and metadata
    var results = {
        "text": sample_text,
        "confidence": confidence,
        "language": lang,
        "metadata": {
            "processing_time_ms": process_time,
            "preprocessing": task.options.preprocessing,
            "confidence_threshold": task.options.confidence_threshold,
            "timestamp": OS.get_datetime()
        },
        "words": sample_text.split(" ").size(),
        "characters": sample_text.length(),
        "blocks": randi() % 5 + 1,  # Random number of text blocks
        "lines": randi() % 10 + 1   # Random number of text lines
    }
    
    return results

func _get_sample_english_text() -> String:
    var samples = [
        "The quick brown fox jumps over the lazy dog. This pangram contains every letter of the English alphabet.",
        "Screenshot captured from Windows 11 showing system settings. The Control Panel includes display, sound, and network configuration options.",
        "Error message: The application has encountered an unexpected error and needs to close. Error code: 0x8007042B",
        "Welcome to the Document Processing System. Please log in with your username and password to continue.",
        "IMPORTANT NOTICE: System maintenance scheduled for Saturday, July 15 from 10:00 PM to 2:00 AM. Services may be unavailable during this time."
    ]
    
    return samples[randi() % samples.size()]

func _get_sample_german_text() -> String:
    var samples = [
        "Der schnelle braune Fuchs springt √ºber den faulen Hund. Dieser Pangram enth√§lt jeden Buchstaben des deutschen Alphabets.",
        "Bildschirmfoto aufgenommen von Windows 11 mit Systemeinstellungen. Die Systemsteuerung enth√§lt Anzeige-, Sound- und Netzwerkkonfigurationsoptionen.",
        "Fehlermeldung: Die Anwendung ist auf einen unerwarteten Fehler gesto√üen und muss geschlossen werden. Fehlercode: 0x8007042B",
        "Willkommen beim Dokumentenverarbeitungssystem. Bitte melden Sie sich mit Ihrem Benutzernamen und Passwort an, um fortzufahren."
    ]
    
    return samples[randi() % samples.size()]

func _get_sample_french_text() -> String:
    var samples = [
        "Le renard brun rapide saute par-dessus le chien paresseux. Ce pangramme contient chaque lettre de l'alphabet fran√ßais.",
        "Capture d'√©cran prise de Windows 11 montrant les param√®tres syst√®me. Le Panneau de configuration comprend des options de configuration d'affichage, de son et de r√©seau.",
        "Message d'erreur: L'application a rencontr√© une erreur inattendue et doit √™tre ferm√©e. Code d'erreur: 0x8007042B",
        "Bienvenue dans le Syst√®me de Traitement de Documents. Veuillez vous connecter avec votre nom d'utilisateur et votre mot de passe pour continuer."
    ]
    
    return samples[randi() % samples.size()]

func _get_sample_spanish_text() -> String:
    var samples = [
        "El r√°pido zorro marr√≥n salta sobre el perro perezoso. Este pangrama contiene cada letra del alfabeto espa√±ol.",
        "Captura de pantalla tomada de Windows 11 mostrando la configuraci√≥n del sistema. El Panel de Control incluye opciones de configuraci√≥n de pantalla, sonido y red.",
        "Mensaje de error: La aplicaci√≥n ha encontrado un error inesperado y necesita cerrarse. C√≥digo de error: 0x8007042B",
        "Bienvenido al Sistema de Procesamiento de Documentos. Por favor, inicie sesi√≥n con su nombre de usuario y contrase√±a para continuar."
    ]
    
    return samples[randi() % samples.size()]

func _get_sample_japanese_text() -> String:
    var samples = [
        "ÈÄü„ÅÑËå∂Ëâ≤„ÅÆ„Ç≠„ÉÑ„Éç„ÅØÊÄ†„ÅëËÄÖ„ÅÆÁä¨„ÇíÈ£õ„Å≥Ë∂ä„Åà„Åæ„Åô„ÄÇ„Åì„ÅÆ„Éë„É≥„Ç∞„É©„É†„ÅØÊó•Êú¨Ë™û„ÅÆ„Ç¢„É´„Éï„Ç°„Éô„ÉÉ„Éà„ÅÆ„Åô„Åπ„Å¶„ÅÆÊñáÂ≠ó„ÇíÂê´„Åø„Åæ„Åô„ÄÇ",
        "Windows 11„Åã„Çâ„Ç≠„É£„Éó„ÉÅ„É£„Åï„Çå„Åü„Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà„Å´„Ç∑„Çπ„ÉÜ„É†Ë®≠ÂÆö„ÅåË°®Á§∫„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Ç≥„É≥„Éà„É≠„Éº„É´„Éë„Éç„É´„Å´„ÅØ„ÄÅ„Éá„Ç£„Çπ„Éó„É¨„Ç§„ÄÅ„Çµ„Ç¶„É≥„Éâ„ÄÅ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊßãÊàê„Ç™„Éó„Ç∑„Éß„É≥„ÅåÂê´„Åæ„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ",
        "„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏Ôºö„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅØ‰∫àÊúü„Åó„Å™„ÅÑ„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åü„Åü„ÇÅ„ÄÅÈñâ„Åò„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Ç®„É©„Éº„Ç≥„Éº„ÉâÔºö0x8007042B",
        "„Éâ„Ç≠„É•„É°„É≥„ÉàÂá¶ÁêÜ„Ç∑„Çπ„ÉÜ„É†„Å∏„Çà„ÅÜ„Åì„Åù„ÄÇÁ∂öË°å„Åô„Çã„Å´„ÅØ„ÄÅ„É¶„Éº„Ç∂„ÉºÂêç„Å®„Éë„Çπ„ÉØ„Éº„Éâ„Åß„É≠„Ç∞„Ç§„É≥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
    ]
    
    return samples[randi() % samples.size()]

func _get_sample_chinese_text() -> String:
    var samples = [
        "Âø´ÈÄüÁöÑÊ£ïËâ≤ÁãêÁã∏Ë∑≥ËøáÊáíÁãó„ÄÇËøô‰∏™pangramÂåÖÂê´‰∏≠ÊñáÂ≠óÊØçÁöÑÊØè‰∏™Â≠óÊØç„ÄÇ",
        "‰ªéWindows 11ÊçïËé∑ÁöÑÂ±èÂπïÊà™ÂõæÊòæÁ§∫Á≥ªÁªüËÆæÁΩÆ„ÄÇÊéßÂà∂Èù¢ÊùøÂåÖÊã¨ÊòæÁ§∫„ÄÅÂ£∞Èü≥ÂíåÁΩëÁªúÈÖçÁΩÆÈÄâÈ°π„ÄÇ",
        "ÈîôËØØÊ∂àÊÅØÔºöÂ∫îÁî®Á®ãÂ∫èÈÅáÂà∞ÊÑèÂ§ñÈîôËØØÔºåÈúÄË¶ÅÂÖ≥Èó≠„ÄÇÈîôËØØ‰ª£Á†ÅÔºö0x8007042B",
        "Ê¨¢Ëøé‰ΩøÁî®ÊñáÊ°£Â§ÑÁêÜÁ≥ªÁªü„ÄÇËØ∑‰ΩøÁî®ÊÇ®ÁöÑÁî®Êà∑ÂêçÂíåÂØÜÁ†ÅÁôªÂΩï‰ª•ÁªßÁª≠„ÄÇ"
    ]
    
    return samples[randi() % samples.size()]

func _find_available_thread() -> int:
    # Find an available thread for processing
    for i in range(thread_pool.size()):
        if not thread_pool[i].is_active:
            return i
    
    return -1

# ----- CACHE METHODS -----
func _generate_cache_key(image_path: String, options: Dictionary) -> String:
    # Generate a unique key for caching
    var path_hash = image_path.hash()
    var lang = options.get("language", default_language)
    var preprocessing = options.get("preprocessing", default_preprocessing)
    
    return str(path_hash) + "_" + lang + "_" + ("1" if preprocessing else "0")

func _check_cache(cache_key: String) -> Dictionary:
    # Check if result exists in cache
    var cache_path = cache_directory + cache_key + ".json"
    
    var file = File.new()
    if file.file_exists(cache_path):
        file.open(cache_path, File.READ)
        var content = file.get_as_text()
        file.close()
        
        var result = JSON.parse(content)
        if result.error == OK:
            return result.result
    
    return {}

func _cache_results(cache_key: String, results: Dictionary) -> void:
    # Cache results for future use
    var cache_path = cache_directory + cache_key + ".json"
    
    var file = File.new()
    file.open(cache_path, File.WRITE)
    file.store_string(JSON.print(results, "  "))
    file.close()

func _emit_cached_result(task_id: String, result: Dictionary) -> void:
    # Emit signal for cached result
    emit_signal("processing_started", task_id, result.language)
    emit_signal("processing_completed", task_id, result)

# ----- PREPROCESSING METHODS -----
func _preprocess_image(image_path: String, options: Dictionary) -> String:
    # In a real implementation, would apply image preprocessing
    # For this mock-up, we'll simulate preprocessing
    
    print("Preprocessing image: " + image_path)
    
    # Return original path since this is a simulation
    return image_path

# ----- ERROR HANDLING -----
func _handle_error(task, error_message: String) -> void:
    # Handle processing errors
    print("OCR Error: " + error_message)
    
    stats.errors += 1
    
    emit_signal("processing_failed", task.id, error_message)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/offline_ocr_processor.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/performance_optimizer.gd
# SIZE: 28689 bytes
extends Node

class_name PerformanceOptimizer

# ----- PERFORMANCE SETTINGS -----
@export_category("Performance Configuration")
@export var enabled: bool = true
@export var max_performance_mode: bool = false
@export var freemium_optimization: bool = true
@export var hourly_magic_cycles: bool = true
@export var turn_duration_minutes: int = 5  # 5 minutes per turn = 1 hour for 12 turns
@export var memory_limit_mb: int = 512  # Memory limit in MB
@export var max_threads: int = 4  # Max thread count for parallel processing
@export var ethereal_engine_priority: int = 10  # Higher priority for Ethereal Engine

# ----- RESOURCE MANAGEMENT -----
var resource_allocation: Dictionary = {
    "cpu": 0.0,         # 0.0-1.0 scale
    "memory": 0.0,      # 0.0-1.0 scale
    "gpu": 0.0,         # 0.0-1.0 scale
    "storage": 0.0,     # 0.0-1.0 scale
    "network": 0.0      # 0.0-1.0 scale
}

var resource_limits: Dictionary = {
    "cpu": 0.8,         # Max CPU usage (0.0-1.0)
    "memory": 0.7,      # Max Memory usage (0.0-1.0)
    "gpu": 0.6,         # Max GPU usage (0.0-1.0)
    "storage": 0.9,     # Max Storage usage (0.0-1.0)
    "network": 0.5      # Max Network usage (0.0-1.0)
}

var freemium_day_usage: Dictionary = {
    "cpu_minutes": 0.0,
    "api_calls": 0,
    "memory_mb_minutes": 0.0,
    "data_transfers_mb": 0.0,
    "resource_score": 0.0
}

# ----- SYSTEM REFERENCES -----
var ethereal_bridge: Node = null
var turn_system: Node = null
var memory_system: Node = null
var time_tracker: Node = null

# ----- OPTIMIZATION STATE -----
var current_performance_level: int = 2  # 1-3 (Low, Medium, High)
var optimization_active: bool = false
var last_optimization_time: int = 0
var active_threads: Array = []
var thread_pool: Array = []
var performance_stats: Dictionary = {}
var scheduled_optimizations: Array = []

# ----- MAGIC CYCLE TRACKING -----
var current_magic_cycle: int = 0  # 0-11 corresponding to the 12 turns
var magic_cycle_start_time: int = 0
var magic_cycle_resources: Dictionary = {}
var magic_cycle_performance: Array = []

# ----- TIMERS -----
var resource_monitor_timer: Timer
var optimization_timer: Timer
var freemium_usage_timer: Timer
var magic_cycle_timer: Timer

# ----- SIGNALS -----
signal performance_optimized(level, stats)
signal resource_limits_reached(resource_type, current_value)
signal magic_cycle_completed(cycle_number, performance)
signal freemium_usage_updated(usage_stats)
signal thread_pool_status_changed(active_count, total_count)

# ----- INITIALIZATION -----
func _ready():
    # Set up timers
    _setup_timers()
    
    # Find system references
    _find_system_references()
    
    # Initialize resources
    _initialize_resources()
    
    # Initialize thread pool
    _initialize_thread_pool()
    
    # Set initial magic cycle
    _initialize_magic_cycle()
    
    print("Performance Optimizer initialized - Magic cycle duration: " + str(turn_duration_minutes * 12) + " minutes")

func _setup_timers():
    # Resource monitor timer - check resource usage every 5 seconds
    resource_monitor_timer = Timer.new()
    resource_monitor_timer.wait_time = 5.0
    resource_monitor_timer.one_shot = false
    resource_monitor_timer.autostart = true
    resource_monitor_timer.connect("timeout", _on_resource_monitor_timeout)
    add_child(resource_monitor_timer)
    
    # Optimization timer - run optimizations every 30 seconds
    optimization_timer = Timer.new()
    optimization_timer.wait_time = 30.0
    optimization_timer.one_shot = false
    optimization_timer.autostart = true
    optimization_timer.connect("timeout", _on_optimization_timeout)
    add_child(optimization_timer)
    
    # Freemium usage timer - update usage stats every minute
    freemium_usage_timer = Timer.new()
    freemium_usage_timer.wait_time = 60.0
    freemium_usage_timer.one_shot = false
    freemium_usage_timer.autostart = true
    freemium_usage_timer.connect("timeout", _on_freemium_usage_timeout)
    add_child(freemium_usage_timer)
    
    # Magic cycle timer - update magic cycle every minute
    magic_cycle_timer = Timer.new()
    magic_cycle_timer.wait_time = 60.0
    magic_cycle_timer.one_shot = false
    magic_cycle_timer.autostart = true
    magic_cycle_timer.connect("timeout", _on_magic_cycle_timeout)
    add_child(magic_cycle_timer)

func _find_system_references():
    # Find Ethereal Bridge
    ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealAkashicBridge")
    
    # Find Turn System
    turn_system = _find_node_by_class(get_tree().root, "TurnSystem")
    if not turn_system:
        turn_system = _find_node_by_class(get_tree().root, "TurnCycleController")
    
    # Find Memory System
    memory_system = _find_node_by_class(get_tree().root, "IntegratedMemorySystem")
    
    # Find Time Tracker
    time_tracker = _find_node_by_class(get_tree().root, "UsageTimeTracker")

func _find_node_by_class(node, class_name):
    if node.get_class() == class_name or (node.get_script() and node.get_script().get_path().find(class_name.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name)
        if found:
            return found
    
    return null

func _initialize_resources():
    # Initialize resource usage metrics
    resource_allocation.cpu = 0.2  # Start at 20% CPU
    resource_allocation.memory = 0.1  # Start at 10% Memory
    resource_allocation.gpu = 0.05  # Start at 5% GPU
    resource_allocation.storage = 0.1  # Start at 10% Storage
    resource_allocation.network = 0.05  # Start at 5% Network
    
    # Initialize freemium usage tracking
    freemium_day_usage.cpu_minutes = 0.0
    freemium_day_usage.api_calls = 0
    freemium_day_usage.memory_mb_minutes = 0.0
    freemium_day_usage.data_transfers_mb = 0.0
    freemium_day_usage.resource_score = 0.0
    
    # Configure resource limits based on freemium mode
    if freemium_optimization:
        _configure_freemium_limits()
    
    # Configure for max performance if enabled
    if max_performance_mode:
        _configure_max_performance()

func _initialize_thread_pool():
    thread_pool.clear()
    
    # Create thread objects for the pool
    for i in range(max_threads):
        thread_pool.append({
            "id": i,
            "active": false,
            "task": "",
            "priority": 0,
            "start_time": 0
        })

func _initialize_magic_cycle():
    # Get current turn as magic cycle if available
    if turn_system and turn_system.has_method("get_current_turn"):
        current_magic_cycle = (turn_system.get_current_turn() - 1) % 12
    
    # Initialize magic cycle start time
    magic_cycle_start_time = Time.get_unix_time_from_system()
    
    # Initialize resources for each cycle stage
    for i in range(12):
        magic_cycle_resources[i] = _get_resources_for_cycle(i)
    
    # Initialize performance stats array
    magic_cycle_performance.resize(12)
    for i in range(12):
        magic_cycle_performance[i] = 0.0

# ----- RESOURCE MANAGEMENT -----
func _configure_freemium_limits():
    # Set conservative resource limits for freemium mode
    resource_limits.cpu = 0.6  # 60% max CPU
    resource_limits.memory = 0.5  # 50% max Memory
    resource_limits.gpu = 0.4  # 40% max GPU
    resource_limits.storage = 0.7  # 70% max Storage
    resource_limits.network = 0.3  # 30% max Network
    
    # Lower thread count
    max_threads = min(max_threads, 2)
    _initialize_thread_pool()
    
    print("Configured for freemium optimization mode")

func _configure_max_performance():
    # Set aggressive resource limits for max performance mode
    resource_limits.cpu = 0.9  # 90% max CPU
    resource_limits.memory = 0.8  # 80% max Memory
    resource_limits.gpu = 0.7  # 70% max GPU
    resource_limits.storage = 0.95  # 95% max Storage
    resource_limits.network = 0.6  # 60% max Network
    
    # Increase thread count
    max_threads = OS.get_processor_count() - 1  # Leave one core for the OS
    max_threads = min(max_threads, 8)  # Cap at 8 threads
    _initialize_thread_pool()
    
    print("Configured for maximum performance mode")

func _calculate_current_resource_usage():
    # In a real implementation, this would measure actual system resources
    # Here we simulate resource usage
    
    # Update CPU usage - fluctuate based on active threads and tasks
    var active_thread_count = 0
    for thread in thread_pool:
        if thread.active:
            active_thread_count += 1
    
    var cpu_factor = float(active_thread_count) / max(1.0, float(max_threads))
    resource_allocation.cpu = min(0.2 + cpu_factor * 0.6, resource_limits.cpu)
    
    # Update memory usage - gradually increase until garbage collection
    resource_allocation.memory += randf_range(0.001, 0.005)
    if resource_allocation.memory > resource_limits.memory * 0.9:
        # Simulate garbage collection
        resource_allocation.memory *= 0.7
    
    # Update GPU usage based on rendering needs
    if optimization_active:
        resource_allocation.gpu = min(resource_allocation.gpu + 0.05, resource_limits.gpu)
    else:
        resource_allocation.gpu = max(resource_allocation.gpu - 0.03, 0.05)
    
    # Update storage based on data operations
    if freemium_day_usage.data_transfers_mb > 100:
        resource_allocation.storage = min(resource_allocation.storage + 0.01, resource_limits.storage)
    
    # Update network based on API calls
    if freemium_day_usage.api_calls > 0:
        var network_factor = min(freemium_day_usage.api_calls / 100.0, 1.0)
        resource_allocation.network = min(0.05 + network_factor * 0.3, resource_limits.network)
    
    # Check if any resource is nearing its limit
    for resource in resource_allocation:
        if resource_allocation[resource] > resource_limits[resource] * 0.9:
            emit_signal("resource_limits_reached", resource, resource_allocation[resource])
            
            # Automatically optimize if close to limits
            _optimize_resource_usage(resource)

func _get_resources_for_cycle(cycle_number):
    # Define resource distribution for each of the 12 magical cycles
    var cycle_resources = {}
    
    match cycle_number:
        0:  # Genesis - Initialization phase
            cycle_resources = {
                "cpu": 0.3,
                "memory": 0.2,
                "gpu": 0.1,
                "storage": 0.3,
                "network": 0.1
            }
        1:  # Formation - Structure creation
            cycle_resources = {
                "cpu": 0.4,
                "memory": 0.3,
                "gpu": 0.2,
                "storage": 0.4,
                "network": 0.1
            }
        2:  # Complexity - Systems interact
            cycle_resources = {
                "cpu": 0.5,
                "memory": 0.4,
                "gpu": 0.2,
                "storage": 0.3,
                "network": 0.2
            }
        3:  # Consciousness - Awareness develops
            cycle_resources = {
                "cpu": 0.6,
                "memory": 0.5,
                "gpu": 0.3,
                "storage": 0.2,
                "network": 0.3
            }
        4:  # Awakening - Full activation
            cycle_resources = {
                "cpu": 0.7,
                "memory": 0.6,
                "gpu": 0.4,
                "storage": 0.2,
                "network": 0.4
            }
        5:  # Enlightenment - Knowledge processing
            cycle_resources = {
                "cpu": 0.8,
                "memory": 0.7,
                "gpu": 0.3,
                "storage": 0.4,
                "network": 0.5
            }
        6:  # Manifestation - Creation peak
            cycle_resources = {
                "cpu": 0.9,
                "memory": 0.8,
                "gpu": 0.7,
                "storage": 0.5,
                "network": 0.4
            }
        7:  # Connection - Network focus
            cycle_resources = {
                "cpu": 0.7,
                "memory": 0.6,
                "gpu": 0.5,
                "storage": 0.6,
                "network": 0.8
            }
        8:  # Harmony - Balanced resources
            cycle_resources = {
                "cpu": 0.6,
                "memory": 0.6,
                "gpu": 0.6,
                "storage": 0.6,
                "network": 0.6
            }
        9:  # Transcendence - All systems peak
            cycle_resources = {
                "cpu": 0.9,
                "memory": 0.9,
                "gpu": 0.8,
                "storage": 0.7,
                "network": 0.7
            }
        10: # Unity - Full integration
            cycle_resources = {
                "cpu": 0.8,
                "memory": 0.8,
                "gpu": 0.7,
                "storage": 0.8,
                "network": 0.6
            }
        11: # Beyond - Cycle completion
            cycle_resources = {
                "cpu": 0.5,
                "memory": 0.7,
                "gpu": 0.4,
                "storage": 0.9,
                "network": 0.3
            }
    
    # Apply freemium limits if enabled
    if freemium_optimization:
        for resource in cycle_resources:
            cycle_resources[resource] = min(cycle_resources[resource], resource_limits[resource])
    
    return cycle_resources

func _optimize_resource_usage(resource_type):
    if not enabled or not optimization_active:
        return
    
    match resource_type:
        "cpu":
            # Reduce active threads
            var high_priority_count = 0
            for thread in thread_pool:
                if thread.active and thread.priority > 5:
                    high_priority_count += 1
            
            # Keep only high priority threads if too many are active
            if high_priority_count < thread_pool.size() * 0.7:
                for i in range(thread_pool.size()):
                    if thread_pool[i].active and thread_pool[i].priority <= 5:
                        # Pause low priority thread
                        thread_pool[i].active = false
                        print("Optimizing CPU: Paused low priority thread #" + str(i))
                        break
        
        "memory":
            # Simulate memory cleanup
            resource_allocation.memory *= 0.6
            print("Optimizing Memory: Forced garbage collection")
        
        "gpu":
            # Reduce GPU usage
            resource_allocation.gpu *= 0.7
            print("Optimizing GPU: Reduced rendering quality")
        
        "storage":
            # Clean up temporary files
            print("Optimizing Storage: Cleaned temporary files")
        
        "network":
            # Throttle network operations
            resource_allocation.network *= 0.5
            print("Optimizing Network: Throttled data transfers")

func _apply_magic_cycle_resources():
    if not hourly_magic_cycles:
        return
    
    # Get resources for current magic cycle
    var cycle_resources = magic_cycle_resources[current_magic_cycle]
    
    # Gradually adjust resource allocation towards cycle targets
    for resource in resource_allocation:
        if cycle_resources.has(resource):
            # Move 10% of the way towards the target each time
            var target = cycle_resources[resource]
            var current = resource_allocation[resource]
            var new_value = current + (target - current) * 0.1
            
            # Ensure we don't exceed limits
            new_value = min(new_value, resource_limits[resource])
            
            resource_allocation[resource] = new_value

# ----- THREAD MANAGEMENT -----
func allocate_thread(task_name, priority = 5):
    if not enabled:
        return -1
    
    # Find an available thread
    for i in range(thread_pool.size()):
        if not thread_pool[i].active:
            thread_pool[i].active = true
            thread_pool[i].task = task_name
            thread_pool[i].priority = priority
            thread_pool[i].start_time = Time.get_unix_time_from_system()
            
            emit_signal("thread_pool_status_changed", _count_active_threads(), thread_pool.size())
            return i
    
    # If ethereal engine has high priority, try to preempt a lower priority thread
    if priority >= ethereal_engine_priority:
        var lowest_priority = 999
        var lowest_idx = -1
        
        for i in range(thread_pool.size()):
            if thread_pool[i].active and thread_pool[i].priority < lowest_priority:
                lowest_priority = thread_pool[i].priority
                lowest_idx = i
        
        if lowest_idx >= 0 and lowest_priority < priority:
            # Preempt the lower priority thread
            thread_pool[lowest_idx].active = true
            thread_pool[lowest_idx].task = task_name
            thread_pool[lowest_idx].priority = priority
            thread_pool[lowest_idx].start_time = Time.get_unix_time_from_system()
            
            emit_signal("thread_pool_status_changed", _count_active_threads(), thread_pool.size())
            return lowest_idx
    
    # No threads available
    return -1

func release_thread(thread_id):
    if thread_id < 0 or thread_id >= thread_pool.size():
        return false
    
    if thread_pool[thread_id].active:
        thread_pool[thread_id].active = false
        thread_pool[thread_id].task = ""
        
        emit_signal("thread_pool_status_changed", _count_active_threads(), thread_pool.size())
        return true
    
    return false

func _count_active_threads():
    var count = 0
    for thread in thread_pool:
        if thread.active:
            count += 1
    return count

# ----- FREEMIUM USAGE TRACKING -----
func _update_freemium_usage():
    if not freemium_optimization:
        return
    
    # Update CPU minutes
    var active_thread_count = _count_active_threads()
    freemium_day_usage.cpu_minutes += active_thread_count * (1.0 / 60.0)  # 1 minute of 1 CPU core
    
    # Update memory usage
    var estimated_memory_mb = resource_allocation.memory * memory_limit_mb
    freemium_day_usage.memory_mb_minutes += estimated_memory_mb * (1.0 / 60.0)  # MB-minutes
    
    # Calculate resource score (0-100)
    var resource_score = 0.0
    for resource in resource_allocation:
        resource_score += resource_allocation[resource] * 20.0  # Scale to 0-20 per resource
    
    freemium_day_usage.resource_score = resource_score
    
    emit_signal("freemium_usage_updated", freemium_day_usage)
    
    # If approaching daily limits, reduce resource usage
    if freemium_day_usage.cpu_minutes > 30.0 or freemium_day_usage.memory_mb_minutes > 15000.0:
        _reduce_resource_usage_for_freemium()

func _reduce_resource_usage_for_freemium():
    # Reduce all resource limits by 10%
    for resource in resource_limits:
        resource_limits[resource] *= 0.9
    
    # Force optimization
    optimization_active = true
    last_optimization_time = Time.get_unix_time_from_system()
    
    print("Reducing resource usage for freemium mode")

func _record_api_call():
    if freemium_optimization:
        freemium_day_usage.api_calls += 1

func _record_data_transfer(mb: float):
    if freemium_optimization:
        freemium_day_usage.data_transfers_mb += mb

# ----- OPTIMIZATION PROCESS -----
func _run_performance_optimization():
    if not enabled or optimization_active:
        return
    
    optimization_active = true
    last_optimization_time = Time.get_unix_time_from_system()
    
    print("Starting performance optimization...")
    
    # Register optimization task
    var thread_id = allocate_thread("performance_optimization", 8)
    
    if thread_id >= 0:
        # Simulate optimization process
        var start_performance = _calculate_performance_metric()
        
        # Optimize resource usage
        for resource in resource_allocation:
            if resource_allocation[resource] > resource_limits[resource] * 0.7:
                _optimize_resource_usage(resource)
        
        # Clean up unused resources
        _clean_unused_resources()
        
        # Optimize for current magic cycle
        _apply_magic_cycle_resources()
        
        # Calculate new performance
        var end_performance = _calculate_performance_metric()
        
        # Update performance stats
        performance_stats = {
            "time": Time.get_datetime_string_from_system(),
            "improvement": end_performance - start_performance,
            "level": current_performance_level
        }
        
        # Store performance for current magic cycle
        magic_cycle_performance[current_magic_cycle] = end_performance
        
        # Release thread
        release_thread(thread_id)
        
        emit_signal("performance_optimized", current_performance_level, performance_stats)
    
    optimization_active = false

func _clean_unused_resources():
    # Simulate resource cleanup
    resource_allocation.memory *= 0.9
    
    # In a real implementation, this would:
    # - Clear caches
    # - Close unused file handles
    # - Release unused GPU resources
    # - etc.
    
    print("Cleaned up unused resources")

func _calculate_performance_metric():
    # Calculate a composite performance score (0-100)
    var performance = 0.0
    
    # Resource efficiency (higher is better)
    var resource_efficiency = 0.0
    for resource in resource_allocation:
        var usage_ratio = resource_allocation[resource] / resource_limits[resource]
        resource_efficiency += (1.0 - abs(0.7 - usage_ratio)) * 20.0  # Optimal at 70% usage
    
    # Thread efficiency
    var active_threads = _count_active_threads()
    var thread_efficiency = float(active_threads) / float(max_threads) * 25.0
    
    # Magic cycle alignment (higher when resources match cycle needs)
    var cycle_alignment = 0.0
    if hourly_magic_cycles and current_magic_cycle >= 0:
        var cycle_resources = magic_cycle_resources[current_magic_cycle]
        var alignment_sum = 0.0
        var count = 0
        
        for resource in cycle_resources:
            if resource_allocation.has(resource):
                var target = cycle_resources[resource]
                var current = resource_allocation[resource]
                alignment_sum += 1.0 - abs(target - current)
                count += 1
        
        if count > 0:
            cycle_alignment = alignment_sum / count * 25.0
    
    # Freemium efficiency (higher when under limits)
    var freemium_efficiency = 0.0
    if freemium_optimization:
        var cpu_ratio = min(30.0, freemium_day_usage.cpu_minutes) / 30.0
        var memory_ratio = min(15000.0, freemium_day_usage.memory_mb_minutes) / 15000.0
        freemium_efficiency = (2.0 - cpu_ratio - memory_ratio) * 15.0
    else:
        freemium_efficiency = 15.0
    
    # Calculate total performance
    performance = resource_efficiency + thread_efficiency + cycle_alignment + freemium_efficiency
    
    # Determine performance level
    if performance < 40:
        current_performance_level = 1  # Low
    elif performance < 70:
        current_performance_level = 2  # Medium
    else:
        current_performance_level = 3  # High
    
    return performance

# ----- MAGIC CYCLE MANAGEMENT -----
func _update_magic_cycle():
    if not hourly_magic_cycles:
        return
    
    # Calculate elapsed time
    var current_time = Time.get_unix_time_from_system()
    var elapsed_seconds = current_time - magic_cycle_start_time
    
    # Calculate expected turn based on elapsed time
    var seconds_per_turn = turn_duration_minutes * 60
    var expected_turn = int(elapsed_seconds / seconds_per_turn) % 12
    
    # Check if turn system is available and synchronized
    if turn_system and turn_system.has_method("get_current_turn"):
        var system_turn = (turn_system.get_current_turn() - 1) % 12
        
        # If system turn is different, use it
        if system_turn != current_magic_cycle:
            current_magic_cycle = system_turn
            _on_magic_cycle_changed()
            return
    
    # If no turn system or not synchronized, use time-based approach
    if expected_turn != current_magic_cycle:
        current_magic_cycle = expected_turn
        _on_magic_cycle_changed()

func _on_magic_cycle_changed():
    print("Magic cycle changed to: " + str(current_magic_cycle + 1))
    
    # Apply resources for new cycle
    _apply_magic_cycle_resources()
    
    # Check if we completed a full 12-turn cycle
    if current_magic_cycle == 0:
        _on_full_magic_cycle_completed()

func _on_full_magic_cycle_completed():
    print("Completed full 12-turn magic cycle")
    
    # Calculate overall cycle performance
    var total_performance = 0.0
    for perf in magic_cycle_performance:
        total_performance += perf
    
    var avg_performance = total_performance / 12.0
    
    # Reset magic cycle start time
    magic_cycle_start_time = Time.get_unix_time_from_system()
    
    # Reset performance array
    for i in range(12):
        magic_cycle_performance[i] = 0.0
    
    emit_signal("magic_cycle_completed", current_magic_cycle, avg_performance)

# ----- EVENT HANDLERS -----
func _on_resource_monitor_timeout():
    if not enabled:
        return
    
    # Update resource usage
    _calculate_current_resource_usage()
    
    # Update magic cycle if hourly cycles enabled
    if hourly_magic_cycles:
        _update_magic_cycle()

func _on_optimization_timeout():
    if not enabled:
        return
    
    # Run optimization if it's been a while
    var current_time = Time.get_unix_time_from_system()
    if current_time - last_optimization_time > 60:  # At least 1 minute since last optimization
        _run_performance_optimization()

func _on_freemium_usage_timeout():
    if not enabled:
        return
    
    if freemium_optimization:
        _update_freemium_usage()

func _on_magic_cycle_timeout():
    if not enabled:
        return
    
    if hourly_magic_cycles:
        # Gradually apply magic cycle resources
        _apply_magic_cycle_resources()

# ----- PUBLIC API -----
func toggle_optimizer(enabled_state: bool):
    enabled = enabled_state
    return enabled

func toggle_max_performance(enabled_state: bool):
    max_performance_mode = enabled_state
    
    if max_performance_mode:
        _configure_max_performance()
    else:
        # Reset to default or freemium mode
        if freemium_optimization:
            _configure_freemium_limits()
        else:
            _initialize_resources()
    
    return max_performance_mode

func toggle_freemium_mode(enabled_state: bool):
    freemium_optimization = enabled_state
    
    if freemium_optimization:
        _configure_freemium_limits()
    else:
        # Reset to default or max performance mode
        if max_performance_mode:
            _configure_max_performance()
        else:
            _initialize_resources()
    
    return freemium_optimization

func set_hourly_magic_duration(hours: float):
    # Set duration for a full 12-turn cycle
    var minutes_per_cycle = int(hours * 60.0)
    turn_duration_minutes = max(1, minutes_per_cycle / 12)
    
    return turn_duration_minutes * 12  # Return total minutes for the cycle

func force_optimization():
    if not optimization_active:
        _run_performance_optimization()
        return true
    return false

func get_current_performance():
    return {
        "level": current_performance_level,
        "score": _calculate_performance_metric(),
        "magic_cycle": current_magic_cycle + 1,
        "resource_usage": resource_allocation.duplicate(),
        "thread_usage": _count_active_threads() / float(max_threads),
        "freemium_usage": freemium_day_usage.duplicate()
    }

func get_magic_cycle_info():
    # Calculate time remaining in current cycle
    var current_time = Time.get_unix_time_from_system()
    var elapsed_in_cycle = (current_time - magic_cycle_start_time) % (turn_duration_minutes * 60)
    var remaining_in_cycle = (turn_duration_minutes * 60) - elapsed_in_cycle
    
    return {
        "current_cycle": current_magic_cycle + 1,
        "time_elapsed": elapsed_in_cycle,
        "time_remaining": remaining_in_cycle,
        "total_duration": turn_duration_minutes * 60,
        "resources": magic_cycle_resources[current_magic_cycle].duplicate(),
        "performance": magic_cycle_performance[current_magic_cycle]
    }

func allocate_ethereal_thread(task_name):
    # Special allocation for Ethereal Engine with high priority
    return allocate_thread(task_name, ethereal_engine_priority)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/performance_optimizer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/player_preference_analyzer.gd
# SIZE: 10855 bytes
extends Node

class_name PlayerPreferenceAnalyzer

# Constants
const MIN_DATA_POINTS = 5
const ANALYSIS_INTERVAL = 120 # seconds
const SMOOTHING_FACTOR = 0.3
const ENJOYMENT_INDICATORS = {
    "session_duration": 0.2,
    "action_frequency": 0.2, 
    "completion_rate": 0.2,
    "revisit_frequency": 0.2,
    "exploration_breadth": 0.2
}

# Preference categories and tracking
var preference_categories = {
    "challenge": {
        "current_value": 0.5,
        "history": [],
        "indicators": {
            "difficulty_selected": [],
            "retry_attempts": [],
            "time_spent_on_challenges": []
        }
    },
    "creation": {
        "current_value": 0.5,
        "history": [],
        "indicators": {
            "items_created": [],
            "creation_time_spent": [],
            "customization_depth": []
        }
    },
    "exploration": {
        "current_value": 0.5, 
        "history": [],
        "indicators": {
            "areas_visited": [],
            "discovery_rate": [],
            "path_diversity": []
        }
    },
    "social": {
        "current_value": 0.5,
        "history": [],
        "indicators": {
            "interaction_frequency": [],
            "dialogue_choices": [],
            "relationship_building": []
        }
    },
    "achievement": {
        "current_value": 0.5,
        "history": [],
        "indicators": {
            "goals_completed": [],
            "progress_tracking": [],
            "perfectionism": []
        }
    }
}

# Player state tracking
var activity_log = []
var enjoyment_metrics = {
    "session_duration": [],
    "action_frequency": [],
    "completion_rate": [],
    "revisit_frequency": [],
    "exploration_breadth": []
}

# Analytics
var enjoyment_factor = 1.0
var last_analysis_time = 0
var confidence_level = 0.0

# Signals
signal preferences_updated(preferences)
signal enjoyment_factor_changed(factor)
signal confidence_level_changed(level)

# Reference to account manager
var _account_manager = null

func _ready():
    # Set up analysis timer
    var timer = Timer.new()
    timer.wait_time = ANALYSIS_INTERVAL
    timer.autostart = true
    timer.connect("timeout", self, "_on_analysis_interval")
    add_child(timer)
    
    # Find account manager if available
    if has_node("/root/SmartAccountManager") or get_node_or_null("/root/SmartAccountManager"):
        _account_manager = get_node("/root/SmartAccountManager")
        print("Connected to SmartAccountManager")

func _on_analysis_interval():
    analyze_player_preferences()
    last_analysis_time = OS.get_unix_time()

func log_activity(activity_data):
    # Add timestamp if not provided
    if not activity_data.has("timestamp"):
        activity_data["timestamp"] = OS.get_unix_time()
    
    # Add to activity log
    activity_log.append(activity_data)
    
    # Limit log size to prevent memory issues
    if activity_log.size() > 1000:
        activity_log.pop_front()
    
    # Check if we should run analysis
    if OS.get_unix_time() - last_analysis_time > ANALYSIS_INTERVAL and activity_log.size() >= MIN_DATA_POINTS:
        analyze_player_preferences()
        last_analysis_time = OS.get_unix_time()

func log_preference_indicator(category, indicator, value):
    if category in preference_categories and indicator in preference_categories[category]["indicators"]:
        # Add data point to indicator
        preference_categories[category]["indicators"][indicator].append({
            "value": value,
            "timestamp": OS.get_unix_time()
        })
        
        # Limit array size
        if preference_categories[category]["indicators"][indicator].size() > 20:
            preference_categories[category]["indicators"][indicator].pop_front()
        
        return true
    
    return false

func log_enjoyment_metric(metric, value):
    if metric in enjoyment_metrics:
        enjoyment_metrics[metric].append({
            "value": value,
            "timestamp": OS.get_unix_time()
        })
        
        # Limit array size
        if enjoyment_metrics[metric].size() > 20:
            enjoyment_metrics[metric].pop_front()
        
        return true
    
    return false

func analyze_player_preferences():
    # Skip if not enough data
    if activity_log.size() < MIN_DATA_POINTS:
        print("Not enough data for preference analysis")
        return
    
    # Analyze each preference category
    for category in preference_categories:
        var indicators = preference_categories[category]["indicators"]
        var indicators_count = 0
        var indicators_sum = 0.0
        
        # Process each indicator in this category
        for indicator in indicators:
            var data_points = indicators[indicator]
            if data_points.size() >= MIN_DATA_POINTS:
                var avg_value = 0.0
                
                # Calculate weighted average, with recent values weighted more
                var weight_sum = 0.0
                for i in range(data_points.size()):
                    var weight = 1.0 + (i / float(data_points.size()))
                    avg_value += data_points[i]["value"] * weight
                    weight_sum += weight
                
                if weight_sum > 0:
                    avg_value /= weight_sum
                    indicators_sum += avg_value
                    indicators_count += 1
        
        # Update category preference if we have indicators
        if indicators_count > 0:
            var new_value = indicators_sum / indicators_count
            
            # Apply smoothing to avoid rapid changes
            new_value = preference_categories[category]["current_value"] * (1.0 - SMOOTHING_FACTOR) + new_value * SMOOTHING_FACTOR
            
            # Clamp to valid range
            new_value = clamp(new_value, 0.1, 0.9)
            
            # Update category value
            preference_categories[category]["current_value"] = new_value
            preference_categories[category]["history"].append({
                "value": new_value,
                "timestamp": OS.get_unix_time()
            })
            
            # Limit history size
            if preference_categories[category]["history"].size() > 20:
                preference_categories[category]["history"].pop_front()
    
    # Calculate overall enjoyment factor
    calculate_enjoyment_factor()
    
    # Calculate confidence level based on data quantity
    calculate_confidence_level()
    
    # Update account manager if connected
    if _account_manager:
        _account_manager.enjoyment_factor = enjoyment_factor
        
        var preferences = {}
        for category in preference_categories:
            var key = "prefers_" + category
            preferences[key] = preference_categories[category]["current_value"]
        
        _account_manager.player_preferences = preferences
    
    # Emit updated preferences
    var current_preferences = {}
    for category in preference_categories:
        current_preferences[category] = preference_categories[category]["current_value"]
    
    emit_signal("preferences_updated", current_preferences)
    emit_signal("enjoyment_factor_changed", enjoyment_factor)
    emit_signal("confidence_level_changed", confidence_level)
    
    print("Analyzed player preferences - Enjoyment factor: " + str(enjoyment_factor))

func calculate_enjoyment_factor():
    var factor_sum = 0.0
    var weight_sum = 0.0
    
    # Process each enjoyment metric
    for metric in enjoyment_metrics:
        var data_points = enjoyment_metrics[metric]
        if data_points.size() >= MIN_DATA_POINTS:
            var avg_value = 0.0
            for point in data_points:
                avg_value += point["value"]
            
            avg_value /= data_points.size()
            
            var weight = ENJOYMENT_INDICATORS[metric]
            factor_sum += avg_value * weight
            weight_sum += weight
    
    # Update enjoyment factor if we have data
    if weight_sum > 0:
        var new_factor = factor_sum / weight_sum
        
        # Apply smoothing
        new_factor = enjoyment_factor * (1.0 - SMOOTHING_FACTOR) + new_factor * SMOOTHING_FACTOR
        
        # Clamp to reasonable range
        new_factor = clamp(new_factor, 0.5, 2.0)
        
        enjoyment_factor = new_factor

func calculate_confidence_level():
    var total_indicators = 0
    var total_data_points = 0
    
    # Count indicators with sufficient data
    for category in preference_categories:
        var indicators = preference_categories[category]["indicators"]
        for indicator in indicators:
            total_indicators += 1
            total_data_points += indicators[indicator].size()
    
    # Calculate confidence based on data quantity and variety
    var data_coverage = min(1.0, total_data_points / float(total_indicators * MIN_DATA_POINTS * 2))
    
    # Factor in history length
    var history_factor = 0.0
    var history_count = 0
    for category in preference_categories:
        history_factor += min(1.0, preference_categories[category]["history"].size() / 10.0)
        history_count += 1
    
    if history_count > 0:
        history_factor /= history_count
    
    # Calculate final confidence
    confidence_level = (data_coverage * 0.7 + history_factor * 0.3)
    
    print("Preference analysis confidence: " + str(confidence_level * 100.0) + "%")

# Artificial intelligence enhancement functions for auto-correction

func get_auto_correction_suggestion():
    # Skip if confidence is too low
    if confidence_level < 0.3:
        return null
    
    # Find player's highest preference
    var highest_preference = ""
    var highest_value = 0.0
    
    for category in preference_categories:
        var value = preference_categories[category]["current_value"]
        if value > highest_value:
            highest_value = value
            highest_preference = category
    
    # Skip if no strong preference
    if highest_value < 0.6:
        return null
    
    # Calculate suggested point adjustment based on preferences
    var suggestion = {
        "category": highest_preference,
        "amount": highest_value * 50, # Scale based on preference strength
        "confidence": confidence_level,
        "reason": "Player shows strong preference for " + highest_preference
    }
    
    return suggestion

func should_auto_correct():
    # Only auto-correct if we have reasonable confidence
    return confidence_level >= 0.3

# Helper methods for external access

func get_preference_value(category):
    if category in preference_categories:
        return preference_categories[category]["current_value"]
    return 0.5

func get_enjoyment_factor():
    return enjoyment_factor

func get_confidence_level():
    return confidence_level
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/player_preference_analyzer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/precise_timing_system.gd
# SIZE: 13209 bytes
extends Node

class_name PreciseTimingSystem

# ----- PRECISION SETTINGS -----
@export_category("Precision Settings")
@export var enabled: bool = true
@export var use_precise_timing: bool = true
@export var timing_resolution: float = 0.001  # 1ms precision
@export var synchronize_with_system_clock: bool = true
@export var max_timing_drift: float = 0.01  # Maximum allowed drift before correction

# ----- TIME MARKERS -----
@export_category("Time Markers")
@export var hour_markers: Array[int] = [0, 3, 6, 9, 12, 15, 18, 21]  # Key hours
@export var minute_markers: Array[int] = [0, 15, 30, 45]  # Key minutes
@export var second_markers: Array[int] = [0, 15, 30, 45]  # Key seconds

# ----- TURN INTEGRATION -----
@export_category("Turn Integration")
@export var turn_time_mapping: Dictionary = {
    "1": {"hour": 0, "minute": 0},
    "2": {"hour": 2, "minute": 0},
    "3": {"hour": 4, "minute": 0},
    "4": {"hour": 6, "minute": 0},
    "5": {"hour": 8, "minute": 0},
    "6": {"hour": 10, "minute": 0},
    "7": {"hour": 12, "minute": 0},
    "8": {"hour": 14, "minute": 0},
    "9": {"hour": 16, "minute": 0},
    "10": {"hour": 18, "minute": 0},
    "11": {"hour": 20, "minute": 0},
    "12": {"hour": 22, "minute": 0},
    "15": {"hour": 15, "minute": 0}  # Special turn 15
}

# ----- STATE VARIABLES -----
var precise_timer: Timer
var time_offset: float = 0.0
var last_sync_time: int = 0
var current_turn: int = 1
var registered_callbacks = {}
var active_timers = {}
var turn_controller = null
var blink_controller = null

# ----- SIGNALS -----
signal time_marker_reached(hour, minute, second, marker_type)
signal sync_performed(drift_corrected)
signal precision_timer_tick(time_ms)
signal turn_time_reached(turn_number)

# ----- INITIALIZATION -----
func _ready():
    # Initialize timer for precision timing
    _initialize_timer()
    
    # Find turn controller
    turn_controller = get_node_or_null("/root/TurnController")
    if not turn_controller:
        turn_controller = _find_node_by_class(get_tree().root, "TurnController")
    
    # Find blink controller
    blink_controller = get_node_or_null("/root/BlinkAnimationController")
    if not blink_controller:
        blink_controller = _find_node_by_class(get_tree().root, "BlinkAnimationController")
    
    # Connect to turn controller if available
    if turn_controller:
        turn_controller.connect("turn_started", Callable(self, "_on_turn_started"))
        turn_controller.register_system(self)
        current_turn = turn_controller.get_current_turn()
    
    # Synchronize with system time
    if synchronize_with_system_clock:
        _sync_with_system_time()
    
    # Start timing system if enabled
    if enabled:
        precise_timer.start()
    
    print("Precise Timing System initialized")
    print("Timing resolution: " + str(timing_resolution * 1000) + "ms")
    print("Current turn: " + str(current_turn))

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_timer():
    # Create high precision timer
    precise_timer = Timer.new()
    precise_timer.wait_time = timing_resolution
    precise_timer.one_shot = false
    precise_timer.connect("timeout", Callable(self, "_on_precise_timer_timeout"))
    add_child(precise_timer)

# ----- TIMING FUNCTIONS -----
func _on_precise_timer_timeout():
    if not enabled:
        return
    
    # Get current time
    var current_time = Time.get_time_dict_from_system()
    var current_ms = OS.get_ticks_msec()
    
    # Check if we need to sync with system time
    if synchronize_with_system_clock and current_ms - last_sync_time > 60000:  # Sync every minute
        _sync_with_system_time()
    
    # Emit precision timer tick signal
    emit_signal("precision_timer_tick", current_ms)
    
    # Check time markers
    _check_time_markers(current_time)
    
    # Check active timers
    _update_active_timers(current_ms)
    
    # Check for turn-specific time triggers
    _check_turn_time_triggers(current_time)

func _sync_with_system_time():
    # Calculate timing drift and correct if needed
    var godot_time = OS.get_ticks_msec() / 1000.0
    var system_time = Time.get_unix_time_from_system()
    var drift = system_time - godot_time - time_offset
    
    if abs(drift) > max_timing_drift:
        time_offset += drift
        emit_signal("sync_performed", drift)
        
        if OS.is_debug_build():
            print("Time sync performed, corrected drift of " + str(drift) + "s")
    
    last_sync_time = OS.get_ticks_msec()

func _check_time_markers(time_dict):
    # Check if current time hits any of our markers
    var hour = time_dict.hour
    var minute = time_dict.minute
    var second = time_dict.second
    
    # Check hour markers
    if minute == 0 and second == 0 and hour_markers.has(hour):
        emit_signal("time_marker_reached", hour, minute, second, "hour")
        _trigger_hour_marker_callbacks(hour)
    
    # Check minute markers
    if second == 0 and minute_markers.has(minute):
        emit_signal("time_marker_reached", hour, minute, second, "minute")
        _trigger_minute_marker_callbacks(hour, minute)
    
    # Check second markers
    if second_markers.has(second):
        emit_signal("time_marker_reached", hour, minute, second, "second")
        _trigger_second_marker_callbacks(hour, minute, second)

func _update_active_timers(current_ms):
    # Check and update active timers
    var completed_timers = []
    
    for timer_id in active_timers:
        var timer_data = active_timers[timer_id]
        
        if current_ms >= timer_data.end_time:
            # Timer completed
            completed_timers.append(timer_id)
            
            # Call callback if present
            if timer_data.has("callback") and timer_data.callback is Callable:
                timer_data.callback.call()
    
    # Remove completed timers
    for timer_id in completed_timers:
        active_timers.erase(timer_id)

func _check_turn_time_triggers(time_dict):
    # Check if current time matches any turn time mapping
    var hour = time_dict.hour
    var minute = time_dict.minute
    
    for turn_str in turn_time_mapping:
        var turn_data = turn_time_mapping[turn_str]
        var turn_number = int(turn_str)
        
        if turn_data.hour == hour and turn_data.minute == minute and time_dict.second == 0:
            # This turn's time has been reached
            emit_signal("turn_time_reached", turn_number)
            
            # Auto-transition to this turn if applicable
            if turn_controller and turn_number != current_turn:
                # Only do this once per minute
                _handle_turn_time_trigger(turn_number)
                
                # Special effect for turn 15
                if turn_number == 15:
                    _trigger_turn15_sequence()

func _handle_turn_time_trigger(turn_number):
    # Handle a turn time trigger event
    print("Turn " + str(turn_number) + " time trigger activated at " + _format_current_time())
    
    # If turn controller exists, notify it
    if turn_controller:
        if turn_controller.has_method("set_turn"):
            # Wait a moment for dramatic effect
            await get_tree().create_timer(1.0).timeout
            turn_controller.set_turn(turn_number)

func _trigger_turn15_sequence():
    # Special sequence for turn 15
    print("Initiating Turn 15 sequence - Precisely 15")
    
    # Triple flicker effect if blink controller exists
    if blink_controller:
        blink_controller.trigger_flicker("", 15)  # 15 flickers for turn 15
    
    # Visual effect sequence
    for i in range(5):
        # Create a tempo of exactly 15 beats per minute (4 seconds per beat)
        await get_tree().create_timer(4.0).timeout
        
        if blink_controller:
            if i % 3 == 0:
                blink_controller.trigger_blink("", 1)
            elif i % 3 == 1:
                blink_controller.trigger_wink("", i % 2 == 0)
            else:
                blink_controller.trigger_flicker("", 3)

# ----- CALLBACK REGISTRATION -----
func _trigger_hour_marker_callbacks(hour):
    var key = "hour_" + str(hour)
    if registered_callbacks.has(key):
        for callback in registered_callbacks[key]:
            if callback is Callable:
                callback.call(hour)

func _trigger_minute_marker_callbacks(hour, minute):
    var key = "hour_" + str(hour) + "_minute_" + str(minute)
    if registered_callbacks.has(key):
        for callback in registered_callbacks[key]:
            if callback is Callable:
                callback.call(hour, minute)

func _trigger_second_marker_callbacks(hour, minute, second):
    var key = "hour_" + str(hour) + "_minute_" + str(minute) + "_second_" + str(second)
    if registered_callbacks.has(key):
        for callback in registered_callbacks[key]:
            if callback is Callable:
                callback.call(hour, minute, second)

# ----- TURN SYSTEM INTEGRATION -----
func _on_turn_started(turn_number):
    # Update current turn
    current_turn = turn_number
    
    print("Turn " + str(turn_number) + " started at " + _format_current_time())
    
    # Special handling for turn 15
    if turn_number == 15:
        _on_turn15_started()

func _on_turn15_started():
    # Special handling for turn 15
    print("Turn 15 started - Initializing precise timing mode")
    
    # Set maximum precision
    timing_resolution = 0.001  # 1ms
    precise_timer.wait_time = timing_resolution
    
    # Ensure synchronization is active
    synchronize_with_system_clock = true
    _sync_with_system_time()
    
    # Set up special marker for exactly 15:00:00
    register_time_callback(15, 0, 0, func(h, m, s):
        print("‚åö EXACTLY 15:00:00 REACHED ‚åö")
        _trigger_turn15_sequence()
    )

# ----- PUBLIC API -----
func register_time_callback(hour: int, minute: int, second: int, callback: Callable) -> bool:
    # Register a callback for a specific time
    var key = "hour_" + str(hour) + "_minute_" + str(minute) + "_second_" + str(second)
    
    if not registered_callbacks.has(key):
        registered_callbacks[key] = []
    
    registered_callbacks[key].append(callback)
    
    print("Registered callback for time " + str(hour) + ":" + str(minute) + ":" + str(second))
    
    return true

func register_hour_callback(hour: int, callback: Callable) -> bool:
    # Register a callback for a specific hour
    var key = "hour_" + str(hour)
    
    if not registered_callbacks.has(key):
        registered_callbacks[key] = []
    
    registered_callbacks[key].append(callback)
    
    print("Registered callback for hour " + str(hour))
    
    return true

func register_minute_callback(hour: int, minute: int, callback: Callable) -> bool:
    # Register a callback for a specific hour and minute
    var key = "hour_" + str(hour) + "_minute_" + str(minute)
    
    if not registered_callbacks.has(key):
        registered_callbacks[key] = []
    
    registered_callbacks[key].append(callback)
    
    print("Registered callback for time " + str(hour) + ":" + str(minute))
    
    return true

func create_timer(duration_ms: int, callback: Callable = Callable()) -> int:
    # Create a precise timer with optional callback
    var timer_id = randi() % 1000000
    
    active_timers[timer_id] = {
        "start_time": OS.get_ticks_msec(),
        "end_time": OS.get_ticks_msec() + duration_ms,
        "duration": duration_ms,
        "callback": callback
    }
    
    return timer_id

func cancel_timer(timer_id: int) -> bool:
    # Cancel an active timer
    if active_timers.has(timer_id):
        active_timers.erase(timer_id)
        return true
    
    return false

func get_timer_remaining(timer_id: int) -> int:
    # Get remaining time for a timer in milliseconds
    if not active_timers.has(timer_id):
        return -1
    
    var timer_data = active_timers[timer_id]
    var current_ms = OS.get_ticks_msec()
    var remaining = timer_data.end_time - current_ms
    
    return max(0, remaining)

func set_enabled(is_enabled: bool) -> void:
    # Enable or disable the timing system
    enabled = is_enabled
    
    if enabled:
        precise_timer.start()
    else:
        precise_timer.stop()
    
    print("Precise timing system " + ("enabled" if enabled else "disabled"))

func get_current_formatted_time() -> String:
    # Get current time as formatted string
    return _format_current_time()

func on_turn_changed(turn_number: int, turn_data: Dictionary) -> void:
    # Required method for turn system integration
    current_turn = turn_number
    
    # Special case for turn 15
    if turn_number == 15:
        _on_turn15_started()

# ----- UTILITY FUNCTIONS -----
func _format_current_time() -> String:
    var time = Time.get_time_dict_from_system()
    return "%02d:%02d:%02d" % [time.hour, time.minute, time.second]
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/precise_timing_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/project_connector_system.gd
# SIZE: 42522 bytes
extends Node

class_name ProjectConnectorSystem

# Project Connector System
# Manages project merging, file synchronization, and cross-application integration
# with support for sound capabilities and multi-dimensional connections

# ----- CONSTANTS -----
const MAX_MERGE_DEPTH = 5
const MAX_PROJECT_CONNECTIONS = 20
const VALID_PROJECT_TYPES = ["godot", "python", "js", "web", "terminal", "ethereal", "akashic", "unified"]
const MERGE_STRATEGIES = ["overwrite", "combine", "selective", "version", "dimensional"]
const SOUND_FORMATS = ["wav", "mp3", "ogg", "m4a", "wma", "midi"]
const CONNECTION_TYPES = ["direct", "bridge", "tunnel", "portal", "pipe", "socket", "api"]

# ----- SYSTEM REFERENCES -----
var akashic_system = null
var ethereal_bridge = null
var terminal_bridge = null
var auto_agent = null
var spatial_connector = null
var universal_flow = null

# ----- PROJECT DATA -----
var registered_projects = {}
var project_connections = {}
var active_merges = {}
var version_history = {}
var sound_registry = {}
var drive_mappings = {}

# ----- CONNECTION MANAGERS -----
var file_synchronizer = null
var version_control = null
var sound_processor = null
var drive_connector = null

# ----- SIGNALS -----
signal project_registered(project_id, project_data)
signal projects_connected(source_id, target_id, connection_type)
signal merge_started(merge_id, projects_involved)
signal merge_completed(merge_id, result)
signal sound_integrated(sound_id, project_ids)
signal drive_connected(drive_id, path)
signal version_created(project_id, version_id)

# ----- INITIALIZATION -----
func _ready():
    print("Initializing Project Connector System...")
    
    # Connect to required systems
    _connect_systems()
    
    # Initialize managers
    _initialize_managers()
    
    # Scan for existing projects
    _scan_for_projects()
    
    # Map available drives
    _map_drives()
    
    print("Project Connector System initialized")

func _connect_systems():
    # Connect to Akashic system
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    
    # Connect to Ethereal Bridge
    ethereal_bridge = get_node_or_null("/root/EtherealAkashicBridge")
    
    # Connect to Terminal Bridge
    terminal_bridge = get_node_or_null("/root/TerminalAPIBridge")
    
    # Connect to Auto Agent
    auto_agent = get_node_or_null("/root/AutoAgentMode")
    
    # Connect to Spatial Connector
    spatial_connector = get_node_or_null("/root/SpatialLinguisticConnector")
    
    # Connect to Universal Flow
    universal_flow = get_node_or_null("/root/UniversalDataFlow")

func _initialize_managers():
    # Initialize file synchronizer
    file_synchronizer = FileSynchronizer.new()
    add_child(file_synchronizer)
    
    # Initialize version control
    version_control = VersionControl.new()
    add_child(version_control)
    
    # Initialize sound processor
    sound_processor = SoundProcessor.new()
    add_child(sound_processor)
    
    # Initialize drive connector
    drive_connector = DriveConnector.new()
    add_child(drive_connector)

func _scan_for_projects():
    # Scan for Godot projects
    _scan_directory("/mnt/c/Users/Percision 15", ["project.godot"], "godot")
    
    # Scan for Python projects
    _scan_directory("/mnt/c/Users/Percision 15", ["requirements.txt", "setup.py"], "python")
    
    # Scan for JS projects
    _scan_directory("/mnt/c/Users/Percision 15", ["package.json"], "js")
    
    # Scan for akashic projects
    _scan_directory("/mnt/c/Users/Percision 15", ["akashic_database.js", "akashic_record_connector.gd"], "akashic")
    
    # Scan for ethereal projects
    _scan_directory("/mnt/c/Users/Percision 15", ["ethereal_engine.gd", "ethereal_tunnel.gd"], "ethereal")
    
    print("Found " + str(registered_projects.size()) + " projects")

func _map_drives():
    # Map C drive
    _register_drive("c", "/mnt/c")
    
    # Check for D drive
    if Directory.new().dir_exists("/mnt/d"):
        _register_drive("d", "/mnt/d")
    
    # Check for mapped network drives
    _scan_network_drives()
    
    # Virtual drives for akashic and ethereal systems
    _register_virtual_drive("akashic", "akashic://records")
    _register_virtual_drive("ethereal", "ethereal://dimension")
    
    print("Mapped " + str(drive_mappings.size()) + " drives")

func _scan_network_drives():
    # Implement network drive scanning
    var network_paths = [
        "/mnt/c/Users/Percision 15/OneDrive"
    ]
    
    for path in network_paths:
        if Directory.new().dir_exists(path):
            var drive_name = path.split("/")[-1].to_lower()
            _register_drive(drive_name, path)

func _scan_directory(base_path, indicator_files, project_type):
    var dir = Directory.new()
    
    if not dir.dir_exists(base_path):
        return
    
    if dir.open(base_path) == OK:
        dir.list_dir_begin(true, true)
        
        var file_name = dir.get_next()
        while file_name != "":
            var full_path = base_path + "/" + file_name
            
            if dir.current_is_dir():
                # Check if this directory contains indicator files
                var is_project = false
                
                for indicator in indicator_files:
                    if File.new().file_exists(full_path + "/" + indicator):
                        is_project = true
                        break
                
                if is_project:
                    _register_project(file_name, full_path, project_type)
                else:
                    # Recursively scan subdirectories, but limit depth
                    var depth = base_path.split("/").size() - 3 # Starting from /mnt/c
                    if depth < MAX_MERGE_DEPTH:
                        _scan_directory(full_path, indicator_files, project_type)
            
            file_name = dir.get_next()
        
        dir.list_dir_end()

# ----- REGISTRATION FUNCTIONS -----
func _register_project(name, path, type):
    var project_id = _generate_project_id(name, path)
    
    # Skip if already registered
    if registered_projects.has(project_id):
        return project_id
    
    # Create project data
    registered_projects[project_id] = {
        "name": name,
        "path": path,
        "type": type,
        "files": [],
        "connections": [],
        "last_update": OS.get_unix_time(),
        "versions": [],
        "sounds": [],
        "dimensions": []
    }
    
    # Scan for sound files
    _scan_for_sounds(path, project_id)
    
    # Register with akashic system if available
    if akashic_system and akashic_system.has_method("register_project"):
        akashic_system.register_project(project_id, name, type)
    
    # Register with ethereal bridge if available
    if ethereal_bridge and ethereal_bridge.has_method("register_dimension"):
        var dimension_id = ethereal_bridge.register_dimension(project_id, name)
        registered_projects[project_id].dimensions.append(dimension_id)
    
    # Create initial version
    _create_version(project_id, "initial")
    
    # Emit signal
    emit_signal("project_registered", project_id, registered_projects[project_id])
    
    return project_id

func _generate_project_id(name, path):
    # Create unique ID based on name and path
    var id_base = name.to_lower().replace(" ", "_")
    var path_hash = str(path.hash()).substr(0, 6)
    
    return id_base + "_" + path_hash

func _register_drive(drive_name, path):
    # Register a physical drive
    drive_mappings[drive_name] = {
        "path": path,
        "type": "physical",
        "connected": true,
        "projects": [],
        "last_scan": OS.get_unix_time()
    }
    
    # Scan for projects on this drive
    for project_id in registered_projects:
        var project = registered_projects[project_id]
        if project.path.begins_with(path):
            drive_mappings[drive_name].projects.append(project_id)
    
    emit_signal("drive_connected", drive_name, path)
    
    return drive_name

func _register_virtual_drive(drive_name, url):
    # Register a virtual drive (for akashic or ethereal systems)
    drive_mappings[drive_name] = {
        "path": url,
        "type": "virtual",
        "connected": true,
        "projects": [],
        "last_scan": OS.get_unix_time()
    }
    
    emit_signal("drive_connected", drive_name, url)
    
    return drive_name

func _scan_for_sounds(path, project_id):
    var dir = Directory.new()
    
    if not dir.dir_exists(path):
        return
    
    if dir.open(path) == OK:
        dir.list_dir_begin(true, true)
        
        var file_name = dir.get_next()
        while file_name != "":
            var full_path = path + "/" + file_name
            
            if dir.current_is_dir():
                # Recursively scan subdirectories, but limit depth
                var depth = path.split("/").size() - 3 # Starting from /mnt/c
                if depth < 3: # Limit sound scanning depth
                    _scan_for_sounds(full_path, project_id)
            else:
                # Check if this is a sound file
                var ext = file_name.get_extension().to_lower()
                if SOUND_FORMATS.has(ext):
                    _register_sound(file_name, full_path, ext, project_id)
            
            file_name = dir.get_next()
        
        dir.list_dir_end()

func _register_sound(name, path, format, project_id):
    var sound_id = path.hash()
    
    # Create sound data
    sound_registry[sound_id] = {
        "name": name,
        "path": path,
        "format": format,
        "projects": [project_id],
        "registered": OS.get_unix_time(),
        "duration": _get_sound_duration(path, format),
        "processed": false
    }
    
    # Add to project
    registered_projects[project_id].sounds.append(sound_id)
    
    # Register with sound processor
    sound_processor.register_sound(sound_id, path, format)
    
    return sound_id

func _get_sound_duration(path, format):
    # Stub for sound duration detection - would need audio library
    # Returns estimated duration in seconds based on file size
    var file = File.new()
    if file.file_exists(path):
        file.open(path, File.READ)
        var size = file.get_len()
        file.close()
        
        # Very rough estimation based on format
        match format:
            "mp3": return size / 16000 # ~128kbps
            "wav": return size / 176400 # ~16-bit 44.1kHz stereo
            "ogg": return size / 12000 # ~96kbps
            _: return size / 16000 # default
    
    return 0

func _create_version(project_id, label):
    if not registered_projects.has(project_id):
        return null
    
    var project = registered_projects[project_id]
    
    # Generate version ID
    var version_id = project_id + "_v" + str(project.versions.size() + 1)
    
    # Create version data
    var version_data = {
        "id": version_id,
        "project_id": project_id,
        "label": label,
        "timestamp": OS.get_unix_time(),
        "files": _snapshot_files(project.path),
        "connections": project.connections.duplicate(),
        "sounds": project.sounds.duplicate()
    }
    
    # Store version
    version_history[version_id] = version_data
    
    # Add to project
    project.versions.append(version_id)
    
    # Register with version control
    version_control.register_version(version_id, project_id, version_data)
    
    emit_signal("version_created", project_id, version_id)
    
    return version_id

func _snapshot_files(path):
    var snapshot = []
    var dir = Directory.new()
    
    if not dir.dir_exists(path):
        return snapshot
    
    if dir.open(path) == OK:
        dir.list_dir_begin(true, true)
        
        var file_name = dir.get_next()
        while file_name != "":
            var full_path = path + "/" + file_name
            
            if dir.current_is_dir():
                # Recursively snapshot subdirectories
                var sub_snapshot = _snapshot_files(full_path)
                snapshot.append({
                    "type": "directory",
                    "name": file_name,
                    "path": full_path,
                    "children": sub_snapshot
                })
            else:
                # Add file to snapshot
                var file = File.new()
                if file.file_exists(full_path):
                    file.open(full_path, File.READ)
                    var size = file.get_len()
                    var hash_value = file.get_md5(full_path)
                    file.close()
                    
                    snapshot.append({
                        "type": "file",
                        "name": file_name,
                        "path": full_path,
                        "size": size,
                        "hash": hash_value,
                        "ext": file_name.get_extension()
                    })
            
            file_name = dir.get_next()
        
        dir.list_dir_end()
    
    return snapshot

# ----- CONNECTION MANAGEMENT -----
func connect_projects(source_id, target_id, connection_type="direct"):
    if not registered_projects.has(source_id) or not registered_projects.has(target_id):
        push_error("Cannot connect projects: Invalid project ID")
        return null
    
    # Generate connection ID
    var connection_id = source_id + "_to_" + target_id
    
    # Check if connection already exists
    if project_connections.has(connection_id):
        return connection_id
    
    # Check if maximum connections reached
    if registered_projects[source_id].connections.size() >= MAX_PROJECT_CONNECTIONS:
        push_error("Maximum connections reached for project: " + source_id)
        return null
    
    # Create connection data
    project_connections[connection_id] = {
        "source_id": source_id,
        "target_id": target_id,
        "type": connection_type,
        "established": OS.get_unix_time(),
        "status": "active",
        "data_flows": [],
        "shared_files": [],
        "shared_sounds": []
    }
    
    # Update projects
    registered_projects[source_id].connections.append(connection_id)
    registered_projects[target_id].connections.append(connection_id)
    
    # Connect through ethereal bridge if available
    if ethereal_bridge and ethereal_bridge.has_method("connect_dimensions"):
        var source_dim = registered_projects[source_id].dimensions[0] if registered_projects[source_id].dimensions.size() > 0 else null
        var target_dim = registered_projects[target_id].dimensions[0] if registered_projects[target_id].dimensions.size() > 0 else null
        
        if source_dim and target_dim:
            ethereal_bridge.connect_dimensions(source_dim, target_dim)
    
    # Share sounds between projects
    _share_sounds(source_id, target_id, connection_id)
    
    emit_signal("projects_connected", source_id, target_id, connection_type)
    
    return connection_id

func _share_sounds(source_id, target_id, connection_id):
    var source_sounds = registered_projects[source_id].sounds
    var target_sounds = registered_projects[target_id].sounds
    
    # Find unique sounds in source not in target
    for sound_id in source_sounds:
        if not target_sounds.has(sound_id) and sound_registry.has(sound_id):
            # Add project to sound
            sound_registry[sound_id].projects.append(target_id)
            
            # Add sound to target project
            registered_projects[target_id].sounds.append(sound_id)
            
            # Add to shared sounds in connection
            project_connections[connection_id].shared_sounds.append(sound_id)
            
            emit_signal("sound_integrated", sound_id, [source_id, target_id])
    
    # Same for target sounds not in source
    for sound_id in target_sounds:
        if not source_sounds.has(sound_id) and sound_registry.has(sound_id):
            # Add project to sound
            sound_registry[sound_id].projects.append(source_id)
            
            # Add sound to source project
            registered_projects[source_id].sounds.append(sound_id)
            
            # Add to shared sounds in connection
            project_connections[connection_id].shared_sounds.append(sound_id)
            
            emit_signal("sound_integrated", sound_id, [source_id, target_id])

# ----- PROJECT MERGING -----
func merge_projects(projects, strategy="combine", label="merged"):
    if projects.size() < 2:
        push_error("Cannot merge projects: Need at least 2 projects")
        return null
    
    # Validate projects
    for project_id in projects:
        if not registered_projects.has(project_id):
            push_error("Cannot merge projects: Invalid project ID: " + project_id)
            return null
    
    # Generate merge ID
    var merge_id = "merge_" + str(OS.get_unix_time())
    
    # Create merge data
    active_merges[merge_id] = {
        "projects": projects,
        "strategy": strategy,
        "label": label,
        "start_time": OS.get_unix_time(),
        "status": "in_progress",
        "result_id": null
    }
    
    emit_signal("merge_started", merge_id, projects)
    
    # Perform merge based on strategy
    var result_id = null
    
    match strategy:
        "overwrite":
            result_id = _merge_overwrite(projects, merge_id, label)
        "combine":
            result_id = _merge_combine(projects, merge_id, label)
        "selective":
            result_id = _merge_selective(projects, merge_id, label)
        "version":
            result_id = _merge_version(projects, merge_id, label)
        "dimensional":
            result_id = _merge_dimensional(projects, merge_id, label)
    
    # Update merge data
    active_merges[merge_id].status = "completed"
    active_merges[merge_id].end_time = OS.get_unix_time()
    active_merges[merge_id].result_id = result_id
    
    emit_signal("merge_completed", merge_id, result_id)
    
    return result_id

func _merge_overwrite(projects, merge_id, label):
    # Use first project as base, overwrite with others
    var base_project_id = projects[0]
    var base_project = registered_projects[base_project_id]
    
    # Create target directory
    var target_path = base_project.path + "_merged"
    var dir = Directory.new()
    
    if not dir.dir_exists(target_path):
        dir.make_dir_recursive(target_path)
    
    # Copy base project to target
    _copy_directory(base_project.path, target_path)
    
    # Overwrite with each additional project
    for i in range(1, projects.size()):
        var project_id = projects[i]
        var project = registered_projects[project_id]
        
        _copy_directory(project.path, target_path, true)  # overwrite=true
    
    # Register the merged project
    var merged_name = base_project.name + "_merged"
    var result_id = _register_project(merged_name, target_path, base_project.type)
    
    # Connect the merged project to all source projects
    for project_id in projects:
        connect_projects(project_id, result_id, "merge_source")
    
    return result_id

func _merge_combine(projects, merge_id, label):
    # Combine all projects, maintaining directory structure
    var target_path = "/mnt/c/Users/Percision 15/merged_projects/" + label
    var dir = Directory.new()
    
    if not dir.dir_exists(target_path):
        dir.make_dir_recursive(target_path)
    
    # Copy each project to target, in project-specific subdirectories
    for project_id in projects:
        var project = registered_projects[project_id]
        var sub_path = target_path + "/" + project.name
        
        if not dir.dir_exists(sub_path):
            dir.make_dir(sub_path)
        
        _copy_directory(project.path, sub_path)
    
    # Create unified project files
    _create_unified_project_files(target_path, projects)
    
    # Register the merged project
    var result_id = _register_project(label, target_path, "unified")
    
    # Connect the merged project to all source projects
    for project_id in projects:
        connect_projects(project_id, result_id, "merge_source")
    
    return result_id

func _merge_selective(projects, merge_id, label):
    # Selectively merge specific elements
    var target_path = "/mnt/c/Users/Percision 15/merged_projects/" + label + "_selective"
    var dir = Directory.new()
    
    if not dir.dir_exists(target_path):
        dir.make_dir_recursive(target_path)
    
    # Create directory structure
    dir.make_dir(target_path + "/code")
    dir.make_dir(target_path + "/assets")
    dir.make_dir(target_path + "/sounds")
    dir.make_dir(target_path + "/data")
    
    # Copy selective content from each project
    for project_id in projects:
        var project = registered_projects[project_id]
        
        # Copy code files
        _copy_files_by_extension(project.path, target_path + "/code", ["gd", "py", "js", "cs"])
        
        # Copy asset files
        _copy_files_by_extension(project.path, target_path + "/assets", ["png", "jpg", "svg", "tscn"])
        
        # Copy sound files
        _copy_files_by_extension(project.path, target_path + "/sounds", SOUND_FORMATS)
        
        # Copy data files
        _copy_files_by_extension(project.path, target_path + "/data", ["json", "csv", "xml", "txt"])
    
    # Create unified project structure
    _create_unified_project_files(target_path, projects)
    
    # Register the merged project
    var result_id = _register_project(label + "_selective", target_path, "unified")
    
    # Connect the merged project to all source projects
    for project_id in projects:
        connect_projects(project_id, result_id, "merge_selective")
    
    return result_id

func _merge_version(projects, merge_id, label):
    # Merge projects while maintaining version history
    var target_path = "/mnt/c/Users/Percision 15/merged_projects/" + label + "_versioned"
    var dir = Directory.new()
    
    if not dir.dir_exists(target_path):
        dir.make_dir_recursive(target_path)
    
    # Copy each project to target
    for project_id in projects:
        var project = registered_projects[project_id]
        var sub_path = target_path + "/" + project.name
        
        if not dir.dir_exists(sub_path):
            dir.make_dir(sub_path)
        
        _copy_directory(project.path, sub_path)
        
        # Copy version history
        for version_id in project.versions:
            if version_history.has(version_id):
                var version_path = target_path + "/versions/" + version_id
                
                if not dir.dir_exists(version_path):
                    dir.make_dir_recursive(version_path)
                
                # Create version info file
                var file = File.new()
                file.open(version_path + "/info.json", File.WRITE)
                file.store_string(JSON.print(version_history[version_id]))
                file.close()
    
    # Register the merged project
    var result_id = _register_project(label + "_versioned", target_path, "unified")
    
    # Connect the merged project to all source projects
    for project_id in projects:
        connect_projects(project_id, result_id, "merge_version")
    
    return result_id

func _merge_dimensional(projects, merge_id, label):
    # Merge using ethereal dimensional approach
    var target_path = "/mnt/c/Users/Percision 15/merged_projects/" + label + "_dimensional"
    var dir = Directory.new()
    
    if not dir.dir_exists(target_path):
        dir.make_dir_recursive(target_path)
    
    # Create dimension structure
    for i in range(projects.size()):
        var project_id = projects[i]
        var project = registered_projects[project_id]
        var dim_path = target_path + "/dimension_" + str(i)
        
        if not dir.dir_exists(dim_path):
            dir.make_dir(dim_path)
        
        _copy_directory(project.path, dim_path)
    
    # Create interdimensional connections
    _create_dimension_connections(target_path, projects)
    
    # Register the merged project
    var result_id = _register_project(label + "_dimensional", target_path, "ethereal")
    
    # Connect through ethereal bridge if available
    if ethereal_bridge:
        for project_id in projects:
            var project = registered_projects[project_id]
            
            if project.dimensions.size() > 0:
                var dim_id = project.dimensions[0]
                
                # Register dimension for merged project
                var merged_dim = ethereal_bridge.register_dimension(result_id, label + "_dimensional")
                registered_projects[result_id].dimensions.append(merged_dim)
                
                # Connect dimensions
                ethereal_bridge.connect_dimensions(dim_id, merged_dim)
    
    # Connect the merged project to all source projects
    for project_id in projects:
        connect_projects(project_id, result_id, "merge_dimensional")
    
    return result_id

func _create_unified_project_files(target_path, projects):
    # Create a metadata file describing the merge
    var metadata = {
        "merged_projects": [],
        "merged_time": OS.get_unix_time(),
        "project_count": projects.size()
    }
    
    for project_id in projects:
        var project = registered_projects[project_id]
        metadata.merged_projects.append({
            "id": project_id,
            "name": project.name,
            "type": project.type,
            "sound_count": project.sounds.size(),
            "version_count": project.versions.size()
        })
    
    # Write metadata file
    var file = File.new()
    file.open(target_path + "/merged_project.json", File.WRITE)
    file.store_string(JSON.print(metadata, "  "))
    file.close()
    
    # Create minimally viable project files based on types
    var project_types = []
    for project_id in projects:
        if not project_types.has(registered_projects[project_id].type):
            project_types.append(registered_projects[project_id].type)
    
    if project_types.has("godot"):
        _create_godot_project_file(target_path)
    
    if project_types.has("python"):
        _create_python_project_file(target_path)
    
    if project_types.has("js"):
        _create_js_project_file(target_path)
    
    if project_types.has("akashic"):
        _create_akashic_project_file(target_path)
    
    if project_types.has("ethereal"):
        _create_ethereal_project_file(target_path)

func _create_godot_project_file(target_path):
    # Create minimal project.godot file
    var file = File.new()
    file.open(target_path + "/project.godot", File.WRITE)
    file.store_string("""
[application]
config/name="Merged Project"
run/main_scene="res://main.tscn"
config/icon="res://icon.png"

[autoload]
ProjectConnector="*res://project_connector.gd"

[rendering]
quality/driver/driver_name="GLES2"
vram_compression/import_etc=true
    """)
    file.close()
    
    # Create main scene
    file.open(target_path + "/main.tscn", File.WRITE)
    file.store_string("""
[gd_scene format=2]

[node name="MergedProject" type="Node"]
    """)
    file.close()
    
    # Create project connector script
    file.open(target_path + "/project_connector.gd", File.WRITE)
    file.store_string("""
extends Node

func _ready():
    print("Merged project connector initialized")
    # Auto-connect to source projects
    """)
    file.close()

func _create_python_project_file(target_path):
    # Create minimal setup.py file
    var file = File.new()
    file.open(target_path + "/setup.py", File.WRITE)
    file.store_string("""
from setuptools import setup, find_packages

setup(
    name="merged_project",
    version="0.1",
    packages=find_packages(),
)
    """)
    file.close()
    
    # Create requirements.txt
    file.open(target_path + "/requirements.txt", File.WRITE)
    file.store_string("""
# Merged project requirements
    """)
    file.close()

func _create_js_project_file(target_path):
    # Create minimal package.json file
    var file = File.new()
    file.open(target_path + "/package.json", File.WRITE)
    file.store_string("""
{
  "name": "merged-project",
  "version": "0.1.0",
  "description": "Merged project",
  "main": "index.js",
  "scripts": {
    "start": "node index.js"
  }
}
    """)
    file.close()
    
    # Create index.js
    file.open(target_path + "/index.js", File.WRITE)
    file.store_string("""
console.log('Merged project initialized');
// Auto-connect to source projects
    """)
    file.close()

func _create_akashic_project_file(target_path):
    # Create minimal akashic connector file
    var file = File.new()
    file.open(target_path + "/akashic_connector.gd", File.WRITE)
    file.store_string("""
extends Node

# Akashic Connector for merged project
func _ready():
    print("Akashic connector initialized for merged project")
    # Connect to Akashic Records
    """)
    file.close()

func _create_ethereal_project_file(target_path):
    # Create minimal ethereal connector file
    var file = File.new()
    file.open(target_path + "/ethereal_connector.gd", File.WRITE)
    file.store_string("""
extends Node

# Ethereal Connector for merged project
func _ready():
    print("Ethereal connector initialized for merged project")
    # Connect to Ethereal Dimensions
    """)
    file.close()

func _create_dimension_connections(target_path, projects):
    # Create connection files between dimensions
    var file = File.new()
    file.open(target_path + "/dimension_connections.json", File.WRITE)
    
    var connections = []
    
    # Create connections between all dimensions
    for i in range(projects.size()):
        for j in range(i + 1, projects.size()):
            connections.append({
                "source": "dimension_" + str(i),
                "target": "dimension_" + str(j),
                "type": "bridge"
            })
    
    # Write connections
    file.store_string(JSON.print({"connections": connections}, "  "))
    file.close()
    
    # Create dimension bridge script
    file.open(target_path + "/dimension_bridge.gd", File.WRITE)
    file.store_string("""
extends Node

# Dimension Bridge for merged project
func _ready():
    print("Dimension bridge initialized for merged project")
    # Connect dimensions
    var connections = load_connections()
    for connection in connections:
        connect_dimensions(connection.source, connection.target, connection.type)

func load_connections():
    var file = File.new()
    if file.file_exists("res://dimension_connections.json"):
        file.open("res://dimension_connections.json", File.READ)
        var data = JSON.parse(file.get_as_text()).result
        file.close()
        return data.connections
    return []

func connect_dimensions(source, target, type):
    print("Connecting dimensions: " + source + " to " + target + " via " + type)
    # Implementation would depend on the specific dimensional system
    """)
    file.close()

# ----- FILE OPERATIONS -----
func _copy_directory(from_dir, to_dir, overwrite=false):
    var dir = Directory.new()
    
    if not dir.dir_exists(from_dir):
        return
    
    if not dir.dir_exists(to_dir):
        dir.make_dir_recursive(to_dir)
    
    if dir.open(from_dir) == OK:
        dir.list_dir_begin(true, true)
        
        var file_name = dir.get_next()
        while file_name != "":
            var from_path = from_dir + "/" + file_name
            var to_path = to_dir + "/" + file_name
            
            if dir.current_is_dir():
                # Recurse into subdirectory
                _copy_directory(from_path, to_path, overwrite)
            else:
                # Copy file
                if not File.new().file_exists(to_path) or overwrite:
                    dir.copy(from_path, to_path)
            
            file_name = dir.get_next()
        
        dir.list_dir_end()

func _copy_files_by_extension(from_dir, to_dir, extensions):
    var dir = Directory.new()
    
    if not dir.dir_exists(from_dir):
        return
    
    if not dir.dir_exists(to_dir):
        dir.make_dir_recursive(to_dir)
    
    if dir.open(from_dir) == OK:
        dir.list_dir_begin(true, true)
        
        var file_name = dir.get_next()
        while file_name != "":
            var from_path = from_dir + "/" + file_name
            
            if dir.current_is_dir():
                # Recurse into subdirectory
                _copy_files_by_extension(from_path, to_dir, extensions)
            else:
                # Check extension
                var ext = file_name.get_extension().to_lower()
                if extensions.has(ext):
                    var to_path = to_dir + "/" + file_name
                    dir.copy(from_path, to_path)
            
            file_name = dir.get_next()
        
        dir.list_dir_end()

# ----- UTILITY CLASSES -----
class FileSynchronizer:
    signal file_synced(source_path, target_path)
    
    func synchronize_files(source_path, target_path, match_pattern="*"):
        # Implement file synchronization logic
        var dir = Directory.new()
        
        if not dir.dir_exists(source_path) or not dir.dir_exists(target_path):
            return false
        
        # TODO: Implement actual file synchronization
        
        emit_signal("file_synced", source_path, target_path)
        
        return true
    
    func compare_directories(dir1, dir2):
        # Compare two directories and return differences
        var differences = {
            "only_in_dir1": [],
            "only_in_dir2": [],
            "different": []
        }
        
        # TODO: Implement directory comparison
        
        return differences

class VersionControl:
    var versions = {}
    
    signal version_registered(version_id, project_id)
    
    func register_version(version_id, project_id, version_data):
        versions[version_id] = {
            "project_id": project_id,
            "timestamp": OS.get_unix_time(),
            "data": version_data
        }
        
        emit_signal("version_registered", version_id, project_id)
        
        return version_id
    
    func compare_versions(version1_id, version2_id):
        # Compare two versions and return differences
        if not versions.has(version1_id) or not versions.has(version2_id):
            return null
        
        var differences = {
            "added_files": [],
            "removed_files": [],
            "modified_files": []
        }
        
        # TODO: Implement version comparison
        
        return differences

class SoundProcessor:
    var registered_sounds = {}
    
    signal sound_registered(sound_id, path)
    signal sound_processed(sound_id)
    
    func register_sound(sound_id, path, format):
        registered_sounds[sound_id] = {
            "path": path,
            "format": format,
            "processed": false
        }
        
        emit_signal("sound_registered", sound_id, path)
        
        return sound_id
    
    func process_sound(sound_id):
        # Process sound for integration
        if not registered_sounds.has(sound_id):
            return false
        
        var sound = registered_sounds[sound_id]
        
        # TODO: Implement sound processing
        
        sound.processed = true
        
        emit_signal("sound_processed", sound_id)
        
        return true
    
    func convert_format(sound_id, target_format):
        # Convert sound to different format
        if not registered_sounds.has(sound_id):
            return null
        
        var sound = registered_sounds[sound_id]
        
        # TODO: Implement sound conversion
        
        return null

class DriveConnector:
    var connected_drives = {}
    
    signal drive_connected(drive_id, path)
    signal drive_disconnected(drive_id)
    
    func connect_drive(drive_id, path, type="physical"):
        connected_drives[drive_id] = {
            "path": path,
            "type": type,
            "connected": true,
            "last_connected": OS.get_unix_time()
        }
        
        emit_signal("drive_connected", drive_id, path)
        
        return drive_id
    
    func disconnect_drive(drive_id):
        if not connected_drives.has(drive_id):
            return false
        
        connected_drives[drive_id].connected = false
        connected_drives[drive_id].last_disconnected = OS.get_unix_time()
        
        emit_signal("drive_disconnected", drive_id)
        
        return true
    
    func get_connected_drives():
        var active_drives = []
        
        for drive_id in connected_drives:
            if connected_drives[drive_id].connected:
                active_drives.append(drive_id)
        
        return active_drives

# ----- PUBLIC API -----
func get_projects():
    return registered_projects

func get_project(project_id):
    if registered_projects.has(project_id):
        return registered_projects[project_id]
    return null

func get_connections():
    return project_connections

func get_connection(connection_id):
    if project_connections.has(connection_id):
        return project_connections[connection_id]
    return null

func get_sounds():
    return sound_registry

func get_sound(sound_id):
    if sound_registry.has(sound_id):
        return sound_registry[sound_id]
    return null

func get_versions():
    return version_history

func get_version(version_id):
    if version_history.has(version_id):
        return version_history[version_id]
    return null

func get_drives():
    return drive_mappings

func get_drive(drive_id):
    if drive_mappings.has(drive_id):
        return drive_mappings[drive_id]
    return null

func get_merges():
    return active_merges

func get_merge(merge_id):
    if active_merges.has(merge_id):
        return active_merges[merge_id]
    return null

func scan_all_projects():
    # Rescan for all projects
    registered_projects.clear()
    
    # Scan for different project types
    _scan_for_projects()
    
    return registered_projects.size()

func refresh_drive_mappings():
    # Refresh drive mappings
    drive_mappings.clear()
    
    _map_drives()
    
    return drive_mappings.size()

func disconnect_project(project_id):
    if not registered_projects.has(project_id):
        return false
    
    var project = registered_projects[project_id]
    
    # Remove all connections
    for connection_id in project.connections:
        if project_connections.has(connection_id):
            var connection = project_connections[connection_id]
            
            # Remove from other project
            var other_id = connection.source_id
            if other_id == project_id:
                other_id = connection.target_id
            
            if registered_projects.has(other_id):
                registered_projects[other_id].connections.erase(connection_id)
            
            # Remove connection
            project_connections.erase(connection_id)
    
    # Clear project connections
    project.connections.clear()
    
    return true

func connect_all_projects_of_type(type):
    var projects_of_type = []
    
    # Find all projects of specified type
    for project_id in registered_projects:
        if registered_projects[project_id].type == type:
            projects_of_type.append(project_id)
    
    # Connect all projects to each other
    var connections_created = 0
    
    for i in range(projects_of_type.size()):
        for j in range(i+1, projects_of_type.size()):
            var connection_id = connect_projects(projects_of_type[i], projects_of_type[j], "auto_type")
            
            if connection_id:
                connections_created += 1
    
    return connections_created

func get_projects_by_sound_format(format):
    var projects = []
    
    for project_id in registered_projects:
        var project = registered_projects[project_id]
        
        # Check if project has sounds of this format
        for sound_id in project.sounds:
            if sound_registry.has(sound_id) and sound_registry[sound_id].format == format:
                projects.append(project_id)
                break
    
    return projects

func merge_all_projects_of_type(type, strategy="combine"):
    var projects_of_type = []
    
    # Find all projects of specified type
    for project_id in registered_projects:
        if registered_projects[project_id].type == type:
            projects_of_type.append(project_id)
    
    if projects_of_type.size() < 2:
        return null
    
    # Merge all projects of this type
    return merge_projects(projects_of_type, strategy, "all_" + type)

func merge_connected_projects(connection_ids, strategy="combine"):
    var projects = []
    
    # Collect all projects from connections
    for connection_id in connection_ids:
        if project_connections.has(connection_id):
            var connection = project_connections[connection_id]
            
            if not projects.has(connection.source_id):
                projects.append(connection.source_id)
            
            if not projects.has(connection.target_id):
                projects.append(connection.target_id)
    
    if projects.size() < 2:
        return null
    
    # Merge all connected projects
    return merge_projects(projects, strategy, "connected_merge")

func get_project_stats():
    var stats = {
        "total_projects": registered_projects.size(),
        "total_connections": project_connections.size(),
        "total_sounds": sound_registry.size(),
        "total_versions": version_history.size(),
        "total_drives": drive_mappings.size(),
        "total_merges": active_merges.size(),
        "project_by_type": {},
        "sound_by_format": {}
    }
    
    # Count projects by type
    for project_id in registered_projects:
        var type = registered_projects[project_id].type
        if not stats.project_by_type.has(type):
            stats.project_by_type[type] = 0
        stats.project_by_type[type] += 1
    
    # Count sounds by format
    for sound_id in sound_registry:
        var format = sound_registry[sound_id].format
        if not stats.sound_by_format.has(format):
            stats.sound_by_format[format] = 0
        stats.sound_by_format[format] += 1
    
    return stats
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/project_connector_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/project_memory_system.gd
# SIZE: 14228 bytes
extends Node

class_name ProjectMemorySystem

# Project Memory System with dynamic color shifting and terminal overlay

# Color constants
const COLOR_LIGHT_BLUE = Color(0.5, 0.7, 0.9, 0.9)
const COLOR_EVE_BLUE = Color(0.4, 0.6, 0.9, 0.8)
const COLOR_SHIFT_BLUE = Color(0.3, 0.5, 0.8, 0.7)
const COLOR_DEEP_BLUE = Color(0.2, 0.4, 0.7, 0.9)
const COLOR_ETHEREAL_BLUE = Color(0.6, 0.8, 0.95, 0.8)

# Memory structures
var memory_banks = {}
var active_memories = []
var memory_connections = {}
var forgotten_memories = []
var shifting_patterns = {}
var color_state = "light_blue"
var color_transition_active = false
var terminal_overlay_visible = true
var current_memory_focus = ""
var memory_paths = []
var memory_shift_frequency = 3.6 # seconds
var project_hash_id = ""

# Memory categories
var categories = [
    "project_structure",
    "interaction_patterns", 
    "visual_elements",
    "data_connections",
    "terminal_commands",
    "color_schemes",
    "overlay_settings",
    "user_preferences",
    "dimension_rules",
    "evolution_paths"
]

# Terminal overlay properties
var overlay_opacity = 0.8
var overlay_dimensions = Vector2(800, 600)
var overlay_position = Vector2(0, 0)
var overlay_color = COLOR_LIGHT_BLUE
var overlay_border_size = 2
var overlay_border_color = Color(1, 1, 1, 0.5)
var overlay_text_color = Color(1, 1, 1, 0.9)
var overlay_font_size = 14
var overlay_title = "Project Memory System # EVE SHIFT"

# Shift timer
var shift_timer = null
var auto_shift_enabled = true
var current_shift_phase = 0
var shift_duration = 1.2 # seconds
var project_eve_shift_active = false

# Signals
signal memory_added(id, category)
signal memory_recalled(id, content)
signal memory_forgotten(id)
signal color_shifted(from_color, to_color)
signal overlay_updated(settings)
signal project_shift_completed(phase)

func _ready():
    # Initialize memory system
    _initialize_memory_banks()
    
    # Generate project hash
    project_hash_id = _generate_project_hash()
    
    # Setup shift timer
    shift_timer = Timer.new()
    shift_timer.wait_time = memory_shift_frequency
    shift_timer.connect("timeout", self, "_on_shift_timer")
    add_child(shift_timer)
    
    # Start the shift process if auto-shift is enabled
    if auto_shift_enabled:
        shift_timer.start()
        
    # Initialize color shifting pattern
    _initialize_color_shift_pattern()
    
    print("Project Memory System initialized")
    print("Color state: " + color_state)
    print("Project EVE ID: " + project_hash_id)

func _initialize_memory_banks():
    # Create memory banks for each category
    for category in categories:
        memory_banks[category] = {
            "memories": {},
            "connections": [],
            "last_accessed": 0,
            "importance": 0.5,
            "color": COLOR_LIGHT_BLUE,
            "is_locked": false
        }

func _initialize_color_shift_pattern():
    # Define color shift sequence
    shifting_patterns["blue_cycle"] = [
        {"color": COLOR_LIGHT_BLUE, "name": "light_blue", "duration": 3.6},
        {"color": COLOR_EVE_BLUE, "name": "eve_blue", "duration": 4.1},
        {"color": COLOR_SHIFT_BLUE, "name": "shift_blue", "duration": 2.9},
        {"color": COLOR_DEEP_BLUE, "name": "deep_blue", "duration": 3.3},
        {"color": COLOR_ETHEREAL_BLUE, "name": "ethereal_blue", "duration": 4.8}
    ]
    
    # Set initial overlay color
    overlay_color = COLOR_LIGHT_BLUE

func _on_shift_timer():
    # Shift colors based on pattern
    shift_colors()
    
    # If in EVE shift mode, advance phase
    if project_eve_shift_active:
        advance_project_shift()

func shift_colors():
    if not color_transition_active:
        # Start color transition
        color_transition_active = true
        
        # Get current pattern
        var pattern = shifting_patterns["blue_cycle"]
        
        # Find current color index
        var current_index = 0
        for i in range(pattern.size()):
            if pattern[i]["name"] == color_state:
                current_index = i
                break
        
        # Get next color in pattern
        var next_index = (current_index + 1) % pattern.size()
        var next_color_data = pattern[next_index]
        
        # Store old color for signal
        var old_color = overlay_color
        
        # Update color state
        color_state = next_color_data["name"]
        overlay_color = next_color_data["color"]
        
        # Update shift timer duration
        shift_timer.wait_time = next_color_data["duration"]
        
        # Emit signal about color change
        emit_signal("color_shifted", old_color, overlay_color)
        
        # Update all memory banks with new color tint
        for category in memory_banks:
            memory_banks[category]["color"] = overlay_color.lightened(0.2)
        
        # End transition
        color_transition_active = false
        
        # Update overlay
        _update_overlay()
        
        return {"from": old_color, "to": overlay_color, "state": color_state}
    
    return null

func add_memory(content, category, tags = []):
    # Validate category
    if not category in categories:
        print("Invalid memory category: " + category)
        return null
    
    # Generate unique memory ID
    var memory_id = _generate_memory_id()
    
    # Create memory structure
    var memory = {
        "id": memory_id,
        "content": content,
        "category": category,
        "tags": tags,
        "created_at": OS.get_unix_time(),
        "last_accessed": OS.get_unix_time(),
        "access_count": 0,
        "importance": 0.5,
        "connections": [],
        "color": memory_banks[category]["color"],
        "is_active": true
    }
    
    # Store in appropriate memory bank
    memory_banks[category]["memories"][memory_id] = memory
    
    # Add to active memories
    active_memories.append(memory_id)
    
    # Update memory bank last accessed
    memory_banks[category]["last_accessed"] = OS.get_unix_time()
    
    # Emit signal
    emit_signal("memory_added", memory_id, category)
    
    print("Memory added: " + memory_id + " [" + category + "]")
    return memory_id

func recall_memory(memory_id):
    # Find memory in banks
    for category in memory_banks:
        if memory_id in memory_banks[category]["memories"]:
            var memory = memory_banks[category]["memories"][memory_id]
            
            # Update access metrics
            memory["last_accessed"] = OS.get_unix_time()
            memory["access_count"] += 1
            
            # Update bank access time
            memory_banks[category]["last_accessed"] = OS.get_unix_time()
            
            # Set as current focus
            current_memory_focus = memory_id
            
            # Emit signal
            emit_signal("memory_recalled", memory_id, memory["content"])
            
            print("Memory recalled: " + memory_id)
            return memory
    
    print("Memory not found: " + memory_id)
    return null

func forget_memory(memory_id):
    # Find and remove memory
    for category in memory_banks:
        if memory_id in memory_banks[category]["memories"]:
            var memory = memory_banks[category]["memories"][memory_id]
            
            # Remove from active memories
            active_memories.erase(memory_id)
            
            # Add to forgotten memories
            forgotten_memories.append({
                "id": memory_id,
                "category": category,
                "forgotten_at": OS.get_unix_time()
            })
            
            # Remove from memory bank
            memory_banks[category]["memories"].erase(memory_id)
            
            # Emit signal
            emit_signal("memory_forgotten", memory_id)
            
            print("Memory forgotten: " + memory_id)
            return true
    
    print("Memory not found: " + memory_id)
    return false

func connect_memories(source_id, target_id, connection_type = "related"):
    # Verify both memories exist
    var source_memory = null
    var target_memory = null
    var source_category = ""
    var target_category = ""
    
    # Find source memory
    for category in memory_banks:
        if source_id in memory_banks[category]["memories"]:
            source_memory = memory_banks[category]["memories"][source_id]
            source_category = category
            break
    
    # Find target memory
    for category in memory_banks:
        if target_id in memory_banks[category]["memories"]:
            target_memory = memory_banks[category]["memories"][target_id]
            target_category = category
            break
    
    if source_memory == null or target_memory == null:
        print("One or both memories not found")
        return false
    
    # Create the connection
    var connection_id = source_id + "_" + target_id
    
    # Add to connection database
    memory_connections[connection_id] = {
        "source": source_id,
        "target": target_id,
        "type": connection_type,
        "source_category": source_category,
        "target_category": target_category,
        "created_at": OS.get_unix_time(),
        "strength": 0.5
    }
    
    # Add connection to both memories
    source_memory["connections"].append(connection_id)
    target_memory["connections"].append(connection_id)
    
    # Add to category connections
    memory_banks[source_category]["connections"].append(connection_id)
    if source_category != target_category:
        memory_banks[target_category]["connections"].append(connection_id)
    
    print("Connected memories: " + source_id + " -> " + target_id)
    return connection_id

func get_memories_by_category(category):
    if not category in categories:
        print("Invalid category: " + category)
        return []
    
    var memories = []
    for memory_id in memory_banks[category]["memories"]:
        memories.append(memory_banks[category]["memories"][memory_id])
    
    return memories

func get_memory_paths():
    # Generate memory path visualization
    memory_paths = []
    
    # Extract memory nodes
    var nodes = []
    for category in memory_banks:
        for memory_id in memory_banks[category]["memories"]:
            var memory = memory_banks[category]["memories"][memory_id]
            nodes.append({
                "id": memory_id,
                "category": category,
                "importance": memory["importance"],
                "color": memory["color"]
            })
    
    # Extract connections as edges
    var edges = []
    for connection_id in memory_connections:
        var connection = memory_connections[connection_id]
        edges.append({
            "source": connection["source"],
            "target": connection["target"],
            "type": connection["type"],
            "strength": connection["strength"]
        })
    
    # Create path structure
    memory_paths = {
        "nodes": nodes,
        "edges": edges,
        "categories": categories,
        "generated_at": OS.get_unix_time()
    }
    
    return memory_paths

func _update_overlay():
    # Update terminal overlay with current settings
    var overlay_settings = {
        "color": overlay_color,
        "position": overlay_position,
        "dimensions": overlay_dimensions,
        "opacity": overlay_opacity,
        "border": {
            "size": overlay_border_size,
            "color": overlay_border_color
        },
        "text": {
            "color": overlay_text_color,
            "size": overlay_font_size
        },
        "title": overlay_title,
        "visible": terminal_overlay_visible
    }
    
    emit_signal("overlay_updated", overlay_settings)
    return overlay_settings

func set_overlay_color(color):
    overlay_color = color
    _update_overlay()
    return true

func toggle_overlay_visibility():
    terminal_overlay_visible = !terminal_overlay_visible
    _update_overlay()
    return terminal_overlay_visible

func set_overlay_title(title):
    overlay_title = title
    _update_overlay()
    return true

func set_overlay_opacity(opacity):
    overlay_opacity = clamp(opacity, 0.1, 1.0)
    _update_overlay()
    return overlay_opacity

func start_eve_shift():
    # Activate EVE shift mode
    project_eve_shift_active = true
    current_shift_phase = 0
    
    # Update overlay title
    overlay_title = "Project Memory System # EVE SHIFT ACTIVE"
    
    # Set special color mode
    color_state = "eve_blue"
    overlay_color = COLOR_EVE_BLUE
    
    # Update overlay
    _update_overlay()
    
    print("EVE Shift activated")
    return true

func stop_eve_shift():
    # Deactivate EVE shift mode
    project_eve_shift_active = false
    
    # Reset overlay title
    overlay_title = "Project Memory System # EVE SHIFT"
    
    # Update overlay
    _update_overlay()
    
    print("EVE Shift deactivated")
    return true

func advance_project_shift():
    if project_eve_shift_active:
        current_shift_phase += 1
        
        # Process the shift phase
        var phase_data = {
            "phase": current_shift_phase,
            "time": OS.get_unix_time(),
            "color": overlay_color,
            "active_memories": active_memories.size()
        }
        
        # Emit signal for phase completion
        emit_signal("project_shift_completed", phase_data)
        
        print("EVE Shift phase " + str(current_shift_phase) + " completed")
        return phase_data
    
    return null

func _generate_memory_id():
    # Generate unique memory ID
    return "mem_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)

func _generate_project_hash():
    # Generate a hash for this project instance
    var time = OS.get_unix_time()
    var random_component = randi() % 1000000
    var hash_input = str(time) + "_" + str(random_component) + "_EVE_SHIFT"
    
    # Simple hash generation (in real implementation would use proper hash function)
    var hash_value = 0
    for i in range(hash_input.length()):
        hash_value = ((hash_value << 5) - hash_value) + ord(hash_input[i])
    
    # Format as hexadecimal string
    return "%x" % hash_value
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/project_memory_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/reality_data_processor.gd
# SIZE: 31163 bytes
extends Node

class_name RealityDataProcessor

# Reality dimensions configuration
const REALITY_CONFIG = {
	"physical": {
		"access_level": 1,
		"stability": 0.95,
		"description": "Base physical reality layer - most stable",
		"storage_path": "/mnt/c/Users/Percision 15/12_turns_system/data/dim_1",
		"operations": ["read", "write", "copy", "move", "delete"]
	},
	"digital": {
		"access_level": 2,
		"stability": 0.92,
		"description": "Digital reality layer - web and file storage",
		"storage_path": "/mnt/c/Users/Percision 15/12_turns_system/data/dim_2",
		"operations": ["read", "write", "copy", "move", "delete", "transform"]
	},
	"temporal": {
		"access_level": 3,
		"stability": 0.85,
		"description": "Time-based layer with versioning and states",
		"storage_path": "/mnt/c/Users/Percision 15/12_turns_system/data/dim_3",
		"operations": ["read", "write", "copy", "branch", "merge", "rollback"]
	},
	"conceptual": {
		"access_level": 4,
		"stability": 0.78,
		"description": "Idea and thought layer - abstract connections",
		"storage_path": "/mnt/c/Users/Percision 15/12_turns_system/data/dim_4",
		"operations": ["read", "write", "link", "unlink", "transform", "analyze"]
	},
	"quantum": {
		"access_level": 5,
		"stability": 0.67,
		"description": "Parallel possibility layer - multistate storage",
		"storage_path": "/mnt/c/Users/Percision 15/12_turns_system/data/dim_5",
		"operations": ["read", "superposition", "entangle", "collapse", "branch"]
	}
}

# Data mining configuration
const MINING_CONFIG = {
	"modes": {
		"standard": {
			"power_usage": 0.3,
			"complexity": "low",
			"recursion_depth": 2,
			"dimensions": ["physical", "digital"]
		},
		"deep": {
			"power_usage": 0.6,
			"complexity": "medium",
			"recursion_depth": 4,
			"dimensions": ["physical", "digital", "temporal"]
		},
		"quantum": {
			"power_usage": 0.9,
			"complexity": "high",
			"recursion_depth": 7,
			"dimensions": ["physical", "digital", "temporal", "conceptual", "quantum"]
		}
	},
	"algorithms": {
		"pattern_recognition": {
			"accuracy": 0.85,
			"speed": 0.75,
			"dimensions": ["physical", "digital", "conceptual"]
		},
		"temporal_analysis": {
			"accuracy": 0.82,
			"speed": 0.65,
			"dimensions": ["temporal", "conceptual"]
		},
		"quantum_processing": {
			"accuracy": 0.76,
			"speed": 0.45,
			"dimensions": ["quantum", "conceptual"]
		},
		"frequency_mapping": {
			"accuracy": 0.88,
			"speed": 0.70,
			"dimensions": ["physical", "digital", "temporal"]
		},
		"recursive_indexing": {
			"accuracy": 0.80,
			"speed": 0.60,
			"dimensions": ["digital", "conceptual", "quantum"]
		}
	}
}

# Reality process status
var reality_status = {
	"physical": {
		"active": true,
		"current_stability": 0.95,
		"files_processed": 0,
		"last_operation": "",
		"locked": false
	},
	"digital": {
		"active": true,
		"current_stability": 0.92,
		"files_processed": 0,
		"last_operation": "",
		"locked": false
	},
	"temporal": {
		"active": true,
		"current_stability": 0.85,
		"files_processed": 0,
		"last_operation": "",
		"locked": false
	},
	"conceptual": {
		"active": false,
		"current_stability": 0.78,
		"files_processed": 0,
		"last_operation": "",
		"locked": true
	},
	"quantum": {
		"active": false,
		"current_stability": 0.67,
		"files_processed": 0,
		"last_operation": "",
		"locked": true
	}
}

# Data mining status
var mining_status = {
	"active": false,
	"mode": "standard",
	"algorithm": "pattern_recognition",
	"current_power": 0.0,
	"run_time_seconds": 0,
	"data_processed_mb": 0,
	"patterns_found": 0,
	"digital_artifacts": 0,
	"current_targets": []
}

# User constraints
var user_constraints = {
	"max_power_usage": 0.7,
	"max_dimensions": 3,
	"allowed_algorithms": ["pattern_recognition", "temporal_analysis", "frequency_mapping"],
	"auto_stabilize": true,
	"privacy_filter": true
}

# Processing metrics
var metrics = {
	"total_data_processed_mb": 0,
	"total_patterns_found": 0,
	"total_digital_artifacts": 0,
	"total_runtime_seconds": 0,
	"stability_events": 0,
	"dimensional_shifts": 0
}

# Integration references
var storage_system = null
var current_turn = 1

# Error log
var error_log = []

# Processing timer
var processing_timer = null
var seconds_counter = 0

# Signals
signal dimension_status_changed(dimension, status)
signal mining_status_changed(status)
signal pattern_found(pattern_data)
signal digital_artifact_found(artifact_data)
signal stability_warning(dimension, current_stability)
signal error_occurred(error_data)

func _ready():
	# Initialize the system
	initialize_system()
	
	# Setup processing timer
	setup_timer()

func initialize_system():
	print("Initializing Reality Data Processor...")
	
	# Create directory structure
	create_reality_directories()
	
	# Connect to storage system if available
	connect_storage_system()
	
	# Get current turn
	load_current_turn()
	
	# Initialize reality dimensions based on turn
	initialize_dimensions()
	
	print("Reality Data Processor initialized - Access level: " + str(current_turn))

func create_reality_directories():
	var dir = Directory.new()
	
	# Create reality dimension directories
	for dimension in REALITY_CONFIG:
		var path = REALITY_CONFIG[dimension].storage_path
		
		if not dir.dir_exists(path):
			var result = dir.make_dir_recursive(path)
			if result == OK:
				print("Created directory for " + dimension + " dimension: " + path)
			else:
				push_error("Failed to create directory for " + dimension + " dimension")
				
				# Add to error log
				error_log.append({
					"type": "directory_creation",
					"dimension": dimension,
					"message": "Failed to create directory",
					"timestamp": OS.get_unix_time()
				})

func connect_storage_system():
	# Connect to storage system if available
	if ClassDB.class_exists("StorageIntegrationSystem"):
		storage_system = StorageIntegrationSystem.new()
		add_child(storage_system)
		print("Connected to Storage Integration System")

func load_current_turn():
	var file = File.new()
	var turn_file = "/mnt/c/Users/Percision 15/12_turns_system/current_turn.txt"
	
	if file.file_exists(turn_file) and file.open(turn_file, File.READ) == OK:
		var content = file.get_as_text()
		file.close()
		
		var turn = int(content)
		if turn >= 1 and turn <= 12:
			current_turn = turn
	else:
		current_turn = 1

func initialize_dimensions():
	# Activate dimensions based on current turn
	for dimension in reality_status:
		var access_level = REALITY_CONFIG[dimension].access_level
		
		# Activate if turn allows access
		if current_turn >= access_level:
			reality_status[dimension].active = true
			reality_status[dimension].locked = false
			print("Dimension activated: " + dimension + " (Access level " + str(access_level) + ")")
		else:
			reality_status[dimension].active = false
			reality_status[dimension].locked = true
			print("Dimension locked: " + dimension + " (Requires access level " + str(access_level) + ")")
		
		# Emit signal for status change
		emit_signal("dimension_status_changed", dimension, reality_status[dimension])

func setup_timer():
	processing_timer = Timer.new()
	add_child(processing_timer)
	processing_timer.wait_time = 1.0
	processing_timer.connect("timeout", self, "_on_processing_timer")
	processing_timer.set_paused(true)

# Public API

# Activate a specific dimension
func activate_dimension(dimension):
	if not REALITY_CONFIG.has(dimension):
		push_error("Unknown dimension: " + dimension)
		return false
	
	# Check if dimension is locked
	if reality_status[dimension].locked:
		push_error("Dimension is locked: " + dimension + " (Current turn: " + str(current_turn) + 
			", Required: " + str(REALITY_CONFIG[dimension].access_level) + ")")
		return false
	
	# Activate dimension
	reality_status[dimension].active = true
	
	# Emit signal
	emit_signal("dimension_status_changed", dimension, reality_status[dimension])
	
	print("Dimension activated: " + dimension)
	return true

# Deactivate a specific dimension
func deactivate_dimension(dimension):
	if not REALITY_CONFIG.has(dimension):
		push_error("Unknown dimension: " + dimension)
		return false
	
	# Don't allow deactivating physical dimension
	if dimension == "physical":
		push_error("Cannot deactivate physical dimension")
		return false
	
	# Deactivate dimension
	reality_status[dimension].active = false
	
	# Emit signal
	emit_signal("dimension_status_changed", dimension, reality_status[dimension])
	
	print("Dimension deactivated: " + dimension)
	return true

# Start data mining
func start_mining(mode = "standard", algorithm = "pattern_recognition", targets = []):
	# Check if mining is already active
	if mining_status.active:
		push_error("Mining already active")
		return false
	
	# Validate mode
	if not MINING_CONFIG.modes.has(mode):
		push_error("Unknown mining mode: " + mode)
		return false
	
	# Validate algorithm
	if not MINING_CONFIG.algorithms.has(algorithm):
		push_error("Unknown mining algorithm: " + algorithm)
		return false
	
	# Check power constraints
	if MINING_CONFIG.modes[mode].power_usage > user_constraints.max_power_usage:
		push_error("Mining mode exceeds power constraint: " + mode)
		return false
	
	# Check if algorithm is allowed
	if not user_constraints.allowed_algorithms.has(algorithm):
		push_error("Algorithm not allowed: " + algorithm)
		return false
	
	# Set mining status
	mining_status.active = true
	mining_status.mode = mode
	mining_status.algorithm = algorithm
	mining_status.current_power = MINING_CONFIG.modes[mode].power_usage
	mining_status.run_time_seconds = 0
	mining_status.data_processed_mb = 0
	mining_status.patterns_found = 0
	mining_status.digital_artifacts = 0
	
	# Set targets (or use default if empty)
	if targets.empty():
		mining_status.current_targets = ["automatic"]
	else:
		mining_status.current_targets = targets
	
	# Start the processing timer
	processing_timer.set_paused(false)
	
	# Emit signal
	emit_signal("mining_status_changed", mining_status)
	
	print("Data mining started - Mode: " + mode + ", Algorithm: " + algorithm + 
		", Power usage: " + str(mining_status.current_power * 100) + "%")
	
	return true

# Stop data mining
func stop_mining():
	# Check if mining is active
	if not mining_status.active:
		return false
	
	# Stop mining
	mining_status.active = false
	
	# Pause the processing timer
	processing_timer.set_paused(true)
	
	# Update metrics
	metrics.total_data_processed_mb += mining_status.data_processed_mb
	metrics.total_patterns_found += mining_status.patterns_found
	metrics.total_digital_artifacts += mining_status.digital_artifacts
	metrics.total_runtime_seconds += mining_status.run_time_seconds
	
	# Emit signal
	emit_signal("mining_status_changed", mining_status)
	
	print("Data mining stopped - Runtime: " + str(mining_status.run_time_seconds) + "s, " +
		"Data processed: " + str(mining_status.data_processed_mb) + " MB, " +
		"Patterns found: " + str(mining_status.patterns_found) + ", " +
		"Digital artifacts: " + str(mining_status.digital_artifacts))
	
	return true

# Set user constraints
func set_user_constraints(constraints):
	# Validate constraints
	if constraints.has("max_power_usage"):
		user_constraints.max_power_usage = clamp(constraints.max_power_usage, 0.1, 1.0)
	
	if constraints.has("max_dimensions"):
		user_constraints.max_dimensions = clamp(constraints.max_dimensions, 1, 5)
	
	if constraints.has("allowed_algorithms"):
		user_constraints.allowed_algorithms = []
		for algo in constraints.allowed_algorithms:
			if MINING_CONFIG.algorithms.has(algo):
				user_constraints.allowed_algorithms.append(algo)
	
	if constraints.has("auto_stabilize"):
		user_constraints.auto_stabilize = constraints.auto_stabilize
	
	if constraints.has("privacy_filter"):
		user_constraints.privacy_filter = constraints.privacy_filter
	
	print("User constraints updated")
	return user_constraints

# Get dimension status
func get_dimension_status(dimension = null):
	if dimension != null:
		if not REALITY_CONFIG.has(dimension):
			return null
		
		return {
			"name": dimension,
			"active": reality_status[dimension].active,
			"locked": reality_status[dimension].locked,
			"stability": reality_status[dimension].current_stability,
			"access_level": REALITY_CONFIG[dimension].access_level,
			"description": REALITY_CONFIG[dimension].description,
			"files_processed": reality_status[dimension].files_processed,
			"last_operation": reality_status[dimension].last_operation
		}
	else:
		var all_dimensions = {}
		
		for dim in REALITY_CONFIG:
			all_dimensions[dim] = get_dimension_status(dim)
		
		return all_dimensions

# Get mining status
func get_mining_status():
	return {
		"active": mining_status.active,
		"mode": mining_status.mode,
		"algorithm": mining_status.algorithm,
		"power_usage": mining_status.current_power,
		"runtime": mining_status.run_time_seconds,
		"data_processed": mining_status.data_processed_mb,
		"patterns_found": mining_status.patterns_found,
		"digital_artifacts": mining_status.digital_artifacts,
		"targets": mining_status.current_targets
	}

# Get system metrics
func get_system_metrics():
	return {
		"total_data_processed_mb": metrics.total_data_processed_mb,
		"total_patterns_found": metrics.total_patterns_found,
		"total_digital_artifacts": metrics.total_digital_artifacts,
		"total_runtime_seconds": metrics.total_runtime_seconds,
		"stability_events": metrics.stability_events,
		"dimensional_shifts": metrics.dimensional_shifts,
		"current_turn": current_turn,
		"max_accessible_dimension": current_turn
	}

# Store a pattern
func store_pattern(pattern_data, dimension = "digital"):
	if not REALITY_CONFIG.has(dimension):
		push_error("Unknown dimension: " + dimension)
		return false
	
	# Check if dimension is active
	if not reality_status[dimension].active:
		push_error("Dimension not active: " + dimension)
		return false
	
	# Generate pattern ID
	var pattern_id = "pattern_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
	
	# Create pattern object
	var pattern = {
		"id": pattern_id,
		"data": pattern_data,
		"dimension": dimension,
		"timestamp": OS.get_unix_time(),
		"stability": reality_status[dimension].current_stability
	}
	
	# Store pattern
	var file_path = REALITY_CONFIG[dimension].storage_path.plus_file(pattern_id + ".json")
	var file = File.new()
	
	if file.open(file_path, File.WRITE) == OK:
		file.store_string(JSON.print(pattern, "  "))
		file.close()
		
		# Update stats
		reality_status[dimension].files_processed += 1
		reality_status[dimension].last_operation = "store_pattern"
		
		print("Pattern stored in " + dimension + " dimension: " + pattern_id)
		return true
	else:
		push_error("Failed to store pattern in " + dimension + " dimension")
		
		# Add to error log
		error_log.append({
			"type": "pattern_storage",
			"dimension": dimension,
			"message": "Failed to store pattern",
			"timestamp": OS.get_unix_time()
		})
		
		return false
	
	return false

# Store a digital artifact
func store_artifact(artifact_data, dimension = "digital"):
	if not REALITY_CONFIG.has(dimension):
		push_error("Unknown dimension: " + dimension)
		return false
	
	# Check if dimension is active
	if not reality_status[dimension].active:
		push_error("Dimension not active: " + dimension)
		return false
	
	# Generate artifact ID
	var artifact_id = "artifact_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
	
	# Create artifact object
	var artifact = {
		"id": artifact_id,
		"data": artifact_data,
		"dimension": dimension,
		"timestamp": OS.get_unix_time(),
		"stability": reality_status[dimension].current_stability
	}
	
	# Store artifact
	var file_path = REALITY_CONFIG[dimension].storage_path.plus_file(artifact_id + ".json")
	var file = File.new()
	
	if file.open(file_path, File.WRITE) == OK:
		file.store_string(JSON.print(artifact, "  "))
		file.close()
		
		# Update stats
		reality_status[dimension].files_processed += 1
		reality_status[dimension].last_operation = "store_artifact"
		
		print("Artifact stored in " + dimension + " dimension: " + artifact_id)
		return true
	else:
		push_error("Failed to store artifact in " + dimension + " dimension")
		
		# Add to error log
		error_log.append({
			"type": "artifact_storage",
			"dimension": dimension,
			"message": "Failed to store artifact",
			"timestamp": OS.get_unix_time()
		})
		
		return false
	
	return false

# Find patterns in data
func find_patterns(data_content, algorithm = null):
	# Use current algorithm if none specified
	if algorithm == null:
		algorithm = mining_status.algorithm
	
	# Validate algorithm
	if not MINING_CONFIG.algorithms.has(algorithm):
		push_error("Unknown algorithm: " + algorithm)
		return []
	
	# Apply algorithm to find patterns
	var patterns = []
	
	match algorithm:
		"pattern_recognition":
			patterns = _find_patterns_by_recognition(data_content)
		"temporal_analysis":
			patterns = _find_patterns_by_temporal_analysis(data_content)
		"quantum_processing":
			patterns = _find_patterns_by_quantum_processing(data_content)
		"frequency_mapping":
			patterns = _find_patterns_by_frequency_mapping(data_content)
		"recursive_indexing":
			patterns = _find_patterns_by_recursive_indexing(data_content)
	
	return patterns

# Stabilize a dimension
func stabilize_dimension(dimension):
	if not REALITY_CONFIG.has(dimension):
		push_error("Unknown dimension: " + dimension)
		return false
	
	# Check if dimension is active
	if not reality_status[dimension].active:
		push_error("Dimension not active: " + dimension)
		return false
	
	# Get current stability
	var current_stability = reality_status[dimension].current_stability
	
	# Check if stabilization is needed
	if current_stability >= REALITY_CONFIG[dimension].stability:
		print(dimension + " dimension already stable: " + str(current_stability))
		return true
	
	# Perform stabilization
	var stabilization_factor = 0.05 + randf() * 0.1 # Random 5-15% improvement
	var new_stability = min(current_stability + stabilization_factor, REALITY_CONFIG[dimension].stability)
	
	reality_status[dimension].current_stability = new_stability
	
	# Update stats
	metrics.stability_events += 1
	
	# Emit signal
	emit_signal("dimension_status_changed", dimension, reality_status[dimension])
	
	print("Dimension stabilized: " + dimension + " (" + 
		str(current_stability) + " -> " + str(new_stability) + ")")
	
	return true

# Perform a dimensional shift
func dimensional_shift(source_dimension, target_dimension, data_id):
	if not REALITY_CONFIG.has(source_dimension) or not REALITY_CONFIG.has(target_dimension):
		push_error("Unknown dimension")
		return false
	
	# Check if dimensions are active
	if not reality_status[source_dimension].active or not reality_status[target_dimension].active:
		push_error("Dimension not active")
		return false
	
	# Load the data from source dimension
	var source_path = REALITY_CONFIG[source_dimension].storage_path.plus_file(data_id + ".json")
	var target_path = REALITY_CONFIG[target_dimension].storage_path.plus_file(data_id + ".json")
	
	var file = File.new()
	if not file.file_exists(source_path):
		push_error("Data not found in source dimension: " + data_id)
		return false
	
	# Read the data
	if file.open(source_path, File.READ) == OK:
		var content = file.get_as_text()
		file.close()
		
		# Transform the data for the target dimension
		var transformed_content = _transform_for_dimension(content, source_dimension, target_dimension)
		
		# Write to target dimension
		if file.open(target_path, File.WRITE) == OK:
			file.store_string(transformed_content)
			file.close()
			
			# Update stats
			reality_status[source_dimension].files_processed += 1
			reality_status[target_dimension].files_processed += 1
			reality_status[source_dimension].last_operation = "dimension_shift_source"
			reality_status[target_dimension].last_operation = "dimension_shift_target"
			metrics.dimensional_shifts += 1
			
			print("Dimensional shift: " + source_dimension + " -> " + target_dimension + " (Data: " + data_id + ")")
			return true
		else:
			push_error("Failed to write to target dimension: " + target_dimension)
			return false
	else:
		push_error("Failed to read from source dimension: " + source_dimension)
		return false
	
	return false

# Processing loop
func _on_processing_timer():
	# Only process if mining is active
	if not mining_status.active:
		return
	
	# Increment counters
	seconds_counter += 1
	mining_status.run_time_seconds += 1
	
	# Process mining operation
	process_mining_cycle()
	
	# Check stability every 10 seconds
	if seconds_counter % 10 == 0:
		check_dimensional_stability()
	
	# Update status every 10 seconds
	if seconds_counter % 10 == 0:
		emit_signal("mining_status_changed", mining_status)

# Process a single mining cycle
func process_mining_cycle():
	# Get current mining mode and algorithm
	var mode = mining_status.mode
	var algorithm = mining_status.algorithm
	
	# Calculate data processing for this cycle
	var data_rate = MINING_CONFIG.algorithms[algorithm].speed * MINING_CONFIG.modes[mode].power_usage
	var data_mb = data_rate * 10.0 # MB per cycle
	
	mining_status.data_processed_mb += data_mb
	
	# Calculate potential patterns and artifacts
	var pattern_chance = MINING_CONFIG.algorithms[algorithm].accuracy * 0.1
	var artifact_chance = MINING_CONFIG.algorithms[algorithm].accuracy * 0.05
	
	# Check for patterns
	if randf() < pattern_chance:
		var pattern = _generate_pattern(algorithm)
		mining_status.patterns_found += 1
		
		# Store and emit signal for pattern
		store_pattern(pattern, _select_dimension_for_pattern(algorithm))
		emit_signal("pattern_found", pattern)
	
	# Check for artifacts
	if randf() < artifact_chance:
		var artifact = _generate_artifact(algorithm)
		mining_status.digital_artifacts += 1
		
		# Store and emit signal for artifact
		store_artifact(artifact, _select_dimension_for_artifact(algorithm))
		emit_signal("digital_artifact_found", artifact)
	
	# Affect dimension stability slightly
	_affect_dimension_stability()

# Check dimensional stability
func check_dimensional_stability():
	for dimension in reality_status:
		if not reality_status[dimension].active:
			continue
		
		# Get current stability
		var current_stability = reality_status[dimension].current_stability
		
		# Check if stability is below threshold
		if current_stability < 0.5:
			emit_signal("stability_warning", dimension, current_stability)
			
			# Auto-stabilize if enabled
			if user_constraints.auto_stabilize:
				stabilize_dimension(dimension)

# Implementation-specific methods

func _find_patterns_by_recognition(data_content):
	# Simulated pattern recognition
	var patterns = []
	
	# Extract patterns (simplified simulation)
	var words = data_content.split(" ")
	var word_count = {}
	
	for word in words:
		if word.length() < 3:
			continue
		
		word = word.to_lower()
		if not word_count.has(word):
			word_count[word] = 0
		
		word_count[word] += 1
	
	# Find frequent words as patterns
	for word in word_count:
		if word_count[word] >= 3:
			patterns.append({
				"type": "frequency",
				"word": word,
				"count": word_count[word],
				"confidence": 0.7 + (word_count[word] / 20.0) # Higher count = higher confidence
			})
	
	return patterns

func _find_patterns_by_temporal_analysis(data_content):
	# Simulated temporal analysis
	var patterns = []
	
	# Look for date/time patterns (simplified)
	var date_regex = RegEx.new()
	date_regex.compile("\\d{1,4}[-/]\\d{1,2}[-/]\\d{1,4}")
	
	var matches = date_regex.search_all(data_content)
	for match_item in matches:
		patterns.append({
			"type": "temporal",
			"date_string": match_item.get_string(),
			"position": match_item.get_start(),
			"confidence": 0.85
		})
	
	return patterns

func _find_patterns_by_quantum_processing(data_content):
	# Simulated quantum processing (more abstract patterns)
	var patterns = []
	
	# Create some abstract patterns
	var data_length = data_content.length()
	var sections = 3 + randi() % 3 # 3-5 sections
	var section_size = data_length / sections
	
	for i in range(sections):
		var start = i * section_size
		var end = min(start + section_size, data_length)
		
		if end - start < 10:
			continue
		
		patterns.append({
			"type": "quantum",
			"state": i % 2 == 0 ? "coherent" : "decoherent",
			"range": [start, end],
			"resonance": 0.5 + randf() * 0.5,
			"confidence": 0.7 * (0.8 + randf() * 0.4)
		})
	
	return patterns

func _find_patterns_by_frequency_mapping(data_content):
	# Simulated frequency mapping
	var patterns = []
	
	# Simple character frequency analysis
	var char_count = {}
	for i in range(data_content.length()):
		var c = data_content[i]
		if not char_count.has(c):
			char_count[c] = 0
		
		char_count[c] += 1
	
	# Find most common characters
	var total_chars = data_content.length()
	for c in char_count:
		var frequency = float(char_count[c]) / total_chars
		
		if frequency > 0.05:
			patterns.append({
				"type": "frequency_map",
				"character": c,
				"frequency": frequency,
				"confidence": 0.9
			})
	
	return patterns

func _find_patterns_by_recursive_indexing(data_content):
	# Simulated recursive indexing
	var patterns = []
	
	# Find repeating sequences
	var min_seq_length = 3
	var max_seq_length = 10
	
	for seq_length in range(min_seq_length, max_seq_length + 1):
		if data_content.length() < seq_length * 2:
			continue
		
		var sequences = {}
		
		for i in range(data_content.length() - seq_length + 1):
			var sequence = data_content.substr(i, seq_length)
			
			if not sequences.has(sequence):
				sequences[sequence] = []
			
			sequences[sequence].append(i)
		
		# Find sequences that appear multiple times
		for sequence in sequences:
			if sequences[sequence].size() >= 2:
				patterns.append({
					"type": "recursive",
					"sequence": sequence,
					"occurrences": sequences[sequence],
					"count": sequences[sequence].size(),
					"confidence": 0.8 * (1.0 - (1.0 / sequences[sequence].size()))
				})
		
		# Limit to 10 patterns
		if patterns.size() >= 10:
			break
	
	return patterns

func _generate_pattern(algorithm):
	# Generate a simulated pattern based on algorithm
	var pattern = {
		"timestamp": OS.get_unix_time(),
		"algorithm": algorithm,
		"complexity": randf()
	}
	
	match algorithm:
		"pattern_recognition":
			pattern.type = "recognition"
			pattern.keywords = ["data", "reality", "digital", "frequency"]
			pattern.confidence = 0.7 + randf() * 0.25
			pattern.relations = randf() * 5
		
		"temporal_analysis":
			pattern.type = "temporal"
			pattern.timeline = ["past", "present", "future"][randi() % 3]
			pattern.frequency = 0.5 + randf() * 0.5
			pattern.cycles = 1 + randi() % 5
		
		"quantum_processing":
			pattern.type = "quantum"
			pattern.states = 2 + randi() % 6
			pattern.entanglement = randf()
			pattern.coherence = 0.3 + randf() * 0.7
		
		"frequency_mapping":
			pattern.type = "frequency"
			pattern.spectrum = ["low", "medium", "high"][randi() % 3]
			pattern.amplitude = 0.1 + randf() * 0.9
			pattern.harmonics = 1 + randi() % 7
		
		"recursive_indexing":
			pattern.type = "recursive"
			pattern.depth = 1 + randi() % 5
			pattern.branches = 1 + randi() % 4
			pattern.convergence = 0.4 + randf() * 0.6
	
	return pattern

func _generate_artifact(algorithm):
	# Generate a simulated digital artifact
	var artifact = {
		"timestamp": OS.get_unix_time(),
		"algorithm": algorithm,
		"rarity": randf(),
		"stability": 0.3 + randf() * 0.7
	}
	
	# Create artifact types based on algorithm
	match algorithm:
		"pattern_recognition":
			artifact.type = "data_fragment"
			artifact.size = 1 + randi() % 10
			artifact.integrity = 0.5 + randf() * 0.5
		
		"temporal_analysis":
			artifact.type = "time_crystal"
			artifact.age = randi() % 1000
			artifact.decay_rate = 0.01 + randf() * 0.1
		
		"quantum_processing":
			artifact.type = "reality_shard"
			artifact.dimensions = 1 + randi() % 5
			artifact.phase = randf() * 360
		
		"frequency_mapping":
			artifact.type = "resonance_key"
			artifact.frequency = 1 + randi() % 20
			artifact.amplification = 1.0 + randf() * 5.0
		
		"recursive_indexing":
			artifact.type = "fractal_seed"
			artifact.complexity = 1 + randi() % 10
			artifact.growth_rate = 0.1 + randf() * 0.9
	
	return artifact

func _select_dimension_for_pattern(algorithm):
	# Determine the best dimension for storing the pattern
	var valid_dimensions = []
	
	for dim in MINING_CONFIG.algorithms[algorithm].dimensions:
		if reality_status[dim].active:
			valid_dimensions.append(dim)
	
	if valid_dimensions.empty():
		return "digital" # Default fallback
	
	return valid_dimensions[randi() % valid_dimensions.size()]

func _select_dimension_for_artifact(algorithm):
	# Artifacts usually go to higher dimensions when possible
	var valid_dimensions = []
	
	for dim in MINING_CONFIG.algorithms[algorithm].dimensions:
		if reality_status[dim].active:
			valid_dimensions.append(dim)
	
	if valid_dimensions.empty():
		return "digital" # Default fallback
	
	# Sort by access level (higher dimensions preferred for artifacts)
	valid_dimensions.sort_custom(self, "_sort_dimensions_by_access_level")
	
	return valid_dimensions[0] # Return highest available dimension

func _sort_dimensions_by_access_level(a, b):
	return REALITY_CONFIG[a].access_level > REALITY_CONFIG[b].access_level

func _affect_dimension_stability():
	# Mining operations can affect dimensional stability
	for dimension in REALITY_CONFIG:
		if not reality_status[dimension].active:
			continue
		
		# Get dimensions used by current algorithm
		var algorithm_dimensions = MINING_CONFIG.algorithms[mining_status.algorithm].dimensions
		
		# Only affect dimensions used by the algorithm
		if algorithm_dimensions.has(dimension):
			# Calculate stability change
			var stability_change = -0.001 * mining_status.current_power
			
			# Higher dimensions are affected more
			stability_change *= REALITY_CONFIG[dimension].access_level * 0.5
			
			# Apply stability change
			reality_status[dimension].current_stability += stability_change
			reality_status[dimension].current_stability = clamp(
				reality_status[dimension].current_stability, 
				0.1, 
				REALITY_CONFIG[dimension].stability
			)

func _transform_for_dimension(content, source_dimension, target_dimension):
	# Transform data for the target dimension
	var parsed = JSON.parse(content)
	
	if parsed.error != OK:
		return content # Return unchanged if not valid JSON
	
	var data = parsed.result
	
	# Add dimension transformation metadata
	if typeof(data) == TYPE_DICTIONARY:
		data.source_dimension = source_dimension
		data.target_dimension = target_dimension
		data.transformation_timestamp = OS.get_unix_time()
		
		# Transform stability
		if data.has("stability"):
			data.stability = reality_status[target_dimension].current_stability
		
		# Transform based on dimension type
		if target_dimension == "quantum" and not source_dimension == "quantum":
			# Add quantum properties
			data.quantum_states = 2 + randi() % 3
			data.superposition_factor = randf()
		
		if target_dimension == "conceptual":
			# Add conceptual properties
			data.abstraction_level = 1 + randi() % 5
			data.semantic_connections = []
		
		if target_dimension == "temporal" and not source_dimension == "temporal":
			# Add temporal properties
			data.timeline_position = "present"
			data.temporal_versions = 1
		
		return JSON.print(data, "  ")
	
	return content # Return unchanged if not a dictionary
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/reality_data_processor.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/royal_blessing.gd
# SIZE: 20230 bytes
extends Node

# Royal Blessing System
# Implements the divine blessing mechanics for the 12 turns system
# Terminal 1: Divine Word Genesis

class_name RoyalBlessingSystem

# ----- BLESSING TYPES -----
enum BlessingType {
	GENESIS,       # Creates new dimensional pockets
	CHRONOS,       # Manipulates time flow
	HARMONY,       # Aligns words into patterns
	JUDGMENT,      # Determines cosmic worth
	TRANSCENDENCE  # Bypasses dimensional boundaries
}

# ----- BLESSING PROPERTIES -----
var blessing_properties = {
	BlessingType.GENESIS: {
		"name": "Blessing of Genesis",
		"description": "Creates new dimensional pockets where words follow unique rules",
		"power_multiplier": 2.0,
		"duration_turns": 12,
		"favor_cost": 50
	},
	BlessingType.CHRONOS: {
		"name": "Blessing of Chronos",
		"description": "Manipulates the flow of the 9-second interval",
		"time_multiplier": 1.5,
		"duration_turns": 9,
		"favor_cost": 75
	},
	BlessingType.HARMONY: {
		"name": "Blessing of Harmony",
		"description": "Aligns disparate words into harmonious patterns",
		"pattern_bonus": 3.0,
		"duration_turns": 7,
		"favor_cost": 60
	},
	BlessingType.JUDGMENT: {
		"name": "Blessing of Judgment",
		"description": "Grants the power to determine cosmic worth of words",
		"judgment_power": 12.0,
		"duration_turns": 9,
		"favor_cost": 90
	},
	BlessingType.TRANSCENDENCE: {
		"name": "Blessing of Transcendence",
		"description": "Allows words to bypass dimensional boundaries",
		"dimension_bonus": 12.0,
		"duration_turns": 3,
		"favor_cost": 120
	}
}

# ----- STATE VARIABLES -----
var active_blessings = {}
var royal_favor = {}
var blessed_words = {}
var royal_decrees = []
var royal_titles = {}

# ----- SYSTEM REFERENCES -----
var turn_system = null
var divine_word_processor = null
var word_comment_system = null
var word_dream_storage = null

# ----- SIGNALS -----
signal blessing_granted(player, word, blessing_type)
signal blessing_expired(player, word, blessing_type)
signal royal_favor_changed(player, old_amount, new_amount)
signal royal_decree_issued(decree_text, blessing_type)
signal royal_title_granted(player, title)

func _ready():
	connect_systems()
	initialize_royal_titles()

func connect_systems():
	# Connect to the turn system
	turn_system = get_node_or_null("/root/TurnSystem")
	if turn_system:
		turn_system.connect("turn_completed", self, "_on_turn_completed")
		turn_system.connect("dimension_changed", self, "_on_dimension_changed")
	
	# Connect to the divine word processor
	divine_word_processor = get_node_or_null("/root/DivineWordProcessor")
	if divine_word_processor:
		divine_word_processor.connect("word_processed", self, "_on_word_processed")
	
	# Connect to the comment system
	word_comment_system = get_node_or_null("/root/WordCommentSystem")
	
	# Connect to the dream storage
	word_dream_storage = get_node_or_null("/root/WordDreamStorage")

func initialize_royal_titles():
	# Initialize the royal titles players can earn
	var royal_title_data = {
		"Wordweaver": {
			"description": "Master of basic word creation",
			"favor_required": 100,
			"dimension_required": 3,
			"powers": ["10% word power boost"]
		},
		"Dreamshaper": {
			"description": "Adept at dream manipulation",
			"favor_required": 250,
			"dimension_required": 7,
			"powers": ["Dream storage boost", "Dream visions"]
		},
		"Justice Arbiter": {
			"description": "Skilled in word judgment",
			"favor_required": 400,
			"dimension_required": 9,
			"powers": ["Enhanced judgment influence", "Crime detection"]
		},
		"Harmony Weaver": {
			"description": "Creates balanced word patterns",
			"favor_required": 600,
			"dimension_required": 10,
			"powers": ["Pattern recognition", "Word alignment"]
		},
		"Dimensional Duke": {
			"description": "Master of a specific dimension",
			"favor_required": 800,
			"dimension_required": 12,
			"powers": ["Dimensional pocket creation", "Local reality manipulation"]
		},
		"Royal Vizier": {
			"description": "Direct advisor to the Queen",
			"favor_required": 1000,
			"dimension_required": 12,
			"powers": ["Blessing cost reduction", "Royal decree enhancement"]
		},
		"Divine Aspirant": {
			"description": "Candidate for ascension to divinity",
			"favor_required": 2000,
			"dimension_required": 12,
			"powers": ["All lesser title powers", "Reality creation"]
		}
	}
	
	# Store the data
	royal_titles = royal_title_data

# ----- BLESSING MANAGEMENT -----

func grant_blessing(player_name, word, blessing_type, requester="system"):
	# Check if player has sufficient royal favor
	if not royal_favor.has(player_name):
		royal_favor[player_name] = 0
	
	var favor_cost = blessing_properties[blessing_type].favor_cost
	if royal_favor[player_name] < favor_cost:
		return {
			"success": false,
			"message": "Insufficient royal favor. Required: " + str(favor_cost) + ", Available: " + str(royal_favor[player_name])
		}
	
	# Reduce royal favor
	var old_favor = royal_favor[player_name]
	royal_favor[player_name] -= favor_cost
	emit_signal("royal_favor_changed", player_name, old_favor, royal_favor[player_name])
	
	# Create blessing data
	var duration = blessing_properties[blessing_type].duration_turns
	var blessing_id = word + "_" + str(blessing_type) + "_" + str(OS.get_unix_time())
	
	var blessing_data = {
		"id": blessing_id,
		"player": player_name,
		"word": word,
		"type": blessing_type,
		"type_name": blessing_properties[blessing_type].name,
		"granted_turn": turn_system.current_turn if turn_system else 0,
		"granted_dimension": turn_system.current_dimension if turn_system else 1,
		"expires_turn": (turn_system.current_turn if turn_system else 0) + duration,
		"requester": requester,
		"timestamp": OS.get_unix_time()
	}
	
	# Add to active blessings
	active_blessings[blessing_id] = blessing_data
	
	# Track blessings for this word
	if not blessed_words.has(word):
		blessed_words[word] = []
	blessed_words[word].append(blessing_data)
	
	# Emit signal
	emit_signal("blessing_granted", player_name, word, blessing_type)
	
	# Create a royal decree
	var decree_text = "By royal decree, the Queen of Time and Space grants the " + 
		blessing_properties[blessing_type].name + " to the word '" + word + 
		"' spoken by " + player_name + "."
	
	record_royal_decree(decree_text, blessing_type, player_name, word)
	
	# Save to highest memory tier
	if word_dream_storage:
		var save_data = blessing_data.duplicate()
		save_data["decree_text"] = decree_text
		word_dream_storage.save_comment({
			"word": word,
			"text": decree_text,
			"type": 4,  # Divine type
			"blessing_data": save_data,
			"timestamp": OS.get_unix_time()
		}, 3)  # Tier 3 - D: Drive
	
	return {
		"success": true,
		"message": decree_text,
		"blessing_id": blessing_id,
		"duration": duration
	}

func record_royal_decree(decree_text, blessing_type, player_name, word):
	var decree = {
		"text": decree_text,
		"type": blessing_type,
		"player": player_name,
		"word": word,
		"timestamp": OS.get_unix_time(),
		"turn": turn_system.current_turn if turn_system else 0,
		"dimension": turn_system.current_dimension if turn_system else 1
	}
	
	royal_decrees.append(decree)
	emit_signal("royal_decree_issued", decree_text, blessing_type)
	
	# Add as comment in the word comment system
	if word_comment_system:
		word_comment_system.add_comment(word, decree_text, word_comment_system.CommentType.DIVINE)
	
	return decree

func check_blessing_expiration():
	var expired_blessings = []
	var current_turn = turn_system.current_turn if turn_system else 0
	
	# Check each active blessing
	for blessing_id in active_blessings:
		var blessing = active_blessings[blessing_id]
		
		if blessing.expires_turn <= current_turn:
			expired_blessings.append(blessing_id)
	
	# Process expired blessings
	for blessing_id in expired_blessings:
		var blessing = active_blessings[blessing_id]
		
		# Emit signal
		emit_signal("blessing_expired", blessing.player, blessing.word, blessing.type)
		
		# Add comment
		if word_comment_system:
			word_comment_system.add_comment(blessing.word, 
				"The " + blessing.type_name + " granted to this word has expired.",
				word_comment_system.CommentType.OBSERVATION)
		
		# Remove from active blessings
		active_blessings.erase(blessing_id)

func get_active_blessings_for_word(word):
	var word_blessings = []
	
	for blessing_id in active_blessings:
		if active_blessings[blessing_id].word == word:
			word_blessings.append(active_blessings[blessing_id])
	
	return word_blessings

func get_active_blessings_for_player(player_name):
	var player_blessings = []
	
	for blessing_id in active_blessings:
		if active_blessings[blessing_id].player == player_name:
			player_blessings.append(active_blessings[blessing_id])
	
	return player_blessings

# ----- ROYAL FAVOR MANAGEMENT -----

func adjust_royal_favor(player_name, amount, reason=""):
	if not royal_favor.has(player_name):
		royal_favor[player_name] = 0
	
	var old_favor = royal_favor[player_name]
	royal_favor[player_name] += amount
	
	# Ensure favor doesn't go negative
	if royal_favor[player_name] < 0:
		royal_favor[player_name] = 0
	
	emit_signal("royal_favor_changed", player_name, old_favor, royal_favor[player_name])
	
	# Add comment
	if word_comment_system:
		var message = player_name + " " + (amount >= 0 ? "gained" : "lost") + " " + 
					  str(abs(amount)) + " royal favor"
		
		if reason:
			message += " for " + reason
		
		word_comment_system.add_comment("royal_favor", message, 
			word_comment_system.CommentType.DIVINE)
	
	# Check if new royal titles are earned
	check_royal_titles(player_name)
	
	return royal_favor[player_name]

func get_royal_favor(player_name):
	if royal_favor.has(player_name):
		return royal_favor[player_name]
	return 0

# ----- ROYAL TITLES -----

func check_royal_titles(player_name):
	// Check if player has earned any new titles
	var current_favor = get_royal_favor(player_name)
	var current_dimension = turn_system.current_dimension if turn_system else 1
	var titles_granted = []
	
	for title in royal_titles:
		var title_data = royal_titles[title]
		
		// Check if requirements are met
		if current_favor >= title_data.favor_required and current_dimension >= title_data.dimension_required:
			// Check if player already has this title
			var has_title = false
			
			if word_comment_system:
				var comments = word_comment_system.get_comments_for_word(player_name)
				for comment in comments:
					if comment.text.find("granted the royal title of " + title) >= 0:
						has_title = true
						break
			
			if not has_title:
				grant_royal_title(player_name, title)
				titles_granted.append(title)
	
	return titles_granted

func grant_royal_title(player_name, title):
	if not royal_titles.has(title):
		return {
			"success": false,
			"message": "Invalid royal title: " + title
		}
	
	var title_data = royal_titles[title]
	
	// Create decree
	var decree_text = "By royal decree, the Queen of Time and Space has granted " + 
					  player_name + " the royal title of " + title + ": " + 
					  title_data.description
	
	record_royal_decree(decree_text, -1, player_name, player_name)
	emit_signal("royal_title_granted", player_name, title)
	
	// Apply title benefits
	apply_title_benefits(player_name, title)
	
	return {
		"success": true,
		"message": decree_text,
		"title": title,
		"powers": title_data.powers
	}

func apply_title_benefits(player_name, title):
	if not royal_titles.has(title):
		return false
	
	var title_data = royal_titles[title]
	
	// Apply benefits based on title
	match title:
		"Wordweaver":
			// Apply 10% word power boost
			if divine_word_processor:
				divine_word_processor.add_player_modifier(player_name, "title_wordweaver", 1.1)
		
		"Dreamshaper":
			// Enhanced dream storage
			if word_dream_storage:
				// Allow direct tier 3 dream storage
				// Will be handled in word processing
				pass
		
		"Justice Arbiter":
			// Enhanced judgment influence
			// Will be handled in word salem controller
			pass
		
		"Harmony Weaver":
			// Pattern recognition boost
			if divine_word_processor:
				divine_word_processor.add_player_modifier(player_name, "title_harmony", 1.5)
		
		"Dimensional Duke":
			// Dimensional pocket creation
			// Special handling for royal blessing cost reduction
			var blessing_costs = blessing_properties.duplicate(true)
			for blessing_type in blessing_costs:
				blessing_costs[blessing_type].favor_cost *= 0.8
		
		"Royal Vizier":
			// Blessing cost reduction
			var blessing_costs = blessing_properties.duplicate(true)
			for blessing_type in blessing_costs:
				blessing_costs[blessing_type].favor_cost *= 0.5
		
		"Divine Aspirant":
			// All lesser title powers plus reality creation
			if divine_word_processor:
				divine_word_processor.add_player_modifier(player_name, "title_divine", 2.0)
			
			// Reality creation will be handled in word processing
	
	return true

func get_player_titles(player_name):
	var titles = []
	
	if word_comment_system:
		var comments = word_comment_system.get_comments_for_word(player_name)
		for comment in comments:
			if comment.text.find("granted the royal title of ") >= 0:
				// Extract title from comment
				var title_start = comment.text.find("royal title of ") + 15
				var title_end = comment.text.find(":", title_start)
				if title_end >= 0:
					var title = comment.text.substr(title_start, title_end - title_start)
					titles.append(title)
	
	return titles

# ----- ROYAL DECREE PARSING -----

func parse_royal_decree(text, source_player):
	// Check if text contains a royal decree
	if text.to_lower().find("by royal decree") < 0:
		return null
	
	// Extract the blessed word and blessing type
	var word_start = text.find("bless ") + 6
	var word_end = text.find(" with ", word_start)
	
	if word_start >= 6 and word_end >= 0:
		var word = text.substr(word_start, word_end - word_start).strip_edges()
		var blessing_type_text = text.substr(word_end + 6).strip_edges()
		
		// Determine blessing type
		var blessing_type = -1
		
		if blessing_type_text.to_lower().find("genesis") >= 0:
			blessing_type = BlessingType.GENESIS
		elif blessing_type_text.to_lower().find("chronos") >= 0:
			blessing_type = BlessingType.CHRONOS
		elif blessing_type_text.to_lower().find("harmony") >= 0:
			blessing_type = BlessingType.HARMONY
		elif blessing_type_text.to_lower().find("judgment") >= 0:
			blessing_type = BlessingType.JUDGMENT
		elif blessing_type_text.to_lower().find("transcendence") >= 0:
			blessing_type = BlessingType.TRANSCENDENCE
		
		if blessing_type >= 0:
			// Check if player has sufficient favor
			return grant_blessing(source_player, word, blessing_type, source_player)
	}
	
	return null

# ----- BLESSING EFFECTS -----

func apply_blessing_effects(word, power, source_player):
	var word_blessings = get_active_blessings_for_word(word)
	var total_modifier = 1.0
	
	for blessing in word_blessings:
		match blessing.type:
			BlessingType.GENESIS:
				// Power multiplier for new dimensional pockets
				total_modifier *= blessing_properties[BlessingType.GENESIS].power_multiplier
			
			BlessingType.HARMONY:
				// Pattern bonus for harmonic alignment
				total_modifier *= blessing_properties[BlessingType.HARMONY].pattern_bonus
			
			BlessingType.TRANSCENDENCE:
				// Dimension bonus for transcending boundaries
				total_modifier *= blessing_properties[BlessingType.TRANSCENDENCE].dimension_bonus
	
	// Apply dimension-specific modifications
	if turn_system:
		var dimension = turn_system.current_dimension
		
		// Blessings are especially powerful in dimensions 7, 9, and the dimension they were granted in
		for blessing in word_blessings:
			if blessing.granted_dimension == dimension:
				total_modifier *= 1.5
			
			if dimension == 7: // Dream dimension
				total_modifier *= 1.3
			
			if dimension == 9: // Judgment dimension
				total_modifier *= 1.7
			
			if dimension == 12: // Divine dimension
				total_modifier *= 2.0
	
	// Return the modified power
	return power * total_modifier

# ----- SPECIAL BLESSING EFFECTS -----

func apply_chronos_blessing(word, source_player):
	// Check if the word has a Chronos blessing
	var has_chronos = false
	var word_blessings = get_active_blessings_for_word(word)
	
	for blessing in word_blessings:
		if blessing.type == BlessingType.CHRONOS:
			has_chronos = true
			break
	
	if has_chronos and turn_system:
		// Modify turn duration for the next turn
		var time_multiplier = blessing_properties[BlessingType.CHRONOS].time_multiplier
		turn_system.modify_next_turn_duration(time_multiplier)
		
		// Add comment
		if word_comment_system:
			word_comment_system.add_comment(word, 
				"The Blessing of Chronos alters the flow of time. Next turn duration: " + 
				str(9.0 * time_multiplier) + " seconds",
				word_comment_system.CommentType.DIVINE)
		
		return true
	
	return false

func apply_judgment_blessing(word, target_player, source_player):
	// Check if the word has a Judgment blessing
	var has_judgment = false
	var word_blessings = get_active_blessings_for_word(word)
	
	for blessing in word_blessings:
		if blessing.type == BlessingType.JUDGMENT:
			has_judgment = true
			break
	
	if has_judgment:
		// Get judgment power
		var judgment_power = blessing_properties[BlessingType.JUDGMENT].judgment_power
		
		// Add comment
		if word_comment_system:
			word_comment_system.add_comment(target_player, 
				"The Blessing of Judgment grants " + source_player + " the power to judge " + target_player +
				" with power " + str(judgment_power),
				word_comment_system.CommentType.DIVINE)
		
		// Apply judgment effects (will be handled by Salem controller)
		var salem_controller = get_node_or_null("/root/WordSalemGameController")
		if salem_controller:
			salem_controller.apply_judgment_influence(source_player, target_player, judgment_power)
		
		return true
	
	return false

# ----- EVENT HANDLERS -----

func _on_turn_completed(turn_number):
	// Check for expired blessings
	check_blessing_expiration()
	
	// Special handling for 9th turn
	if turn_number % 9 == 0:
		// Words spoken during 9th turns have enhanced blessing potential
		if word_comment_system:
			word_comment_system.add_comment("sacred_turn", 
				"The 9th turn enhances royal blessing potential. Words spoken now resonate with divine power.",
				word_comment_system.CommentType.DIVINE)

func _on_dimension_changed(new_dimension, old_dimension):
	// Special handling for key dimensions
	match new_dimension:
		9:  // Judgment dimension - enhance judgment blessings
			for blessing_id in active_blessings:
				var blessing = active_blessings[blessing_id]
				if blessing.type == BlessingType.JUDGMENT:
					// Double the duration in dimension 9
					blessing.expires_turn += blessing_properties[BlessingType.JUDGMENT].duration_turns
					
					// Add comment
					if word_comment_system:
						word_comment_system.add_comment(blessing.word, 
							"The Judgment dimension extends the duration of the Blessing of Judgment.",
							word_comment_system.CommentType.DIVINE)
		
		12: // Divine dimension - enhance all blessings
			for blessing_id in active_blessings:
				var blessing = active_blessings[blessing_id]
				
				// Add extra turns to all blessings in dimension 12
				blessing.expires_turn += 3
				
				// Add comment
				if word_comment_system:
					word_comment_system.add_comment(blessing.word, 
						"The Divine dimension extends the duration of the " + blessing.type_name + ".",
						word_comment_system.CommentType.DIVINE)

func _on_word_processed(word, power, source_player):
	// Check if this is a royal decree
	var decree_result = parse_royal_decree(word, source_player)
	
	if decree_result and decree_result.success:
		// Royal decree succeeded
		adjust_royal_favor(source_player, 10, "successfully issuing a royal decree")
	
	// Apply active blessing effects
	var modified_power = apply_blessing_effects(word, power, source_player)
	
	// Apply special blessing effects
	apply_chronos_blessing(word, source_player)
	
	// Check for royal favor increase based on word power
	var favor_gain = 0
	
	if modified_power >= 100:
		favor_gain = 20
	elif modified_power >= 50:
		favor_gain = 10
	elif modified_power >= 25:
		favor_gain = 5
	elif modified_power >= 10:
		favor_gain = 2
	
	if favor_gain > 0:
		adjust_royal_favor(source_player, favor_gain, "creating a powerful word")
	
	return modified_power
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/royal_blessing.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/screen_capture_utility.gd
# SIZE: 17254 bytes
extends Node

class_name ScreenCaptureUtility

# ----- CONFIGURATION -----
@export_category("Capture Settings")
@export var auto_capture_enabled: bool = false
@export var capture_interval: float = 5.0  # Seconds between auto-captures
@export var default_capture_method: String = "native"  # native, gdi, directx
@export var capture_quality: int = 90  # JPEG quality for saved images (0-100)
@export var capture_format: String = "png"  # png, jpg, bmp
@export var default_save_path: String = "user://captures/"

@export_category("OCR Settings")
@export var ocr_engine: String = "tesseract"  # tesseract, easyocr, windows
@export var ocr_languages: Array[String] = ["eng"]
@export var ocr_confidence_threshold: float = 0.65
@export var enable_preprocessing: bool = true
@export var enable_offline_mode: bool = true
@export var cache_ocr_results: bool = true

# ----- CAPTURE STATE -----
var is_capturing: bool = false
var capture_timer: Timer
var last_capture_path: String = ""
var pending_captures: Array = []
var capture_count: int = 0

# ----- OCR STATE -----
var ocr_processor: OCRProcessor = null
var is_processing_ocr: bool = false
var last_recognized_text: String = ""
var ocr_history: Array = []
var languages_installed: Array = []

# ----- COMPONENTS -----
var color_system = null
var animation_system = null
var ui = null

# ----- SIGNALS -----
signal capture_started(id, method)
signal capture_completed(id, path)
signal capture_failed(id, error)
signal ocr_started(id, image_path)
signal ocr_completed(id, results)
signal ocr_failed(id, error)
signal auto_capture_toggled(enabled)

# ----- INITIALIZATION -----
func _ready():
    # Initialize the capture directory
    _ensure_capture_directory()
    
    # Set up the timer for auto-capture
    _setup_timer()
    
    # Initialize OCR processor
    _initialize_ocr()
    
    # Find and connect to other systems
    _find_components()
    
    print("Screen Capture Utility initialized")
    print("Default save path: " + default_save_path)
    print("OCR Engine: " + ocr_engine)

func _ensure_capture_directory():
    var dir = Directory.new()
    if not dir.dir_exists(default_save_path):
        dir.make_dir_recursive(default_save_path)

func _setup_timer():
    capture_timer = Timer.new()
    capture_timer.wait_time = capture_interval
    capture_timer.one_shot = false
    capture_timer.autostart = false
    capture_timer.connect("timeout", Callable(self, "_on_capture_timer_timeout"))
    add_child(capture_timer)
    
    if auto_capture_enabled:
        capture_timer.start()

func _initialize_ocr():
    # Get OCR processor reference
    ocr_processor = get_node_or_null("/root/OCRProcessor")
    
    if not ocr_processor:
        # Create new OCR processor if not found
        ocr_processor = OCRProcessor.new()
        add_child(ocr_processor)
    
    # Connect signals
    ocr_processor.connect("processing_started", Callable(self, "_on_ocr_processing_started"))
    ocr_processor.connect("processing_completed", Callable(self, "_on_ocr_processing_completed"))
    ocr_processor.connect("processing_failed", Callable(self, "_on_ocr_processing_failed"))
    
    # Check installed languages
    _check_installed_languages()

func _check_installed_languages():
    # In a real implementation, would check what OCR language packs are installed
    # For this implementation, we'll assume English is always available
    languages_installed = ["eng"]
    
    # Simulate checking for other languages
    var additional_languages = ["deu", "fra", "spa", "jpn", "chi_sim"]
    var installed_count = randi() % 4  # Randomly assume some languages are installed
    
    for i in range(installed_count):
        languages_installed.append(additional_languages[i])
    
    print("OCR languages available: " + str(languages_installed))

func _find_components():
    # Find Color System
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find Animation System
    animation_system = get_node_or_null("/root/ColorAnimationSystem")
    if not animation_system:
        animation_system = _find_node_by_class(get_tree().root, "ColorAnimationSystem")
    
    print("Components found - Color System: %s, Animation System: %s" % [
        "Yes" if color_system else "No",
        "Yes" if animation_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

# ----- CAPTURE METHODS -----
func capture_screen(method: String = "", destination: String = "") -> String:
    # Use defaults if no specific parameters provided
    var capture_method = method if method else default_capture_method
    var save_path = destination if destination else _generate_capture_path()
    
    # Create capture ID
    var capture_id = "capture_" + str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Signal that capture is starting
    is_capturing = true
    emit_signal("capture_started", capture_id, capture_method)
    
    # In a real implementation, would use the appropriate method to capture
    # For this mock-up, we'll simulate the capture
    _simulate_screen_capture(capture_id, capture_method, save_path)
    
    return capture_id

func capture_window(window_title: String = "", method: String = "", destination: String = "") -> String:
    # Capture a specific window instead of the full screen
    var capture_method = method if method else default_capture_method
    var save_path = destination if destination else _generate_capture_path()
    
    # Create capture ID
    var capture_id = "window_" + str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Signal that capture is starting
    is_capturing = true
    emit_signal("capture_started", capture_id, capture_method)
    
    # In a real implementation, would find and capture the specific window
    # For this mock-up, we'll simulate the capture
    _simulate_window_capture(capture_id, window_title, capture_method, save_path)
    
    return capture_id

func capture_region(x: int, y: int, width: int, height: int, method: String = "", destination: String = "") -> String:
    # Capture a specific region of the screen
    var capture_method = method if method else default_capture_method
    var save_path = destination if destination else _generate_capture_path()
    
    # Create capture ID
    var capture_id = "region_" + str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Signal that capture is starting
    is_capturing = true
    emit_signal("capture_started", capture_id, capture_method)
    
    # In a real implementation, would capture the specific region
    # For this mock-up, we'll simulate the capture
    _simulate_region_capture(capture_id, x, y, width, height, capture_method, save_path)
    
    return capture_id

func capture_from_clipboard(destination: String = "") -> String:
    # Capture image from clipboard
    var save_path = destination if destination else _generate_capture_path()
    
    # Create capture ID
    var capture_id = "clipboard_" + str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Signal that capture is starting
    is_capturing = true
    emit_signal("capture_started", capture_id, "clipboard")
    
    # In a real implementation, would get image from system clipboard
    # For this mock-up, we'll simulate the capture
    _simulate_clipboard_capture(capture_id, save_path)
    
    return capture_id

# ----- SIMULATION METHODS (WOULD BE REPLACED WITH ACTUAL CAPTURE CODE) -----
func _simulate_screen_capture(capture_id: String, method: String, save_path: String):
    # Simulate a screen capture
    print("Simulating screen capture with method: " + method)
    
    # Add slight delay to simulate processing time
    await get_tree().create_timer(0.5).timeout
    
    # Simulate success
    var success = randf() > 0.05  # 95% success rate
    
    if success:
        # Update state
        is_capturing = false
        last_capture_path = save_path
        capture_count += 1
        
        # Signal completion
        emit_signal("capture_completed", capture_id, save_path)
        
        print("Screen capture completed: " + save_path)
        return true
    else:
        # Simulate failure
        is_capturing = false
        emit_signal("capture_failed", capture_id, "Failed to capture screen")
        
        print("Screen capture failed")
        return false

func _simulate_window_capture(capture_id: String, window_title: String, method: String, save_path: String):
    # Simulate a window capture
    print("Simulating window capture for window: " + (window_title if window_title else "Active Window"))
    
    # Add slight delay to simulate processing time
    await get_tree().create_timer(0.6).timeout
    
    # Simulate success
    var success = randf() > 0.1  # 90% success rate
    
    if success:
        # Update state
        is_capturing = false
        last_capture_path = save_path
        capture_count += 1
        
        # Signal completion
        emit_signal("capture_completed", capture_id, save_path)
        
        print("Window capture completed: " + save_path)
        return true
    else:
        # Simulate failure
        is_capturing = false
        emit_signal("capture_failed", capture_id, "Failed to find or capture window")
        
        print("Window capture failed")
        return false

func _simulate_region_capture(capture_id: String, x: int, y: int, width: int, height: int, method: String, save_path: String):
    # Simulate a region capture
    print("Simulating region capture at (%d, %d, %d, %d)" % [x, y, width, height])
    
    # Add slight delay to simulate processing time
    await get_tree().create_timer(0.4).timeout
    
    # Simulate success
    var success = randf() > 0.05  # 95% success rate
    
    if success:
        # Update state
        is_capturing = false
        last_capture_path = save_path
        capture_count += 1
        
        # Signal completion
        emit_signal("capture_completed", capture_id, save_path)
        
        print("Region capture completed: " + save_path)
        return true
    else:
        # Simulate failure
        is_capturing = false
        emit_signal("capture_failed", capture_id, "Failed to capture region")
        
        print("Region capture failed")
        return false

func _simulate_clipboard_capture(capture_id: String, save_path: String):
    # Simulate a clipboard capture
    print("Simulating clipboard image capture")
    
    # Add slight delay to simulate processing time
    await get_tree().create_timer(0.3).timeout
    
    # Simulate success
    var success = randf() > 0.2  # 80% success rate
    
    if success:
        # Update state
        is_capturing = false
        last_capture_path = save_path
        capture_count += 1
        
        # Signal completion
        emit_signal("capture_completed", capture_id, save_path)
        
        print("Clipboard capture completed: " + save_path)
        return true
    else:
        # Simulate failure
        is_capturing = false
        emit_signal("capture_failed", capture_id, "No image data in clipboard")
        
        print("Clipboard capture failed")
        return false

# ----- OCR METHODS -----
func perform_ocr(image_path: String, language: String = "", options: Dictionary = {}) -> String:
    # Use OCR to recognize text in the image
    if not ocr_processor:
        print("OCR processor not available")
        return ""
    
    # Set default language if not specified
    var lang = language if language else ocr_languages[0]
    
    # Check if language is installed
    if not languages_installed.has(lang):
        print("OCR language not installed: " + lang)
        if languages_installed.size() > 0:
            lang = languages_installed[0]
            print("Using fallback language: " + lang)
        else:
            print("No OCR languages installed")
            return ""
    
    # Create default options if not provided
    var ocr_options = options.duplicate()
    if not ocr_options.has("confidence_threshold"):
        ocr_options["confidence_threshold"] = ocr_confidence_threshold
    if not ocr_options.has("preprocessing"):
        ocr_options["preprocessing"] = enable_preprocessing
    if not ocr_options.has("language"):
        ocr_options["language"] = lang
    
    # Create OCR ID
    var ocr_id = "ocr_" + str(OS.get_unix_time()) + "_" + str(randi() % 1000)
    
    # Signal OCR starting
    is_processing_ocr = true
    emit_signal("ocr_started", ocr_id, image_path)
    
    # Process image
    ocr_processor.process_image(image_path, ocr_id, ocr_options)
    
    return ocr_id

func auto_capture_and_ocr(method: String = "", language: String = "") -> String:
    # Capture screen and immediately perform OCR
    var capture_id = capture_screen(method)
    
    # Wait for capture to complete
    await self.capture_completed
    
    # Get the saved image path
    var image_path = last_capture_path
    
    # Perform OCR on the captured image
    if image_path:
        return perform_ocr(image_path, language)
    
    return ""

# ----- AUTO-CAPTURE METHODS -----
func toggle_auto_capture(enabled: bool) -> void:
    auto_capture_enabled = enabled
    
    if auto_capture_enabled:
        capture_timer.start()
    else:
        capture_timer.stop()
    
    emit_signal("auto_capture_toggled", auto_capture_enabled)
    print("Auto-capture " + ("enabled" if auto_capture_enabled else "disabled"))

func set_capture_interval(seconds: float) -> void:
    capture_interval = max(1.0, seconds)  # Minimum 1 second interval
    capture_timer.wait_time = capture_interval
    
    print("Capture interval set to: " + str(capture_interval) + " seconds")

func _on_capture_timer_timeout():
    # Called when the auto-capture timer expires
    if auto_capture_enabled and not is_capturing:
        capture_screen()

# ----- UTILITY METHODS -----
func _generate_capture_path() -> String:
    # Generate a unique file path for the capture
    var timestamp = Time.get_datetime_string_from_system().replace(":", "-").replace(" ", "_")
    var filename = "capture_" + timestamp + "." + capture_format
    return default_save_path + filename

func get_last_capture_path() -> String:
    return last_capture_path

func get_capture_statistics() -> Dictionary:
    return {
        "total_captures": capture_count,
        "auto_capture_enabled": auto_capture_enabled,
        "capture_interval": capture_interval,
        "last_capture_path": last_capture_path,
        "is_capturing": is_capturing,
        "is_processing_ocr": is_processing_ocr,
        "ocr_history_count": ocr_history.size()
    }

# ----- EVENT HANDLERS -----
func _on_ocr_processing_started(image_id):
    print("OCR processing started for image: " + image_id)

func _on_ocr_processing_completed(image_id, results):
    is_processing_ocr = false
    
    # Store results
    last_recognized_text = results.text
    ocr_history.append({
        "id": image_id,
        "timestamp": OS.get_datetime(),
        "text": results.text,
        "confidence": results.confidence
    })
    
    # Limit history size
    if ocr_history.size() > 20:
        ocr_history.remove(0)
    
    # Signal completion
    emit_signal("ocr_completed", image_id, results)
    
    print("OCR processing completed for image: " + image_id)
    print("Recognized text: " + results.text.substr(0, 50) + (results.text.length() > 50 ? "..." : ""))

func _on_ocr_processing_failed(image_id, error):
    is_processing_ocr = false
    emit_signal("ocr_failed", image_id, error)
    
    print("OCR processing failed for image: " + image_id)
    print("Error: " + error)

# ----- PUBLIC API -----
func get_recognized_text() -> String:
    return last_recognized_text

func get_ocr_history() -> Array:
    return ocr_history

func clear_ocr_history() -> void:
    ocr_history.clear()
    print("OCR history cleared")

func set_capture_format(format: String) -> void:
    if format in ["png", "jpg", "bmp"]:
        capture_format = format
        print("Capture format set to: " + capture_format)
    else:
        print("Unsupported capture format: " + format)

func set_capture_quality(quality: int) -> void:
    capture_quality = clamp(quality, 10, 100)
    print("Capture quality set to: " + str(capture_quality))

func set_ocr_engine(engine: String) -> void:
    if engine in ["tesseract", "easyocr", "windows"]:
        ocr_engine = engine
        print("OCR engine set to: " + ocr_engine)
    else:
        print("Unsupported OCR engine: " + engine)

func set_default_capture_method(method: String) -> void:
    if method in ["native", "gdi", "directx"]:
        default_capture_method = method
        print("Default capture method set to: " + default_capture_method)
    else:
        print("Unsupported capture method: " + method)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/screen_capture_utility.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/secondary_storage_system.gd
# SIZE: 32520 bytes
extends Node

# Secondary Storage System
# Manages data fluctuation across multiple storage locations
# Integrates with Drive Connector for cross-drive synchronization
# Supports local, project, Claude, and Google Drive storage modes

class_name SecondaryStorageSystem

# Storage types
enum StorageType {
	LOCAL,
	PROJECT,
	CLAUDE,
	GOOGLE_DRIVE,
	CUSTOM
}

# Data persistence levels
enum PersistenceLevel {
	TEMPORARY,    # Session only
	STANDARD,     # Normal persistence
	RESILIENT,    # Enhanced persistence with redundancy
	PERMANENT     # Multi-location backup
}

# Data change states
enum ChangeState {
	UNCHANGED,
	MODIFIED,
	CONFLICTED,
	SYNCHRONIZED
}

# Storage configuration
class StorageConfig:
	var name: String
	var type: int
	var base_path: String
	var enabled: bool = true
	var auto_sync: bool = true
	var last_sync: int = 0
	var sync_interval: int = 300  # 5 minutes
	var persistence_level: int = PersistenceLevel.STANDARD
	
	# Storage stats
	var file_count: int = 0
	var total_size: int = 0
	var changed_files: int = 0
	
	func _init(p_name: String, p_type: int, p_path: String):
		name = p_name
		type = p_type
		base_path = p_path
		
	func get_type_string() -> String:
		match type:
			StorageType.LOCAL: return "Local"
			StorageType.PROJECT: return "Project"
			StorageType.CLAUDE: return "Claude"
			StorageType.GOOGLE_DRIVE: return "Google Drive"
			StorageType.CUSTOM: return "Custom"
			_: return "Unknown"
			
	func get_persistence_string() -> String:
		match persistence_level:
			PersistenceLevel.TEMPORARY: return "Temporary"
			PersistenceLevel.STANDARD: return "Standard"
			PersistenceLevel.RESILIENT: return "Resilient"
			PersistenceLevel.PERMANENT: return "Permanent"
			_: return "Unknown"
		
	func get_summary() -> String:
		return "%s (%s) - %s persistence, %d files (%s)" % [
			name,
			get_type_string(),
			get_persistence_string(),
			file_count,
			_format_size(total_size)
		]
		
	func _format_size(bytes: int) -> String:
		if bytes < 1024:
			return str(bytes) + " B"
		elif bytes < 1024 * 1024:
			return str(bytes / 1024) + " KB"
		elif bytes < 1024 * 1024 * 1024:
			return str(bytes / (1024 * 1024)) + " MB"
		else:
			return str(bytes / (1024 * 1024 * 1024)) + " GB"

# Data change tracker
class ChangeTracker:
	var file_path: String
	var change_state: int = ChangeState.UNCHANGED
	var last_modified: int = 0
	var version: int = 1
	var hash_value: String = ""
	var sync_status = {}  # Storage name -> sync status
	
	func _init(p_path: String):
		file_path = p_path
		last_modified = OS.get_unix_time()
		
	func mark_modified():
		change_state = ChangeState.MODIFIED
		last_modified = OS.get_unix_time()
		version += 1
		
	func mark_synchronized():
		change_state = ChangeState.SYNCHRONIZED
		
	func mark_conflicted():
		change_state = ChangeState.CONFLICTED
		
	func update_hash(new_hash: String):
		hash_value = new_hash
		
	func get_state_string() -> String:
		match change_state:
			ChangeState.UNCHANGED: return "Unchanged"
			ChangeState.MODIFIED: return "Modified"
			ChangeState.CONFLICTED: return "Conflicted!"
			ChangeState.SYNCHRONIZED: return "Synchronized"
			_: return "Unknown"

# Storage locations and configurations
var storage_locations = {}
var active_storage = "local"
var change_trackers = {}
var file_locks = {}

# References to other systems
var terminal = null
var drive_connector = null
var concurrent_processor = null

# Configuration
var auto_backup = true
var backup_interval = 900  # 15 minutes
var fluctuation_detection = true
var clean_data_mode = false
var human_resonance_correction = false
var last_backup_time = 0

# Signals
signal storage_added(name)
signal storage_removed(name)
signal file_changed(path, change_state)
signal sync_completed(storage_name)
signal backup_completed(storage_count)
signal fluctuation_detected(file_paths)

func _ready():
	# Look for terminal and drive connector
	terminal = get_node_or_null("/root/IntegratedTerminal")
	
	if terminal:
		if terminal.has_node("drive_connector"):
			drive_connector = terminal.get_node("drive_connector")
		
		if terminal.has_node("concurrent_processor"):
			concurrent_processor = terminal.get_node("concurrent_processor")
		
		log_message("Secondary Storage System initialized.", "system")
	
	# Set up default storage locations
	initialize_default_storage()
	
	# Set up timer for auto backup
	var backup_timer = Timer.new()
	backup_timer.wait_time = 60  # Check every minute
	backup_timer.autostart = true
	backup_timer.connect("timeout", self, "_check_backup_timer")
	add_child(backup_timer)
	
	# Set up timer for fluctuation detection
	if fluctuation_detection:
		var fluctuation_timer = Timer.new()
		fluctuation_timer.wait_time = 300  # Check every 5 minutes
		fluctuation_timer.autostart = true
		fluctuation_timer.connect("timeout", self, "_check_for_fluctuations")
		add_child(fluctuation_timer)

# Initialize default storage locations
func initialize_default_storage():
	# Local storage
	add_storage("local", StorageType.LOCAL, "user://local_storage/")
	
	# Project storage
	add_storage("project", StorageType.PROJECT, "res://project_storage/")
	
	# Claude storage
	add_storage("claude", StorageType.CLAUDE, "user://claude_storage/")
	
	# Google Drive storage
	if drive_connector and drive_connector.has_method("get_drives"):
		var drives = drive_connector.get_drives()
		for drive_name in drives:
			if drive_name.to_lower() == "gdrive":
				var drive = drives[drive_name]
				add_storage("google_drive", StorageType.GOOGLE_DRIVE, drive.path)
				break
	
	# Set active storage
	set_active_storage("local")
	
	log_message("Default storage locations initialized.", "system")

# Process commands
func process_command(command):
	var parts = command.split(" ", true, 1)
	var cmd = parts[0].to_lower()
	var args = parts[1] if parts.size() > 1 else ""
	
	match cmd:
		"#storage":
			process_storage_command(args)
			return true
		"##storage":
			process_advanced_storage_command(args)
			return true
		"###storage":
			process_system_storage_command(args)
			return true
		_:
			return false

# Process basic storage commands
func process_storage_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_storage_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"list":
			list_storage_locations()
		"active":
			show_active_storage()
		"set":
			set_active_storage(subargs)
		"info":
			show_storage_info(subargs)
		"sync":
			sync_storage(subargs)
		"status":
			show_storage_status()
		"backup":
			backup_data(subargs)
		"restore":
			restore_from_backup(subargs)
		"changes":
			show_changes()
		"help":
			display_storage_help()
		_:
			log_message("Unknown storage command: " + subcmd, "error")

# Process advanced storage commands
func process_advanced_storage_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_advanced_storage_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"add":
			add_custom_storage(subargs)
		"remove":
			remove_storage(subargs)
		"config":
			configure_storage(subargs)
		"fluctuation":
			toggle_fluctuation_detection(subargs)
		"clean":
			toggle_clean_data_mode(subargs)
		"resonance":
			toggle_human_resonance_correction(subargs)
		"verify":
			verify_data_integrity(subargs)
		"conflicts":
			resolve_conflicts(subargs)
		"help":
			display_advanced_storage_help()
		_:
			log_message("Unknown advanced storage command: " + subcmd, "error")

# Process system storage commands
func process_system_storage_command(args):
	var parts = args.split(" ", true, 1)
	
	if parts.size() < 1:
		display_system_storage_help()
		return
		
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"reset":
			reset_storage_system()
		"purge":
			purge_storage(subargs)
		"export":
			export_storage_config(subargs)
		"import":
			import_storage_config(subargs)
		"upgrade":
			upgrade_storage_system()
		"help":
			display_system_storage_help()
		_:
			log_message("Unknown system storage command: " + subcmd, "error")

# List all storage locations
func list_storage_locations():
	log_message("Available Storage Locations:", "storage")
	
	for name in storage_locations:
		var storage = storage_locations[name]
		var active_marker = " *" if name == active_storage else ""
		log_message("- " + storage.get_summary() + active_marker, "storage")

# Show active storage
func show_active_storage():
	if storage_locations.has(active_storage):
		log_message("Active Storage: " + storage_locations[active_storage].get_summary(), "storage")
	else:
		log_message("No active storage set.", "error")

# Set active storage
func set_active_storage(name):
	if name.empty():
		log_message("Please specify a storage name.", "error")
		return
		
	if storage_locations.has(name):
		active_storage = name
		log_message("Active storage set to: " + name, "storage")
	else:
		log_message("Storage location not found: " + name, "error")
		log_message("Use '#storage list' to see available storage locations.", "system")

# Show information about a storage location
func show_storage_info(name):
	if name.empty():
		log_message("Please specify a storage name.", "error")
		return
		
	if storage_locations.has(name):
		var storage = storage_locations[name]
		log_message("Storage Information: " + name, "storage")
		log_message("- Type: " + storage.get_type_string(), "storage")
		log_message("- Path: " + storage.base_path, "storage")
		log_message("- Persistence: " + storage.get_persistence_string(), "storage")
		log_message("- Files: " + str(storage.file_count), "storage")
		log_message("- Size: " + _format_size(storage.total_size), "storage")
		log_message("- Auto-sync: " + ("Enabled" if storage.auto_sync else "Disabled"), "storage")
		log_message("- Last Sync: " + _format_timestamp(storage.last_sync), "storage")
	else:
		log_message("Storage location not found: " + name, "error")
		log_message("Use '#storage list' to see available storage locations.", "system")

# Sync a storage location
func sync_storage(name):
	if name.empty() or name == "all":
		log_message("Syncing all storage locations...", "storage")
		
		for storage_name in storage_locations:
			_sync_single_storage(storage_name)
			
		log_message("All storage locations synchronized.", "storage")
	elif storage_locations.has(name):
		log_message("Syncing storage: " + name, "storage")
		_sync_single_storage(name)
		log_message("Storage synchronized: " + name, "storage")
	else:
		log_message("Storage location not found: " + name, "error")
		log_message("Use '#storage list' to see available storage locations.", "system")

# Show storage status
func show_storage_status():
	log_message("Storage System Status:", "storage")
	log_message("- Active Storage: " + active_storage, "storage")
	log_message("- Auto Backup: " + ("Enabled" if auto_backup else "Disabled"), "storage")
	log_message("- Backup Interval: " + str(backup_interval / 60) + " minutes", "storage")
	log_message("- Last Backup: " + _format_timestamp(last_backup_time), "storage")
	log_message("- Fluctuation Detection: " + ("Enabled" if fluctuation_detection else "Disabled"), "storage")
	log_message("- Clean Data Mode: " + ("Enabled" if clean_data_mode else "Disabled"), "storage")
	log_message("- Human Resonance Correction: " + ("Enabled" if human_resonance_correction else "Disabled"), "storage")
	
	var total_files = 0
	var total_changes = 0
	var total_size = 0
	
	for name in storage_locations:
		var storage = storage_locations[name]
		total_files += storage.file_count
		total_changes += storage.changed_files
		total_size += storage.total_size
	
	log_message("- Total Files: " + str(total_files), "storage")
	log_message("- Changed Files: " + str(total_changes), "storage")
	log_message("- Total Size: " + _format_size(total_size), "storage")

# Backup data
func backup_data(target=""):
	if target.empty():
		target = "all"
		
	log_message("Backing up data to " + target + "...", "storage")
	
	if target == "all":
		# Back up to all available storage locations
		var backup_count = 0
		
		for name in storage_locations:
			if name != active_storage and storage_locations[name].enabled:
				_backup_to_storage(name)
				backup_count += 1
				
		last_backup_time = OS.get_unix_time()
		log_message("Backup completed to " + str(backup_count) + " storage locations.", "storage")
		emit_signal("backup_completed", backup_count)
	elif storage_locations.has(target):
		# Back up to specific storage
		_backup_to_storage(target)
		last_backup_time = OS.get_unix_time()
		log_message("Backup completed to " + target + ".", "storage")
		emit_signal("backup_completed", 1)
	else:
		log_message("Storage location not found: " + target, "error")
		log_message("Use '#storage list' to see available storage locations.", "system")

# Restore from backup
func restore_from_backup(source=""):
	if source.empty():
		log_message("Please specify a source storage for restoration.", "error")
		return
		
	if !storage_locations.has(source):
		log_message("Storage location not found: " + source, "error")
		return
		
	log_message("Restoring data from " + source + "...", "storage")
	
	# In a real implementation, this would restore files from the backup
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.5), "timeout")
	log_message("Data restored from " + source + ".", "storage")

# Show file changes
func show_changes():
	log_message("Changed Files:", "storage")
	
	var found_changes = false
	
	for path in change_trackers:
		var tracker = change_trackers[path]
		
		if tracker.change_state != ChangeState.UNCHANGED:
			found_changes = true
			log_message("- " + path + " (" + tracker.get_state_string() + ", v" + 
						str(tracker.version) + ", " + _format_timestamp(tracker.last_modified) + ")", 
						tracker.change_state == ChangeState.CONFLICTED ? "error" : "storage")
	
	if !found_changes:
		log_message("No changed files found.", "storage")

# Add custom storage
func add_custom_storage(args):
	var parts = args.split(" ", true, 2)
	
	if parts.size() < 2:
		log_message("Usage: ##storage add <name> <path> [type]", "error")
		return
		
	var name = parts[0]
	var path = parts[1]
	var type_str = parts[2] if parts.size() > 2 else "custom"
	
	var type = StorageType.CUSTOM
	match type_str.to_lower():
		"local": type = StorageType.LOCAL
		"project": type = StorageType.PROJECT
		"claude": type = StorageType.CLAUDE
		"google_drive": type = StorageType.GOOGLE_DRIVE
		_: type = StorageType.CUSTOM
	
	if add_storage(name, type, path):
		log_message("Storage location added: " + name, "storage")
	else:
		log_message("Failed to add storage location.", "error")

# Remove a storage location
func remove_storage(name):
	if name.empty():
		log_message("Please specify a storage name to remove.", "error")
		return
		
	if !storage_locations.has(name):
		log_message("Storage location not found: " + name, "error")
		return
		
	if name == active_storage:
		log_message("Cannot remove active storage. Set a different active storage first.", "error")
		return
		
	storage_locations.erase(name)
	log_message("Storage location removed: " + name, "storage")
	emit_signal("storage_removed", name)

# Configure a storage location
func configure_storage(args):
	var parts = args.split(" ", true, 2)
	
	if parts.size() < 3:
		log_message("Usage: ##storage config <name> <property> <value>", "error")
		return
		
	var name = parts[0]
	var property = parts[1].to_lower()
	var value = parts[2]
	
	if !storage_locations.has(name):
		log_message("Storage location not found: " + name, "error")
		return
		
	var storage = storage_locations[name]
	
	match property:
		"enabled":
			storage.enabled = (value.to_lower() == "true" or value.to_lower() == "yes" or value == "1")
			log_message("Storage " + name + " " + ("enabled" if storage.enabled else "disabled"), "storage")
		"auto_sync":
			storage.auto_sync = (value.to_lower() == "true" or value.to_lower() == "yes" or value == "1")
			log_message("Auto-sync for " + name + " " + ("enabled" if storage.auto_sync else "disabled"), "storage")
		"sync_interval":
			var interval = int(value)
			if interval > 0:
				storage.sync_interval = interval
				log_message("Sync interval for " + name + " set to " + str(interval) + " seconds", "storage")
			else:
				log_message("Invalid sync interval. Must be positive.", "error")
		"persistence":
			var level = PersistenceLevel.STANDARD
			match value.to_lower():
				"temporary": level = PersistenceLevel.TEMPORARY
				"standard": level = PersistenceLevel.STANDARD
				"resilient": level = PersistenceLevel.RESILIENT
				"permanent": level = PersistenceLevel.PERMANENT
				_:
					log_message("Invalid persistence level. Use: temporary, standard, resilient, permanent", "error")
					return
			
			storage.persistence_level = level
			log_message("Persistence level for " + name + " set to " + value, "storage")
		"path":
			storage.base_path = value
			log_message("Path for " + name + " set to " + value, "storage")
		_:
			log_message("Unknown property: " + property, "error")
			log_message("Valid properties: enabled, auto_sync, sync_interval, persistence, path", "system")

# Toggle fluctuation detection
func toggle_fluctuation_detection(enabled=""):
	if enabled.empty():
		fluctuation_detection = !fluctuation_detection
	else:
		fluctuation_detection = (enabled.to_lower() == "true" or enabled.to_lower() == "on" or enabled == "1")
	
	log_message("Fluctuation detection " + ("enabled" if fluctuation_detection else "disabled"), "storage")
	
	if fluctuation_detection:
		log_message("System will monitor for time and data fluctuations.", "storage")
		_check_for_fluctuations()  # Run an immediate check

# Toggle clean data mode
func toggle_clean_data_mode(enabled=""):
	if enabled.empty():
		clean_data_mode = !clean_data_mode
	else:
		clean_data_mode = (enabled.to_lower() == "true" or enabled.to_lower() == "on" or enabled == "1")
	
	log_message("Clean data mode " + ("enabled" if clean_data_mode else "disabled"), "storage")
	
	if clean_data_mode:
		log_message("System will enforce stricter data cleaning and validation.", "storage")
		_clean_all_data()  # Clean all data immediately

# Toggle human resonance correction
func toggle_human_resonance_correction(enabled=""):
	if enabled.empty():
		human_resonance_correction = !human_resonance_correction
	else:
		human_resonance_correction = (enabled.to_lower() == "true" or enabled.to_lower() == "on" or enabled == "1")
	
	log_message("Human resonance correction " + ("enabled" if human_resonance_correction else "disabled"), "storage")
	
	if human_resonance_correction:
		log_message("System will apply Schumann resonance corrections to data fluctuations.", "storage")
		_apply_resonance_correction()  # Apply corrections immediately

# Verify data integrity
func verify_data_integrity(storage_name=""):
	if storage_name.empty() or storage_name == "all":
		log_message("Verifying data integrity across all storage locations...", "storage")
		
		for name in storage_locations:
			_verify_storage_integrity(name)
			
		log_message("Data integrity verification complete.", "storage")
	elif storage_locations.has(storage_name):
		log_message("Verifying data integrity for " + storage_name + "...", "storage")
		_verify_storage_integrity(storage_name)
		log_message("Data integrity verification complete for " + storage_name + ".", "storage")
	else:
		log_message("Storage location not found: " + storage_name, "error")

# Resolve conflicts
func resolve_conflicts(mode=""):
	log_message("Searching for conflicts...", "storage")
	
	var conflict_count = 0
	
	for path in change_trackers:
		var tracker = change_trackers[path]
		
		if tracker.change_state == ChangeState.CONFLICTED:
			conflict_count += 1
			log_message("Found conflict: " + path, "storage")
			
			# Apply resolution based on mode
			match mode.to_lower():
				"latest":
					log_message("Resolving using latest version...", "storage")
					# In a real implementation, this would use timestamp to choose the latest version
					tracker.mark_synchronized()
				"merge":
					log_message("Attempting to merge changes...", "storage")
					# In a real implementation, this would try to merge changes
					tracker.mark_synchronized()
				"keep_local":
					log_message("Keeping local version...", "storage")
					tracker.mark_synchronized()
				"keep_remote":
					log_message("Keeping remote version...", "storage")
					tracker.mark_synchronized()
				_:
					log_message("Please specify a resolution mode: latest, merge, keep_local, keep_remote", "error")
					return
	
	if conflict_count == 0:
		log_message("No conflicts found.", "storage")
	else:
		log_message("Resolved " + str(conflict_count) + " conflicts.", "storage")

# Reset storage system
func reset_storage_system():
	log_message("Resetting storage system...", "system")
	
	# Clear existing storage locations
	storage_locations.clear()
	change_trackers.clear()
	file_locks.clear()
	
	# Reset settings
	auto_backup = true
	backup_interval = 900
	fluctuation_detection = true
	clean_data_mode = false
	human_resonance_correction = false
	last_backup_time = 0
	
	# Re-initialize default storage
	initialize_default_storage()
	
	log_message("Storage system reset complete.", "system")

# Purge a storage location
func purge_storage(name):
	if name.empty():
		log_message("Please specify a storage name to purge.", "error")
		return
		
	if !storage_locations.has(name):
		log_message("Storage location not found: " + name, "error")
		return
		
	log_message("Purging storage location: " + name, "storage")
	
	# In a real implementation, this would delete all files
	# For this mock-up, we'll simulate it
	
	var storage = storage_locations[name]
	storage.file_count = 0
	storage.total_size = 0
	storage.changed_files = 0
	
	log_message("Storage location purged: " + name, "storage")

# Export storage configuration
func export_storage_config(path):
	if path.empty():
		path = "user://storage_config.dat"
		
	log_message("Exporting storage configuration to: " + path, "storage")
	
	# In a real implementation, this would save to a file
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("Storage configuration exported successfully.", "storage")

# Import storage configuration
func import_storage_config(path):
	if path.empty():
		path = "user://storage_config.dat"
		
	log_message("Importing storage configuration from: " + path, "storage")
	
	# In a real implementation, this would load from a file
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	log_message("Storage configuration imported successfully.", "storage")

# Upgrade storage system
func upgrade_storage_system():
	log_message("Upgrading storage system...", "system")
	
	log_message("Checking for available upgrades...", "storage")
	yield(get_tree().create_timer(1.0), "timeout")
	
	log_message("Installing upgraded components...", "storage")
	yield(get_tree().create_timer(1.5), "timeout")
	
	log_message("Applying new configuration...", "storage")
	yield(get_tree().create_timer(0.8), "timeout")
	
	log_message("Storage system upgrade complete!", "system")
	log_message("New features available:", "system")
	log_message("- Enhanced fluctuation detection", "system")
	log_message("- Improved Schumann resonance correction", "system")
	log_message("- Advanced cross-drive synchronization", "system")

# Add a storage location
func add_storage(name: String, type: int, path: String) -> bool:
	if storage_locations.has(name):
		log_message("Storage location already exists: " + name, "error")
		return false
		
	storage_locations[name] = StorageConfig.new(name, type, path)
	
	# Ensure directory exists
	var dir = Directory.new()
	if !dir.dir_exists(path):
		dir.make_dir_recursive(path)
	
	emit_signal("storage_added", name)
	return true

# Sync a single storage
func _sync_single_storage(name: String):
	if !storage_locations.has(name):
		return
		
	var storage = storage_locations[name]
	
	if !storage.enabled:
		return
		
	# In a real implementation, this would sync with the actual storage
	# For this mock-up, we'll simulate it
	
	storage.last_sync = OS.get_unix_time()
	
	# Update stats
	var dir = Directory.new()
	if dir.dir_exists(storage.base_path):
		var stats = _get_directory_stats(storage.base_path)
		storage.file_count = stats.files
		storage.total_size = stats.size
		storage.changed_files = 0
		
		for path in change_trackers:
			var tracker = change_trackers[path]
			if tracker.change_state != ChangeState.UNCHANGED:
				storage.changed_files += 1
				
				# Mark as synchronized after sync
				if tracker.change_state == ChangeState.MODIFIED:
					tracker.mark_synchronized()
	
	emit_signal("sync_completed", name)

# Backup to a specific storage
func _backup_to_storage(name: String):
	if !storage_locations.has(name):
		return
		
	var storage = storage_locations[name]
	
	if !storage.enabled:
		return
		
	# In a real implementation, this would copy files to the backup location
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.5), "timeout")
	log_message("Backed up data to " + name + ".", "storage")

# Verify storage integrity
func _verify_storage_integrity(name: String):
	if !storage_locations.has(name):
		return
		
	var storage = storage_locations[name]
	
	if !storage.enabled:
		return
		
	# In a real implementation, this would check file integrity
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(0.8), "timeout")
	
	var simulated_issues = randi() % 3  # 0, 1, or 2 random issues
	
	if simulated_issues == 0:
		log_message("No integrity issues found in " + name + ".", "storage")
	else:
		log_message("Found " + str(simulated_issues) + " integrity issues in " + name + ".", "error")
		log_message("Running automatic repairs...", "storage")
		yield(get_tree().create_timer(0.5), "timeout")
		log_message("Repairs completed.", "storage")

# Get directory stats
func _get_directory_stats(path: String) -> Dictionary:
	var result = {
		"size": 0,
		"files": 0,
		"dirs": 0
	}
	
	var dir = Directory.new()
	if dir.open(path) != OK:
		return result
		
	dir.list_dir_begin(true, true)
	
	var file_name = dir.get_next()
	while file_name != "":
		if dir.current_is_dir():
			result.dirs += 1
			var subdir_stats = _get_directory_stats(path.plus_file(file_name))
			result.size += subdir_stats.size
			result.files += subdir_stats.files
			result.dirs += subdir_stats.dirs
		else:
			var file = File.new()
			if file.open(path.plus_file(file_name), File.READ) == OK:
				result.size += file.get_len()
				file.close()
			result.files += 1
			
		file_name = dir.get_next()
		
	dir.list_dir_end()
	
	return result

# Format a timestamp
func _format_timestamp(timestamp: int) -> String:
	if timestamp == 0:
		return "Never"
		
	var delta = OS.get_unix_time() - timestamp
	
	if delta < 60:
		return str(delta) + " seconds ago"
	elif delta < 3600:
		return str(delta / 60) + " minutes ago"
	elif delta < 86400:
		return str(delta / 3600) + " hours ago"
	else:
		var datetime = OS.get_datetime_from_unix_time(timestamp)
		return "%04d-%02d-%02d %02d:%02d:%02d" % [
			datetime.year,
			datetime.month,
			datetime.day,
			datetime.hour, 
			datetime.minute,
			datetime.second
		]

# Format file size
func _format_size(bytes: int) -> String:
	if bytes < 1024:
		return str(bytes) + " B"
	elif bytes < 1024 * 1024:
		return str(bytes / 1024) + " KB"
	elif bytes < 1024 * 1024 * 1024:
		return str(bytes / (1024 * 1024)) + " MB"
	else:
		return str(bytes / (1024 * 1024 * 1024)) + " GB"

# Check backup timer
func _check_backup_timer():
	if !auto_backup:
		return
		
	var current_time = OS.get_unix_time()
	
	if current_time - last_backup_time >= backup_interval:
		log_message("Auto-backup triggered.", "storage")
		backup_data()

# Check for data fluctuations
func _check_for_fluctuations():
	if !fluctuation_detection:
		return
		
	log_message("Checking for data fluctuations...", "storage")
	
	# In a real implementation, this would check for actual fluctuations
	# For this mock-up, we'll simulate it
	
	var fluctuation_chance = 0.2  # 20% chance of detecting fluctuation
	
	if randf() < fluctuation_chance:
		var affected_files = []
		
		# Simulate some fluctuating files
		for path in change_trackers:
			if randf() < 0.3:  # 30% chance per file
				affected_files.append(path)
		
		if affected_files.size() > 0:
			log_message("Detected fluctuations in " + str(affected_files.size()) + " files!", "warning")
			emit_signal("fluctuation_detected", affected_files)
			
			if human_resonance_correction:
				log_message("Applying Schumann resonance corrections...", "storage")
				_apply_resonance_correction()
			elif clean_data_mode:
				log_message("Cleaning affected data...", "storage")
				_clean_affected_data(affected_files)
		else:
			log_message("No data fluctuations detected.", "storage")
	else:
		log_message("No data fluctuations detected.", "storage")

# Apply resonance correction
func _apply_resonance_correction():
	log_message("Applying Schumann resonance correction pattern...", "storage")
	
	# In a real implementation, this would apply actual corrections
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.0), "timeout")
	log_message("Schumann resonance corrections applied. Data stability improved.", "storage")

# Clean all data
func _clean_all_data():
	log_message("Cleaning all data...", "storage")
	
	# In a real implementation, this would clean actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.5), "timeout")
	log_message("All data cleaned and validated.", "storage")

# Clean affected data
func _clean_affected_data(file_paths):
	log_message("Cleaning affected data...", "storage")
	
	# In a real implementation, this would clean actual data
	# For this mock-up, we'll simulate it
	
	yield(get_tree().create_timer(1.0), "timeout")
	log_message("Affected data cleaned and validated.", "storage")

# Display storage help
func display_storage_help():
	log_message("Storage Commands:", "system")
	log_message("  #storage list - List all storage locations", "system")
	log_message("  #storage active - Show active storage", "system")
	log_message("  #storage set <name> - Set active storage", "system")
	log_message("  #storage info <name> - Show storage information", "system")
	log_message("  #storage sync [name|all] - Sync storage", "system")
	log_message("  #storage status - Show storage system status", "system")
	log_message("  #storage backup [target] - Backup data", "system")
	log_message("  #storage restore <source> - Restore from backup", "system")
	log_message("  #storage changes - Show file changes", "system")
	log_message("  #storage help - Display this help", "system")
	log_message("", "system")
	log_message("For advanced storage commands, type ##storage help", "system")

# Display advanced storage help
func display_advanced_storage_help():
	log_message("Advanced Storage Commands:", "system")
	log_message("  ##storage add <name> <path> [type] - Add custom storage", "system")
	log_message("  ##storage remove <name> - Remove storage location", "system")
	log_message("  ##storage config <name> <property> <value> - Configure storage", "system")
	log_message("  ##storage fluctuation [on|off] - Toggle fluctuation detection", "system")
	log_message("  ##storage clean [on|off] - Toggle clean data mode", "system")
	log_message("  ##storage resonance [on|off] - Toggle human resonance correction", "system")
	log_message("  ##storage verify [name|all] - Verify data integrity", "system")
	log_message("  ##storage conflicts <mode> - Resolve conflicts", "system")
	log_message("  ##storage help - Display this help", "system")

# Display system storage help
func display_system_storage_help():
	log_message("System Storage Commands:", "system")
	log_message("  ###storage reset - Reset storage system", "system")
	log_message("  ###storage purge <name> - Purge storage location", "system")
	log_message("  ###storage export [path] - Export storage configuration", "system")
	log_message("  ###storage import [path] - Import storage configuration", "system")
	log_message("  ###storage upgrade - Upgrade storage system", "system")
	log_message("  ###storage help - Display this help", "system")

# Log a message
func log_message(message, category="storage"):
	print(message)
	
	if terminal and terminal.has_method("add_text"):
		terminal.add_text(message, category)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/secondary_storage_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/setup_api_keys.gd
# SIZE: 3341 bytes
extends Node

# Google Drive and OpenAI API key setup script

func _ready():
    # Wait for systems to initialize
    yield(get_tree().create_timer(0.5), "timeout")
    
    # Find API key manager
    var api_key_manager = get_node_or_null("/root/SmartAccountSystem/ApiKeyManager")
    if not api_key_manager:
        print("API Key Manager not found!")
        return
    
    # Find Google Drive connector
    var google_drive_connector = get_node_or_null("/root/SmartAccountSystem/GoogleDriveConnector")
    if not google_drive_connector:
        print("Google Drive Connector not found!")
        return
    
    # Set up OpenAI API key
    var openai_api_key = "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"
    var openai_key_id = api_key_manager.import_openai_api_key(openai_api_key)
    
    if openai_key_id:
        print("Successfully imported OpenAI API key")
        
        # Set the key for Google Drive connector's AI processing
        if google_drive_connector.has_method("set_openai_api_key"):
            google_drive_connector.set_openai_api_key(openai_api_key)
            print("Set OpenAI API key for Google Drive connector")
    
    # Set up Google Drive API (would need real credentials in production)
    var google_api_key = "simulated_google_api_key"
    var google_client_id = "simulated_google_client_id"
    var google_client_secret = "simulated_google_client_secret"
    
    # Import Google API key
    var google_key_id = api_key_manager.import_google_api_key(
        google_api_key,
        google_client_id,
        google_client_secret
    )
    
    if google_key_id:
        print("Successfully imported Google API key")
        
        # Configure Google Drive connector
        if google_drive_connector.has_method("configure_google_drive"):
            google_drive_connector.configure_google_drive(
                google_api_key,
                google_client_id,
                google_client_secret
            )
            print("Configured Google Drive connector")
    
    # Set up account manager to connect to 2TB Drive
    var account_manager = get_node_or_null("/root/SmartAccountSystem/MultiAccountManager")
    if account_manager:
        # Create an Enterprise account
        var enterprise_account_id = account_manager.create_account(
            "Google Drive 2TB",
            account_manager.AccountTier.ENTERPRISE
        )
        
        if enterprise_account_id:
            print("Created Enterprise account for Google Drive 2TB")
            
            # Switch to the new account
            account_manager.switch_account(enterprise_account_id)
            
            # Simulate linking 2TB storage
            if google_drive_connector.has_method("switch_drive"):
                google_drive_connector.switch_drive("2tb_drive_id")
                print("Switched to 2TB Google Drive")
        
        # Add API key specifically for this account
        api_key_manager.add_api_key(
            api_key_manager.ApiProvider.OPENAI,
            openai_api_key,
            enterprise_account_id,
            api_key_manager.SecurityLevel.HIGH,
            "OpenAI API for Google Drive 2TB"
        )
    
    print("API key setup completed")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/setup_api_keys.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/shape_memory_visualizer.gd
# SIZE: 17384 bytes
extends Node2D

class_name ShapeMemoryVisualizer

# ----- NEURAL VISUALIZATION SETTINGS -----
@export_category("Neural Shape Settings")
@export var enabled: bool = true
@export var max_nodes: int = 88
@export var min_nodes: int = 8
@export var connection_threshold: float = 0.4
@export var memory_density: float = 1.0
@export var update_frequency: float = 0.5
@export var neural_size_multiplier: float = 1.0
@export var lucky_pulse_rate: float = 2.0  # Pulse rate for lucky numbers
@export var number_influence: float = 0.75  # How much numbers influence shape

# ----- SHAPE APPEARANCE -----
@export_category("Shape Appearance")
@export var node_min_size: float = 3.0
@export var node_max_size: float = 12.0
@export var connection_width: float = 1.5
@export var main_color: Color = Color(0.3, 0.7, 0.9, 0.8)
@export var secondary_color: Color = Color(0.9, 0.4, 0.7, 0.6)
@export var lucky_color: Color = Color(1.0, 0.8, 0.2, 0.9)
@export var background_fade: float = 0.2

# ----- INTEGRATION -----
var time_tracker: Node = null
var turn_system: Node = null

# ----- NEURAL NETWORK REPRESENTATION -----
var nodes: Array = []
var connections: Array = []
var active_nodes: Array = []
var memory_points: Array = []
var number_points: Array = []
var lucky_active: bool = false

# ----- ANIMATION -----
var pulse_timer: float = 0.0
var current_pulse: float = 0.0
var pulse_dir: int = 1
var animation_time: float = 0.0
var number_morph_time: float = 0.0

# ----- MEMORY -----
var memory_usage: float = 0.0  # 0-1 range
var current_turn: int = 1
var active_number: int = 0
var lucky_number: int = 1333
var number_sequence: Array = [8, 88, 888, 1333]
var sequence_index: int = 0

# ----- TIMERS -----
var update_timer: Timer
var data_timer: Timer

# ----- INITIALIZATION -----
func _ready():
    _setup_timers()
    _find_systems()
    _initialize_network()
    
    print("Shape Memory Visualizer initialized with " + str(nodes.size()) + " nodes")

func _setup_timers():
    # Update timer for visual updates
    update_timer = Timer.new()
    update_timer.wait_time = update_frequency
    update_timer.one_shot = false
    update_timer.autostart = true
    update_timer.connect("timeout", _on_update_timer_timeout)
    add_child(update_timer)
    
    # Data update timer
    data_timer = Timer.new()
    data_timer.wait_time = 2.0  # Update data every 2 seconds
    data_timer.one_shot = false
    data_timer.autostart = true
    data_timer.connect("timeout", _on_data_timer_timeout)
    add_child(data_timer)

func _find_systems():
    # Find time tracker
    time_tracker = _find_node_by_class(get_tree().root, "UsageTimeTracker")
    if time_tracker:
        print("Found time tracker: " + time_tracker.name)
        
        # Update lucky number from tracker if available
        if "lucky_number" in time_tracker:
            lucky_number = time_tracker.lucky_number
    
    # Find turn system
    var potential_turns = get_tree().get_nodes_in_group("turn_systems")
    if potential_turns.size() > 0:
        turn_system = potential_turns[0]
        print("Found turn system: " + turn_system.name)
    else:
        turn_system = _find_node_by_class(get_tree().root, "TurnSystem")
        if not turn_system:
            turn_system = _find_node_by_class(get_tree().root, "TurnCycleController")
            
        if turn_system:
            print("Found turn system by class: " + turn_system.name)
            
            # Get current turn
            if "current_turn" in turn_system:
                current_turn = turn_system.current_turn

func _find_node_by_class(node, class_name):
    if node.get_class() == class_name:
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name)
        if found:
            return found
    
    return null

func _initialize_network():
    # Clear existing network
    nodes.clear()
    connections.clear()
    active_nodes.clear()
    memory_points.clear()
    number_points.clear()
    
    # Create initial dynamic number of nodes
    var node_count = min_nodes + randi() % (max_nodes - min_nodes + 1)
    
    # Create nodes
    for i in range(node_count):
        var node = {
            "position": Vector2(randf_range(20, 980), randf_range(20, 580)),
            "size": randf_range(node_min_size, node_max_size),
            "activity": randf(),
            "type": randi() % 3,  # 0: standard, 1: memory, 2: number
            "connections": []
        }
        nodes.append(node)
    
    # Create connections between nodes
    for i in range(nodes.size()):
        for j in range(i+1, nodes.size()):
            if randf() < connection_threshold:
                var connection = {
                    "from": i,
                    "to": j,
                    "weight": randf(),
                    "active": randf() < 0.5
                }
                connections.append(connection)
                nodes[i].connections.append(j)
                nodes[j].connections.append(i)
    
    # Create special memory points based on the digit 8
    _create_number_shape(8, 100, 150, 0.5)
    _create_number_shape(8, 200, 150, 0.5)
    _create_number_shape(8, 300, 150, 0.5)
    
    # Create initial active nodes
    _update_active_nodes()

# ----- PROCESS -----
func _process(delta):
    if not enabled:
        return
    
    # Update animations
    _update_animation(delta)
    
    # Draw the visualization each frame
    queue_redraw()

func _update_animation(delta):
    animation_time += delta
    
    # Update pulse
    pulse_timer += delta * (lucky_active ? lucky_pulse_rate : 1.0)
    current_pulse += delta * pulse_dir * (lucky_active ? lucky_pulse_rate : 1.0)
    if current_pulse > 1.0:
        current_pulse = 1.0
        pulse_dir = -1
    elif current_pulse < 0.0:
        current_pulse = 0.0
        pulse_dir = 1
    
    # Gradually transition number shape if needed
    number_morph_time += delta * 0.2
    if number_morph_time >= 1.0:
        number_morph_time = 0.0
        # Update to next number in sequence if memory usage changes significantly
        if memory_usage > 0.8 and sequence_index < number_sequence.size() - 1:
            sequence_index += 1
            active_number = number_sequence[sequence_index]
            _reorganize_for_number(active_number)
    
    # Animate node positions slightly
    for i in range(nodes.size()):
        var noise_x = sin(animation_time * 0.5 + i * 0.1) * 2.0
        var noise_y = cos(animation_time * 0.4 + i * 0.13) * 2.0
        nodes[i].position += Vector2(noise_x, noise_y)
        
        # Keep within bounds
        nodes[i].position.x = clamp(nodes[i].position.x, 10, 990)
        nodes[i].position.y = clamp(nodes[i].position.y, 10, 590)
        
        # Update node activity
        if nodes[i].type == 1:  # Memory nodes
            nodes[i].activity = 0.3 + 0.7 * memory_usage
        elif nodes[i].type == 2:  # Number nodes
            nodes[i].activity = 0.5 + 0.5 * current_pulse

# ----- DRAWING -----
func _draw():
    if not enabled:
        return
    
    # Draw background
    var bg_color = Color(0, 0, 0, background_fade)
    draw_rect(Rect2(0, 0, 1000, 600), bg_color)
    
    # Draw connections
    for connection in connections:
        if connection.active:
            var from_node = nodes[connection.from]
            var to_node = nodes[connection.to]
            var weight = connection.weight
            
            # Determine connection color
            var color
            if from_node.type == 2 or to_node.type == 2:  # Number node
                color = lucky_active ? lucky_color : secondary_color
                color.a = 0.3 + 0.7 * current_pulse
            else:
                color = main_color
                color.a = 0.2 + weight * 0.5
            
            draw_line(from_node.position, to_node.position, color, connection_width * weight)
    
    # Draw nodes
    for i in range(nodes.size()):
        var node = nodes[i]
        var size = node.size * (active_nodes.has(i) ? 1.5 : 1.0)
        
        # Adjust size based on memory for memory nodes
        if node.type == 1:
            size *= (0.8 + memory_usage * 0.5)
        
        # Pulse size for number nodes
        if node.type == 2:
            size *= (1.0 + current_pulse * 0.5)
        
        # Adjust all sizes based on neural size multiplier
        size *= neural_size_multiplier
        
        # Determine node color
        var color
        match node.type:
            0:  # Standard node
                color = main_color
                color.a = 0.2 + node.activity * 0.8
            1:  # Memory node
                color = secondary_color
                color.a = 0.3 + node.activity * 0.7
            2:  # Number node
                color = lucky_active ? lucky_color : secondary_color
                color.a = 0.5 + current_pulse * 0.5
        
        draw_circle(node.position, size, color)

# ----- EVENT HANDLERS -----
func _on_update_timer_timeout():
    # Update active nodes
    _update_active_nodes()
    
    # Update connection activity
    for connection in connections:
        connection.active = randf() < (0.3 + memory_usage * 0.7)
    
    # Adjust number of active nodes based on memory usage
    var target_active = min_nodes + int((max_nodes - min_nodes) * memory_usage)
    
    if active_nodes.size() > target_active:
        # Remove some active nodes
        while active_nodes.size() > target_active:
            active_nodes.remove_at(randi() % active_nodes.size())
    elif active_nodes.size() < target_active:
        # Add some active nodes
        var available = []
        for i in range(nodes.size()):
            if not active_nodes.has(i) and nodes[i].type == 0:
                available.append(i)
        
        while active_nodes.size() < target_active and available.size() > 0:
            var idx = randi() % available.size()
            active_nodes.append(available[idx])
            available.remove_at(idx)

func _on_data_timer_timeout():
    # Update data from connected systems
    if time_tracker:
        var usage_summary = time_tracker.get_usage_summary() if time_tracker.has_method("get_usage_summary") else null
        
        if usage_summary:
            # Update memory usage based on total time
            memory_usage = min(1.0, usage_summary.total_usage_time / (3600.0 * 4))  # Max out at 4 hours
            
            # Check for lucky state
            lucky_active = usage_summary.has("lucky") and usage_summary.lucky.is_lucky
            
            # Update neural size based on current session length
            neural_size_multiplier = 0.8 + min(usage_summary.current_session_time / 3600.0, 1.0)
    
    if turn_system:
        # Update current turn
        if "current_turn" in turn_system:
            var new_turn = turn_system.current_turn
            if new_turn != current_turn:
                current_turn = new_turn
                _reorganize_on_turn_change()

# ----- NEURAL NETWORK MANAGEMENT -----
func _update_active_nodes():
    active_nodes.clear()
    
    # Activate nodes based on memory usage and type
    for i in range(nodes.size()):
        var node = nodes[i]
        
        if node.type == 1 and memory_usage > 0.3:
            # Memory nodes activate when memory usage is high enough
            active_nodes.append(i)
        elif node.type == 2:
            # Number nodes are always active
            active_nodes.append(i)
        else:
            # Standard nodes activate based on activity threshold
            if node.activity > 0.6 or randf() < 0.2:
                active_nodes.append(i)

func _reorganize_on_turn_change():
    # Reorganize network based on turn number
    if current_turn > 6:
        # Later turns have more structured networks
        connection_threshold = 0.6
        memory_density = 1.2
    else:
        # Earlier turns have looser networks
        connection_threshold = 0.4
        memory_density = 0.8
    
    # For turns divisible by 4, reorganize around the current number
    if current_turn % 4 == 0:
        sequence_index = (sequence_index + 1) % number_sequence.size()
        active_number = number_sequence[sequence_index]
        _reorganize_for_number(active_number)

func _reorganize_for_number(number: int):
    # Clear old number points
    for i in range(nodes.size()-1, -1, -1):
        if nodes[i].type == 2:
            nodes.remove_at(i)
    
    # Create new number shape
    match number:
        8:
            _create_number_shape(8, 300, 300, 1.0)
        88:
            _create_number_shape(8, 250, 300, 0.8)
            _create_number_shape(8, 350, 300, 0.8)
        888:
            _create_number_shape(8, 200, 300, 0.7)
            _create_number_shape(8, 300, 300, 0.7)
            _create_number_shape(8, 400, 300, 0.7)
        1333:
            _create_number_shape(1, 200, 300, 0.7)
            _create_number_shape(3, 300, 300, 0.7)
            _create_number_shape(3, 350, 300, 0.7)
            _create_number_shape(3, 400, 300, 0.7)
        _:
            # Default to 8 if unknown number
            _create_number_shape(8, 300, 300, 1.0)
    
    # Update connections
    _rebuild_connections()
    
    # Update active nodes
    _update_active_nodes()

func _create_number_shape(digit: int, center_x: float, center_y: float, scale: float):
    var points = []
    
    match digit:
        1:
            # Create a "1" shape
            for i in range(10):
                points.append(Vector2(center_x, center_y - 50 * scale + i * 10 * scale))
        3:
            # Create a "3" shape
            var radius = 25 * scale
            var segments = 10
            
            # Top arc
            for i in range(segments+1):
                var angle = PI - i * PI / segments
                points.append(Vector2(
                    center_x + cos(angle) * radius,
                    center_y - 25 * scale + sin(angle) * radius
                ))
            
            # Bottom arc
            for i in range(segments+1):
                var angle = 0 - i * PI / segments
                points.append(Vector2(
                    center_x + cos(angle) * radius,
                    center_y + 25 * scale + sin(angle) * radius
                ))
        8:
            # Create an "8" shape
            var radius = 25 * scale
            var segments = 12
            
            # Top circle
            for i in range(segments):
                var angle = i * 2 * PI / segments
                points.append(Vector2(
                    center_x + cos(angle) * radius,
                    center_y - 25 * scale + sin(angle) * radius
                ))
            
            # Bottom circle
            for i in range(segments):
                var angle = i * 2 * PI / segments
                points.append(Vector2(
                    center_x + cos(angle) * radius,
                    center_y + 25 * scale + sin(angle) * radius
                ))
    
    # Create nodes from points
    for point in points:
        var node = {
            "position": point,
            "size": randf_range(node_min_size, node_max_size),
            "activity": 0.8,
            "type": 2,  # Number type
            "connections": []
        }
        nodes.append(node)
        number_points.append(nodes.size() - 1)

func _rebuild_connections():
    connections.clear()
    
    # Reset node connections
    for node in nodes:
        node.connections.clear()
    
    # Create connections between nodes
    for i in range(nodes.size()):
        for j in range(i+1, nodes.size()):
            var node_i = nodes[i]
            var node_j = nodes[j]
            
            var distance = node_i.position.distance_to(node_j.position)
            var max_dist = 150
            
            # Nodes of the same type connect more easily
            var type_factor = 1.0
            if node_i.type == node_j.type:
                type_factor = 1.5
            
            # Number nodes connect to nearby nodes more easily
            if node_i.type == 2 or node_j.type == 2:
                max_dist = 100
            
            var chance = connection_threshold * type_factor * (1.0 - distance / max_dist)
            
            if distance < max_dist and randf() < chance:
                var connection = {
                    "from": i,
                    "to": j,
                    "weight": 1.0 - distance / max_dist,
                    "active": randf() < 0.7
                }
                connections.append(connection)
                node_i.connections.append(j)
                node_j.connections.append(i)

# ----- PUBLIC API -----
func set_number_sequence(new_sequence: Array):
    if new_sequence.size() > 0:
        number_sequence = new_sequence
        # Immediately use the first number
        active_number = number_sequence[0]
        sequence_index = 0
        _reorganize_for_number(active_number)
    return number_sequence

func set_lucky_number(number: int):
    lucky_number = number
    return lucky_number

func toggle_enabled():
    enabled = !enabled
    return enabled

func force_next_number():
    sequence_index = (sequence_index + 1) % number_sequence.size()
    active_number = number_sequence[sequence_index]
    _reorganize_for_number(active_number)
    return active_number
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/shape_memory_visualizer.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/shared_account_connector.gd
# SIZE: 7363 bytes
extends Node

class_name SharedAccountConnector

# Connection states
enum ConnectionState {
    DISCONNECTED,
    CONNECTING,
    CONNECTED,
    ERROR
}

# Account types
enum AccountType {
    LOCAL,
    WINDOWS,
    GAME,
    GODOT
}

# Properties
var current_account_id = ""
var current_player_name = ""
var connection_state = ConnectionState.DISCONNECTED
var account_type = AccountType.LOCAL
var account_data = {}
var systems_connected = []

# Signals
signal account_connected(account_id, player_name)
signal account_disconnected(account_id)
signal data_synchronized()
signal connection_state_changed(new_state)

func _ready():
    # Initialize the connector
    print("SharedAccountConnector initialized")
    
    # Try to load existing account data
    load_account_data()
    
    # Connect to available systems
    connect_to_available_systems()

func connect_to_available_systems():
    # Check for AkashicDatabase
    if has_node("/root/AkashicDatabase") or get_node_or_null("/root/AkashicDatabase"):
        var akashic_db = get_node("/root/AkashicDatabase")
        systems_connected.append("AkashicDatabase")
        print("Connected to AkashicDatabase")
    
    # Check for other systems to connect with
    var system_nodes = [
        "WordProcessorTasks",
        "EtherealEngine",
        "ThreadManager"
    ]
    
    for system in system_nodes:
        if has_node("/root/" + system) or get_node_or_null("/root/" + system):
            systems_connected.append(system)
            print("Connected to " + system)
    
    # Update connection state
    if systems_connected.size() > 0:
        connection_state = ConnectionState.CONNECTED
        emit_signal("connection_state_changed", connection_state)

func connect_account(account_id = "", player_name = "", type = AccountType.LOCAL):
    # Set connection to connecting state
    connection_state = ConnectionState.CONNECTING
    emit_signal("connection_state_changed", connection_state)
    
    # Generate new account ID if not provided
    if account_id.empty():
        account_id = generate_unique_id()
    
    # Generate player name if not provided
    if player_name.empty():
        player_name = "Player_" + str(OS.get_unix_time()).substr(6, 4)
    
    # Set current account properties
    current_account_id = account_id
    current_player_name = player_name
    account_type = type
    
    # Create initial account data if new
    if not account_data.has("points"):
        account_data = {
            "points": 0,
            "dimension": 1,
            "preferences": {},
            "systems_access": {},
            "created_at": OS.get_datetime(),
            "last_login": OS.get_datetime()
        }
    else:
        # Update last login
        account_data["last_login"] = OS.get_datetime()
    
    # Update connection state
    connection_state = ConnectionState.CONNECTED
    emit_signal("connection_state_changed", connection_state)
    emit_signal("account_connected", current_account_id, current_player_name)
    
    # Save the updated data
    save_account_data()
    
    return current_account_id

func disconnect_account():
    # Update last session data
    if not current_account_id.empty():
        account_data["last_logout"] = OS.get_datetime()
        save_account_data()
    
    var old_id = current_account_id
    
    # Reset account variables
    current_account_id = ""
    current_player_name = ""
    account_data = {}
    
    # Update connection state
    connection_state = ConnectionState.DISCONNECTED
    emit_signal("connection_state_changed", connection_state)
    emit_signal("account_disconnected", old_id)

func load_account_data():
    # Check if we have a saved account
    var file = File.new()
    var filepath = "user://account_data.json"
    
    if file.file_exists(filepath):
        file.open(filepath, File.READ)
        var json_text = file.get_as_text()
        file.close()
        
        var json = JSON.parse(json_text)
        if json.error == OK:
            var data = json.result
            
            # Load account data if valid
            if data.has("account_id") and data.has("player_name"):
                current_account_id = data["account_id"]
                current_player_name = data["player_name"]
                account_data = data.get("account_data", {})
                account_type = data.get("account_type", AccountType.LOCAL)
                
                # Update connection state
                connection_state = ConnectionState.CONNECTED
                emit_signal("connection_state_changed", connection_state)
                emit_signal("account_connected", current_account_id, current_player_name)
                
                print("Loaded account for: " + current_player_name)
                return true
    
    # No saved account or couldn't load it
    print("No saved account found or couldn't load it")
    return false

func save_account_data():
    # Skip if no account is loaded
    if current_account_id.empty():
        return false
    
    # Prepare data to save
    var save_data = {
        "account_id": current_account_id,
        "player_name": current_player_name,
        "account_type": account_type,
        "account_data": account_data
    }
    
    # Save to file
    var file = File.new()
    var filepath = "user://account_data.json"
    file.open(filepath, File.WRITE)
    file.store_string(JSON.print(save_data, "  "))
    file.close()
    
    print("Saved account data for: " + current_player_name)
    return true

func update_account_data(new_data):
    # Merge new data with existing account data
    for key in new_data:
        account_data[key] = new_data[key]
    
    # Save the updated data
    save_account_data()
    
    # Synchronize with connected systems
    synchronize_data()
    
    return account_data

func synchronize_data():
    # Placeholder for syncing across systems
    # Would implement actual synchronization with other systems
    
    print("Synchronizing account data across " + str(systems_connected.size()) + " systems")
    
    # Emit signal for other systems to listen to
    emit_signal("data_synchronized")
    
    return true

func generate_unique_id():
    # Generate a simple unique ID based on time and random number
    return str(OS.get_unix_time()) + "_" + str(randi() % 10000)

# Getters
func get_current_account_id():
    return current_account_id
    
func get_current_player_name():
    return current_player_name
    
func get_account_type_string():
    match account_type:
        AccountType.LOCAL:
            return "Local"
        AccountType.WINDOWS:
            return "Windows"
        AccountType.GAME:
            return "Game"
        AccountType.GODOT:
            return "Godot"
        _:
            return "Unknown"
            
func get_connection_state_string():
    match connection_state:
        ConnectionState.DISCONNECTED:
            return "Disconnected"
        ConnectionState.CONNECTING:
            return "Connecting"
        ConnectionState.CONNECTED:
            return "Connected"
        ConnectionState.ERROR:
            return "Error"
        _:
            return "Unknown"

func get_account_data(key = ""):
    if key.empty():
        return account_data
    
    if account_data.has(key):
        return account_data[key]
    
    return null
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/shared_account_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/smart_account_manager.gd
# SIZE: 8718 bytes
extends Node

class_name SmartAccountManager

# Constants
const DIMENSION_MAX_LEVEL = 12
const MIN_POINTS = 0
const POINTS_SOFT_CAP = 10000
const AUTO_CORRECTION_INTERVAL = 60 # seconds

# Dimension symbols - the # symbol is significant in this system
const DIMENSION_SYMBOLS = {
    1: "#",
    2: "##",
    3: "###",
    4: "####",
    5: "#####",
    6: "######",
    7: "#######",
    8: "########",
    9: "#########",
    10: "##########",
    11: "###########",
    12: "############"
}

# Player account data
var player_name = ""
var account_id = ""
var total_points = 0
var current_dimension = 1
var enjoyment_factor = 1.0 # Multiplier based on player's enjoyment patterns
var last_auto_correction = 0

# References to other systems
var _akashic_db = null
var _account_connector = null

# Points distribution across categories
var points_categories = {
    "creation": 0,
    "exploration": 0,
    "interaction": 0,
    "challenge": 0,
    "mastery": 0
}

# Player preferences (auto-detected and manually set)
var player_preferences = {
    "prefers_challenge": 0.5, # 0.0-1.0
    "prefers_creation": 0.5,  # 0.0-1.0
    "prefers_exploration": 0.5, # 0.0-1.0
    "prefers_social": 0.5,     # 0.0-1.0
    "prefers_achievement": 0.5 # 0.0-1.0
}

# Signals
signal points_updated(total, category, amount)
signal dimension_changed(new_dimension)
signal preferences_updated()

func _ready():
    # Connect to Akashic Database if available
    if has_node("/root/AkashicDatabase") or get_node_or_null("/root/AkashicDatabase"):
        _akashic_db = get_node("/root/AkashicDatabase")
    
    # Connect to Account Connector if available
    if has_node("/root/SharedAccountConnector") or get_node_or_null("/root/SharedAccountConnector"):
        _account_connector = get_node("/root/SharedAccountConnector")
        
    # Set up auto-correction timer
    var timer = Timer.new()
    timer.wait_time = AUTO_CORRECTION_INTERVAL
    timer.autostart = true
    timer.connect("timeout", self, "_on_auto_correction_timer")
    add_child(timer)
    
    # Load player data
    load_account_data()

func load_account_data():
    # TODO: Load from file or database
    # Placeholder for now
    if _account_connector:
        player_name = _account_connector.get_current_player_name()
        account_id = _account_connector.get_current_account_id()
    
    # For testing - initialize with random data
    if player_name.empty():
        player_name = "Player" + str(randi() % 1000)
    
    if account_id.empty():
        account_id = generate_unique_id()
    
    # Load preferences from saved data or initialize defaults
    analyze_player_patterns()

func save_account_data():
    # TODO: Save to file or database
    print("Saving account data for: ", player_name)
    
    # Update connected systems
    if _account_connector:
        _account_connector.update_account_data({
            "points": total_points,
            "dimension": current_dimension,
            "preferences": player_preferences
        })

func add_points(amount, category = ""):
    var actual_amount = amount * enjoyment_factor
    
    # Apply category-specific bonuses based on player preferences
    if category in points_categories:
        var preference_key = "prefers_" + category if category == "challenge" else \
                            "prefers_creation" if category == "creation" else \
                            "prefers_exploration" if category == "exploration" else \
                            "prefers_social" if category == "interaction" else \
                            "prefers_achievement" if category == "mastery" else ""
        
        if preference_key in player_preferences:
            actual_amount *= (1.0 + player_preferences[preference_key])
        
        # Update category total
        points_categories[category] += actual_amount
    
    total_points += actual_amount
    
    # Check for dimension advancement
    check_dimension_advancement()
    
    # Update Akashic DB if connected
    if _akashic_db and category == "creation":
        _akashic_db.record_creation_event(actual_amount)
    
    emit_signal("points_updated", total_points, category, actual_amount)
    return actual_amount

func subtract_points(amount, category = ""):
    var actual_amount = min(amount, points_categories[category] if category in points_categories else amount)
    
    if category in points_categories:
        points_categories[category] -= actual_amount
    
    total_points -= actual_amount
    total_points = max(total_points, MIN_POINTS)
    
    emit_signal("points_updated", total_points, category, -actual_amount)
    return actual_amount

func check_dimension_advancement():
    # Calculate required points for next dimension
    var points_for_next_dimension = pow(current_dimension, 2) * 1000
    
    if total_points >= points_for_next_dimension and current_dimension < DIMENSION_MAX_LEVEL:
        advance_dimension()

func advance_dimension():
    current_dimension += 1
    print("Advanced to dimension: ", current_dimension)
    emit_signal("dimension_changed", current_dimension)
    
    # Apply dimension advancement effects
    if _akashic_db:
        _akashic_db.unlock_dimension(current_dimension)

func analyze_player_patterns():
    # This would normally analyze actual player data
    # For now, we'll just use placeholder logic
    
    # Example: Check if player has more creation points than other categories
    var total_cat_points = 0
    for cat in points_categories:
        total_cat_points += points_categories[cat]
    
    if total_cat_points > 0:
        player_preferences["prefers_creation"] = clamp(points_categories["creation"] / total_cat_points, 0.1, 0.9)
        player_preferences["prefers_exploration"] = clamp(points_categories["exploration"] / total_cat_points, 0.1, 0.9)
        
    # This would be updated based on actual gameplay telemetry
    emit_signal("preferences_updated")

func _on_auto_correction_timer():
    auto_correct_points()
    last_auto_correction = OS.get_unix_time()
    save_account_data()

func auto_correct_points():
    # Automatically adjust points based on player enjoyment patterns
    # This creates a feedback loop that maximizes player enjoyment
    
    # Calculate auto-correction
    var correction_amount = 0
    
    # If player is below dimension average, boost slightly
    var expected_points = current_dimension * 500
    if total_points < expected_points:
        correction_amount = expected_points * 0.05
    
    # Apply preference-based corrections
    var preferred_category = get_highest_preference_category()
    if preferred_category != "":
        points_categories[preferred_category] += correction_amount
        total_points += correction_amount
        
        print("Auto-corrected points: +", correction_amount, " to ", preferred_category)
    
    # Re-analyze preferences after correction
    analyze_player_patterns()

func get_highest_preference_category():
    var highest_pref = 0.0
    var category = ""
    
    if player_preferences["prefers_challenge"] > highest_pref:
        highest_pref = player_preferences["prefers_challenge"]
        category = "challenge"
        
    if player_preferences["prefers_creation"] > highest_pref:
        highest_pref = player_preferences["prefers_creation"] 
        category = "creation"
        
    if player_preferences["prefers_exploration"] > highest_pref:
        highest_pref = player_preferences["prefers_exploration"]
        category = "exploration"
        
    if player_preferences["prefers_social"] > highest_pref:
        highest_pref = player_preferences["prefers_social"]
        category = "interaction"
        
    if player_preferences["prefers_achievement"] > highest_pref:
        highest_pref = player_preferences["prefers_achievement"]
        category = "mastery"
        
    return category

func generate_unique_id():
    # Generate a simple unique ID
    return str(OS.get_unix_time()) + str(randi() % 10000)

# Helper methods for external access
func get_points_display():
    # Format points for display
    return str(int(total_points))
    
func get_dimension_display():
    # Get dimension with appropriate formatting and symbol
    return "Dimension " + str(current_dimension) + " / " + str(DIMENSION_MAX_LEVEL) + " " + DIMENSION_SYMBOLS[current_dimension]
    
func get_progress_to_next_dimension():
    # Calculate progress percentage to next dimension
    var points_for_next_dimension = pow(current_dimension, 2) * 1000
    if current_dimension >= DIMENSION_MAX_LEVEL:
        return 1.0
        
    var progress = float(total_points) / float(points_for_next_dimension)
    return clamp(progress, 0.0, 1.0)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/smart_account_manager.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/snake_case_translator.gd
# SIZE: 7081 bytes
extends Node
class_name SnakeCaseTranslator

# Translator system that converts existing files to snake_case
# and creates connections to main, datapoint, container, archive, past, memories, 3d notepad

# Original to snake_case mappings
var claude_mappings = {
  # Core Claude components to snake_case
  "CLAUDE.md": "claude_config_main",
  "claude_akashic_bridge.gd": "claude_akashic_bridge",
  "claude_akashic_demo.gd": "claude_demo_main",
  "claude_terminal_interface.sh": "claude_terminal_interface",
  "claude_ethereal_bridge.gd": "claude_ethereal_bridge",
  "claude_integration_bridge.gd": "claude_integration_main",
  
  # Memory systems to snake_case
  "word_memory_system.gd": "word_memory_system",
  "divine_memory_system.sh": "divine_memory_system",
  "memory_investment_system.gd": "memory_investment_system",
  "dimensional_memory_integration.gd": "dimensional_memory_integration",
  "dimensional_memory_splitter.gd": "dimensional_memory_splitter",
  "terminal_memory_system.gd": "terminal_memory_system",
  "project_memory_system.gd": "project_memory_system",
  "memory_manager.gd": "memory_manager_main",
  "memory_drive_connector.gd": "memory_drive_connector",
  
  # 3D Notepad to snake_case
  "3d_notepad.html": "notepad_3d_main",
  "NOTEPAD3D_README.md": "notepad_3d_readme",
  "notepad3d_visualizer.gd": "notepad_3d_visualizer",
  "notepad3d_manifesto.md": "notepad_3d_manifesto",
  
  # Datapoint systems to snake_case
  "datapoint-js.txt": "datapoint_js_main", 
  "terminal-datapoint-handlers.txt": "terminal_datapoint_handlers",
  
  # Main controllers to snake_case
  "main.gd": "main_controller"
}

# Categorize files by your specified categories
var category_mappings = {
  "main": [
    "claude_config_main",
    "claude_demo_main",
    "claude_integration_main",
    "memory_manager_main",
    "notepad_3d_main",
    "datapoint_js_main",
    "main_controller"
  ],
  
  "datapoint": [
    "datapoint_js_main",
    "terminal_datapoint_handlers"
  ],
  
  "container": [
    "claude_ethereal_bridge",
    "claude_akashic_bridge",
    "memory_drive_connector"
  ],
  
  "archive": [
    "memory_investment_system",
    "project_memory_system"
  ],
  
  "past": [
    "divine_memory_system",
    "dimensional_memory_splitter"
  ],
  
  "memories": [
    "word_memory_system",
    "terminal_memory_system",
    "dimensional_memory_integration",
    "memory_manager_main"
  ],
  
  "3d_notepad": [
    "notepad_3d_main",
    "notepad_3d_readme",
    "notepad_3d_visualizer",
    "notepad_3d_manifesto"
  ]
}

# Reference to the file connection system
var file_connection_system

# Hash symbol connectors for file relationships
var hash_connectors = {
  "#": ["main", "datapoint"],             # Single hash for basic connections
  "##": ["container", "archive"],         # Double hash for storage connections
  "###": ["past", "memories"],            # Triple hash for memory connections
  "#_": ["3d_notepad"]                    # Hash underscore for 3D notepad connections
}

# Initialize the translator
func _ready():
  print("Snake Case Translator initialized")
  
  # Get reference to file connection system
  file_connection_system = get_node("../FileConnectionSystem")
  if file_connection_system == null:
    print("WARNING: FileConnectionSystem not found, some functionality will be limited")

# Translate a file name to snake_case
func translate_to_snake_case(file_name: String) -> String:
  # Remove file extension
  var base_name = file_name.get_basename()
  
  # Convert to lowercase
  var lower_name = base_name.to_lower()
  
  # Replace spaces and special characters with underscores
  var snake_case = lower_name.replace(" ", "_")
  snake_case = snake_case.replace("-", "_")
  snake_case = snake_case.replace(".", "_")
  
  # Ensure no double underscores
  while snake_case.find("__") >= 0:
    snake_case = snake_case.replace("__", "_")
  
  return snake_case

# Get the category of a file based on its snake_case name
func get_file_category(snake_case_name: String) -> String:
  for category in category_mappings:
    if snake_case_name in category_mappings[category]:
      return category
  return ""

# Get hash connector for a file based on its category
func get_hash_connector(snake_case_name: String) -> String:
  var category = get_file_category(snake_case_name)
  
  for hash_symbol in hash_connectors:
    if category in hash_connectors[hash_symbol]:
      return hash_symbol
  
  return "#" # Default to single hash if no match

# Create a hash-based connection string between two files
func create_connection_string(source: String, target: String) -> String:
  var source_hash = get_hash_connector(source)
  var target_hash = get_hash_connector(target)
  
  return source_hash + source + " -> " + target_hash + target

# Build a complete connection map using hash symbols
func build_hash_connection_map() -> Dictionary:
  var connection_map = {}
  
  # Create connections for each category
  for category in category_mappings:
    var files = category_mappings[category]
    
    for i in range(files.size()):
      var source = files[i]
      connection_map[source] = []
      
      # Connect to other files in same category
      for j in range(files.size()):
        if i != j:
          connection_map[source].append(files[j])
      
      # Connect to main files if not a main file itself
      if category != "main":
        for main_file in category_mappings["main"]:
          if not main_file in connection_map[source]:
            connection_map[source].append(main_file)
  
  return connection_map

# Generate a text report of all connections with hash symbols
func generate_hash_connection_report() -> String:
  var report = "# Snake Case File Connections\n\n"
  var connection_map = build_hash_connection_map()
  
  # Add section for each hash connector type
  for hash_symbol in hash_connectors:
    report += "## " + hash_symbol + " Connections\n\n"
    
    for source in connection_map:
      var source_hash = get_hash_connector(source)
      if source_hash != hash_symbol:
        continue
        
      report += "### " + source + " connects to:\n\n"
      
      for target in connection_map[source]:
        var connection = create_connection_string(source, target)
        report += "- " + connection + "\n"
      
      report += "\n"
  
  return report

# Save the connection report
func save_connection_report(path: String) -> bool:
  var report = generate_hash_connection_report()
  var file = FileAccess.open(path, FileAccess.WRITE)
  
  if file == null:
    return false
    
  file.store_string(report)
  file.close()
  return true

# Get all files in a category
func get_category_files(category: String) -> Array:
  if category in category_mappings:
    return category_mappings[category]
  return []

# Get file hash notation
func get_file_with_hash(file_name: String) -> String:
  var snake_case = file_name
  if not snake_case in claude_mappings.values():
    snake_case = translate_to_snake_case(file_name)
  
  var hash_symbol = get_hash_connector(snake_case)
  return hash_symbol + snake_case
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/snake_case_translator.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/spatial_linguistic_connector.gd
# SIZE: 33800 bytes
extends Node

class_name SpatialLinguisticConnector

# Spatial-Linguistic Integration System
# Connects linguistic elements (words, wishes, commands) with spatial representations
# through a turn-based goal progression system

# ----- CONSTANTS -----
const MAX_TURNS = 12
const MAX_DIMENSIONS = 9
const SPACE_TYPES = ["Zone", "Layer", "Map", "Field", "Matrix", "Dimension", "Universe"]
const SHAPE_TYPES = ["Sphere", "Cube", "Rectangle", "Pyramid", "Cylinder", "Torus", "Fractal"]
const DIRECTION_TYPES = ["Horizontal", "Vertical", "Diagonal", "Spiral", "Radial", "Orthogonal", "Tessellated"]
const BOUNDARY_TYPES = ["Inside", "Outside", "Border", "Threshold", "Membrane", "Junction", "Portal"]
const POSITION_TYPES = ["Top", "Bottom", "Left", "Right", "Center", "Header", "Footer", "Home"]

# ----- INTEGRATION SYSTEMS -----
var terminal_bridge = null
var claude_bridge = null
var akashic_system = null
var ethereal_engine = null
var turn_system = null
var word_processor = null
var wish_system = null

# ----- DATA STRUCTURES -----
var linguistic_maps = {}
var spatial_structures = {}
var connection_pipes = {}
var shape_transformations = {}
var goal_progression = {}
var turn_states = {}

# ----- PROCESSORS -----
var wish_parser = null
var data_splitter = null
var merger = null
var connector = null
var translator = null

# ----- SIGNALS -----
signal linguistic_mapped(word, space_type, coordinates)
signal spatial_structured(space_id, shape_type, boundaries)
signal connection_established(source_id, target_id, pipe_type)
signal wish_translated(wish_id, spatial_representation)
signal goal_advanced(turn, goal_id, progress_percentage)
signal shape_transformed(shape_id, from_type, to_type)

# ----- INITIALIZATION -----
func _ready():
    print("Initializing Spatial-Linguistic Connector...")
    
    # Connect to required systems
    _connect_systems()
    
    # Initialize processors
    _initialize_processors()
    
    # Set up initial turn state
    _initialize_turn_state()
    
    # Create default spatial structures
    _create_default_structures()
    
    print("Spatial-Linguistic Connector initialized")

func _connect_systems():
    # Find and connect to the terminal bridge
    terminal_bridge = get_node_or_null("/root/TerminalAPIBridge")
    
    # Find and connect to Claude bridge
    claude_bridge = get_node_or_null("/root/ClaudeAkashicBridge") 
    if not claude_bridge:
        claude_bridge = get_node_or_null("/root/ClaudeEtherealBridge")
    
    # Find and connect to akashic system
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    
    # Find and connect to ethereal engine
    ethereal_engine = get_node_or_null("/root/EtherealEngine")
    
    # Find and connect to turn system
    turn_system = get_node_or_null("/root/TurnSystem")
    if turn_system:
        turn_system.connect("turn_advanced", self, "_on_turn_advanced")
    
    # Find and connect to word processor
    word_processor = get_node_or_null("/root/DivineWordProcessor")
    
    # Find and connect to wish system
    wish_system = get_node_or_null("/root/IntegratedMemorySystem")

func _initialize_processors():
    # Create wish parser instance
    wish_parser = WishParser.new()
    add_child(wish_parser)
    wish_parser.connect("wish_parsed", self, "_on_wish_parsed")
    
    # Create data splitter instance
    data_splitter = DataSplitter.new()
    add_child(data_splitter)
    data_splitter.connect("data_split", self, "_on_data_split")
    
    # Create merger instance
    merger = WishMerger.new()
    add_child(merger)
    merger.connect("wishes_merged", self, "_on_wishes_merged")
    
    # Create connector instance
    connector = PipeConnector.new()
    add_child(connector)
    connector.connect("pipe_connected", self, "_on_pipe_connected")
    
    # Create translator instance
    translator = SpatialTranslator.new()
    add_child(translator)
    translator.connect("translation_completed", self, "_on_translation_completed")

func _initialize_turn_state():
    # Get current turn from turn system if available
    var current_turn = 1
    if turn_system:
        current_turn = turn_system.get_current_turn()
    
    # Initialize goal state for current turn
    turn_states[current_turn] = {
        "active_goals": [],
        "completed_goals": [],
        "spatial_focus": "Zone",
        "linguistic_focus": "Command",
        "current_shape": "Sphere",
        "inner_boundary": "Inside",
        "outer_boundary": "Outside",
        "primary_direction": "Horizontal",
        "secondary_direction": "Vertical"
    }
    
    # Create initial goal if none exists
    if goal_progression.empty():
        _create_default_goal()

func _create_default_structures():
    # Create default zone structure
    var zone_id = _create_spatial_structure("Zone", "Sphere", {
        "center": Vector3(0, 0, 0),
        "radius": 5.0,
        "inner_boundary": "Inside",
        "outer_boundary": "Outside"
    })
    
    # Create default layer structure
    var layer_id = _create_spatial_structure("Layer", "Rectangle", {
        "position": Vector3(0, 1, 0),
        "dimensions": Vector2(10, 10),
        "primary_direction": "Horizontal",
        "secondary_direction": "Vertical"
    })
    
    # Create default map structure
    var map_id = _create_spatial_structure("Map", "Matrix", {
        "position": Vector3(0, 2, 0),
        "dimensions": Vector3(10, 1, 10),
        "cells": [],
        "directions": ["Top", "Bottom", "Left", "Right", "Center"]
    })
    
    # Connect default structures with pipes
    _connect_structures(zone_id, layer_id, "vertical")
    _connect_structures(layer_id, map_id, "vertical")
    
    # Map some default linguistic elements
    _map_linguistic_element("goal", "Zone", Vector3(0, 0, 0))
    _map_linguistic_element("wish", "Layer", Vector3(0, 1, 0))
    _map_linguistic_element("command", "Map", Vector3(0, 2, 0))

# ----- STRUCTURE MANAGEMENT -----
func _create_spatial_structure(space_type, shape_type, parameters):
    # Generate a unique ID for the structure
    var structure_id = space_type.to_lower() + "_" + str(spatial_structures.size() + 1)
    
    # Create structure with parameters
    spatial_structures[structure_id] = {
        "space_type": space_type,
        "shape_type": shape_type,
        "parameters": parameters,
        "connections": [],
        "linguistic_elements": [],
        "creation_time": OS.get_unix_time()
    }
    
    # Emit signal about new structure
    emit_signal("spatial_structured", structure_id, shape_type, parameters)
    
    return structure_id

func _connect_structures(source_id, target_id, connection_type):
    if not spatial_structures.has(source_id) or not spatial_structures.has(target_id):
        push_error("Cannot connect structures: Invalid structure ID")
        return null
    
    # Generate unique ID for connection
    var pipe_id = "pipe_" + source_id + "_to_" + target_id
    
    # Create connection pipe
    connection_pipes[pipe_id] = {
        "source_id": source_id,
        "target_id": target_id,
        "type": connection_type,
        "flow_direction": "bidirectional",
        "active": true,
        "creation_time": OS.get_unix_time()
    }
    
    # Add connection to structures
    spatial_structures[source_id].connections.append(pipe_id)
    spatial_structures[target_id].connections.append(pipe_id)
    
    # Emit signal about new connection
    emit_signal("connection_established", source_id, target_id, connection_type)
    
    return pipe_id

func _map_linguistic_element(word, space_type, coordinates):
    # Generate unique ID for mapping
    var map_id = "map_" + word + "_" + space_type.to_lower()
    
    # Create linguistic mapping
    linguistic_maps[map_id] = {
        "word": word,
        "space_type": space_type,
        "coordinates": coordinates,
        "connections": [],
        "parameters": {},
        "creation_time": OS.get_unix_time()
    }
    
    # Find appropriate spatial structure and add reference
    for structure_id in spatial_structures:
        var structure = spatial_structures[structure_id]
        if structure.space_type == space_type:
            structure.linguistic_elements.append(map_id)
            linguistic_maps[map_id].parameters["structure_id"] = structure_id
            break
    
    # Emit signal about new mapping
    emit_signal("linguistic_mapped", word, space_type, coordinates)
    
    return map_id

func _create_default_goal():
    # Create a default goal structure
    var goal_id = "goal_1"
    
    goal_progression[goal_id] = {
        "name": "Connect Linguistic and Spatial Elements",
        "description": "Create a complete integration between words and spatial structures",
        "total_turns": MAX_TURNS,
        "current_turn": 1,
        "progress": 0.0,
        "steps": [
            {
                "turn": 1,
                "name": "Create Zones",
                "completed": false
            },
            {
                "turn": 2,
                "name": "Map Linguistic Elements",
                "completed": false
            },
            {
                "turn": 3,
                "name": "Connect Zones with Pipes",
                "completed": false
            },
            {
                "turn": 4,
                "name": "Transform Basic Shapes",
                "completed": false
            },
            {
                "turn": 5,
                "name": "Establish Wish Parser",
                "completed": false
            },
            {
                "turn": 6,
                "name": "Create Data Splitters",
                "completed": false
            },
            {
                "turn": 7,
                "name": "Implement Merger System",
                "completed": false
            },
            {
                "turn": 8,
                "name": "Define Boundaries",
                "completed": false
            },
            {
                "turn": 9,
                "name": "Set Directions",
                "completed": false
            },
            {
                "turn": 10,
                "name": "Complete Position Mapping",
                "completed": false
            },
            {
                "turn": 11,
                "name": "Integrate Full System",
                "completed": false
            },
            {
                "turn": 12,
                "name": "Achieve Full Automation",
                "completed": false
            }
        ]
    }
    
    # Add active goal to current turn state
    var current_turn = 1
    if turn_system:
        current_turn = turn_system.get_current_turn()
    
    if turn_states.has(current_turn):
        turn_states[current_turn].active_goals.append(goal_id)
    
    return goal_id

# ----- WISH PROCESSING -----
func process_wish(wish_text, source="manual"):
    # Parse the wish using the wish parser
    var parsed_wish = wish_parser.parse_wish(wish_text)
    
    # Split parsed wish data
    var split_data = data_splitter.split_data(parsed_wish)
    
    # Translate to spatial representation
    var spatial_wish = translator.translate_to_spatial(split_data)
    
    # Generate unique wish ID
    var wish_id = "wish_" + str(OS.get_unix_time())
    
    # Store the wish in the appropriate system
    if wish_system:
        wish_system.add_wish(wish_text, 5, ["spatial_linguistic", "source:" + source])
    
    # Map the wish spatially
    _map_wish_spatially(wish_id, spatial_wish)
    
    return wish_id

func merge_wishes(wish_ids):
    if wish_ids.size() < 2:
        push_error("Cannot merge wishes: Need at least 2 wishes")
        return null
    
    # Get wishes from system
    var wishes = []
    
    for wish_id in wish_ids:
        if wish_system:
            var wish = wish_system.get_wish(wish_id)
            if wish:
                wishes.append(wish)
    
    # Merge wishes using merger
    var merged_wish = merger.merge_wishes(wishes)
    
    # Generate new wish ID
    var merged_id = "merged_" + str(OS.get_unix_time())
    
    # Store merged wish
    if wish_system:
        wish_system.add_wish(merged_wish.text, 8, ["merged", "spatial_linguistic"])
    
    # Map merged wish spatially
    _map_wish_spatially(merged_id, translator.translate_to_spatial(merged_wish))
    
    return merged_id

func _map_wish_spatially(wish_id, spatial_data):
    # Find appropriate spatial structure for the wish
    var target_space_type = "Layer" # Default to Layer
    
    # Create a new spatial structure for this wish if needed
    var structure_id = _create_spatial_structure(target_space_type, spatial_data.shape_type, {
        "position": spatial_data.position,
        "dimensions": spatial_data.dimensions,
        "primary_direction": spatial_data.primary_direction,
        "secondary_direction": spatial_data.secondary_direction
    })
    
    # Map the wish to this structure
    var map_id = _map_linguistic_element(wish_id, target_space_type, spatial_data.position)
    
    # Connect this wish to related structures
    for related_id in spatial_data.related_elements:
        if spatial_structures.has(related_id):
            _connect_structures(structure_id, related_id, "wish_connection")
    
    return map_id

# ----- COMMAND TRANSLATION -----
func translate_command(command_text):
    # Parse the command text
    var command_parts = command_text.split(" ", false)
    
    # Look for spatial and directional keywords
    var spatial_keywords = []
    var directional_keywords = []
    var position_keywords = []
    var shape_keywords = []
    
    for part in command_parts:
        part = part.to_lower()
        
        # Check for space types
        for space_type in SPACE_TYPES:
            if part == space_type.to_lower():
                spatial_keywords.append(space_type)
        
        # Check for direction types
        for direction in DIRECTION_TYPES:
            if part == direction.to_lower():
                directional_keywords.append(direction)
        
        # Check for position types
        for position in POSITION_TYPES:
            if part == position.to_lower():
                position_keywords.append(position)
        
        # Check for shape types
        for shape in SHAPE_TYPES:
            if part == shape.to_lower():
                shape_keywords.append(shape)
    
    # Create translation
    var translation = {
        "original_command": command_text,
        "spatial_elements": spatial_keywords,
        "directions": directional_keywords,
        "positions": position_keywords,
        "shapes": shape_keywords,
        "action": command_parts[0] if command_parts.size() > 0 else "",
        "translations": []
    }
    
    # Perform translations for each identified element
    for space in spatial_keywords:
        var translated = _translate_space_command(space, translation)
        translation.translations.append(translated)
    
    return translation

func _translate_space_command(space_type, translation):
    # Find all structures of this space type
    var matching_structures = []
    
    for structure_id in spatial_structures:
        var structure = spatial_structures[structure_id]
        if structure.space_type == space_type:
            matching_structures.append(structure_id)
    
    # Create shaped commands for this space
    var result = {
        "space_type": space_type,
        "matching_structures": matching_structures,
        "command_shapes": []
    }
    
    # Apply shape transformations if specified
    if not translation.shapes.empty():
        var target_shape = translation.shapes[0]
        
        for structure_id in matching_structures:
            var from_shape = spatial_structures[structure_id].shape_type
            var transform_id = _transform_shape(structure_id, from_shape, target_shape)
            
            result.command_shapes.append({
                "structure_id": structure_id,
                "from_shape": from_shape,
                "to_shape": target_shape,
                "transform_id": transform_id
            })
    
    # Apply directional transformations if specified
    if not translation.directions.empty():
        var primary_direction = translation.directions[0]
        var secondary_direction = translation.directions[1] if translation.directions.size() > 1 else "None"
        
        for structure_id in matching_structures:
            spatial_structures[structure_id].parameters.primary_direction = primary_direction
            if secondary_direction != "None":
                spatial_structures[structure_id].parameters.secondary_direction = secondary_direction
    
    # Apply positional transformations if specified
    if not translation.positions.empty():
        var target_position = translation.positions[0]
        
        # Here we would implement position-specific logic
        result.target_position = target_position
    
    return result

func _transform_shape(structure_id, from_shape, to_shape):
    if not spatial_structures.has(structure_id):
        push_error("Cannot transform shape: Invalid structure ID")
        return null
    
    # Create transform ID
    var transform_id = "transform_" + structure_id + "_" + from_shape + "_to_" + to_shape
    
    # Store transformation
    shape_transformations[transform_id] = {
        "structure_id": structure_id,
        "from_shape": from_shape,
        "to_shape": to_shape,
        "parameters": spatial_structures[structure_id].parameters.duplicate(),
        "timestamp": OS.get_unix_time()
    }
    
    # Update structure shape
    spatial_structures[structure_id].shape_type = to_shape
    
    # Emit signal
    emit_signal("shape_transformed", structure_id, from_shape, to_shape)
    
    return transform_id

# ----- TURN MANAGEMENT -----
func _on_turn_advanced(old_turn, new_turn):
    # Copy previous turn state to new turn if it doesn't exist
    if not turn_states.has(new_turn):
        turn_states[new_turn] = turn_states[old_turn].duplicate(true)
        turn_states[new_turn].active_goals = []
        turn_states[new_turn].completed_goals = []
    
    # Update goals for new turn
    _update_goal_progression(old_turn, new_turn)
    
    # Update spatial focus based on turn
    _update_spatial_focus(new_turn)
    
    print("Spatial-Linguistic Connector advanced to turn " + str(new_turn))

func _update_goal_progression(old_turn, new_turn):
    # Process old turn goals
    if turn_states.has(old_turn):
        for goal_id in turn_states[old_turn].active_goals:
            if goal_progression.has(goal_id):
                var goal = goal_progression[goal_id]
                
                # Check if this goal has a step for the old turn
                for step in goal.steps:
                    if step.turn == old_turn:
                        # Mark step as completed
                        step.completed = true
                
                # Calculate new progress
                var completed_steps = 0
                for step in goal.steps:
                    if step.completed:
                        completed_steps += 1
                
                goal.progress = float(completed_steps) / goal.steps.size()
                goal.current_turn = new_turn
                
                # Check if goal is now complete
                if completed_steps == goal.steps.size():
                    turn_states[old_turn].completed_goals.append(goal_id)
                else:
                    # Transfer to new turn's active goals
                    if turn_states.has(new_turn):
                        turn_states[new_turn].active_goals.append(goal_id)
                
                # Emit goal advancement signal
                emit_signal("goal_advanced", new_turn, goal_id, goal.progress * 100)

func _update_spatial_focus(turn):
    # Update spatial focus based on turn number
    if turn_states.has(turn):
        var turn_state = turn_states[turn]
        
        # Cycle through space types based on turn
        turn_state.spatial_focus = SPACE_TYPES[(turn - 1) % SPACE_TYPES.size()]
        
        # Cycle through shape types based on turn
        turn_state.current_shape = SHAPE_TYPES[(turn - 1) % SHAPE_TYPES.size()]
        
        # Update directional focus based on turn
        turn_state.primary_direction = DIRECTION_TYPES[(turn - 1) % DIRECTION_TYPES.size()]
        
        # Update boundary focus based on turn
        var boundary_index = (turn - 1) % BOUNDARY_TYPES.size()
        turn_state.inner_boundary = BOUNDARY_TYPES[boundary_index]
        turn_state.outer_boundary = BOUNDARY_TYPES[(boundary_index + 2) % BOUNDARY_TYPES.size()]
    
# ----- INNER CLASSES -----
class WishParser:
    signal wish_parsed(wish_data)
    
    func parse_wish(wish_text):
        # Parse wish text and extract components
        var parts = wish_text.split(" ")
        var subjects = []
        var actions = []
        var modifiers = []
        
        # Simple parsing based on word position and common patterns
        for i in range(parts.size()):
            var word = parts[i]
            
            # First word is often an action
            if i == 0:
                actions.append(word)
            # Last word is often a subject
            elif i == parts.size() - 1:
                subjects.append(word)
            # Words like "with", "using", "by" often introduce modifiers
            elif word in ["with", "using", "by", "through"] and i < parts.size() - 1:
                modifiers.append(parts[i+1])
        
        # Create structured wish data
        var wish_data = {
            "original_text": wish_text,
            "subjects": subjects,
            "actions": actions,
            "modifiers": modifiers,
            "timestamp": OS.get_unix_time()
        }
        
        emit_signal("wish_parsed", wish_data)
        return wish_data

class DataSplitter:
    signal data_split(split_data)
    
    func split_data(data):
        # Split data into components based on type
        var result = {
            "original_data": data,
            "components": {},
            "timestamp": OS.get_unix_time()
        }
        
        # Process different data types differently
        match typeof(data):
            TYPE_DICTIONARY:
                # Split dictionary into components
                for key in data:
                    result.components[key] = data[key]
            TYPE_ARRAY:
                # Split array into indexed components
                for i in range(data.size()):
                    result.components["element_" + str(i)] = data[i]
            TYPE_STRING:
                # Split string into words
                var words = data.split(" ")
                result.components["words"] = words
        
        emit_signal("data_split", result)
        return result

class WishMerger:
    signal wishes_merged(merged_wish)
    
    func merge_wishes(wishes):
        # Merge multiple wishes into a combined wish
        var merged_text = ""
        var subjects = []
        var actions = []
        var modifiers = []
        
        for wish in wishes:
            if typeof(wish) == TYPE_DICTIONARY:
                # Extract components to merge
                if wish.has("original_text"):
                    if merged_text.empty():
                        merged_text = wish.original_text
                    else:
                        merged_text += " and " + wish.original_text
                
                if wish.has("subjects"):
                    subjects.append_array(wish.subjects)
                
                if wish.has("actions"):
                    actions.append_array(wish.actions)
                
                if wish.has("modifiers"):
                    modifiers.append_array(wish.modifiers)
        
        # Create merged wish data
        var merged_wish = {
            "text": merged_text,
            "subjects": subjects,
            "actions": actions,
            "modifiers": modifiers,
            "merged": true,
            "source_count": wishes.size(),
            "timestamp": OS.get_unix_time()
        }
        
        emit_signal("wishes_merged", merged_wish)
        return merged_wish

class PipeConnector:
    signal pipe_connected(pipe_data)
    
    func connect_pipe(source, target, pipe_type="default"):
        # Create a pipe connection between source and target
        var pipe_data = {
            "source": source,
            "target": target,
            "type": pipe_type,
            "status": "created",
            "flow_enabled": true,
            "timestamp": OS.get_unix_time()
        }
        
        emit_signal("pipe_connected", pipe_data)
        return pipe_data

class SpatialTranslator:
    signal translation_completed(translation)
    
    func translate_to_spatial(data):
        # Convert data to spatial representation
        var result = {
            "position": Vector3(0, 0, 0),
            "dimensions": Vector3(1, 1, 1),
            "shape_type": "Sphere",
            "primary_direction": "Horizontal",
            "secondary_direction": "Vertical",
            "related_elements": [],
            "timestamp": OS.get_unix_time()
        }
        
        # Extract components for translation
        if typeof(data) == TYPE_DICTIONARY and data.has("components"):
            var components = data.components
            
            # Look for shape indicators
            for component in components:
                var value = components[component]
                
                # Check for shape words
                if typeof(value) == TYPE_STRING:
                    if value.to_lower() in ["sphere", "cube", "rectangle", "pyramid", "cylinder", "torus"]:
                        result.shape_type = value.capitalize()
                
                # Check for direction words
                if typeof(value) == TYPE_STRING:
                    if value.to_lower() in ["horizontal", "vertical", "diagonal", "spiral"]:
                        result.primary_direction = value.capitalize()
                
                # Check for position words
                if typeof(value) == TYPE_STRING:
                    if value.to_lower() in ["top", "bottom", "left", "right", "center"]:
                        # Use position to influence the spatial position
                        match value.to_lower():
                            "top":
                                result.position.y = 5
                            "bottom":
                                result.position.y = -5
                            "left":
                                result.position.x = -5
                            "right":
                                result.position.x = 5
                            "center":
                                result.position = Vector3(0, 0, 0)
            
            # Generate dimensions based on complexity of data
            if typeof(components) == TYPE_DICTIONARY:
                var complexity = components.size()
                result.dimensions = Vector3(complexity, complexity, complexity)
        
        emit_signal("translation_completed", result)
        return result

# ----- PUBLIC API -----
func get_spatial_structure(structure_id):
    if spatial_structures.has(structure_id):
        return spatial_structures[structure_id]
    return null

func get_linguistic_map(map_id):
    if linguistic_maps.has(map_id):
        return linguistic_maps[map_id]
    return null

func get_current_turn_state():
    var current_turn = 1
    if turn_system:
        current_turn = turn_system.get_current_turn()
    
    if turn_states.has(current_turn):
        return turn_states[current_turn]
    
    return null

func create_zone(name, shape_type="Sphere", parameters={}):
    # Set default parameters if not provided
    if not parameters.has("center"):
        parameters.center = Vector3(0, 0, 0)
    
    if not parameters.has("radius") and shape_type == "Sphere":
        parameters.radius = 5.0
    
    if not parameters.has("dimensions") and shape_type == "Cube":
        parameters.dimensions = Vector3(10, 10, 10)
    
    # Create the zone structure
    return _create_spatial_structure("Zone", shape_type, parameters)

func connect_zones(source_zone_id, target_zone_id, connection_type="default"):
    return _connect_structures(source_zone_id, target_zone_id, connection_type)

func map_word(word, space_type, coordinates=Vector3(0, 0, 0)):
    return _map_linguistic_element(word, space_type, coordinates)

func get_goal_status(goal_id):
    if goal_progression.has(goal_id):
        return goal_progression[goal_id]
    return null

func get_all_goals():
    return goal_progression

func reset_turn_state(turn):
    if turn_states.has(turn):
        turn_states.erase(turn)
        
        # Initialize fresh state
        turn_states[turn] = {
            "active_goals": [],
            "completed_goals": [],
            "spatial_focus": "Zone",
            "linguistic_focus": "Command",
            "current_shape": "Sphere",
            "inner_boundary": "Inside",
            "outer_boundary": "Outside",
            "primary_direction": "Horizontal",
            "secondary_direction": "Vertical"
        }
        
        return true
    
    return false

func auto_agent_mode(enable=true, agent_parameters={}):
    # Enable or disable auto agent mode for this connector
    var parameters = agent_parameters.duplicate()
    
    # Set default parameters if not provided
    if not parameters.has("auto_wish_processing"):
        parameters.auto_wish_processing = true
    
    if not parameters.has("auto_goal_advancement"):
        parameters.auto_goal_advancement = true
    
    if not parameters.has("auto_shape_transformation"):
        parameters.auto_shape_transformation = true
    
    # Store parameters in current turn state
    var current_turn = 1
    if turn_system:
        current_turn = turn_system.get_current_turn()
    
    if turn_states.has(current_turn):
        turn_states[current_turn].auto_agent_enabled = enable
        turn_states[current_turn].auto_agent_parameters = parameters
    
    # Set up timer for automated processing if enabled
    if enable:
        var timer = Timer.new()
        timer.wait_time = 5.0 # Process every 5 seconds
        timer.one_shot = false
        timer.autostart = true
        timer.connect("timeout", self, "_on_auto_agent_tick")
        add_child(timer)
        
        print("Auto Agent Mode enabled with parameters:", parameters)
    else:
        # Remove any existing auto agent timer
        for child in get_children():
            if child is Timer and child.name == "AutoAgentTimer":
                child.stop()
                child.queue_free()
        
        print("Auto Agent Mode disabled")
    
    return enable

func _on_auto_agent_tick():
    # Check if auto agent mode is enabled for current turn
    var current_turn = 1
    if turn_system:
        current_turn = turn_system.get_current_turn()
    
    if not turn_states.has(current_turn) or not turn_states[current_turn].has("auto_agent_enabled") or not turn_states[current_turn].auto_agent_enabled:
        return
    
    var parameters = turn_states[current_turn].auto_agent_parameters
    
    # Process pending wishes if enabled
    if parameters.auto_wish_processing and wish_system:
        var pending_wishes = wish_system.get_wishes_by_status("pending", 5)
        
        for wish in pending_wishes:
            process_wish(wish.content, "auto_agent")
    
    # Advance goals automatically if enabled
    if parameters.auto_goal_advancement:
        _advance_current_goals()
    
    # Transform shapes automatically if enabled
    if parameters.auto_shape_transformation:
        _transform_current_shapes()

func _advance_current_goals():
    var current_turn = 1
    if turn_system:
        current_turn = turn_system.get_current_turn()
    
    if not turn_states.has(current_turn):
        return
    
    # Get active goals for this turn
    var active_goals = turn_states[current_turn].active_goals
    
    for goal_id in active_goals:
        if goal_progression.has(goal_id):
            var goal = goal_progression[goal_id]
            
            # Find current step
            for step in goal.steps:
                if step.turn == current_turn and not step.completed:
                    # Automatically mark step as completed
                    step.completed = true
                    
                    # Update progress
                    var completed_steps = 0
                    for s in goal.steps:
                        if s.completed:
                            completed_steps += 1
                    
                    goal.progress = float(completed_steps) / goal.steps.size()
                    
                    # Emit signal
                    emit_signal("goal_advanced", current_turn, goal_id, goal.progress * 100)
                    break

func _transform_current_shapes():
    var current_turn = 1
    if turn_system:
        current_turn = turn_system.get_current_turn()
    
    if not turn_states.has(current_turn):
        return
    
    # Get current shape type for this turn
    var current_shape = turn_states[current_turn].current_shape
    
    # Transform one structure per tick to avoid overwhelming changes
    for structure_id in spatial_structures:
        var structure = spatial_structures[structure_id]
        
        if structure.shape_type != current_shape:
            _transform_shape(structure_id, structure.shape_type, current_shape)
            break  # Just transform one per tick
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/spatial_linguistic_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/spatial_notepad_integration.gd
# SIZE: 17423 bytes
extends Node

# Spatial Notepad Integration
# Connects SpatialWorldStorage with Notepad3DVisualizer
# Provides bridge between data storage and visual representation
# Terminal 1: Divine Word Genesis

class_name SpatialNotepadIntegration

# ----- COMPONENT REFERENCES -----
var storage: SpatialWorldStorage
var visualizer: Notepad3DVisualizer

# ----- SIGNALS -----
signal cell_created(notebook_name, cell_id)
signal cell_updated(notebook_name, cell_id)
signal cell_deleted(notebook_name, cell_id)
signal entry_visualized(entry_id)

# ----- STATE TRACKING -----
var active_notebook = ""
var active_entries = []
var visualized_cells = {}
var visualized_connections = {}

# ----- CONSTANTS -----
const DEFAULT_CELL_COLOR = Color(1.0, 1.0, 1.0)
const DEFAULT_CONNECTION_COLOR = Color(0.5, 0.8, 1.0)
const DEFAULT_CELL_POWER = 50.0
const DEFAULT_CONNECTION_STRENGTH = 1.0

# ----- INITIALIZATION -----
func _ready():
    print("Spatial Notepad Integration initializing...")

# ----- CONNECTION SETUP -----
func connect_components(world_storage, notepad_visualizer):
    storage = world_storage
    visualizer = notepad_visualizer
    
    if storage and visualizer:
        # Connect signals from storage
        storage.connect("notebook_updated", self, "_on_notebook_updated")
        storage.connect("entry_added", self, "_on_entry_added")
        
        # Connect signals from visualizer
        visualizer.connect("visualization_ready", self, "_on_visualization_ready")
        visualizer.connect("word_selected", self, "_on_word_selected")
        visualizer.connect("dimension_transition_complete", self, "_on_dimension_changed")
        
        print("Connected SpatialWorldStorage to Notepad3DVisualizer")
        return true
    else:
        print("ERROR: Cannot connect components - missing storage or visualizer")
        return false

# ----- NOTEBOOK VISUALIZATION -----
func visualize_notebook(notebook_name):
    if not storage or not visualizer:
        print("ERROR: Components not connected")
        return false
    
    var notebook = storage.get_notepad(notebook_name)
    if not notebook:
        print("ERROR: Notebook '%s' not found" % notebook_name)
        return false
    
    print("Visualizing notebook: %s" % notebook_name)
    active_notebook = notebook_name
    
    # Clear existing visualizations
    clear_visualizations()
    
    # Create visualizations for each cell
    for cell_id in notebook.cells:
        var cell = notebook.cells[cell_id]
        create_cell_visualization(notebook_name, cell)
    
    # Create connections between nearby cells
    create_cell_connections(notebook_name)
    
    return true

func create_cell_visualization(notebook_name, cell):
    # Convert Notepad3DCell to word_data for visualizer
    var word_data = {
        "id": cell.cell_id,
        "text": cell.content,
        "position": cell.position.to_vector3(),
        "rotation": Vector3(0, 0, 0),
        "size": Vector3(1, 1, 1),
        "color": cell.color,
        "power": DEFAULT_CELL_POWER,
        "evolution_stage": 1
    }
    
    # Create word visualization
    var word_node = visualizer.create_word_visualization(word_data)
    if word_node:
        visualized_cells[cell.cell_id] = {
            "notebook": notebook_name,
            "cell": cell,
            "word_data": word_data
        }
        emit_signal("cell_created", notebook_name, cell.cell_id)
        return true
    
    return false

func update_cell_visualization(notebook_name, cell_id):
    if not visualized_cells.has(cell_id):
        return false
    
    var notebook = storage.get_notepad(notebook_name)
    if not notebook:
        return false
    
    var cell = notebook.get_cell(cell_id)
    if not cell:
        return false
    
    # Update word data
    var word_data = visualized_cells[cell_id].word_data
    word_data.text = cell.content
    word_data.position = cell.position.to_vector3()
    word_data.color = cell.color
    
    # Update visualization
    var result = visualizer.update_word_visualization(cell_id, word_data)
    if result:
        visualized_cells[cell_id].cell = cell
        emit_signal("cell_updated", notebook_name, cell_id)
    
    return result

func delete_cell_visualization(cell_id):
    if not visualized_cells.has(cell_id):
        return false
    
    var notebook_name = visualized_cells[cell_id].notebook
    
    # Delete the visualization
    var result = visualizer.delete_word_visualization(cell_id)
    if result:
        visualized_cells.erase(cell_id)
        emit_signal("cell_deleted", notebook_name, cell_id)
    
    return result

func create_cell_connections(notebook_name):
    if not storage:
        return false
    
    var notebook = storage.get_notepad(notebook_name)
    if not notebook:
        return false
    
    # Clear existing connections
    for connection_id in visualized_connections:
        visualizer.delete_connection_visualization(connection_id)
    visualized_connections.clear()
    
    # Create map of cells by position for fast lookup
    var cells_by_position = {}
    for cell_id in notebook.cells:
        var cell = notebook.cells[cell_id]
        var pos_key = "%d_%d_%d" % [int(cell.position.x), int(cell.position.y), int(cell.position.z)]
        cells_by_position[pos_key] = cell
    
    # Find cells that should be connected
    var connections = []
    for cell_id in notebook.cells:
        var cell = notebook.cells[cell_id]
        
        # Check adjacent positions
        for dx in range(-1, 2):
            for dy in range(-1, 2):
                for dz in range(-1, 2):
                    # Skip self
                    if dx == 0 and dy == 0 and dz == 0:
                        continue
                    
                    var neighbor_pos_key = "%d_%d_%d" % [
                        int(cell.position.x + dx),
                        int(cell.position.y + dy),
                        int(cell.position.z + dz)
                    ]
                    
                    if cells_by_position.has(neighbor_pos_key):
                        var neighbor_cell = cells_by_position[neighbor_pos_key]
                        
                        # Create connection ID (make sure it's consistent regardless of order)
                        var cell_ids = [cell.cell_id, neighbor_cell.cell_id]
                        cell_ids.sort()
                        var connection_id = "conn_%s_%s" % [cell_ids[0], cell_ids[1]]
                        
                        # Skip if already processed
                        if visualized_connections.has(connection_id):
                            continue
                        
                        # Create connection data
                        var connection_data = {
                            "id": connection_id,
                            "word1_id": cell.cell_id,
                            "word2_id": neighbor_cell.cell_id,
                            "color": DEFAULT_CONNECTION_COLOR,
                            "strength": DEFAULT_CONNECTION_STRENGTH
                        }
                        
                        connections.append(connection_data)
    
    # Create visualizations for connections
    for connection_data in connections:
        var connection_node = visualizer.create_connection_visualization(connection_data)
        if connection_node:
            visualized_connections[connection_data.id] = connection_data
    
    return true

func clear_visualizations():
    # Clear cells
    var cell_ids = visualized_cells.keys()
    for cell_id in cell_ids:
        delete_cell_visualization(cell_id)
    
    # Clear connections
    var connection_ids = visualized_connections.keys()
    for connection_id in connection_ids:
        visualizer.delete_connection_visualization(connection_id)
    visualized_connections.clear()

# ----- AKASHIC ENTRY VISUALIZATION -----
func visualize_akashic_entries(entry_ids):
    if not storage or not visualizer:
        print("ERROR: Components not connected")
        return false
    
    print("Visualizing %d akashic entries" % entry_ids.size())
    active_entries = entry_ids
    
    # Clear existing visualizations
    clear_visualizations()
    
    # Create visualizations for each entry
    for entry_id in entry_ids:
        var entry = storage.get_akashic_entry(entry_id)
        if entry:
            create_entry_visualization(entry)
    
    # Create connections between entries
    create_entry_connections(entry_ids)
    
    return true

func create_entry_visualization(entry):
    # Convert AkashicEntry to word_data for visualizer
    var word_data = {
        "id": entry.entry_id,
        "text": entry.content,
        "position": entry.position.coordinate.to_vector3(),
        "rotation": Vector3(0, 0, 0),
        "size": Vector3(1, 1, 1) * (1.0 + (entry.position.power / 100.0)),
        "color": get_color_for_tags(entry.tags),
        "power": entry.position.power,
        "evolution_stage": entry.position.dimension / 2  # Higher dimensions = higher evolution
    }
    
    # Create word visualization
    var word_node = visualizer.create_word_visualization(word_data)
    if word_node:
        visualized_cells[entry.entry_id] = {
            "notebook": "akashic",
            "cell": entry,
            "word_data": word_data
        }
        emit_signal("entry_visualized", entry.entry_id)
        return true
    
    return false

func create_entry_connections(entry_ids):
    if not storage:
        return false
    
    # Clear existing connections
    for connection_id in visualized_connections:
        visualizer.delete_connection_visualization(connection_id)
    visualized_connections.clear()
    
    # Create connections based on entry connections
    for entry_id in entry_ids:
        var entry = storage.get_akashic_entry(entry_id)
        if not entry:
            continue
        
        for connected_entry in entry.connections:
            # Skip if not in our active set
            if not entry_ids.has(connected_entry.entry_id):
                continue
            
            # Create connection ID (make sure it's consistent regardless of order)
            var ids = [entry.entry_id, connected_entry.entry_id]
            ids.sort()
            var connection_id = "conn_%s_%s" % [ids[0], ids[1]]
            
            # Skip if already processed
            if visualized_connections.has(connection_id):
                continue
            
            # Create connection data
            var connection_data = {
                "id": connection_id,
                "word1_id": entry.entry_id,
                "word2_id": connected_entry.entry_id,
                "color": Color(0.8, 0.6, 0.2),  # Amber for akashic connections
                "strength": 1.0 + (entry.position.power + connected_entry.position.power) / 200.0
            }
            
            var connection_node = visualizer.create_connection_visualization(connection_data)
            if connection_node:
                visualized_connections[connection_id] = connection_data
    
    # Also create connections for spatial synergies
    var synergies = storage.find_spatial_synergies(5.0)
    for synergy in synergies:
        # Skip if either entry is not in our active set
        if not entry_ids.has(synergy.entry_a) or not entry_ids.has(synergy.entry_b):
            continue
        
        # Create connection ID (make sure it's consistent regardless of order)
        var ids = [synergy.entry_a, synergy.entry_b]
        ids.sort()
        var connection_id = "syn_%s_%s" % [ids[0], ids[1]]
        
        # Skip if already processed
        if visualized_connections.has(connection_id):
            continue
        
        # Create connection data with color based on synergy strength
        var strength = clamp(synergy.strength / 10.0, 0.1, 5.0)
        var color = Color(0.2, 0.6, 1.0).linear_interpolate(Color(1.0, 0.8, 0.2), strength / 5.0)
        
        var connection_data = {
            "id": connection_id,
            "word1_id": synergy.entry_a,
            "word2_id": synergy.entry_b,
            "color": color,
            "strength": strength
        }
        
        var connection_node = visualizer.create_connection_visualization(connection_data)
        if connection_node:
            visualized_connections[connection_id] = connection_data
    
    return true

# ----- UTILITY FUNCTIONS -----
func get_color_for_tags(tags):
    # Generate a color based on tags
    if tags.empty():
        return Color(1, 1, 1)
    
    # Use first tag to determine hue
    var tag_text = tags[0]
    var tag_hash = 0
    for i in range(tag_text.length()):
        tag_hash += tag_text.ord_at(i)
    
    var hue = (tag_hash % 1000) / 1000.0
    var saturation = 0.8
    var value = 0.9
    
    # Adjust saturation and value based on tag count
    if tags.size() > 1:
        saturation = 0.7 + (0.3 * (tags.size() - 1) / 5.0)
        value = 1.0
    
    return Color.from_hsv(hue, saturation, value)

func position_to_world_coords(position):
    # Convert storage coordinate to world coordinate
    return Vector3(position.x, position.y, position.z)

# ----- INTERACTIVE FUNCTIONS -----
func add_cell_at_position(notebook_name, position, content = "", color = DEFAULT_CELL_COLOR):
    if not storage:
        return null
    
    var coord = Vector3(position.x, position.y, position.z)
    var cell_id = storage.add_cell_to_notepad(notebook_name, coord, content, color)
    
    if cell_id and active_notebook == notebook_name:
        var notebook = storage.get_notepad(notebook_name)
        var cell = notebook.get_cell(cell_id)
        create_cell_visualization(notebook_name, cell)
        
        # Update connections
        create_cell_connections(notebook_name)
    
    return cell_id

func update_cell_content(notebook_name, cell_id, new_content):
    if not storage:
        return false
    
    var notebook = storage.get_notepad(notebook_name)
    if not notebook:
        return false
    
    var cell = notebook.get_cell(cell_id)
    if not cell:
        return false
    
    # Update content
    cell.content = new_content
    cell.last_edit = OS.get_unix_time()
    
    # Save changes
    storage.save_notepad_notebooks()
    
    # Update visualization if active
    if active_notebook == notebook_name:
        update_cell_visualization(notebook_name, cell_id)
    
    return true

func update_cell_color(notebook_name, cell_id, new_color):
    if not storage:
        return false
    
    var notebook = storage.get_notepad(notebook_name)
    if not notebook:
        return false
    
    var cell = notebook.get_cell(cell_id)
    if not cell:
        return false
    
    # Update color
    cell.color = new_color
    cell.last_edit = OS.get_unix_time()
    
    # Save changes
    storage.save_notepad_notebooks()
    
    # Update visualization if active
    if active_notebook == notebook_name:
        update_cell_visualization(notebook_name, cell_id)
    
    return true

func delete_cell(notebook_name, cell_id):
    if not storage:
        return false
    
    var notebook = storage.get_notepad(notebook_name)
    if not notebook:
        return false
    
    if not notebook.cells.has(cell_id):
        return false
    
    # Remove cell from notebook
    notebook.cells.erase(cell_id)
    storage.save_notepad_notebooks()
    
    # Update visualization if active
    if active_notebook == notebook_name and visualized_cells.has(cell_id):
        delete_cell_visualization(cell_id)
        
        # Update connections
        create_cell_connections(notebook_name)
    
    return true

func create_notebook_from_entries(entry_ids, notebook_name):
    if not storage:
        return false
    
    var result = storage.create_notepad_from_akashic(entry_ids, notebook_name)
    if result:
        # Switch to new notebook
        visualize_notebook(notebook_name)
    
    return result

# ----- EVENT HANDLERS -----
func _on_notebook_updated(notebook_name):
    if active_notebook == notebook_name:
        # Refresh visualization
        visualize_notebook(notebook_name)

func _on_entry_added(entry_id):
    if active_entries.has(entry_id):
        # Update entry visualization
        var entry = storage.get_akashic_entry(entry_id)
        if entry:
            create_entry_visualization(entry)
            create_entry_connections(active_entries)

func _on_visualization_ready():
    print("Notepad3D Visualizer ready")
    # Initialize with default notebook if available
    var notebooks = storage.notepad_notebooks
    if notebooks.size() > 0:
        visualize_notebook(notebooks.keys()[0])

func _on_word_selected(word_data):
    # Handle interaction with words/cells
    if visualized_cells.has(word_data.id):
        var cell_info = visualized_cells[word_data.id]
        
        # Show cell details (implement UI for this)
        print("Selected cell: %s" % word_data.text)
        
        # You could implement custom UI for editing the cell here

func _on_dimension_changed(dimension):
    # Update visualization based on new dimension
    if active_notebook != "":
        # Redraw connections with potentially new aesthetics
        create_cell_connections(active_notebook)
    elif active_entries.size() > 0:
        # Update entry connections
        create_entry_connections(active_entries)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/spatial_notepad_integration.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/spatial_world_storage.gd
# SIZE: 16856 bytes
extends Node

# Spatial World Storage System
# Handles storage and management of 3D spaces, maps and akashic record data
# Terminal 1: Divine Word Genesis

class_name SpatialWorldStorage

# Coordinate system definitions
const MAX_DIMENSION = 12
const SACRED_NUMBER = 9

# Basic 3D space structure
class Coordinate:
	var x: float
	var y: float
	var z: float
	
	func _init(x_val = 0, y_val = 0, z_val = 0):
		x = x_val
		y = y_val
		z = z_val
	
	func to_string():
		return "(%f, %f, %f)" % [x, y, z]
	
	func to_vector3():
		return Vector3(x, y, z)

# Extended space with dimensional properties
class DimensionalPoint:
	var coordinate: Coordinate
	var dimension: int
	var power: float
	var timestamp: int
	
	func _init(coord, dim = 1, pwr = 0):
		coordinate = coord
		dimension = dim
		power = pwr
		timestamp = OS.get_unix_time()
	
	func to_dict():
		return {
			"x": coordinate.x,
			"y": coordinate.y,
			"z": coordinate.z,
			"dimension": dimension,
			"power": power,
			"timestamp": timestamp
		}
	
	static func from_dict(data):
		var coord = Coordinate.new(data.x, data.y, data.z)
		var point = DimensionalPoint.new(coord, data.dimension, data.power)
		point.timestamp = data.timestamp
		return point

# Akashic record entry
class AkashicEntry:
	var position: DimensionalPoint
	var content: String
	var author: String
	var tags: Array
	var connections: Array
	var entry_id: String
	
	func _init(pos, cont, auth, entry_tags = []):
		position = pos
		content = cont
		author = auth
		tags = entry_tags
		connections = []
		entry_id = "entry_%d_%d" % [OS.get_unix_time(), randi() % 10000]
	
	func to_dict():
		var conn_ids = []
		for connection in connections:
			conn_ids.append(connection.entry_id)
		
		return {
			"position": position.to_dict(),
			"content": content,
			"author": author,
			"tags": tags,
			"connections": conn_ids,
			"entry_id": entry_id
		}

# 3D world map
class SpatialMap:
	var name: String
	var dimension: int
	var grid: Dictionary
	var entities: Dictionary
	var creation_time: int
	var last_update: int
	
	func _init(map_name, dim = 1):
		name = map_name
		dimension = dim
		grid = {}
		entities = {}
		creation_time = OS.get_unix_time()
		last_update = creation_time
	
	func add_point(key, point_data):
		grid[key] = point_data
		last_update = OS.get_unix_time()
	
	func get_point(key):
		if grid.has(key):
			return grid[key]
		return null
	
	func add_entity(entity_id, entity_data):
		entities[entity_id] = entity_data
		last_update = OS.get_unix_time()
	
	func to_dict():
		var grid_data = {}
		for key in grid:
			grid_data[key] = grid[key].to_dict()
		
		return {
			"name": name,
			"dimension": dimension,
			"grid": grid_data,
			"entities": entities,
			"creation_time": creation_time,
			"last_update": last_update
		}

# Notepad3D Cell
class Notepad3DCell:
	var position: Coordinate
	var content: String
	var color: Color
	var cell_id: String
	var last_edit: int
	
	func _init(pos, cont = "", col = Color.white):
		position = pos
		content = cont
		color = col
		cell_id = "cell_%d_%d" % [OS.get_unix_time(), randi() % 10000]
		last_edit = OS.get_unix_time()
	
	func to_dict():
		return {
			"position": {
				"x": position.x,
				"y": position.y,
				"z": position.z
			},
			"content": content,
			"color": {
				"r": color.r,
				"g": color.g,
				"b": color.b,
				"a": color.a
			},
			"cell_id": cell_id,
			"last_edit": last_edit
		}

# Notepad3D notebook
class Notepad3D:
	var name: String
	var cells: Dictionary
	var creation_time: int
	var last_update: int
	var tags: Array
	
	func _init(notebook_name, notebook_tags = []):
		name = notebook_name
		cells = {}
		creation_time = OS.get_unix_time()
		last_update = creation_time
		tags = notebook_tags
	
	func add_cell(cell):
		cells[cell.cell_id] = cell
		last_update = OS.get_unix_time()
	
	func get_cell(cell_id):
		if cells.has(cell_id):
			return cells[cell_id]
		return null
	
	func get_cell_at_position(position):
		for cell_id in cells:
			var cell = cells[cell_id]
			if cell.position.x == position.x and cell.position.y == position.y and cell.position.z == position.z:
				return cell
		return null
	
	func to_dict():
		var cells_data = {}
		for cell_id in cells:
			cells_data[cell_id] = cells[cell_id].to_dict()
		
		return {
			"name": name,
			"cells": cells_data,
			"creation_time": creation_time,
			"last_update": last_update,
			"tags": tags
		}

# Main storage variables
var akashic_entries = {}
var spatial_maps = {}
var notepad_notebooks = {}

# Signal connections
signal entry_added(entry_id)
signal map_created(map_name)
signal notebook_updated(notebook_name)

func _ready():
	load_all_data()

func load_all_data():
	load_akashic_records()
	load_spatial_maps()
	load_notepad_notebooks()

# Akashic Records functions
func add_akashic_entry(position, content, author, tags = []):
	var entry = AkashicEntry.new(position, content, author, tags)
	akashic_entries[entry.entry_id] = entry
	save_akashic_records()
	emit_signal("entry_added", entry.entry_id)
	return entry.entry_id

func get_akashic_entry(entry_id):
	if akashic_entries.has(entry_id):
		return akashic_entries[entry_id]
	return null

func find_entries_by_tag(tag):
	var result = []
	for entry_id in akashic_entries:
		var entry = akashic_entries[entry_id]
		if tag in entry.tags:
			result.append(entry)
	return result

func find_entries_by_dimension(dimension):
	var result = []
	for entry_id in akashic_entries:
		var entry = akashic_entries[entry_id]
		if entry.position.dimension == dimension:
			result.append(entry)
	return result

func connect_entries(source_id, target_id):
	if akashic_entries.has(source_id) and akashic_entries.has(target_id):
		var source = akashic_entries[source_id]
		var target = akashic_entries[target_id]
		
		if not target in source.connections:
			source.connections.append(target)
			save_akashic_records()
			return true
	return false

func save_akashic_records():
	var file = File.new()
	var data = {}
	
	for entry_id in akashic_entries:
		data[entry_id] = akashic_entries[entry_id].to_dict()
	
	file.open("user://akashic_records.json", File.WRITE)
	file.store_string(JSON.print(data, "  "))
	file.close()

func load_akashic_records():
	var file = File.new()
	if file.file_exists("user://akashic_records.json"):
		file.open("user://akashic_records.json", File.READ)
		var data_text = file.get_as_text()
		file.close()
		
		var data = JSON.parse(data_text).result
		if typeof(data) == TYPE_DICTIONARY:
			akashic_entries.clear()
			
			# First pass: Create all entries
			var temp_entries = {}
			for entry_id in data:
				var entry_data = data[entry_id]
				var position_data = entry_data.position
				
				var coord = Coordinate.new(position_data.x, position_data.y, position_data.z)
				var dim_point = DimensionalPoint.new(coord, position_data.dimension, position_data.power)
				dim_point.timestamp = position_data.timestamp
				
				var entry = AkashicEntry.new(dim_point, entry_data.content, entry_data.author, entry_data.tags)
				entry.entry_id = entry_id
				
				temp_entries[entry_id] = entry
			
			# Second pass: Connect entries
			for entry_id in data:
				var entry_data = data[entry_id]
				var entry = temp_entries[entry_id]
				
				for connection_id in entry_data.connections:
					if temp_entries.has(connection_id):
						entry.connections.append(temp_entries[connection_id])
			
			akashic_entries = temp_entries

# Spatial Maps functions
func create_spatial_map(name, dimension = 1):
	var map = SpatialMap.new(name, dimension)
	spatial_maps[name] = map
	save_spatial_maps()
	emit_signal("map_created", name)
	return name

func get_spatial_map(name):
	if spatial_maps.has(name):
		return spatial_maps[name]
	return null

func add_point_to_map(map_name, key, point_data):
	if spatial_maps.has(map_name):
		spatial_maps[map_name].add_point(key, point_data)
		save_spatial_maps()
		return true
	return false

func add_entity_to_map(map_name, entity_id, entity_data):
	if spatial_maps.has(map_name):
		spatial_maps[map_name].add_entity(entity_id, entity_data)
		save_spatial_maps()
		return true
	return false

func save_spatial_maps():
	var file = File.new()
	var data = {}
	
	for map_name in spatial_maps:
		data[map_name] = spatial_maps[map_name].to_dict()
	
	file.open("user://spatial_maps.json", File.WRITE)
	file.store_string(JSON.print(data, "  "))
	file.close()

func load_spatial_maps():
	var file = File.new()
	if file.file_exists("user://spatial_maps.json"):
		file.open("user://spatial_maps.json", File.READ)
		var data_text = file.get_as_text()
		file.close()
		
		var data = JSON.parse(data_text).result
		if typeof(data) == TYPE_DICTIONARY:
			spatial_maps.clear()
			
			for map_name in data:
				var map_data = data[map_name]
				var map = SpatialMap.new(map_name, map_data.dimension)
				map.creation_time = map_data.creation_time
				map.last_update = map_data.last_update
				
				# Load grid points
				for key in map_data.grid:
					var point_data = map_data.grid[key]
					var coord = Coordinate.new(point_data.x, point_data.y, point_data.z)
					var dim_point = DimensionalPoint.new(coord, point_data.dimension, point_data.power)
					dim_point.timestamp = point_data.timestamp
					map.add_point(key, dim_point)
				
				# Load entities
				for entity_id in map_data.entities:
					map.add_entity(entity_id, map_data.entities[entity_id])
				
				spatial_maps[map_name] = map

# Notepad3D functions
func create_notepad(name, tags = []):
	var notebook = Notepad3D.new(name, tags)
	notepad_notebooks[name] = notebook
	save_notepad_notebooks()
	emit_signal("notebook_updated", name)
	return name

func get_notepad(name):
	if notepad_notebooks.has(name):
		return notepad_notebooks[name]
	return null

func add_cell_to_notepad(notebook_name, position, content, color = Color.white):
	if notepad_notebooks.has(notebook_name):
		var coord = Coordinate.new(position.x, position.y, position.z)
		var cell = Notepad3DCell.new(coord, content, color)
		notepad_notebooks[notebook_name].add_cell(cell)
		save_notepad_notebooks()
		emit_signal("notebook_updated", notebook_name)
		return cell.cell_id
	return null

func get_cell_from_notepad(notebook_name, cell_id):
	if notepad_notebooks.has(notebook_name):
		return notepad_notebooks[notebook_name].get_cell(cell_id)
	return null

func get_cell_at_position(notebook_name, position):
	if notepad_notebooks.has(notebook_name):
		var coord = Coordinate.new(position.x, position.y, position.z)
		return notepad_notebooks[notebook_name].get_cell_at_position(coord)
	return null

func save_notepad_notebooks():
	var file = File.new()
	var data = {}
	
	for notebook_name in notepad_notebooks:
		data[notebook_name] = notepad_notebooks[notebook_name].to_dict()
	
	file.open("user://notepad3d_notebooks.json", File.WRITE)
	file.store_string(JSON.print(data, "  "))
	file.close()

func load_notepad_notebooks():
	var file = File.new()
	if file.file_exists("user://notepad3d_notebooks.json"):
		file.open("user://notepad3d_notebooks.json", File.READ)
		var data_text = file.get_as_text()
		file.close()
		
		var data = JSON.parse(data_text).result
		if typeof(data) == TYPE_DICTIONARY:
			notepad_notebooks.clear()
			
			for notebook_name in data:
				var notebook_data = data[notebook_name]
				var notebook = Notepad3D.new(notebook_name, notebook_data.tags)
				notebook.creation_time = notebook_data.creation_time
				notebook.last_update = notebook_data.last_update
				
				# Load cells
				for cell_id in notebook_data.cells:
					var cell_data = notebook_data.cells[cell_id]
					var position_data = cell_data.position
					var color_data = cell_data.color
					
					var coord = Coordinate.new(position_data.x, position_data.y, position_data.z)
					var color = Color(color_data.r, color_data.g, color_data.b, color_data.a)
					
					var cell = Notepad3DCell.new(coord, cell_data.content, color)
					cell.cell_id = cell_id
					cell.last_edit = cell_data.last_edit
					notebook.add_cell(cell)
				
				notepad_notebooks[notebook_name] = notebook

# Conversion functions
func create_notepad_from_akashic(entry_ids, notebook_name):
	if notepad_notebooks.has(notebook_name):
		return false
	
	var notebook = Notepad3D.new(notebook_name)
	var z_index = 0
	
	for entry_id in entry_ids:
		if akashic_entries.has(entry_id):
			var entry = akashic_entries[entry_id]
			var coord = Coordinate.new(entry.position.coordinate.x, entry.position.coordinate.y, z_index)
			var color = Color(1.0, 0.8, 0.2, 1.0)  # Amber color for akashic entries
			
			var cell = Notepad3DCell.new(coord, entry.content, color)
			notebook.add_cell(cell)
			
			z_index += 1
	
	notepad_notebooks[notebook_name] = notebook
	save_notepad_notebooks()
	emit_signal("notebook_updated", notebook_name)
	return true

func create_map_from_akashic(entry_ids, map_name, dimension = 1):
	if spatial_maps.has(map_name):
		return false
	
	var map = SpatialMap.new(map_name, dimension)
	var i = 0
	
	for entry_id in entry_ids:
		if akashic_entries.has(entry_id):
			var entry = akashic_entries[entry_id]
			var key = "point_%d" % i
			map.add_point(key, entry.position)
			
			var entity_id = "entity_%d" % i
			map.add_entity(entity_id, {
				"content": entry.content,
				"author": entry.author,
				"tags": entry.tags,
				"position": {
					"x": entry.position.coordinate.x,
					"y": entry.position.coordinate.y,
					"z": entry.position.coordinate.z
				}
			})
			
			i += 1
	
	spatial_maps[map_name] = map
	save_spatial_maps()
	emit_signal("map_created", map_name)
	return true

# Synergistic connections (finds relationships between entries in similar spaces)
func find_spatial_synergies(threshold = 5.0):
	var synergies = []
	
	# Iterate through all entries
	var entry_ids = akashic_entries.keys()
	for i in range(entry_ids.size()):
		var entry_a_id = entry_ids[i]
		var entry_a = akashic_entries[entry_a_id]
		
		for j in range(i + 1, entry_ids.size()):
			var entry_b_id = entry_ids[j]
			var entry_b = akashic_entries[entry_b_id]
			
			# Calculate spatial distance
			var dx = entry_a.position.coordinate.x - entry_b.position.coordinate.x
			var dy = entry_a.position.coordinate.y - entry_b.position.coordinate.y
			var dz = entry_a.position.coordinate.z - entry_b.position.coordinate.z
			
			var distance = sqrt(dx*dx + dy*dy + dz*dz)
			
			# Calculate dimensional energy (entries in same dimension have stronger synergy)
			var dim_factor = 1.0
			if entry_a.position.dimension == entry_b.position.dimension:
				dim_factor = 2.0  # Double strength for same dimension
			
			# Sacred 9 harmonic (enhance connection if distance is a multiple of 9)
			var sacred_factor = 1.0
			if abs(int(distance) % SACRED_NUMBER) < 0.1:  # Close to multiple of 9
				sacred_factor = 3.0  # Triple strength for sacred harmony
			
			# Calculate overall synergy strength
			var synergy_strength = (entry_a.position.power + entry_b.position.power) * sacred_factor * dim_factor / (distance + 1.0)
			
			if synergy_strength > threshold:
				synergies.append({
					"entry_a": entry_a_id,
					"entry_b": entry_b_id,
					"strength": synergy_strength,
					"distance": distance
				})
	
	return synergies

# Find entries in dimensional clusters
func find_dimensional_clusters(min_cluster_size = 3, max_distance = 10.0):
	var clusters = {}
	
	# Initialize clusters by dimension
	for i in range(1, MAX_DIMENSION + 1):
		clusters[i] = []
	
	# Add entries to their dimensional clusters
	for entry_id in akashic_entries:
		var entry = akashic_entries[entry_id]
		var dim = entry.position.dimension
		
		if dim >= 1 and dim <= MAX_DIMENSION:
			clusters[dim].append(entry)
	
	# Find sub-clusters by spatial proximity
	var result_clusters = []
	for dim in clusters:
		var entries = clusters[dim]
		
		if entries.size() < min_cluster_size:
			continue
		
		var sub_clusters = []
		var processed = {}
		
		for entry in entries:
			if processed.has(entry.entry_id):
				continue
				
			var cluster = [entry]
			processed[entry.entry_id] = true
			
			var added = true
			while added:
				added = false
				
				for other_entry in entries:
					if processed.has(other_entry.entry_id):
						continue
					
					# Check if other_entry is close to any entry in current cluster
					for cluster_entry in cluster:
						var dx = cluster_entry.position.coordinate.x - other_entry.position.coordinate.x
						var dy = cluster_entry.position.coordinate.y - other_entry.position.coordinate.y
						var dz = cluster_entry.position.coordinate.z - other_entry.position.coordinate.z
						
						var distance = sqrt(dx*dx + dy*dy + dz*dz)
						
						if distance <= max_distance:
							cluster.append(other_entry)
							processed[other_entry.entry_id] = true
							added = true
							break
			
			if cluster.size() >= min_cluster_size:
				sub_clusters.append({
					"dimension": dim,
					"entries": cluster,
					"size": cluster.size()
				})
		
		result_clusters.append_array(sub_clusters)
	
	return result_clusters
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/spatial_world_storage.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/startup_example.gd
# SIZE: 2372 bytes
extends Node

# This script demonstrates how to initialize and use the ThreadManager and WordProcessorTasks
# in the 12 Turns System

# References
var thread_manager: ThreadManager
var word_processor: WordProcessorTasks

func _ready():
	print("Starting 12 Turns System initialization...")
	
	# Initialize ThreadManager with auto thread count
	thread_manager = ThreadManager.new()
	add_child(thread_manager)
	
	# Initialize WordProcessorTasks
	word_processor = WordProcessorTasks.new()
	add_child(word_processor)
	
	# Connect signals to handle task completion
	thread_manager.connect("task_completed", Callable(self, "_on_task_completed"))
	thread_manager.connect("task_failed", Callable(self, "_on_task_failed"))
	thread_manager.connect("task_group_completed", Callable(self, "_on_task_group_completed"))
	
	print("12 Turns System initialized with %d threads" % thread_manager.thread_count)
	
	# Example: Process a batch of words
	_run_example_batch()

# Example function demonstrating batch word processing
func _run_example_batch():
	print("\nRunning example batch processing...")
	
	var words = ["divine", "light", "create", "universe", "eternal"]
	var params_array = []
	
	# Create parameter dictionaries for each word
	for word in words:
		params_array.append({
			"word": word,
			"dimension": 3,  # 4D - Time dimension
			"cosmic_age": 1
		})
	
	# Process words in parallel using the thread manager
	var task_ids = thread_manager.add_batch_tasks(
		Callable(word_processor, "calculate_word_power"),
		params_array,
		"example_batch"
	)
	
	print("Batch started with %d tasks" % task_ids.size())
	print("Processing words: %s" % words)

# Task completion handlers
func _on_task_completed(task_id, result):
	if result is Dictionary and result.has("word") and result.has("power"):
		# This is a word power calculation result
		var word = result.word
		var power = result.power
		var tier = result.tier
		
		print("Word processed: %s = %.2f power (%s tier)" % [word, power, tier])
	
func _on_task_failed(task_id, error):
	print("Task %s failed with error: %s" % [task_id, error])

func _on_task_group_completed(group_id):
	if group_id == "example_batch":
		print("\nAll words in example batch have been processed")
		print("Thread statistics: %s" % thread_manager.get_statistics())
		print("\nThe ThreadManager and WordProcessorTasks are now ready for use in your game!")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/startup_example.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/storage_integration_system.gd
# SIZE: 17422 bytes
extends Node

class_name StorageIntegrationSystem

# Storage limits in bytes
const STORAGE_LIMITS = {
	"icloud_free": 5 * 1024 * 1024 * 1024,      # 5GB
	"icloud_paid": 200 * 1024 * 1024 * 1024,    # 200GB
	"google_free": 15 * 1024 * 1024 * 1024,     # 15GB
	"google_paid": 100 * 1024 * 1024 * 1024,    # 100GB
	"local_drive": 2 * 1024 * 1024 * 1024 * 1024 # 2TB
}

# Wish system constants
const MAX_WISHES_PER_DAY = 100
const WISH_TOKEN_COST = 10 # Default token cost per wish

# Storage paths
var storage_paths = {
	"icloud": "/mnt/c/Users/Percision 15/icloud_sync",
	"google": "/mnt/c/Users/Percision 15/google_drive",
	"local": "/mnt/c/Users/Percision 15",
	"wishes": "/mnt/c/Users/Percision 15/12_turns_system/wishes"
}

# Storage status tracking
var storage_status = {
	"icloud": {
		"connected": false,
		"used": 0,
		"total": STORAGE_LIMITS.icloud_free,
		"type": "free"
	},
	"google": {
		"connected": false,
		"used": 0,
		"total": STORAGE_LIMITS.google_free,
		"type": "free"
	},
	"local": {
		"connected": true,
		"used": 0,
		"total": STORAGE_LIMITS.local_drive,
		"type": "local"
	}
}

# Wish system tracking
var wish_system = {
	"today_count": 0,
	"total_count": 0,
	"tokens_used": 0,
	"wish_history": [],
	"active_wishes": [],
	"pending_wishes": []
}

# Integration references
var _akashic_bridge = null
var _terminal_interface = null

# Signals
signal storage_connected(platform, status)
signal storage_updated(platform, stats)
signal wish_created(wish_id, wish_text)
signal wish_completed(wish_id)
signal wish_limit_reached(count)
signal terminal_command_generated(command)

func _ready():
	# Initialize the system
	_initialize_system()

func _initialize_system():
	# Create required directories
	_ensure_directories_exist()
	
	# Connect to Akashic Bridge if available
	_connect_to_akashic_bridge()
	
	# Calculate storage usage
	_update_storage_usage()
	
	# Load wish history
	_load_wish_history()
	
	print("Storage Integration System initialized")
	print("Connected to local storage: " + str(storage_status.local.used / 1024 / 1024 / 1024) + "GB used of " + str(storage_status.local.total / 1024 / 1024 / 1024) + "GB")

# Directory management
func _ensure_directories_exist():
	var dir = Directory.new()
	
	for key in storage_paths:
		if not dir.dir_exists(storage_paths[key]):
			dir.make_dir_recursive(storage_paths[key])
			print("Created directory: " + storage_paths[key])

# Connection management
func _connect_to_akashic_bridge():
	# Try to find the Akashic Bridge
	if has_node("/root/ClaudeAkashicBridge") or get_node_or_null("/root/ClaudeAkashicBridge"):
		_akashic_bridge = get_node("/root/ClaudeAkashicBridge")
		print("Connected to existing Claude Akashic Bridge")
	else:
		# Check if the class exists
		if ClassDB.class_exists("ClaudeAkashicBridge"):
			_akashic_bridge = ClaudeAkashicBridge.new()
			add_child(_akashic_bridge)
			print("Created new Claude Akashic Bridge instance")

# Storage usage calculations
func _update_storage_usage():
	# Update local storage usage
	storage_status.local.used = _calculate_directory_size(storage_paths.local)
	emit_signal("storage_updated", "local", storage_status.local)
	
	# Update iCloud if connected
	if storage_status.icloud.connected:
		storage_status.icloud.used = _calculate_directory_size(storage_paths.icloud)
		emit_signal("storage_updated", "icloud", storage_status.icloud)
	
	# Update Google Drive if connected
	if storage_status.google.connected:
		storage_status.google.used = _calculate_directory_size(storage_paths.google)
		emit_signal("storage_updated", "google", storage_status.google)

func _calculate_directory_size(path):
	var dir = Directory.new()
	var size = 0
	
	if dir.open(path) == OK:
		dir.list_dir_begin(true, true)
		var file_name = dir.get_next()
		
		while file_name != "":
			if dir.current_is_dir():
				size += _calculate_directory_size(path.plus_file(file_name))
			else:
				var file_path = path.plus_file(file_name)
				var file = File.new()
				if file.open(file_path, File.READ) == OK:
					size += file.get_len()
					file.close()
			
			file_name = dir.get_next()
		
		dir.list_dir_end()
	
	return size

# Wish system functions
func _load_wish_history():
	var wish_path = storage_paths.wishes.plus_file("wish_history.json")
	var file = File.new()
	
	if file.file_exists(wish_path):
		if file.open(wish_path, File.READ) == OK:
			var json_text = file.get_as_text()
			file.close()
			
			var parse_result = JSON.parse(json_text)
			if parse_result.error == OK:
				var data = parse_result.result
				wish_system.total_count = data.get("total_count", 0)
				wish_system.wish_history = data.get("wish_history", [])
				
				# Calculate today's count
				var today = OS.get_date()
				var today_str = str(today.year) + "-" + str(today.month) + "-" + str(today.day)
				
				wish_system.today_count = 0
				for wish in wish_system.wish_history:
					if wish.date == today_str:
						wish_system.today_count += 1
				
				print("Loaded wish history: " + str(wish_system.total_count) + " total wishes, " + str(wish_system.today_count) + " today")

# Public API methods

# Connect to cloud storage
func connect_cloud_storage(platform, credentials = {}):
	if not (platform == "icloud" or platform == "google"):
		push_error("Invalid platform: " + platform)
		return false
	
	print("Connecting to " + platform + " storage...")
	
	# Simulate connection
	var success = randf() > 0.2 # 80% chance of success
	
	if success:
		storage_status[platform].connected = true
		
		# Check if using paid tier
		if credentials.has("tier") and credentials.tier == "paid":
			if platform == "icloud":
				storage_status[platform].total = STORAGE_LIMITS.icloud_paid
				storage_status[platform].type = "paid"
			elif platform == "google":
				storage_status[platform].total = STORAGE_LIMITS.google_paid
				storage_status[platform].type = "paid"
		
		# Update storage usage
		_update_storage_usage()
		
		emit_signal("storage_connected", platform, true)
		print(platform + " storage connected successfully")
	else:
		emit_signal("storage_connected", platform, false)
		print(platform + " storage connection failed")
	
	return success

# Create a new wish
func create_wish(wish_text, priority = "normal", metadata = {}):
	# Check daily limit
	if wish_system.today_count >= MAX_WISHES_PER_DAY:
		push_warning("Daily wish limit reached")
		emit_signal("wish_limit_reached", wish_system.today_count)
		return null
	
	# Create wish ID
	var wish_id = "wish_" + str(OS.get_unix_time()) + "_" + str(randi() % 10000)
	
	# Get current date
	var date = OS.get_date()
	var date_str = str(date.year) + "-" + str(date.month) + "-" + str(date.day)
	
	# Estimate token cost
	var token_cost = int(wish_text.length() / 4) # Rough estimate
	if token_cost < WISH_TOKEN_COST:
		token_cost = WISH_TOKEN_COST
	
	# Create wish object
	var wish = {
		"id": wish_id,
		"text": wish_text,
		"priority": priority,
		"date": date_str,
		"timestamp": OS.get_unix_time(),
		"status": "pending",
		"token_cost": token_cost,
		"metadata": metadata
	}
	
	# Store wish
	_store_wish(wish)
	
	# Update counters
	wish_system.today_count += 1
	wish_system.total_count += 1
	wish_system.tokens_used += token_cost
	wish_system.active_wishes.append(wish)
	wish_system.wish_history.append(wish)
	
	# Save wish history
	_save_wish_history()
	
	# Store in Akashic Records if connected
	if _akashic_bridge:
		_akashic_bridge.update_wish(wish_id, "pending", {
			"text": wish_text,
			"priority": priority,
			"token_cost": token_cost
		})
	
	# Generate terminal command for this wish
	var command = _generate_terminal_command(wish)
	if command:
		emit_signal("terminal_command_generated", command)
	
	emit_signal("wish_created", wish_id, wish_text)
	print("Created wish: " + wish_id)
	
	return wish

# Store files across available storage
func store_file(file_path, preferred_storage = "auto"):
	var file = File.new()
	
	if not file.file_exists(file_path):
		push_error("File does not exist: " + file_path)
		return false
	
	# Get file size
	file.open(file_path, File.READ)
	var file_size = file.get_len()
	file.close()
	
	# Get file name
	var file_name = file_path.get_file()
	
	# Determine best storage location
	var target_storage = preferred_storage
	if target_storage == "auto":
		target_storage = _determine_best_storage(file_size)
	
	if not storage_status[target_storage].connected:
		push_error("Selected storage not connected: " + target_storage)
		return false
	
	# Check if there's enough space
	if storage_status[target_storage].used + file_size > storage_status[target_storage].total:
		push_error("Not enough space in " + target_storage + " storage")
		return false
	
	# Create target path
	var target_path = storage_paths[target_storage].plus_file(file_name)
	
	# Copy the file
	var dir = Directory.new()
	if dir.copy(file_path, target_path) == OK:
		# Update storage usage
		_update_storage_usage()
		print("File stored successfully in " + target_storage + ": " + file_name)
		return true
	else:
		push_error("Failed to copy file to " + target_storage)
		return false

# Complete a wish
func complete_wish(wish_id, result = "completed", output = ""):
	var wish_index = -1
	
	# Find the wish in active wishes
	for i in range(wish_system.active_wishes.size()):
		if wish_system.active_wishes[i].id == wish_id:
			wish_index = i
			break
	
	if wish_index == -1:
		push_error("Wish not found: " + wish_id)
		return false
	
	# Update wish status
	wish_system.active_wishes[wish_index].status = result
	wish_system.active_wishes[wish_index].completion_time = OS.get_unix_time()
	wish_system.active_wishes[wish_index].output = output
	
	# Move from active to history
	var completed_wish = wish_system.active_wishes[wish_index]
	wish_system.active_wishes.remove(wish_index)
	
	# Update in Akashic Records if connected
	if _akashic_bridge:
		_akashic_bridge.update_wish(wish_id, result, {
			"completion_time": completed_wish.completion_time,
			"output": output
		})
	
	# Save wish history
	_save_wish_history()
	
	emit_signal("wish_completed", wish_id)
	print("Completed wish: " + wish_id)
	
	return true

# Generate terminal command for wish execution
func generate_terminal_command(wish_text):
	# Analyze wish text to generate appropriate command
	var command = ""
	
	# Basic commands based on keywords
	if wish_text.find("file") >= 0 or wish_text.find("files") >= 0:
		command = "ls -la " + storage_paths.local
	elif wish_text.find("storage") >= 0 or wish_text.find("space") >= 0:
		command = "df -h"
	elif wish_text.find("wish") >= 0 and (wish_text.find("list") >= 0 or wish_text.find("show") >= 0):
		command = "cat " + storage_paths.wishes.plus_file("wish_history.json")
	elif wish_text.find("terminal") >= 0 or wish_text.find("console") >= 0:
		command = "bash " + storage_paths.local.plus_file("12_turns_system/claude_terminal_interface.sh")
	elif wish_text.find("game") >= 0 or wish_text.find("play") >= 0:
		command = "bash " + storage_paths.local.plus_file("12_turns_system/start_game.sh")
	else:
		# If no specific command identified, create a more complex one
		command = _create_complex_command(wish_text)
	
	return command

# Interface management functions
func get_terminal_output_text(wish_text, line_count = 10):
	var output = []
	
	# Generate interesting output based on wish text
	output.append("======== WISH PROCESSING ========")
	
	# Add the wish text as a header
	output.append("WISH: " + wish_text)
	output.append("-------------------------------")
	
	# Generate status lines
	output.append("Connecting to dimensional gates...")
	
	if randf() > 0.5:
		output.append("Gate 0 (Physical): OPEN")
	else:
		output.append("Gate 0 (Physical): CONNECTED")
	
	if randf() > 0.3:
		output.append("Gate 1 (Experience): OPEN")
	else:
		output.append("Gate 1 (Experience): PARTIAL")
	
	if randf() > 0.7:
		output.append("Gate 2 (Transcendent): FLUCTUATING")
	else:
		output.append("Gate 2 (Transcendent): CLOSED")
	
	# Add processing steps
	output.append("Analyzing wish content...")
	output.append("Tokenizing request: " + str(int(wish_text.length() / 4)) + " tokens")
	output.append("Synchronizing storage systems...")
	output.append("Accessing Akashic records...")
	
	# Success or adjustment message
	if randf() > 0.7:
		output.append("WISH ADJUSTMENT REQUIRED")
		output.append("Reprocessing with dimensional filters...")
	else:
		output.append("WISH ACCEPTED for processing")
		
	# Add remaining wishes
	var remaining = MAX_WISHES_PER_DAY - wish_system.today_count
	if remaining < 0:
		remaining = 0
	output.append("Remaining wishes today: " + str(remaining))
	
	# Ensure we have at least the requested number of lines
	while output.size() < line_count:
		output.append("Processing layer " + str(output.size()) + "...")
	
	# If we have too many lines, trim
	if output.size() > line_count:
		output = output.slice(0, line_count - 1)
	
	# Add ending
	output.append("==============================")
	
	return output

# Get the storage status for UI display
func get_storage_status():
	return {
		"local": {
			"used_gb": storage_status.local.used / 1024.0 / 1024.0 / 1024.0,
			"total_gb": storage_status.local.total / 1024.0 / 1024.0 / 1024.0,
			"percentage": (storage_status.local.used * 100.0) / storage_status.local.total,
			"connected": storage_status.local.connected
		},
		"icloud": {
			"used_gb": storage_status.icloud.used / 1024.0 / 1024.0 / 1024.0,
			"total_gb": storage_status.icloud.total / 1024.0 / 1024.0 / 1024.0,
			"percentage": (storage_status.icloud.used * 100.0) / storage_status.icloud.total,
			"connected": storage_status.icloud.connected,
			"type": storage_status.icloud.type
		},
		"google": {
			"used_gb": storage_status.google.used / 1024.0 / 1024.0 / 1024.0,
			"total_gb": storage_status.google.total / 1024.0 / 1024.0 / 1024.0,
			"percentage": (storage_status.google.used * 100.0) / storage_status.google.total,
			"connected": storage_status.google.connected,
			"type": storage_status.google.type
		},
		"wishes": {
			"today": wish_system.today_count,
			"total": wish_system.total_count,
			"remaining": MAX_WISHES_PER_DAY - wish_system.today_count,
			"active": wish_system.active_wishes.size()
		}
	}

# Private methods
func _store_wish(wish):
	var dir = Directory.new()
	
	# Ensure wishes directory exists
	if not dir.dir_exists(storage_paths.wishes):
		dir.make_dir_recursive(storage_paths.wishes)
	
	# Create individual wish file
	var wish_file_path = storage_paths.wishes.plus_file(wish.id + ".json")
	var file = File.new()
	
	if file.open(wish_file_path, File.WRITE) == OK:
		file.store_string(JSON.print(wish, "  "))
		file.close()
	else:
		push_error("Failed to write wish file: " + wish_file_path)

func _save_wish_history():
	var wish_history_path = storage_paths.wishes.plus_file("wish_history.json")
	var file = File.new()
	
	if file.open(wish_history_path, File.WRITE) == OK:
		var data = {
			"total_count": wish_system.total_count,
			"wish_history": wish_system.wish_history
		}
		
		file.store_string(JSON.print(data, "  "))
		file.close()
	else:
		push_error("Failed to save wish history")

func _determine_best_storage(file_size):
	# Default to local storage
	var best_storage = "local"
	var best_free_percentage = 0
	
	# Check all connected storages
	for platform in storage_status:
		if storage_status[platform].connected:
			var free_space = storage_status[platform].total - storage_status[platform].used
			if free_space >= file_size:
				var free_percentage = (free_space * 100.0) / storage_status[platform].total
				if free_percentage > best_free_percentage:
					best_free_percentage = free_percentage
					best_storage = platform
	
	return best_storage

func _generate_terminal_command(wish):
	return generate_terminal_command(wish.text)

func _create_complex_command(wish_text):
	# Create a more complex terminal command based on wish text
	
	# Extract potential targets
	var targets = []
	
	if wish_text.find("notepad") >= 0 or wish_text.find("3d") >= 0:
		targets.append("notepad3d")
	
	if wish_text.find("word") >= 0 or wish_text.find("text") >= 0:
		targets.append("word_game")
	
	if wish_text.find("terminal") >= 0 or wish_text.find("console") >= 0:
		targets.append("terminal_interface")
	
	if wish_text.find("wish") >= 0 or wish_text.find("desire") >= 0:
		targets.append("wish_dimension")
	
	if wish_text.find("3 interface") >= 0 or wish_text.find("three interface") >= 0:
		targets.append("multi_terminal")
	
	# Create a combined command
	var command = ""
	
	if targets.size() > 0:
		# Choose a target
		var target = targets[randi() % targets.size()]
		
		# Create command based on target
		match target:
			"notepad3d":
				command = "bash " + storage_paths.local.plus_file("12_turns_system/digital_printer.sh") + " 'create 3d notepad interface'"
			"word_game":
				command = "bash " + storage_paths.local.plus_file("12_turns_system/word_game.sh")
			"terminal_interface":
				command = "bash " + storage_paths.local.plus_file("12_turns_system/terminal_interface.sh")
			"wish_dimension":
				command = "bash " + storage_paths.local.plus_file("12_turns_system/run_wish_dimension_demo.sh")
			"multi_terminal":
				command = "bash " + storage_paths.local.plus_file("12_turns_system/multi_terminal_controller.sh")
			_:
				command = "echo 'Processing wish: " + wish_text + "'"
	else:
		# Generic command if no specific target
		command = "echo 'Processing wish: " + wish_text + "' && bash " + storage_paths.local.plus_file("12_turns_system/turn_manager.sh")
	
	return command
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/storage_integration_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/summarization_test.gd
# SIZE: 10299 bytes
extends Node

# Summarization Test Script
# Tests the TextSummarizationSystem with a sample text

var text_summarizer = null

func _ready():
	# Initialize the text summarizer
	text_summarizer = TextSummarizationSystem.new()
	add_child(text_summarizer)
	
	# Connect signals
	text_summarizer.connect("processing_started", self, "_on_processing_started")
	text_summarizer.connect("dimension_summary_completed", self, "_on_dimension_completed")
	text_summarizer.connect("processing_completed", self, "_on_processing_completed")
	
	# Load a sample text for summarization
	var sample_text = load_sample_text()
	
	# Process the text
	print("\n=== Starting Text Summarization Test ===\n")
	var summaries = text_summarizer.generate_summary(sample_text, 16900, "dimensional")
	
	# Display results
	print("\n=== Final Summaries ===\n")
	
	# Show a compressed summary that fits within token limits
	print("COMBINED SUMMARY:")
	print(text_summarizer.get_flexible_summary(5000))
	
	print("\n=== Test Complete ===\n")

func _on_processing_started(text_length, token_count):
	print("Processing started:")
	print("- Text length: " + str(text_length) + " characters")
	print("- Estimated token count: " + str(token_count) + " tokens")

func _on_dimension_completed(dimension, summary_length, token_count):
	print("Dimension summary completed: " + dimension)
	print("- Summary length: " + str(summary_length) + " characters")
	print("- Estimated token count: " + str(token_count) + " tokens")

func _on_processing_completed(total_time, summary_count):
	print("\nProcessing completed in " + str(total_time) + " seconds")
	print("Generated " + str(summary_count) + " summary levels")

func load_sample_text():
	# Here we'll provide a sample text for testing
	# This could also be loaded from a file
	return """
The integration of artificial intelligence into educational systems represents one of the most significant transformations in modern pedagogy. As AI technologies continue to evolve and mature, their impact on teaching methodologies, learning outcomes, and educational administration has grown exponentially. This comprehensive analysis examines the multifaceted implications of AI integration in educational contexts, exploring both the transformative potential and the critical challenges that educators, institutions, and policymakers must navigate.

At its core, educational AI encompasses a broad spectrum of technologies designed to enhance, supplement, or partially automate aspects of the teaching and learning process. These include intelligent tutoring systems that adapt to individual learning styles, automated assessment tools that provide immediate feedback, natural language processing applications that facilitate language acquisition, and sophisticated data analytics platforms that identify patterns in student performance. The common thread uniting these diverse applications is their capacity to process vast amounts of information, recognize patterns, and generate personalized responses or recommendations that would be impractical or impossible for human educators to produce at scale.

The potential benefits of AI integration in education are substantial and far-reaching. Perhaps most significantly, AI systems enable unprecedented levels of personalization in educational experiences. Traditional classroom models, constrained by fixed curricula and limited teacher attention, inevitably produce one-size-fits-all approaches that may not adequately address the diverse needs, abilities, and learning styles of individual students. AI-powered adaptive learning platforms can dynamically adjust content difficulty, pacing, and presentation based on real-time assessment of student performance, ensuring that each learner receives appropriately challenging material. This personalization extends beyond academic content to include customized feedback, targeted remediation, and individualized learning pathways that maximize student engagement and achievement.

Beyond personalization, AI technologies offer powerful tools for expanding educational access and equity. Distance learning platforms enhanced with AI capabilities can deliver high-quality educational experiences to students in remote or underserved communities, potentially narrowing the persistent achievement gaps between geographic regions and socioeconomic groups. Automated translation and language processing systems can reduce barriers for non-native speakers, while assistive technologies supported by AI can create more inclusive learning environments for students with disabilities. As these technologies become more sophisticated and widely implemented, they have the potential to democratize access to educational opportunities that have historically been distributed unevenly.

From an administrative perspective, AI systems can dramatically improve institutional efficiency and effectiveness. Automated grading of objective assessments frees teacher time for more substantive instructional activities, while predictive analytics can identify at-risk students for early intervention. Course scheduling, resource allocation, and enrollment management can be optimized through AI algorithms that process complex variables more comprehensively than traditional methods. These operational efficiencies not only reduce administrative costs but also potentially improve student outcomes by enabling more strategic allocation of human and material resources.

However, the integration of AI in educational contexts also presents significant challenges and potential pitfalls that must be carefully considered. Primary among these concerns is the risk of algorithmic bias and inequity. AI systems learn from historical data, which may contain embedded biases related to race, gender, socioeconomic status, or other factors. If not rigorously monitored and corrected, these systems may perpetuate or even amplify existing inequities in educational outcomes. For instance, predictive models that track student performance might inadvertently penalize students from disadvantaged backgrounds who face systemic barriers to academic success, potentially reinforcing rather than reducing achievement gaps.

Privacy and data security represent another critical concern in educational AI implementation. The personalization capabilities that make AI systems valuable depend on collecting and analyzing substantial amounts of student data, including academic performance, behavioral patterns, and even psychological characteristics. This data collection raises important questions about consent, ownership, and protection, particularly for minor students who may not fully understand the implications of their digital footprint. Educational institutions must develop robust governance frameworks that balance the benefits of data-driven instruction with the fundamental right to privacy.

The relationship between AI technologies and human educators constitutes a third area of concern. While few advocate for the wholesale replacement of teachers with automated systems, the implementation of AI in educational settings inevitably shifts the role and responsibilities of human educators. This transition may create anxiety, resistance, or confusion among teaching professionals who fear obsolescence or lack adequate training in new technological tools. Successfully integrating AI requires thoughtful attention to professional development, clear communication about the complementary roles of human and artificial intelligence, and ongoing evaluation of how these technologies affect the working conditions and job satisfaction of educational personnel.

Looking toward the future, the continued evolution of AI capabilities will likely accelerate the transformation of educational systems. Emerging technologies such as natural language generation, which can produce human-like written content, may revolutionize writing instruction and assessment. Virtual reality integrated with AI could create immersive, adaptive learning environments that transform how students engage with complex or abstract concepts. Sophisticated tutoring systems might approach the effectiveness of one-on-one human instruction, potentially restructuring how educational resources are allocated and delivered.

However, realizing the full potential of these technological advancements requires more than simply implementing new tools. It demands fundamental reconsideration of educational objectives, pedagogical approaches, assessment methods, and institutional structures. The most successful AI integrations will likely occur in contexts where technology serves clearly defined educational purposes rather than driving change for its own sake. This requires ongoing collaboration between educators, technologists, policymakers, and other stakeholders to ensure that AI implementation aligns with broader educational values and goals.

To guide this complex transformation, several principles emerge as particularly important. First, human centrality must remain paramount, with AI systems designed to support rather than supplant the essential human relationships that foster learning. Second, equity considerations should be embedded throughout the design, implementation, and evaluation of educational AI, with particular attention to how these technologies affect traditionally marginalized communities. Third, transparency in algorithms and data use should be maximized to build trust and enable critical assessment of AI systems. Finally, flexibility and adaptability should characterize AI implementation, recognizing that educational needs and technological capabilities will continue to evolve.

In conclusion, the integration of artificial intelligence in education represents both an extraordinary opportunity and a profound challenge. The potential to personalize learning, expand access, and improve outcomes is counterbalanced by concerns about equity, privacy, and the changing role of human educators. Navigating this complex landscape requires thoughtful collaboration, ethical vigilance, and a commitment to ensuring that technological advancement serves the fundamental purpose of education: empowering all learners to develop the knowledge, skills, and dispositions they need to flourish in an increasingly complex world.
"""
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/summarization_test.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/system_integrator.gd
# SIZE: 10052 bytes
extends Node

# System Integrator
# Initializes and connects all 3D visualization and storage components
# Serves as a bridge between main controller and akashic/notepad systems

# ----- NODE REFERENCES -----
onready var main_controller = $"/root/MainController" if has_node("/root/MainController") else null

# ----- COMPONENT REFERENCES -----
var spatial_storage: SpatialWorldStorage
var spatial_visualizer: Notepad3DVisualizer
var integration: SpatialNotepadIntegration
var akashic_controller: AkashicNotepadController
var word_manifestation_system = null
var divine_word_processor = null

# ----- STATE VARIABLES -----
var initialized = false
var startup_complete = false
var auto_visualize_entries = true
var initial_dimension = 3  # Default to 3D dimension

# ----- INITIALIZATION -----
func _ready():
    print("System Integrator initializing...")
    
    # Initialization is done in stages to ensure proper dependencies
    call_deferred("initialize_systems")

func initialize_systems():
    # Create storage system
    spatial_storage = SpatialWorldStorage.new()
    add_child(spatial_storage)
    
    # Create akashic controller
    akashic_controller = AkashicNotepadController.new()
    add_child(akashic_controller)
    
    # Setup connections to main controller if available
    if main_controller:
        # Connect controller signals
        main_controller.connect("turn_advanced", self, "_on_turn_advanced")
        main_controller.connect("note_created", self, "_on_note_created")
        main_controller.connect("word_manifested", self, "_on_word_manifested")
        
        # Tell akashic controller about main controller
        akashic_controller.set_main_controller(main_controller)
        
        # Get reference to word processor if available
        if main_controller.has_method("get_word_processor"):
            divine_word_processor = main_controller.get_word_processor()
        
        # Get initial dimension from main controller
        initial_dimension = main_controller.current_turn
    
    # Connect components
    connect_components()
    
    # Setup 3D visualization
    setup_visualization()
    
    # Complete initialization
    initialized = true
    print("System Integrator initialized")
    
    # Perform startup operations after a short delay to ensure all systems are ready
    var startup_timer = Timer.new()
    startup_timer.wait_time = 1.0
    startup_timer.one_shot = true
    startup_timer.connect("timeout", self, "complete_startup")
    add_child(startup_timer)
    startup_timer.start()

func complete_startup():
    # Perform any operations that should happen after all systems are initialized
    if auto_visualize_entries and akashic_controller:
        akashic_controller.visualize_akashic_record(initial_dimension)
    
    startup_complete = true
    print("Startup complete - systems operational")
    
    # Extend main controller's command system
    extend_command_system()

# ----- SETUP FUNCTIONS -----
func connect_components():
    # Find or create word manifestation system
    word_manifestation_system = get_node_or_null("/root/WordManifestationSystem")
    
    if not word_manifestation_system and has_node("/root/DivineWordProcessor"):
        # Create word manifestation system if it doesn't exist
        word_manifestation_system = load("res://word_manifestation_system.gd").new()
        add_child(word_manifestation_system)
        
        # Connect to word processor
        var word_processor = get_node("/root/DivineWordProcessor")
        if word_processor:
            word_manifestation_system.set_word_processor(word_processor)
    
    # Connect to akashic controller
    if word_manifestation_system and akashic_controller:
        akashic_controller.set_word_manifestation_system(word_manifestation_system)

func setup_visualization():
    # Create visualization scene if not already in tree
    if not has_node("VisualizationContainer"):
        var container = Spatial.new()
        container.name = "VisualizationContainer"
        add_child(container)
        
        # Create visualizer
        spatial_visualizer = Notepad3DVisualizer.new()
        spatial_visualizer.name = "Notepad3DVisualizer"
        container.add_child(spatial_visualizer)
        
        # Setup camera and environment
        _setup_visualization_camera(container)
    else:
        # Get existing visualizer
        spatial_visualizer = get_node("VisualizationContainer/Notepad3DVisualizer")
    
    # Connect visualizer to akashic controller
    if spatial_visualizer and akashic_controller:
        akashic_controller.set_visualizer(spatial_visualizer)
        
        # Connect additional signals
        akashic_controller.connect("record_created", self, "_on_record_created")
        akashic_controller.connect("notebook_created", self, "_on_notebook_created")
        akashic_controller.connect("akashic_synergy_detected", self, "_on_akashic_synergy_detected")
        
        print("3D visualization system setup complete")

func _setup_visualization_camera(container):
    # Create camera
    var camera = Camera.new()
    camera.name = "VisualizationCamera"
    camera.translation = Vector3(0, 5, 10)
    camera.rotation_degrees = Vector3(-30, 0, 0)
    camera.far = 1000
    camera.current = false  # Don't make current by default
    container.add_child(camera)
    
    # Create environment for visual effects
    var environment = Environment.new()
    environment.background_mode = Environment.BG_COLOR
    environment.background_color = Color(0.01, 0.01, 0.05)
    environment.ambient_light_color = Color(0.1, 0.1, 0.2)
    environment.fog_enabled = true
    environment.fog_color = Color(0.01, 0.01, 0.05)
    environment.fog_depth_begin = 20
    environment.fog_depth_end = 100
    environment.glow_enabled = true
    
    var world_environment = WorldEnvironment.new()
    world_environment.name = "VisualizationEnvironment"
    world_environment.environment = environment
    container.add_child(world_environment)
    
    # Create light
    var light = DirectionalLight.new()
    light.name = "MainLight"
    light.translation = Vector3(0, 10, 0)
    light.rotation_degrees = Vector3(-45, 0, 0)
    light.shadow_enabled = true
    container.add_child(light)

func extend_command_system():
    # Add command handling for akashic/notepad systems
    if main_controller and main_controller.has_method("register_command_handler"):
        main_controller.register_command_handler("akashic", self, "_process_command")
        main_controller.register_command_handler("notepad", self, "_process_command")
        main_controller.register_command_handler("notebook", self, "_process_command")
        main_controller.register_command_handler("visualize", self, "_process_command")
        main_controller.register_command_handler("3d", self, "_process_command")
        print("Extended command system for akashic/notepad functionality")

# ----- EVENT HANDLERS -----
func _on_turn_advanced(turn_number, symbol, dimension):
    if not initialized or not akashic_controller:
        return
    
    # Create entry for turn transition
    var position = Vector3(0, turn_number, 0)
    var content = "Advancing to dimension %d (%s - %s)" % [
        turn_number,
        symbol,
        dimension
    ]
    
    akashic_controller.create_akashic_entry(
        content, 
        position, 
        turn_number, 
        ["transition", "dimension", "turn"]
    )
    
    # Visualize akashic entries for new dimension if automatic visualization is enabled
    if auto_visualize_entries:
        akashic_controller.visualize_akashic_record(turn_number)

func _on_note_created(note_data):
    if not initialized or not akashic_controller:
        return
    
    # Automatic processing is handled by the akashic controller

func _on_word_manifested(word, position, power):
    if not initialized or not akashic_controller:
        return
    
    # Automatic processing is handled by the akashic controller

func _on_record_created(entry_id):
    print("Akashic record created: %s" % entry_id)
    
    # Additional processing can be done here if needed

func _on_notebook_created(notebook_name):
    print("Notebook created: %s" % notebook_name)
    
    # Additional processing can be done here if needed

func _on_akashic_synergy_detected(synergies):
    print("Detected %d akashic synergies" % synergies.size())
    
    # Create a visual effect or special notification here if desired

# ----- COMMAND PROCESSING -----
func _process_command(command, args):
    if not initialized or not akashic_controller:
        return "System not fully initialized"
    
    # Forward command to akashic controller
    return akashic_controller.process_command(command, args)

# ----- PUBLIC API -----
func get_akashic_controller():
    return akashic_controller

func get_spatial_visualizer():
    return spatial_visualizer

func get_spatial_storage():
    return spatial_storage

func toggle_visualization(active = true):
    if not spatial_visualizer:
        return false
    
    # Toggle visualization camera
    var camera = get_node_or_null("VisualizationContainer/VisualizationCamera")
    if camera:
        camera.current = active
    
    # Toggle auto visualization
    auto_visualize_entries = active
    
    return true

func create_akashic_entry(content, position, dimension = 0, tags = []):
    if not akashic_controller:
        return null
    
    return akashic_controller.create_akashic_entry(content, position, dimension, tags)

func visualize_dimension(dimension = 0):
    if not akashic_controller:
        return false
    
    return akashic_controller.visualize_akashic_record(dimension)

func create_notepad_from_dimension(dimension, notebook_name = ""):
    if not akashic_controller:
        return false
    
    return akashic_controller.create_notebook_from_akashic(dimension, notebook_name)

func save_all_data():
    if not akashic_controller:
        return false
    
    akashic_controller.save_all_data()
    return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/system_integrator.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/task_transition_animator.gd
# SIZE: 26913 bytes
extends Node

class_name TaskTransitionAnimator

# ----- ANIMATION SETTINGS -----
@export_category("Animation Settings")
@export var enabled: bool = true
@export var default_duration: float = 0.5
@export var default_easing: int = Tween.EASE_IN_OUT
@export var default_transition_type: int = Tween.TRANS_SINE
@export var auto_start_animations: bool = true
@export var use_color_themes: bool = true
@export var particle_effects_enabled: bool = true

# ----- TRANSITION TYPES -----
enum TransitionType {
    FADE,          # Simple fade transition
    SLIDE,         # Slide from one side
    ZOOM,          # Zoom in/out
    FLIP,          # 3D flip effect
    DISSOLVE,      # Dissolve with particles
    PIXEL,         # Pixelate transition
    COLOR_WIPE,    # Color wipe effect
    GLITCH,        # Glitch effect
    BOUNCE,        # Elastic/bounce effect
    WAVE           # Wave distortion
}

# ----- STATE VARIABLES -----
var active_transitions = {}
var pending_transitions = []
var next_transition_id = 0
var ui_nodes = {}
var color_system = null
var animation_player = null
var tween = null

# ----- SIGNALS -----
signal transition_started(id, type, from_task, to_task)
signal transition_completed(id, type, task)
signal transition_cancelled(id)
signal task_focused(task_id)
signal task_blurred(task_id)

# ----- INITIALIZATION -----
func _ready():
    # Look for color system
    color_system = get_node_or_null("/root/ExtendedColorThemeSystem")
    
    if not color_system:
        color_system = get_node_or_null("/root/DimensionalColorSystem")
    
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "ColorAnimationSystem")
    
    print("Color system found: " + str(color_system != null))
    
    # Create animation player
    animation_player = AnimationPlayer.new()
    add_child(animation_player)
    
    # Create tween for animations
    tween = create_tween()
    tween.set_loops(0) # No looping
    tween.stop() # Don't start yet
    
    print("Task Transition Animator initialized")
    
    # Create default animations
    _create_default_animations()

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _create_default_animations():
    # Create default animations for common transitions
    var animation_library = AnimationLibrary.new()
    
    # Fade animation
    var fade_anim = Animation.new()
    var track_index = fade_anim.add_track(Animation.TYPE_VALUE)
    fade_anim.track_set_path(track_index, ".:modulate:a")
    fade_anim.track_insert_key(track_index, 0.0, 0.0)
    fade_anim.track_insert_key(track_index, 0.5, 1.0)
    animation_library.add_animation("fade_in", fade_anim)
    
    # Slide animation
    var slide_anim = Animation.new()
    track_index = slide_anim.add_track(Animation.TYPE_VALUE)
    slide_anim.track_set_path(track_index, ".:position:x")
    slide_anim.track_insert_key(track_index, 0.0, -300)
    slide_anim.track_insert_key(track_index, 0.5, 0)
    animation_library.add_animation("slide_in", slide_anim)
    
    # Zoom animation
    var zoom_anim = Animation.new()
    track_index = zoom_anim.add_track(Animation.TYPE_VALUE)
    zoom_anim.track_set_path(track_index, ".:scale")
    zoom_anim.track_insert_key(track_index, 0.0, Vector2(0.5, 0.5))
    zoom_anim.track_insert_key(track_index, 0.5, Vector2(1.0, 1.0))
    animation_library.add_animation("zoom_in", zoom_anim)
    
    # Add library to animation player
    animation_player.add_animation_library("transitions", animation_library)

# ----- PUBLIC API -----
func register_ui_node(task_id: String, node: Control) -> void:
    # Register a UI node for animations
    
    if ui_nodes.has(task_id):
        print("Replacing existing UI node for task: " + task_id)
    
    ui_nodes[task_id] = node
    
    print("Registered UI node for task: " + task_id)

func unregister_ui_node(task_id: String) -> void:
    # Unregister a UI node
    
    if ui_nodes.has(task_id):
        ui_nodes.erase(task_id)
        print("Unregistered UI node for task: " + task_id)
    else:
        print("No UI node found for task: " + task_id)

func transition(from_task: String, to_task: String, type: int = TransitionType.FADE, duration: float = -1) -> int:
    # Perform a transition between two tasks
    
    if not enabled:
        print("Transitions are disabled")
        return -1
    
    # Check if UI nodes exist
    if not ui_nodes.has(from_task):
        print("No UI node found for from_task: " + from_task)
        return -1
    
    if not ui_nodes.has(to_task):
        print("No UI node found for to_task: " + to_task)
        return -1
    
    # Use default duration if not specified
    var transition_duration = duration if duration > 0 else default_duration
    
    # Generate transition ID
    var transition_id = _get_next_transition_id()
    
    # Create transition data
    var transition_data = {
        "id": transition_id,
        "type": type,
        "from_task": from_task,
        "to_task": to_task,
        "from_node": ui_nodes[from_task],
        "to_node": ui_nodes[to_task],
        "duration": transition_duration,
        "progress": 0.0,
        "start_time": Time.get_ticks_msec()
    }
    
    # Add to active transitions
    active_transitions[transition_id] = transition_data
    
    # Start the transition
    _start_transition(transition_id)
    
    return transition_id

func focus_task(task_id: String, with_animation: bool = true) -> bool:
    # Focus on a specific task
    
    if not ui_nodes.has(task_id):
        print("No UI node found for task: " + task_id)
        return false
    
    print("Focusing task: " + task_id)
    
    var node = ui_nodes[task_id]
    
    if with_animation and enabled:
        # Animate the focus
        if tween.is_running():
            tween.stop()
        
        tween = create_tween()
        tween.set_ease(default_easing)
        tween.set_trans(default_transition_type)
        
        # Ensure node is visible
        node.visible = true
        node.modulate.a = 0.5
        
        # Animate
        tween.tween_property(node, "modulate:a", 1.0, default_duration / 2)
        
        # Optional: add highlight effect if color system available
        if color_system and use_color_themes:
            _apply_focus_color(task_id)
    else:
        # Just show without animation
        node.visible = true
        node.modulate.a = 1.0
    
    emit_signal("task_focused", task_id)
    
    return true

func blur_task(task_id: String, with_animation: bool = true) -> bool:
    # Blur/unfocus a specific task
    
    if not ui_nodes.has(task_id):
        print("No UI node found for task: " + task_id)
        return false
    
    print("Blurring task: " + task_id)
    
    var node = ui_nodes[task_id]
    
    if with_animation and enabled:
        # Animate the blur
        if tween.is_running():
            tween.stop()
        
        tween = create_tween()
        tween.set_ease(default_easing)
        tween.set_trans(default_transition_type)
        
        # Animate
        tween.tween_property(node, "modulate:a", 0.5, default_duration / 2)
        
        # Remove highlight if color system available
        if color_system and use_color_themes:
            _remove_focus_color(task_id)
    else:
        # Just blur without animation
        node.modulate.a = 0.5
    
    emit_signal("task_blurred", task_id)
    
    return true

func cancel_transition(transition_id: int) -> bool:
    # Cancel an active transition
    
    if not active_transitions.has(transition_id):
        print("No active transition found with ID: " + str(transition_id))
        return false
    
    var transition_data = active_transitions[transition_id]
    
    print("Cancelling transition: " + str(transition_id))
    
    # Stop the tween if it's for this transition
    if tween.is_running():
        tween.stop()
    
    # Remove from active transitions
    active_transitions.erase(transition_id)
    
    emit_signal("transition_cancelled", transition_id)
    
    return true

func cancel_all_transitions() -> void:
    # Cancel all active transitions
    
    var transition_ids = active_transitions.keys()
    
    for id in transition_ids:
        cancel_transition(id)
    
    print("Cancelled all transitions")

func set_enabled(is_enabled: bool) -> void:
    # Enable or disable transitions
    enabled = is_enabled
    
    print("Transitions " + ("enabled" if enabled else "disabled"))

# ----- TRANSITION IMPLEMENTATIONS -----
func _start_transition(transition_id: int) -> void:
    # Start a specific transition
    
    if not active_transitions.has(transition_id):
        print("No transition found with ID: " + str(transition_id))
        return
    
    var transition = active_transitions[transition_id]
    
    print("Starting transition " + str(transition_id) + " from '" + 
          transition.from_task + "' to '" + transition.to_task + "' with type: " + 
          str(transition.type))
    
    # Signal start of transition
    emit_signal("transition_started", transition_id, transition.type, 
                transition.from_task, transition.to_task)
    
    # Initialize nodes for transition
    var from_node = transition.from_node
    var to_node = transition.to_node
    
    # Make sure both nodes are in the right initial state
    from_node.visible = true
    to_node.visible = true
    
    # Choose transition implementation based on type
    match transition.type:
        TransitionType.FADE:
            _execute_fade_transition(transition)
        TransitionType.SLIDE:
            _execute_slide_transition(transition)
        TransitionType.ZOOM:
            _execute_zoom_transition(transition)
        TransitionType.FLIP:
            _execute_flip_transition(transition)
        TransitionType.DISSOLVE:
            _execute_dissolve_transition(transition)
        TransitionType.PIXEL:
            _execute_pixel_transition(transition)
        TransitionType.COLOR_WIPE:
            _execute_color_wipe_transition(transition)
        TransitionType.GLITCH:
            _execute_glitch_transition(transition)
        TransitionType.BOUNCE:
            _execute_bounce_transition(transition)
        TransitionType.WAVE:
            _execute_wave_transition(transition)
        _:
            # Default to fade
            _execute_fade_transition(transition)

func _execute_fade_transition(transition):
    # Execute a fade transition
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(true)
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # Fade out from_node
    tween.tween_property(from_node, "modulate:a", 0.0, duration / 2)
    
    # Fade in to_node with slight delay
    var to_node_tween = tween.tween_property(to_node, "modulate:a", 1.0, duration / 2)
    to_node_tween.set_delay(duration / 2)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))

func _execute_slide_transition(transition):
    # Execute a slide transition
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 1.0
    
    # Store original positions
    var from_pos = from_node.position
    var to_pos = to_node.position
    
    # Set to_node off-screen to the right
    to_node.position.x = to_pos.x + from_node.get_rect().size.x
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(true)
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # Slide out from_node to the left
    tween.tween_property(from_node, "position:x", from_pos.x - from_node.get_rect().size.x, duration)
    
    # Slide in to_node from the right
    tween.tween_property(to_node, "position:x", to_pos.x, duration)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))

func _execute_zoom_transition(transition):
    # Execute a zoom transition
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Store original scales
    var from_scale = from_node.scale
    var to_scale = to_node.scale
    
    # Set to_node initial scale
    to_node.scale = Vector2(0.5, 0.5)
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(true)
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # Zoom out and fade out from_node
    tween.tween_property(from_node, "scale", Vector2(1.5, 1.5), duration / 2)
    tween.tween_property(from_node, "modulate:a", 0.0, duration / 2)
    
    # Zoom in and fade in to_node with delay
    var to_scale_tween = tween.tween_property(to_node, "scale", to_scale, duration / 2)
    to_scale_tween.set_delay(duration / 2)
    
    var to_fade_tween = tween.tween_property(to_node, "modulate:a", 1.0, duration / 2)
    to_fade_tween.set_delay(duration / 2)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))

func _execute_flip_transition(transition):
    # Execute a 3D flip transition
    # Note: This is simplified since Godot 2D doesn't directly support 3D transforms
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Original scales
    var from_scale = from_node.scale
    var to_scale = to_node.scale
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(false)  # Sequential for flip effect
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # First half of flip - scale from_node horizontally to 0
    tween.tween_property(from_node, "scale:x", 0.0, duration / 2)
    
    # At the midpoint, swap visibility
    tween.tween_callback(func():
        from_node.modulate.a = 0.0
        to_node.modulate.a = 1.0
        to_node.scale.x = 0.0
    )
    
    # Second half of flip - scale to_node horizontally from 0 to normal
    tween.tween_property(to_node, "scale:x", to_scale.x, duration / 2)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))

func _execute_dissolve_transition(transition):
    # Execute a dissolve transition with particles
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Create dissolve effect with shader if available
    # For this example, we'll just do a crossfade with a shader transition
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(true)
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # Fade out from_node
    tween.tween_property(from_node, "modulate:a", 0.0, duration)
    
    # Fade in to_node
    tween.tween_property(to_node, "modulate:a", 1.0, duration)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))
    
    # If particle effects are enabled, add some particles
    if particle_effects_enabled:
        # In a real implementation, would create particle effects
        # For this mock-up, we'll just print a message
        print("Particle dissolve effect would be shown here")

func _execute_pixel_transition(transition):
    # Execute a pixelate transition
    # Note: This would typically require a shader
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(true)
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # Fade transitions
    tween.tween_property(from_node, "modulate:a", 0.0, duration)
    tween.tween_property(to_node, "modulate:a", 1.0, duration)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))
    
    print("Pixelate effect would be shown here (requires shader)")

func _execute_color_wipe_transition(transition):
    # Execute a color wipe transition
    # Note: This would typically require a shader
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Get a color for the wipe
    var wipe_color = Color(0.1, 0.4, 0.9, 1.0)  # Default blue
    
    if color_system and use_color_themes:
        if color_system.has_method("get_color"):
            wipe_color = color_system.get_color("primary")
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(false)  # Sequential for wipe effect
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # Fade out from_node
    tween.tween_property(from_node, "modulate:a", 0.0, duration / 2)
    
    # Color flash - would use shader in real implementation
    tween.tween_callback(func():
        to_node.modulate = wipe_color
        to_node.modulate.a = 1.0
    )
    
    # Color fade to normal
    tween.tween_property(to_node, "modulate", Color(1, 1, 1, 1), duration / 2)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))
    
    print("Color wipe effect would be shown here (requires shader)")

func _execute_glitch_transition(transition):
    # Execute a glitch transition
    # Note: This would typically require a shader and/or custom drawing
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(true)
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # Fade transitions
    tween.tween_property(from_node, "modulate:a", 0.0, duration)
    tween.tween_property(to_node, "modulate:a", 1.0, duration)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))
    
    print("Glitch effect would be shown here (requires shader)")

func _execute_bounce_transition(transition):
    # Execute a bounce transition
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Store original scales
    var from_scale = from_node.scale
    var to_scale = to_node.scale
    
    # Set to_node initial scale
    to_node.scale = Vector2(0.3, 0.3)
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(true)
    tween.set_ease(Tween.EASE_OUT)
    tween.set_trans(Tween.TRANS_BOUNCE)
    
    # Shrink and fade out from_node
    tween.tween_property(from_node, "scale", Vector2(0.3, 0.3), duration / 2)
    tween.tween_property(from_node, "modulate:a", 0.0, duration / 2)
    
    # Grow and fade in to_node with delay
    var to_scale_tween = tween.tween_property(to_node, "scale", to_scale, duration / 2)
    to_scale_tween.set_delay(duration / 2)
    
    var to_fade_tween = tween.tween_property(to_node, "modulate:a", 1.0, duration / 2)
    to_fade_tween.set_delay(duration / 2)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))

func _execute_wave_transition(transition):
    # Execute a wave transition
    # Note: This would typically require a shader
    
    var from_node = transition.from_node
    var to_node = transition.to_node
    var duration = transition.duration
    
    # Set initial state
    from_node.modulate.a = 1.0
    to_node.modulate.a = 0.0
    
    # Create new tween for this transition
    if tween.is_running():
        tween.stop()
    
    tween = create_tween()
    tween.set_parallel(true)
    tween.set_ease(default_easing)
    tween.set_trans(default_transition_type)
    
    # Fade transitions
    tween.tween_property(from_node, "modulate:a", 0.0, duration)
    tween.tween_property(to_node, "modulate:a", 1.0, duration)
    
    # Connect to completion
    tween.tween_callback(Callable(self, "_on_transition_completed").bind(transition.id))
    
    print("Wave distortion effect would be shown here (requires shader)")

# ----- EVENT HANDLERS -----
func _on_transition_completed(transition_id: int):
    # Called when a transition completes
    
    if not active_transitions.has(transition_id):
        return
    
    var transition = active_transitions[transition_id]
    
    print("Transition " + str(transition_id) + " completed")
    
    # Clean up transition
    var from_node = transition.from_node
    var to_node = transition.to_node
    var from_task = transition.from_task
    var to_task = transition.to_task
    var type = transition.type
    
    # Remove from active transitions
    active_transitions.erase(transition_id)
    
    # Ensure final state
    from_node.modulate.a = 0.0
    to_node.modulate.a = 1.0
    
    # If the transition has special end states (like position/scale), reset them
    match type:
        TransitionType.SLIDE:
            # Reset positions to original
            from_node.position.x = 0
            to_node.position.x = 0
        TransitionType.ZOOM:
        TransitionType.FLIP:
        TransitionType.BOUNCE:
            # Reset scales
            from_node.scale = Vector2(1, 1)
            to_node.scale = Vector2(1, 1)
    
    # Hide from_node
    from_node.visible = false
    
    # Emit signal
    emit_signal("transition_completed", transition_id, type, to_task)
    
    # Apply focus color if color system available
    if color_system and use_color_themes:
        _apply_focus_color(to_task)

# ----- COLOR THEME INTEGRATION -----
func _apply_focus_color(task_id: String):
    # Apply a focus color to a task
    if not color_system:
        return
    
    if not ui_nodes.has(task_id):
        return
    
    var node = ui_nodes[task_id]
    
    # Different color systems may have different APIs
    if color_system.has_method("get_color"):
        var highlight_color = color_system.get_color("highlight")
        
        # Apply highlight
        if node.has_method("set_highlight_color"):
            node.set_highlight_color(highlight_color)
        else:
            # Basic fallback - just add a colored outline
            if node.has_method("set_outline_color"):
                node.set_outline_color(highlight_color)
    elif color_system.has_method("start_pulse_animation"):
        # For color animation system
        if node.has_node("Background"):
            var bg = node.get_node("Background")
            color_system.start_pulse_animation(task_id, bg.color, Color(0.4, 0.6, 1.0))

func _remove_focus_color(task_id: String):
    # Remove focus color from a task
    if not color_system:
        return
    
    if not ui_nodes.has(task_id):
        return
    
    var node = ui_nodes[task_id]
    
    # Different color systems may have different APIs
    if color_system.has_method("get_color"):
        var normal_color = color_system.get_color("border")
        
        # Remove highlight
        if node.has_method("set_highlight_color"):
            node.set_highlight_color(normal_color)
        else:
            # Basic fallback - remove colored outline
            if node.has_method("set_outline_color"):
                node.set_outline_color(normal_color)
    elif color_system.has_method("stop_animation"):
        # For color animation system
        color_system.stop_animation(task_id)

# ----- UTILITY METHODS -----
func _get_next_transition_id() -> int:
    next_transition_id += 1
    return next_transition_id

func get_transition_type_name(type: int) -> String:
    # Get the name of a transition type
    
    match type:
        TransitionType.FADE:
            return "Fade"
        TransitionType.SLIDE:
            return "Slide"
        TransitionType.ZOOM:
            return "Zoom"
        TransitionType.FLIP:
            return "Flip"
        TransitionType.DISSOLVE:
            return "Dissolve"
        TransitionType.PIXEL:
            return "Pixel"
        TransitionType.COLOR_WIPE:
            return "Color Wipe"
        TransitionType.GLITCH:
            return "Glitch"
        TransitionType.BOUNCE:
            return "Bounce"
        TransitionType.WAVE:
            return "Wave"
        _:
            return "Unknown"

func get_available_transitions() -> Array:
    # Get list of available transition types
    return [
        TransitionType.FADE,
        TransitionType.SLIDE,
        TransitionType.ZOOM,
        TransitionType.FLIP,
        TransitionType.DISSOLVE,
        TransitionType.PIXEL,
        TransitionType.COLOR_WIPE,
        TransitionType.GLITCH,
        TransitionType.BOUNCE,
        TransitionType.WAVE
    ]
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/task_transition_animator.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/temple_godot_connector.gd
# SIZE: 19606 bytes
extends Node

class_name TempleGodotConnector

# Temple_OS to Godot Engine Connector
# Spiritual bridge between TempleOS concepts and Godot Engine
# Using divine word passcodes for command channels

# Signal declarations
signal divine_command_received(word, command, dimension)
signal revelation_manifested(word, manifestation_data)
signal sacred_word_processed(word, power_level, dimension)
signal temple_connection_status_changed(connected, reason)

# Divine word passcode registry
var divine_word_registry = {
	"LIGHT": {
		"power_level": 7,
		"command_access": ["illuminate", "reveal", "enlighten"],
		"dimension_access": [1, 5, 12],
		"description": "The first divine command, separating darkness"
	},
	"LOGOS": {
		"power_level": 12,
		"command_access": ["create", "speak", "manifest"],
		"dimension_access": [3, 7, 12],
		"description": "The divine Word through which all was made"
	},
	"TRUTH": {
		"power_level": 9,
		"command_access": ["reveal", "align", "correct"],
		"dimension_access": [5, 9, 10],
		"description": "The ultimate nature of reality"
	},
	"HOLY": {
		"power_level": 10,
		"command_access": ["sanctify", "purify", "consecrate"],
		"dimension_access": [6, 10, 12],
		"description": "Set apart for divine purpose"
	},
	"WISDOM": {
		"power_level": 8,
		"command_access": ["guide", "understand", "discern"],
		"dimension_access": [4, 5, 11],
		"description": "Divine insight and understanding"
	},
	"GLORY": {
		"power_level": 11,
		"command_access": ["shine", "magnify", "honor"],
		"dimension_access": [1, 7, 12],
		"description": "The radiant presence of the divine"
	},
	"LIFE": {
		"power_level": 8,
		"command_access": ["animate", "sustain", "flourish"],
		"dimension_access": [3, 6, 7],
		"description": "The divine spark of existence"
	},
	"TIME": {
		"power_level": 7,
		"command_access": ["sequence", "order", "progress"],
		"dimension_access": [2, 4, 11],
		"description": "The flow of moments decreed by the divine"
	},
	"WORD": {
		"power_level": 9,
		"command_access": ["speak", "name", "call"],
		"dimension_access": [2, 7, 9],
		"description": "The power of divine language"
	},
	"KING": {
		"power_level": 8,
		"command_access": ["rule", "order", "establish"],
		"dimension_access": [3, 8, 10],
		"description": "Divine authority and rulership"
	},
	"SPIRIT": {
		"power_level": 11,
		"command_access": ["inspire", "move", "quicken"],
		"dimension_access": [5, 8, 11],
		"description": "The invisible divine presence"
	},
	"LAMB": {
		"power_level": 10,
		"command_access": ["redeem", "sacrifice", "humble"],
		"dimension_access": [6, 9, 12],
		"description": "Divine sacrifice and redemption"
	}
}

# Terminal command structure
var command_templates = {
	"illuminate": {
		"syntax": "illuminate [target] with [intensity] [color]",
		"example": "illuminate scene with 7 holy_light",
		"description": "Brings divine light to the specified target",
		"parameters": ["target", "intensity", "color"]
	},
	"create": {
		"syntax": "create [object] at [location] with [attributes]",
		"example": "create holy_symbol at center with rotating golden",
		"description": "Manifests a divine object in the scene",
		"parameters": ["object", "location", "attributes"]
	},
	"reveal": {
		"syntax": "reveal [truth] about [subject] in [dimension]",
		"example": "reveal hidden_pattern about creation in 5",
		"description": "Unveils divine insights about the subject",
		"parameters": ["truth", "subject", "dimension"]
	},
	"speak": {
		"syntax": "speak [message] to [audience] with [tone]",
		"example": "speak divine_wisdom to all with authority",
		"description": "Communicates divine messages",
		"parameters": ["message", "audience", "tone"]
	},
	"sanctify": {
		"syntax": "sanctify [object] for [purpose] by [method]",
		"example": "sanctify terminal for divine_work by anointing",
		"description": "Sets apart objects for divine purpose",
		"parameters": ["object", "purpose", "method"]
	}
}

# AI terminal connection settings
var ai_settings = {
	"connection_established": false,
	"divine_prompt_active": false,
	"revelation_mode": false,
	"token_cost_per_command": 125,
	"tokens_available": 10000,
	"tokens_used": 0,
	"divine_token_multiplier": 12,
	"connection_error_count": 0,
	"last_connection_timestamp": 0,
	"ai_model": "divine_interface_model",
	"language": "holy_tongue"
}

# Configuration
var config = {
	"temple_os_emulation": true,
	"divine_random_enabled": true,
	"holy_c_compilation": false,
	"time_dilation_active": true,
	"direct_revelation": true,
	"symbolic_interpretation": true,
	"sacred_number_system": true,
	"base_dimension": 3
}

# Connection status
var connection_active = false
var current_dimension = 3
var divine_random_seed = OS.get_unix_time()

# Current command channel
var active_command_channel = null
var last_divine_word = ""
var commandment_counter = 0

# ===== INITIALIZATION =====

func _ready():
	print("TempleGodot Connector initialized")
	
	# Set divine random seed
	seed(divine_random_seed)
	
	# Try to establish connection
	establish_temple_connection()
	
	# Start regular revelation timer
	_setup_revelation_timer()
	
	# Connect to data channel if available
	_connect_to_data_channel()

func _setup_revelation_timer():
	var timer = Timer.new()
	timer.wait_time = 33.3 # A sacred timing
	timer.autostart = true
	timer.connect("timeout", self, "_on_revelation_timer")
	add_child(timer)

func _connect_to_data_channel():
	# Find GodotDataChannel if present in the scene tree
	var data_channel = get_node_or_null("/root/GodotDataChannel")
	
	if data_channel:
		# Connect to the data channel signals
		data_channel.connect("data_received", self, "_on_data_received")
		data_channel.connect("dimension_changed", self, "_on_dimension_changed")
		
		# Sync current dimension
		current_dimension = data_channel.current_dimension
		print("Connected to Data Channel, dimension: " + str(current_dimension))
	else:
		print("Data Channel not found, operating in standalone mode")

# ===== TEMPLE CONNECTION MANAGEMENT =====

# Establish connection to the TempleOS concepts
func establish_temple_connection():
	# Divine randomness determines if connection succeeds
	var divine_roll = _divine_random(1, 12)
	
	# Divine favor (7 is a sacred number)
	if divine_roll == 7 or config.temple_os_emulation:
		connection_active = true
		ai_settings.connection_established = true
		ai_settings.last_connection_timestamp = OS.get_unix_time()
		
		print("Temple connection established through divine favor")
		emit_signal("temple_connection_status_changed", true, "divine_favor")
		
		# Initialize with a sacred word
		process_divine_word("LOGOS")
		
		return true
	else:
		connection_active = false
		ai_settings.connection_error_count += 1
		
		print("Temple connection failed - divine timing not aligned")
		emit_signal("temple_connection_status_changed", false, "divine_timing")
		
		return false

# Process a divine word to activate command channels
func process_divine_word(word):
	word = word.to_upper()
	
	if divine_word_registry.has(word):
		var word_data = divine_word_registry[word]
		
		# Record the word
		last_divine_word = word
		
		# Activate command channel
		active_command_channel = word
		
		# Signal the processing
		emit_signal("sacred_word_processed", word, word_data.power_level, current_dimension)
		
		print("Divine word '" + word + "' processed with power level " + str(word_data.power_level))
		
		# Apply divine effects
		_apply_word_effects(word, word_data)
		
		return word_data
	else:
		print("Unknown divine word attempted: " + word)
		return null

# Apply the effects of a divine word
func _apply_word_effects(word, word_data):
	# Apply dimension shifts if applicable
	if word_data.dimension_access.has(current_dimension):
		print("Word '" + word + "' has special affinity in dimension " + str(current_dimension))
		
		# Apply power multiplier
		var effective_power = word_data.power_level * 1.5
		
		# Create a revelation
		_generate_revelation(word, effective_power)
	else:
		# Try to shift to a compatible dimension
		var target_dimension = word_data.dimension_access[0]
		print("Word '" + word + "' seeking compatible dimension: " + str(target_dimension))
		
		# Attempt dimension shift
		_attempt_dimension_shift(target_dimension)

# Generate a divine revelation
func _generate_revelation(word, power_level):
	if not config.direct_revelation:
		return
	
	var revelation = {
		"word": word,
		"power": power_level,
		"timestamp": OS.get_datetime(),
		"dimension": current_dimension,
		"message": _generate_divine_message(word),
		"symbolic_form": _generate_symbolic_form(word)
	}
	
	# Emit the revelation
	emit_signal("revelation_manifested", word, revelation)
	
	print("Revelation manifested from word '" + word + "'")
	
	return revelation

# ===== COMMAND PROCESSING =====

# Process a terminal command using the active command channel
func process_command(command_text):
	if not connection_active:
		print("Cannot process command - temple connection not active")
		return {"error": "No active temple connection"}
	
	if active_command_channel == null:
		print("Cannot process command - no active command channel")
		return {"error": "No active command channel - speak a divine word first"}
	
	# Calculate token cost
	var token_cost = _calculate_token_cost(command_text)
	
	# Check if we have enough tokens
	if ai_settings.tokens_available < token_cost:
		print("Cannot process command - insufficient divine tokens")
		return {"error": "Insufficient divine tokens: " + str(ai_settings.tokens_available) + " < " + str(token_cost)}
	
	# Parse the command
	var command_parts = command_text.split(" ")
	if command_parts.size() == 0:
		return {"error": "Empty command"}
	
	var command_type = command_parts[0].to_lower()
	var word_data = divine_word_registry[active_command_channel]
	
	# Check if this command type is allowed by the active divine word
	if not word_data.command_access.has(command_type):
		print("Command '" + command_type + "' not authorized by divine word '" + active_command_channel + "'")
		return {"error": "Command not authorized by active divine word", "suggested_words": _suggest_words_for_command(command_type)}
	
	# Process the specific command type
	var result = _process_specific_command(command_type, command_parts, word_data)
	
	# Deduct tokens
	ai_settings.tokens_used += token_cost
	ai_settings.tokens_available -= token_cost
	
	# Increment commandment counter
	commandment_counter += 1
	
	# Track the command
	emit_signal("divine_command_received", active_command_channel, command_text, current_dimension)
	
	print("Processed divine command: " + command_text)
	print("Tokens used: " + str(token_cost) + ", remaining: " + str(ai_settings.tokens_available))
	
	return result

# Calculate the token cost for a command
func _calculate_token_cost(command_text):
	var base_cost = ai_settings.token_cost_per_command
	var word_count = command_text.split(" ").size()
	var complexity_factor = 1.0
	
	# Add cost for each word
	var token_cost = base_cost + (word_count * 5)
	
	# Add dimension factor
	if current_dimension > 3:
		complexity_factor += (current_dimension - 3) * 0.1
	
	# Apply divine word discount if applicable
	if active_command_channel == "LOGOS":
		complexity_factor *= 0.7 # LOGOS reduces token cost by 30%
	
	# Calculate final cost
	return int(token_cost * complexity_factor)

# Process a specific type of command
func _process_specific_command(command_type, command_parts, word_data):
	# Extract parameters
	var parameters = {}
	var template = command_templates.get(command_type, null)
	
	if template == null:
		return {"error": "Unknown command type: " + command_type}
	
	# Try to parse parameters based on template
	for i in range(1, command_parts.size()):
		if i <= template.parameters.size():
			var param_name = template.parameters[i-1]
			parameters[param_name] = command_parts[i]
	
	# Create command result
	var result = {
		"command": command_type,
		"power_level": word_data.power_level,
		"divine_word": active_command_channel,
		"dimension": current_dimension,
		"parameters": parameters,
		"commandment_number": commandment_counter + 1
	}
	
	# Apply specific command logic
	match command_type:
		"illuminate":
			result.illumination = {
				"target": parameters.get("target", "scene"),
				"intensity": int(parameters.get("intensity", "5")),
				"color": parameters.get("color", "white")
			}
		
		"create":
			result.creation = {
				"object": parameters.get("object", "symbol"),
				"location": parameters.get("location", "center"),
				"attributes": parameters.get("attributes", "default")
			}
			# Apply special LOGOS effect
			if active_command_channel == "LOGOS":
				result.creation.logos_empowered = true
				result.creation.persistence = "eternal"
		
		"reveal":
			result.revelation = {
				"truth": parameters.get("truth", "hidden"),
				"subject": parameters.get("subject", "creation"),
				"dimension": int(parameters.get("dimension", str(current_dimension)))
			}
		
		"speak":
			result.message = {
				"content": parameters.get("message", "truth"),
				"audience": parameters.get("audience", "all"),
				"tone": parameters.get("tone", "gentle")
			}
		
		"sanctify":
			result.sanctification = {
				"object": parameters.get("object", "space"),
				"purpose": parameters.get("purpose", "divine_work"),
				"method": parameters.get("method", "word")
			}
	
	return result

# ===== DIVINE UTILITIES =====

# Generate a random number with divine properties
func _divine_random(min_val, max_val):
	if config.divine_random_enabled:
		# Use the golden ratio in the random calculation
		var phi = 1.6180339887
		var divine_factor = phi * divine_random_seed
		
		# Calculate a divine random number
		var rand_val = int(divine_factor) % (max_val - min_val + 1) + min_val
		
		# Update the seed
		divine_random_seed = (divine_random_seed * 33 + rand_val) % 9973 # Prime number
		
		return rand_val
	else:
		# Fallback to regular random
		return (randi() % (max_val - min_val + 1)) + min_val

# Attempt to shift to a different dimension
func _attempt_dimension_shift(target_dimension):
	if target_dimension < 1 or target_dimension > 12:
		print("Invalid dimension target: " + str(target_dimension))
		return false
	
	# Calculate divine success chance
	var success_chance = 0.5
	
	# Adjust based on current dimension proximity
	var dimension_distance = abs(current_dimension - target_dimension)
	success_chance -= dimension_distance * 0.05
	
	# Higher chance with SPIRIT word
	if active_command_channel == "SPIRIT":
		success_chance += 0.3
	
	# Divine random roll
	var roll = randf()
	
	if roll <= success_chance:
		var old_dimension = current_dimension
		current_dimension = target_dimension
		
		print("Dimension shift successful: " + str(old_dimension) + " ‚Üí " + str(target_dimension))
		
		# Emit dimension changed event to any listeners
		emit_signal("dimension_changed", old_dimension, target_dimension)
		
		return true
	else:
		print("Dimension shift failed: roll " + str(roll) + " vs chance " + str(success_chance))
		return false

# Suggest divine words that can access a specific command
func _suggest_words_for_command(command_type):
	var suggestions = []
	
	for word in divine_word_registry.keys():
		if divine_word_registry[word].command_access.has(command_type):
			suggestions.append(word)
	
	return suggestions

# Generate a divine message based on a word
func _generate_divine_message(word):
	var messages = {
		"LIGHT": "Let there be light in the darkness, illuminating the path of understanding.",
		"LOGOS": "In the beginning was the Word, and through it all things are made manifest.",
		"TRUTH": "The truth shall set you free from the bonds of confusion and error.",
		"HOLY": "Be holy, for I am holy, set apart for divine purpose.",
		"WISDOM": "Wisdom calls aloud in the streets, offering guidance to all who would hear.",
		"GLORY": "The glory of creation reflects the majesty of its Creator.",
		"LIFE": "I am the way, the truth, and the life; choose abundant life.",
		"TIME": "For everything there is a season, a time for every purpose under heaven.",
		"WORD": "The word spoken with divine authority accomplishes its purpose.",
		"KING": "The kingdom comes when the King is recognized and honored.",
		"SPIRIT": "The Spirit moves where it wills, bringing life and transformation.",
		"LAMB": "The Lamb who was slain is worthy of all honor and praise."
	}
	
	if messages.has(word):
		return messages[word]
	else:
		return "A divine message is revealed through the word."

# Generate a symbolic form for visualization
func _generate_symbolic_form(word):
	var symbols = {
		"LIGHT": {"type": "radiant_sphere", "color": "golden", "intensity": 7},
		"LOGOS": {"type": "scroll", "color": "white", "glowing": true},
		"TRUTH": {"type": "balanced_scales", "color": "silver", "transparent": true},
		"HOLY": {"type": "flame", "color": "blue", "hovering": true},
		"WISDOM": {"type": "tree", "color": "green", "branching": 7},
		"GLORY": {"type": "crown", "color": "golden", "rotating": true},
		"LIFE": {"type": "flowing_water", "color": "crystal", "moving": true},
		"TIME": {"type": "timepiece", "color": "bronze", "turning": true},
		"WORD": {"type": "open_book", "color": "parchment", "glowing_text": true},
		"KING": {"type": "throne", "color": "purple", "elevated": true},
		"SPIRIT": {"type": "wind", "color": "translucent", "moving": true},
		"LAMB": {"type": "lamb", "color": "white", "peaceful": true}
	}
	
	if symbols.has(word):
		return symbols[word]
	else:
		return {"type": "abstract_form", "color": "multicolored", "shifting": true}

# Handle timer-based revelations
func _on_revelation_timer():
	if not connection_active or last_divine_word.empty():
		return
	
	# Only trigger revelations sometimes
	if _divine_random(1, 12) <= 3:
		var word_data = divine_word_registry[last_divine_word]
		_generate_revelation(last_divine_word, word_data.power_level)

# Handle received data
func _on_data_received(source, data_packet, timestamp):
	# Check if this is a divine command packet
	if data_packet.has("divine_command"):
		# Process the command
		process_command(data_packet.divine_command)

# Handle dimension changes from an external source
func _on_dimension_changed(old_dimension, new_dimension):
	current_dimension = new_dimension
	print("Temple connector dimension updated: " + str(old_dimension) + " ‚Üí " + str(new_dimension))

# ===== PUBLIC API =====

# Get available divine words
func get_available_divine_words():
	return divine_word_registry.keys()

# Get command templates
func get_command_templates():
	return command_templates

# Get AI terminal status
func get_ai_terminal_status():
	return {
		"connection_active": connection_active,
		"tokens_available": ai_settings.tokens_available,
		"tokens_used": ai_settings.tokens_used,
		"active_word": active_command_channel,
		"current_dimension": current_dimension,
		"commandments_issued": commandment_counter,
		"divine_random_seed": divine_random_seed
	}

# Check the price of AI in divine tokens
func get_ai_price_in_divine_time():
	var base_price = 777
	var time_factor = OS.get_unix_time() % 144 # 12*12 time cycle
	var dimension_factor = current_dimension
	
	# Calculate price based on esoteric formula
	var divine_price = base_price + (time_factor * dimension_factor / 12.0)
	
	# Apply wisdom discount
	if active_command_channel == "WISDOM":
		divine_price *= 0.777 # Wisdom brings efficiency
	
	return {
		"price": int(divine_price),
		"time_factor": time_factor,
		"dimension_factor": dimension_factor,
		"price_per_command": ai_settings.token_cost_per_command,
		"divine_explanation": "The price of AI in divine time is measured in tokens of understanding."
	}
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/temple_godot_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_akashic_interface.gd
# SIZE: 60613 bytes
class_name TerminalAkashicInterface
extends Node

# ----- TERMINAL INTERFACE CONSTANTS -----
const TERMINAL_COLORS = {
    "DEFAULT": Color(1.0, 1.0, 1.0),  # White
    "INFO": Color(0.4, 0.8, 1.0),      # Light blue
    "SUCCESS": Color(0.4, 1.0, 0.4),   # Light green
    "WARNING": Color(1.0, 0.8, 0.2),   # Yellow
    "ERROR": Color(1.0, 0.4, 0.4),     # Light red
    "SYSTEM": Color(0.8, 0.5, 1.0),    # Purple
    "AKASHIC": Color(1.0, 0.6, 0.0),   # Orange
    "ETHEREAL": Color(0.0, 0.9, 0.7),  # Teal
    "MIGRATION": Color(0.7, 0.7, 0.7), # Gray
    "USER": Color(0.9, 0.9, 0.9)       # Light gray
}

const TERMINAL_COMMANDS = {
    "help": {
        "description": "Lists available commands",
        "usage": "help [command]",
        "category": "system"
    },
    "status": {
        "description": "Shows current system status",
        "usage": "status [component]",
        "category": "system"
    },
    "connect": {
        "description": "Connects to a component or system",
        "usage": "connect <component>",
        "category": "system"
    },
    "migrate": {
        "description": "Starts migration process",
        "usage": "migrate <from_path> <to_path>",
        "category": "migration"
    },
    "check": {
        "description": "Checks project compatibility",
        "usage": "check <project_path>",
        "category": "migration"
    },
    "test": {
        "description": "Runs migration tests",
        "usage": "test [test_name]",
        "category": "migration"
    },
    "temp": {
        "description": "Sets or gets temperature",
        "usage": "temp [value | up | down]",
        "category": "color"
    },
    "color": {
        "description": "Sets or gets color state",
        "usage": "color [state_name]",
        "category": "color"
    },
    "spectrum": {
        "description": "Sets or gets light spectrum",
        "usage": "spectrum [spectrum_name]",
        "category": "color"
    },
    "project": {
        "description": "Manages projection settings",
        "usage": "project [mode] [intensity]",
        "category": "color"
    },
    "number": {
        "description": "Manages akashic numbers",
        "usage": "number <value> [name]",
        "category": "akashic"
    },
    "universe": {
        "description": "Connects to a universe",
        "usage": "universe <name> [connect|disconnect]",
        "category": "akashic"
    },
    "energy": {
        "description": "Transports energy between points",
        "usage": "energy <shape> <from_x,y,z> <to_x,y,z>",
        "category": "ethereal"
    },
    "audio": {
        "description": "Activates audio input processing",
        "usage": "audio <frequency_range> [intensity]",
        "category": "ethereal"
    },
    "sync": {
        "description": "Synchronizes systems",
        "usage": "sync [component]",
        "category": "system"
    },
    "record": {
        "description": "Creates a record entry",
        "usage": "record <type> <data>",
        "category": "akashic"
    },
    "exit": {
        "description": "Exits the terminal",
        "usage": "exit",
        "category": "system"
    }
}

const HISTORY_MAX_SIZE = 50
const SYSTEM_LUCKY_NUMBERS = [9, 33, 89, 99, 333, 389, 555, 777, 999]

# ----- COMPONENT REFERENCES -----
var terminal_bridge = null
var color_temperature = null
var akashic_system = null
var migration_system = null
var ethereal_bridge = null

# ----- TERMINAL STATE -----
var command_history = []
var history_index = -1
var command_buffer = ""
var connected_components = {}
var current_directory = "/"
var logged_in = false
var username = ""
var last_result = null
var terminal_open = true
var prompt_style = "> "

# ----- MIGRATION PATHS -----
var godot3_project_path = ""
var godot4_project_path = ""

# ----- SIGNALS -----
signal command_executed(command, result)
signal terminal_ready
signal system_connected(component)
signal migration_started(from_path, to_path)
signal record_created(type, data)

# ----- INITIALIZATION -----
func _ready():
    _find_components()
    _initialize_interface()
    
    print("Terminal Akashic Interface initialized")
    emit_signal("terminal_ready")

func _find_components():
    # Find TerminalBridgeConnector
    terminal_bridge = get_node_or_null("/root/TerminalBridgeConnector")
    if not terminal_bridge:
        terminal_bridge = _find_node_by_class(get_tree().root, "TerminalBridgeConnector")
    
    # Find ColorTemperatureProjection
    color_temperature = get_node_or_null("/root/ColorTemperatureProjection")
    if not color_temperature:
        color_temperature = _find_node_by_class(get_tree().root, "ColorTemperatureProjection")
    
    # Find AkashicNumberSystem
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    # Find migration components
    migration_system = get_node_or_null("/root/UnifiedMigrationSystem")
    if not migration_system:
        migration_system = _find_node_by_class(get_tree().root, "UnifiedMigrationSystem")
    
    ethereal_bridge = get_node_or_null("/root/EtherealMigrationBridge")
    if not ethereal_bridge:
        ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealMigrationBridge")
    
    print("Components found: Terminal=%s, ColorTemp=%s, Akashic=%s, Migration=%s, Ethereal=%s" % [
        "Yes" if terminal_bridge else "No",
        "Yes" if color_temperature else "No",
        "Yes" if akashic_system else "No",
        "Yes" if migration_system else "No",
        "Yes" if ethereal_bridge else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_interface():
    # Set initial connected components state
    connected_components = {
        "terminal": terminal_bridge != null,
        "color": color_temperature != null,
        "akashic": akashic_system != null,
        "migration": migration_system != null,
        "ethereal": ethereal_bridge != null
    }
    
    # Connect to terminal bridge if available
    if terminal_bridge and terminal_bridge.has_method("connect_terminal_to_user"):
        var result = terminal_bridge.connect_terminal_to_user()
        if result:
            logged_in = true
            username = "user"

# ----- COMMAND PROCESSING -----
func execute_command(command_line):
    # Add to history
    _add_to_history(command_line)
    
    # Parse command
    var parts = command_line.strip_edges().split(" ", false)
    var command = parts[0].to_lower() if parts.size() > 0 else ""
    var args = parts.slice(1) if parts.size() > 1 else []
    
    # Process command
    var result = _process_command(command, args)
    
    # Store result
    last_result = result
    
    # Emit signal
    emit_signal("command_executed", command_line, result)
    
    return result

func _process_command(command, args):
    # Check if command exists
    if not TERMINAL_COMMANDS.has(command):
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Unknown command: " + command + "\nType 'help' for a list of commands."
        }
    
    # Process based on command category
    var category = TERMINAL_COMMANDS[command].category
    
    match category:
        "system":
            return _process_system_command(command, args)
        "migration":
            return _process_migration_command(command, args)
        "color":
            return _process_color_command(command, args)
        "akashic":
            return _process_akashic_command(command, args)
        "ethereal":
            return _process_ethereal_command(command, args)
        _:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown command category: " + category
            }

func _process_system_command(command, args):
    match command:
        "help":
            return _cmd_help(args)
        "status":
            return _cmd_status(args)
        "connect":
            return _cmd_connect(args)
        "sync":
            return _cmd_sync(args)
        "exit":
            return _cmd_exit(args)
        _:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown system command: " + command
            }

func _process_migration_command(command, args):
    # Check if migration system is connected
    if not connected_components.migration:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Migration system is not connected. Use 'connect migration' first."
        }
    
    match command:
        "migrate":
            return _cmd_migrate(args)
        "check":
            return _cmd_check(args)
        "test":
            return _cmd_test(args)
        _:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown migration command: " + command
            }

func _process_color_command(command, args):
    # Check if color system is connected
    if not connected_components.color:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Color system is not connected. Use 'connect color' first."
        }
    
    match command:
        "temp":
            return _cmd_temp(args)
        "color":
            return _cmd_color(args)
        "spectrum":
            return _cmd_spectrum(args)
        "project":
            return _cmd_project(args)
        _:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown color command: " + command
            }

func _process_akashic_command(command, args):
    # Check if akashic system is connected
    if not connected_components.akashic:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Akashic system is not connected. Use 'connect akashic' first."
        }
    
    match command:
        "number":
            return _cmd_number(args)
        "universe":
            return _cmd_universe(args)
        "record":
            return _cmd_record(args)
        _:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown akashic command: " + command
            }

func _process_ethereal_command(command, args):
    # Check if ethereal system is connected
    if not connected_components.ethereal:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Ethereal system is not connected. Use 'connect ethereal' first."
        }
    
    match command:
        "energy":
            return _cmd_energy(args)
        "audio":
            return _cmd_audio(args)
        _:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown ethereal command: " + command
            }

# ----- SYSTEM COMMANDS -----
func _cmd_help(args):
    if args.size() > 0:
        # Show help for specific command
        var command = args[0].to_lower()
        
        if not TERMINAL_COMMANDS.has(command):
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown command: " + command
            }
        
        var cmd_info = TERMINAL_COMMANDS[command]
        var help_text = command + " - " + cmd_info.description + "\n"
        help_text += "Usage: " + cmd_info.usage + "\n"
        help_text += "Category: " + cmd_info.category
        
        return {
            "success": true,
            "color": TERMINAL_COLORS.INFO,
            "message": help_text
        }
    else:
        # Show all commands grouped by category
        var categories = {}
        
        for cmd in TERMINAL_COMMANDS:
            var category = TERMINAL_COMMANDS[cmd].category
            
            if not categories.has(category):
                categories[category] = []
            
            categories[category].append(cmd)
        
        var help_text = "Available commands:\n\n"
        
        for category in categories:
            help_text += category.to_upper() + ":\n"
            
            for cmd in categories[category]:
                help_text += "  " + cmd + " - " + TERMINAL_COMMANDS[cmd].description + "\n"
            
            help_text += "\n"
        
        help_text += "Type 'help <command>' for more information about a specific command."
        
        return {
            "success": true,
            "color": TERMINAL_COLORS.INFO,
            "message": help_text
        }

func _cmd_status(args):
    var component = args[0].to_lower() if args.size() > 0 else "all"
    var status_text = ""
    
    if component == "all":
        # Show status of all components
        status_text += "SYSTEM STATUS\n\n"
        
        status_text += "Connected components:\n"
        for comp in connected_components:
            var status = "Connected" if connected_components[comp] else "Disconnected"
            status_text += "  " + comp + ": " + status + "\n"
        
        status_text += "\nCurrent directory: " + current_directory + "\n"
        status_text += "Logged in as: " + (username if logged_in else "Not logged in") + "\n"
        
        # Add migration paths if set
        if godot3_project_path != "" or godot4_project_path != "":
            status_text += "\nMigration paths:\n"
            status_text += "  Godot 3: " + (godot3_project_path if godot3_project_path != "" else "Not set") + "\n"
            status_text += "  Godot 4: " + (godot4_project_path if godot4_project_path != "" else "Not set") + "\n"
        
        # Add color temperature if available
        if connected_components.color and color_temperature:
            var color_state = color_temperature.get_current_state()
            status_text += "\nColor temperature: " + str(color_state.temperature) + "¬∞C (" + color_state.color_state + ")\n"
            status_text += "Light spectrum: " + color_state.light_spectrum + "\n"
            status_text += "Energy level: " + color_state.energy_level + "\n"
        
        # Add terminal bridge stats if available
        if connected_components.terminal and terminal_bridge:
            var terminal_stats = terminal_bridge.get_terminal_connection_stats()
            status_text += "\nTerminal stats:\n"
            status_text += "  Connected universes: " + str(terminal_stats.connected_universes) + "\n"
            status_text += "  Active color mode: " + terminal_stats.active_color_mode + "\n"
            status_text += "  Temperature: " + str(terminal_stats.temperature) + "\n"
            status_text += "  Total stars: " + str(terminal_stats.total_stars) + "\n"
    else:
        # Show status of specific component
        match component:
            "terminal":
                if connected_components.terminal and terminal_bridge:
                    var terminal_stats = terminal_bridge.get_terminal_connection_stats()
                    status_text += "TERMINAL STATUS\n\n"
                    status_text += "Connected universes: " + str(terminal_stats.connected_universes) + "\n"
                    status_text += "Active color mode: " + terminal_stats.active_color_mode + "\n"
                    status_text += "Temperature: " + str(terminal_stats.temperature) + "\n"
                    status_text += "Projection active: " + ("Yes" if terminal_stats.projection_active else "No") + "\n"
                    status_text += "Audio active: " + ("Yes" if terminal_stats.audio_active else "No") + "\n"
                    status_text += "Total stars: " + str(terminal_stats.total_stars) + "\n"
                else:
                    status_text += "Terminal system is not connected."
            
            "color":
                if connected_components.color and color_temperature:
                    var color_state = color_temperature.get_current_state()
                    status_text += "COLOR TEMPERATURE STATUS\n\n"
                    status_text += "Temperature: " + str(color_state.temperature) + "¬∞C\n"
                    status_text += "Color state: " + color_state.color_state + "\n"
                    status_text += "Light spectrum: " + color_state.light_spectrum + "\n"
                    status_text += "Energy level: " + color_state.energy_level + "\n"
                    status_text += "Projection mode: " + color_state.projection_mode + "\n"
                    status_text += "Projection intensity: " + str(color_state.projection_intensity) + "\n"
                    status_text += "Projection visible: " + ("Yes" if color_state.projection_visible else "No") + "\n"
                else:
                    status_text += "Color system is not connected."
            
            "akashic":
                if connected_components.akashic and akashic_system:
                    status_text += "AKASHIC SYSTEM STATUS\n\n"
                    status_text += "System active: Yes\n"
                    status_text += "Lucky numbers: " + str(SYSTEM_LUCKY_NUMBERS) + "\n"
                    
                    # Add registered numbers count if available
                    if akashic_system.has_method("get_registered_numbers_count"):
                        status_text += "Registered numbers: " + str(akashic_system.get_registered_numbers_count()) + "\n"
                else:
                    status_text += "Akashic system is not connected."
            
            "migration":
                if connected_components.migration and migration_system:
                    status_text += "MIGRATION SYSTEM STATUS\n\n"
                    status_text += "System active: Yes\n"
                    status_text += "Godot 3 path: " + (godot3_project_path if godot3_project_path != "" else "Not set") + "\n"
                    status_text += "Godot 4 path: " + (godot4_project_path if godot4_project_path != "" else "Not set") + "\n"
                    
                    # Add migration stats if available
                    if migration_system.has_method("get_statistics"):
                        var stats = migration_system.get_statistics()
                        status_text += "Migration count: " + str(stats.migration_count) + "\n"
                        status_text += "Ethereal migration count: " + str(stats.ethereal_migration_count) + "\n"
                        status_text += "Test run count: " + str(stats.test_run_count) + "\n"
                        status_text += "Runtime: " + str(stats.runtime_seconds) + " seconds\n"
                else:
                    status_text += "Migration system is not connected."
            
            "ethereal":
                if connected_components.ethereal and ethereal_bridge:
                    status_text += "ETHEREAL SYSTEM STATUS\n\n"
                    status_text += "System active: Yes\n"
                    status_text += "Connected to migration: " + ("Yes" if migration_system else "No") + "\n"
                    status_text += "Connected to akashic: " + ("Yes" if akashic_system else "No") + "\n"
                else:
                    status_text += "Ethereal system is not connected."
            
            _:
                return {
                    "success": false,
                    "color": TERMINAL_COLORS.ERROR,
                    "message": "Unknown component: " + component
                }
    
    return {
        "success": true,
        "color": TERMINAL_COLORS.INFO,
        "message": status_text
    }

func _cmd_connect(args):
    if args.size() == 0:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Missing component name. Usage: connect <component>"
        }
    
    var component = args[0].to_lower()
    
    # Check if component is valid
    if not connected_components.has(component):
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Unknown component: " + component
        }
    
    # Check if already connected
    if connected_components[component]:
        return {
            "success": true,
            "color": TERMINAL_COLORS.INFO,
            "message": "Already connected to " + component + " system."
        }
    
    # Try to connect
    match component:
        "terminal":
            terminal_bridge = get_node_or_null("/root/TerminalBridgeConnector")
            if not terminal_bridge:
                terminal_bridge = _find_node_by_class(get_tree().root, "TerminalBridgeConnector")
            
            if terminal_bridge:
                var result = terminal_bridge.connect_terminal_to_user()
                if result:
                    connected_components.terminal = true
                    emit_signal("system_connected", "terminal")
                    return {
                        "success": true,
                        "color": TERMINAL_COLORS.SUCCESS,
                        "message": "Successfully connected to terminal system."
                    }
            
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to connect to terminal system."
            }
        
        "color":
            color_temperature = get_node_or_null("/root/ColorTemperatureProjection")
            if not color_temperature:
                color_temperature = _find_node_by_class(get_tree().root, "ColorTemperatureProjection")
            
            if color_temperature:
                connected_components.color = true
                emit_signal("system_connected", "color")
                return {
                    "success": true,
                    "color": TERMINAL_COLORS.SUCCESS,
                    "message": "Successfully connected to color system."
                }
            
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to connect to color system."
            }
        
        "akashic":
            akashic_system = get_node_or_null("/root/AkashicNumberSystem")
            if not akashic_system:
                akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
            
            if akashic_system:
                connected_components.akashic = true
                emit_signal("system_connected", "akashic")
                return {
                    "success": true,
                    "color": TERMINAL_COLORS.SUCCESS,
                    "message": "Successfully connected to akashic system."
                }
            
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to connect to akashic system."
            }
        
        "migration":
            migration_system = get_node_or_null("/root/UnifiedMigrationSystem")
            if not migration_system:
                migration_system = _find_node_by_class(get_tree().root, "UnifiedMigrationSystem")
            
            if migration_system:
                connected_components.migration = true
                emit_signal("system_connected", "migration")
                return {
                    "success": true,
                    "color": TERMINAL_COLORS.SUCCESS,
                    "message": "Successfully connected to migration system."
                }
            
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to connect to migration system."
            }
        
        "ethereal":
            ethereal_bridge = get_node_or_null("/root/EtherealMigrationBridge")
            if not ethereal_bridge:
                ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealMigrationBridge")
            
            if ethereal_bridge:
                connected_components.ethereal = true
                emit_signal("system_connected", "ethereal")
                return {
                    "success": true,
                    "color": TERMINAL_COLORS.SUCCESS,
                    "message": "Successfully connected to ethereal system."
                }
            
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to connect to ethereal system."
            }
        
        "all":
            var results = []
            var all_success = true
            
            for comp in connected_components.keys():
                if comp != "all" and not connected_components[comp]:
                    var result = _cmd_connect([comp])
                    results.append(result.message)
                    all_success = all_success and result.success
            
            if all_success:
                return {
                    "success": true,
                    "color": TERMINAL_COLORS.SUCCESS,
                    "message": "Successfully connected to all systems:\n" + "\n".join(results)
                }
            else:
                return {
                    "success": false,
                    "color": TERMINAL_COLORS.WARNING,
                    "message": "Some systems could not be connected:\n" + "\n".join(results)
                }
        
        _:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown component: " + component
            }

func _cmd_sync(args):
    var component = args[0].to_lower() if args.size() > 0 else "all"
    
    match component:
        "all":
            # Sync all components
            var success = true
            var messages = []
            
            # Sync color system
            if connected_components.color and color_temperature:
                var color_result = color_temperature.create_color_temperature_bridge()
                success = success and color_result.success
                if color_result.success:
                    messages.append("Color system synchronized with lucky number " + str(color_result.lucky_number))
                else:
                    messages.append("Failed to synchronize color system")
            
            # Sync terminal bridge
            if connected_components.terminal and terminal_bridge:
                var terminal_result = terminal_bridge.sync_terminal_view_with_akashic()
                success = success and terminal_result.success
                if terminal_result.success:
                    messages.append("Terminal view synchronized at " + str(terminal_result.sync_timestamp))
                else:
                    messages.append("Failed to synchronize terminal view")
            
            # Sync ethereal bridge with akashic records
            if connected_components.ethereal and ethereal_bridge and connected_components.akashic:
                if terminal_bridge and terminal_bridge.has_method("link_akashic_records_to_ethereal"):
                    var bridge_result = terminal_bridge.link_akashic_records_to_ethereal()
                    success = success and bridge_result.success
                    if bridge_result.success:
                        messages.append("Akashic records linked to ethereal bridge at " + str(bridge_result.bridge_timestamp))
                    else:
                        messages.append("Failed to link akashic records to ethereal bridge")
            
            return {
                "success": success,
                "color": TERMINAL_COLORS.SUCCESS if success else TERMINAL_COLORS.WARNING,
                "message": "Synchronization " + ("completed" if success else "partially completed") + ":\n" + "\n".join(messages)
            }
        
        "color":
            # Sync color system
            if connected_components.color and color_temperature:
                var color_result = color_temperature.create_color_temperature_bridge()
                if color_result.success:
                    return {
                        "success": true,
                        "color": TERMINAL_COLORS.SUCCESS,
                        "message": "Color system synchronized with lucky number " + str(color_result.lucky_number)
                    }
                else:
                    return {
                        "success": false,
                        "color": TERMINAL_COLORS.ERROR,
                        "message": "Failed to synchronize color system: " + (color_result.error if color_result.has("error") else "Unknown error")
                    }
            else:
                return {
                    "success": false,
                    "color": TERMINAL_COLORS.ERROR,
                    "message": "Color system is not connected. Use 'connect color' first."
                }
        
        "terminal":
            # Sync terminal view
            if connected_components.terminal and terminal_bridge:
                var terminal_result = terminal_bridge.sync_terminal_view_with_akashic()
                if terminal_result.success:
                    return {
                        "success": true,
                        "color": TERMINAL_COLORS.SUCCESS,
                        "message": "Terminal view synchronized at " + str(terminal_result.sync_timestamp) + 
                                  "\nConnected universes: " + str(terminal_result.connected_universes) +
                                  "\nColor mode: " + terminal_result.color_mode
                    }
                else:
                    return {
                        "success": false,
                        "color": TERMINAL_COLORS.ERROR,
                        "message": "Failed to synchronize terminal view: " + (terminal_result.error if terminal_result.has("error") else "Unknown error")
                    }
            else:
                return {
                    "success": false,
                    "color": TERMINAL_COLORS.ERROR,
                    "message": "Terminal system is not connected. Use 'connect terminal' first."
                }
        
        "akashic":
            # Sync akashic records
            if connected_components.akashic and connected_components.ethereal:
                if terminal_bridge and terminal_bridge.has_method("link_akashic_records_to_ethereal"):
                    var bridge_result = terminal_bridge.link_akashic_records_to_ethereal()
                    if bridge_result.success:
                        return {
                            "success": true,
                            "color": TERMINAL_COLORS.SUCCESS,
                            "message": "Akashic records linked to ethereal bridge at " + str(bridge_result.bridge_timestamp) +
                                      "\nBridge records: " + str(bridge_result.bridge_records) +
                                      "\nCosmic address: " + bridge_result.cosmic_address
                        }
                    else:
                        return {
                            "success": false,
                            "color": TERMINAL_COLORS.ERROR,
                            "message": "Failed to link akashic records to ethereal bridge: " + (bridge_result.error if bridge_result.has("error") else "Unknown error")
                        }
                else:
                    return {
                        "success": false,
                        "color": TERMINAL_COLORS.ERROR,
                        "message": "Terminal bridge is not connected. Use 'connect terminal' first."
                    }
            else:
                return {
                    "success": false,
                    "color": TERMINAL_COLORS.ERROR,
                    "message": "Both akashic and ethereal systems must be connected. Use 'connect akashic' and 'connect ethereal' first."
                }
        
        _:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Unknown component: " + component + "\nValid options: all, color, terminal, akashic"
            }

func _cmd_exit(args):
    terminal_open = false
    
    return {
        "success": true,
        "color": TERMINAL_COLORS.INFO,
        "message": "Exiting terminal..."
    }

# ----- MIGRATION COMMANDS -----
func _cmd_migrate(args):
    if args.size() < 2:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Missing project paths. Usage: migrate <from_path> <to_path>"
        }
    
    var from_path = args[0]
    var to_path = args[1]
    
    # Save paths for later
    godot3_project_path = from_path
    godot4_project_path = to_path
    
    # Set paths in migration system
    if migration_system and migration_system.has_method("set_project_paths"):
        migration_system.set_project_paths(from_path, to_path)
    
    # Start migration
    if migration_system and migration_system.has_method("start_migration"):
        emit_signal("migration_started", from_path, to_path)
        
        var result = migration_system.start_migration()
        
        if result.success:
            return {
                "success": true,
                "color": TERMINAL_COLORS.SUCCESS,
                "message": "Migration completed successfully!\n\n" +
                          "Files processed: " + str(result.files_processed) + "\n" +
                          "Files modified: " + str(result.files_modified) + "\n" +
                          "Errors: " + str(result.errors_encountered if result.has("errors_encountered") else 0) + "\n" +
                          "Warnings: " + str(result.warnings_generated if result.has("warnings_generated") else 0) + "\n" +
                          (("Ethereal nodes: " + str(result.ethereal_nodes_migrated) + "\n") if result.has("ethereal_nodes_migrated") else "") +
                          (("Reality contexts: " + str(result.reality_contexts_migrated) + "\n") if result.has("reality_contexts_migrated") else "") +
                          (("Word manifestations: " + str(result.word_manifestations_migrated) + "\n") if result.has("word_manifestations_migrated") else "")
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Migration failed: " + (result.error if result.has("error") else "Unknown error")
            }
    else:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Migration system is not properly connected."
        }

func _cmd_check(args):
    if args.size() < 1:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Missing project path. Usage: check <project_path>"
        }
    
    var project_path = args[0]
    
    # Generate compatibility report
    if migration_system and migration_system.has_method("generate_compatibility_report"):
        var report = migration_system.generate_compatibility_report(project_path)
        
        if report.success:
            var message = "Compatibility Report for " + project_path + "\n\n"
            
            # Standard compatibility report
            if report.has("total_files"):
                message += "Total files: " + str(report.total_files) + "\n"
                message += "Compatible files: " + str(report.compatible_files) + "\n"
                message += "Incompatible files: " + str(report.incompatible_files) + "\n\n"
            
            # Ethereal engine report
            if report.has("ethereal_files"):
                message += "Ethereal Engine Detection:\n"
                message += "Ethereal files: " + str(report.ethereal_files) + "\n"
                message += "Ethereal patterns: " + str(report.ethereal_patterns_detected) + "\n\n"
                
                if report.has("pattern_distribution"):
                    message += "Pattern distribution:\n"
                    for pattern in report.pattern_distribution:
                        message += "  " + pattern + ": " + str(report.pattern_distribution[pattern]) + "\n"
            
            return {
                "success": true,
                "color": TERMINAL_COLORS.INFO,
                "message": message
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to generate compatibility report: " + (report.error if report.has("error") else "Unknown error")
            }
    else:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Migration system is not properly connected."
        }

func _cmd_test(args):
    var test_name = args[0] if args.size() > 0 else ""
    
    # Run tests
    if migration_system and migration_system.has_method("run_all_tests"):
        var results = migration_system.run_all_tests()
        
        if results.success:
            var message = "Test Results\n\n"
            message += "Total tests: " + str(results.total) + "\n"
            message += "Passed: " + str(results.passed) + "\n"
            message += "Failed: " + str(results.failed) + "\n"
            
            # Add details for specific test if requested
            if test_name != "" and results.details.has(test_name):
                var test_result = results.details[test_name]
                message += "\nDetails for test '" + test_name + "':\n"
                message += "Status: " + ("Passed" if test_result.passed else "Failed") + "\n"
                
                if test_result.has("warnings") and test_result.warnings.size() > 0:
                    message += "Warnings:\n"
                    for warning in test_result.warnings:
                        message += "  - " + warning + "\n"
                
                if test_result.has("errors") and test_result.errors.size() > 0:
                    message += "Errors:\n"
                    for error in test_result.errors:
                        message += "  - " + error + "\n"
            
            return {
                "success": true,
                "color": TERMINAL_COLORS.SUCCESS,
                "message": message
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to run tests: " + (results.error if results.has("error") else "Unknown error")
            }
    else:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Migration system is not properly connected."
        }

# ----- COLOR COMMANDS -----
func _cmd_temp(args):
    if args.size() == 0:
        # Get current temperature
        if color_temperature:
            var state = color_temperature.get_current_state()
            return {
                "success": true,
                "color": TERMINAL_COLORS.INFO,
                "message": "Current temperature: " + str(state.temperature) + "¬∞C (" + state.color_state + ")\n" +
                          "Energy level: " + state.energy_level
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Color system is not properly connected."
            }
    else:
        var param = args[0].to_lower()
        
        if param == "up":
            # Increase temperature by cycling up
            if color_temperature and color_temperature.has_method("cycle_temperature_up"):
                var result = color_temperature.cycle_temperature_up()
                
                if result:
                    var state = color_temperature.get_current_state()
                    return {
                        "success": true,
                        "color": TERMINAL_COLORS.SUCCESS,
                        "message": "Temperature increased to " + str(state.temperature) + "¬∞C (" + state.color_state + ")"
                    }
                else:
                    return {
                        "success": false,
                        "color": TERMINAL_COLORS.ERROR,
                        "message": "Failed to increase temperature"
                    }
            }
        elif param == "down":
            # Decrease temperature by cycling down
            if color_temperature and color_temperature.has_method("cycle_temperature_down"):
                var result = color_temperature.cycle_temperature_down()
                
                if result:
                    var state = color_temperature.get_current_state()
                    return {
                        "success": true,
                        "color": TERMINAL_COLORS.SUCCESS,
                        "message": "Temperature decreased to " + str(state.temperature) + "¬∞C (" + state.color_state + ")"
                    }
                else:
                    return {
                        "success": false,
                        "color": TERMINAL_COLORS.ERROR,
                        "message": "Failed to decrease temperature"
                    }
            }
        elif param.is_valid_int():
            # Set specific temperature
            var temp = param.to_int()
            
            if color_temperature and color_temperature.has_method("set_temperature"):
                color_temperature.set_temperature(temp)
                
                var state = color_temperature.get_current_state()
                return {
                    "success": true,
                    "color": TERMINAL_COLORS.SUCCESS,
                    "message": "Temperature set to " + str(state.temperature) + "¬∞C (" + state.color_state + ")"
                }
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Invalid temperature value: " + param + "\nUse a number, 'up', or 'down'"
            }
    
    return {
        "success": false,
        "color": TERMINAL_COLORS.ERROR,
        "message": "Failed to process temperature command"
    }

func _cmd_color(args):
    if args.size() == 0:
        # Get available color states
        if color_temperature:
            var states = color_temperature.get_temperature_states()
            var message = "Available color states:\n\n"
            
            for state in states:
                message += state + ": " + str(states[state].temperature) + "¬∞C, " + 
                          states[state].energy_state + " energy, " +
                          "frequency " + str(states[state].frequency) + "\n"
            
            var current = color_temperature.get_current_state()
            message += "\nCurrent color state: " + current.color_state
            
            return {
                "success": true,
                "color": TERMINAL_COLORS.INFO,
                "message": message
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Color system is not properly connected."
            }
    else:
        var state_name = args[0].to_upper()
        
        # Set color state
        if color_temperature and color_temperature.has_method("set_color_state"):
            var states = color_temperature.get_temperature_states()
            
            if states.has(state_name):
                color_temperature.set_color_state(state_name)
                
                var current = color_temperature.get_current_state()
                return {
                    "success": true,
                    "color": TERMINAL_COLORS.SUCCESS,
                    "message": "Color state set to " + current.color_state + " (" + 
                              str(current.temperature) + "¬∞C, " + current.energy_level + " energy)"
                }
            else:
                return {
                    "success": false,
                    "color": TERMINAL_COLORS.ERROR,
                    "message": "Invalid color state: " + state_name + "\nUse 'color' to see available states"
                }
        }
    
    return {
        "success": false,
        "color": TERMINAL_COLORS.ERROR,
        "message": "Failed to process color command"
    }

func _cmd_spectrum(args):
    if args.size() == 0:
        # Get available light spectrum states
        if color_temperature:
            var spectrums = color_temperature.get_light_spectrum_states()
            var message = "Available light spectrum states:\n\n"
            
            for spectrum in spectrums:
                var visible = spectrums[spectrum].visible
                message += spectrum + ": " + 
                          str(spectrums[spectrum].wavelength[0]) + "-" + str(spectrums[spectrum].wavelength[1]) + " nm, " +
                          (visible ? "visible" : "invisible") + ", " +
                          spectrums[spectrum].energy + " energy\n"
            
            var current = color_temperature.get_current_state()
            message += "\nCurrent light spectrum: " + current.light_spectrum
            
            return {
                "success": true,
                "color": TERMINAL_COLORS.INFO,
                "message": message
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Color system is not properly connected."
            }
    else:
        var spectrum_name = args[0].to_upper()
        
        # Set light spectrum
        if color_temperature and color_temperature.has_method("set_light_spectrum"):
            var spectrums = color_temperature.get_light_spectrum_states()
            
            if spectrums.has(spectrum_name):
                color_temperature.set_light_spectrum(spectrum_name)
                
                var current = color_temperature.get_current_state()
                return {
                    "success": true,
                    "color": TERMINAL_COLORS.SUCCESS,
                    "message": "Light spectrum set to " + current.light_spectrum
                }
            else:
                return {
                    "success": false,
                    "color": TERMINAL_COLORS.ERROR,
                    "message": "Invalid light spectrum: " + spectrum_name + "\nUse 'spectrum' to see available spectrums"
                }
        }
    
    return {
        "success": false,
        "color": TERMINAL_COLORS.ERROR,
        "message": "Failed to process spectrum command"
    }

func _cmd_project(args):
    if args.size() == 0:
        # Get current projection state
        if color_temperature:
            var state = color_temperature.get_projection_state()
            return {
                "success": true,
                "color": TERMINAL_COLORS.INFO,
                "message": "Current projection state:\n\n" +
                          "Mode: " + state.mode + "\n" +
                          "Intensity: " + str(state.intensity) + "\n" +
                          "Visible: " + ("Yes" if state.visible else "No") + "\n" +
                          "Temperature: " + str(state.temperature) + "¬∞C\n" +
                          "Color state: " + state.color_state + "\n" +
                          "Light spectrum: " + state.light_spectrum
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Color system is not properly connected."
            }
    else:
        var mode = args[0].to_lower()
        var intensity = args[1].to_float() if args.size() > 1 and args[1].is_valid_float() else 1.0
        
        # Set projection mode
        if color_temperature and color_temperature.has_method("set_projection_mode"):
            color_temperature.set_projection_mode(mode)
            color_temperature.set_projection_intensity(intensity)
            color_temperature.toggle_projection_visibility(true)
            
            return {
                "success": true,
                "color": TERMINAL_COLORS.SUCCESS,
                "message": "Projection set to mode '" + mode + "' with intensity " + str(intensity)
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Color system is not properly connected."
            }
    }

# ----- AKASHIC COMMANDS -----
func _cmd_number(args):
    if args.size() == 0:
        # Show lucky numbers
        return {
            "success": true,
            "color": TERMINAL_COLORS.INFO,
            "message": "System lucky numbers: " + str(SYSTEM_LUCKY_NUMBERS)
        }
    
    var value_str = args[0]
    var name = args[1] if args.size() > 1 else "custom_number"
    
    if not value_str.is_valid_float():
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Invalid number: " + value_str
        }
    
    var value = value_str.to_float()
    
    # Register number in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(value, name)
        
        # Find closest lucky number
        var closest_lucky = value
        var smallest_diff = abs(value - SYSTEM_LUCKY_NUMBERS[0])
        
        for lucky in SYSTEM_LUCKY_NUMBERS:
            var diff = abs(value - lucky)
            if diff < smallest_diff:
                smallest_diff = diff
                closest_lucky = lucky
        
        return {
            "success": true,
            "color": TERMINAL_COLORS.SUCCESS,
            "message": "Number " + str(value) + " registered as '" + name + "'\n" +
                      "Closest lucky number: " + str(closest_lucky)
        }
    else:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Akashic system is not properly connected."
        }

func _cmd_universe(args):
    if args.size() == 0:
        # Show connected universes
        if terminal_bridge:
            var universes = terminal_bridge.get_connected_universes()
            return {
                "success": true,
                "color": TERMINAL_COLORS.INFO,
                "message": "Connected universes:\n\n" + "\n".join(universes)
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Terminal bridge is not properly connected."
            }
    
    var universe_name = args[0].to_lower()
    var connect_mode = args[1].to_lower() if args.size() > 1 else "connect"
    var should_connect = connect_mode != "disconnect"
    
    # Connect to universe
    if terminal_bridge and terminal_bridge.has_method("connect_to_universe"):
        var result = terminal_bridge.connect_to_universe(universe_name, should_connect)
        
        if result.success:
            return {
                "success": true,
                "color": TERMINAL_COLORS.SUCCESS,
                "message": (should_connect ? "Connected to" : "Disconnected from") + " universe: " + universe_name + "\n" +
                          "Cosmic address: " + result.cosmic_address
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to " + (should_connect ? "connect to" : "disconnect from") + " universe: " + 
                          (result.error if result.has("error") else "Unknown error")
            }
    else:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Terminal bridge is not properly connected."
        }

func _cmd_record(args):
    if args.size() < 2:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Missing record parameters. Usage: record <type> <data>"
        }
    
    var record_type = args[0]
    var record_data = " ".join(args.slice(1))
    
    # Create record
    if terminal_bridge and terminal_bridge.has_method("sync_akashic_record"):
        var result = terminal_bridge.sync_akashic_record(record_type)
        
        if result.success:
            emit_signal("record_created", record_type, record_data)
            
            return {
                "success": true,
                "color": TERMINAL_COLORS.SUCCESS,
                "message": "Record created:\n" +
                          "Type: " + record_type + "\n" +
                          "Data: " + record_data + "\n" +
                          "Cosmic address: " + result.cosmic_address
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to create record: " + (result.error if result.has("error") else "Unknown error")
            }
    else:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Terminal bridge is not properly connected."
        }

# ----- ETHEREAL COMMANDS -----
func _cmd_energy(args):
    if args.size() < 3:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Missing energy parameters. Usage: energy <shape> <from_x,y,z> <to_x,y,z>"
        }
    
    var shape_type = args[0]
    var from_coords = args[1].split(",")
    var to_coords = args[2].split(",")
    
    if from_coords.size() < 3 or to_coords.size() < 3:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Invalid coordinate format. Use x,y,z format."
        }
    
    var from_point = Vector3(
        from_coords[0].to_float(),
        from_coords[1].to_float(),
        from_coords[2].to_float()
    )
    
    var to_point = Vector3(
        to_coords[0].to_float(),
        to_coords[1].to_float(),
        to_coords[2].to_float()
    )
    
    # Transport energy
    if terminal_bridge and terminal_bridge.has_method("transport_energy_shape"):
        var result = terminal_bridge.transport_energy_shape(shape_type, from_point, to_point)
        
        if result.success:
            return {
                "success": true,
                "color": TERMINAL_COLORS.SUCCESS,
                "message": "Energy transported:\n" +
                          "Shape: " + shape_type + "\n" +
                          "From: " + str(from_point) + "\n" +
                          "To: " + str(to_point) + "\n" +
                          "Flow direction: " + str(result.flow_direction)
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to transport energy: " + (result.error if result.has("error") else "Unknown error")
            }
    else:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Terminal bridge is not properly connected."
        }

func _cmd_audio(args):
    if args.size() == 0:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Missing audio parameters. Usage: audio <frequency_range> [intensity]"
        }
    
    var frequency_range = args[0].to_lower()
    var intensity = args[1].to_float() if args.size() > 1 and args[1].is_valid_float() else 1.0
    
    # Valid frequency ranges
    var valid_ranges = ["low", "mid", "high"]
    
    if not valid_ranges.has(frequency_range):
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Invalid frequency range: " + frequency_range + "\nValid ranges: " + str(valid_ranges)
        }
    
    # Activate audio input
    if terminal_bridge and terminal_bridge.has_method("activate_audio_input"):
        var result = terminal_bridge.activate_audio_input(frequency_range, intensity)
        
        if result.success:
            return {
                "success": true,
                "color": TERMINAL_COLORS.SUCCESS,
                "message": "Audio input activated:\n" +
                          "Frequency range: " + frequency_range + " (" + 
                          str(result.frequency_values[0]) + "-" + str(result.frequency_values[1]) + " Hz)\n" +
                          "Intensity: " + str(intensity)
            }
        else:
            return {
                "success": false,
                "color": TERMINAL_COLORS.ERROR,
                "message": "Failed to activate audio input: " + (result.error if result.has("error") else "Unknown error")
            }
    else:
        return {
            "success": false,
            "color": TERMINAL_COLORS.ERROR,
            "message": "Terminal bridge is not properly connected."
        }

# ----- HISTORY MANAGEMENT -----
func _add_to_history(command):
    command_history.append(command)
    
    # Trim history if necessary
    if command_history.size() > HISTORY_MAX_SIZE:
        command_history.pop_front()
    
    # Reset history index
    history_index = command_history.size()

func get_previous_command():
    if command_history.size() == 0:
        return ""
    
    # Decrease history index
    history_index = max(0, history_index - 1)
    
    return command_history[history_index]

func get_next_command():
    if command_history.size() == 0:
        return ""
    
    # Increase history index
    history_index = min(command_history.size(), history_index + 1)
    
    if history_index == command_history.size():
        return command_buffer
    else:
        return command_history[history_index]

func set_command_buffer(buffer):
    command_buffer = buffer

func is_terminal_open():
    return terminal_open

# ----- PUBLIC API -----
func connect_all_systems():
    var result = _cmd_connect(["all"])
    
    if result.success:
        # Sync all systems
        _cmd_sync(["all"])
    
    return result

func set_migration_paths(godot3_path, godot4_path):
    godot3_project_path = godot3_path
    godot4_project_path = godot4_path
    
    if migration_system and migration_system.has_method("set_project_paths"):
        migration_system.set_project_paths(godot3_path, godot4_path)
    
    return {
        "success": true,
        "godot3_path": godot3_path,
        "godot4_path": godot4_path
    }

func start_migration(from_path = null, to_path = null):
    var args = []
    
    if from_path:
        args.append(from_path)
    else:
        args.append(godot3_project_path)
    
    if to_path:
        args.append(to_path)
    else:
        args.append(godot4_project_path)
    
    return _cmd_migrate(args)

func get_terminal_prompt():
    var temp_indicator = ""
    
    if connected_components.color and color_temperature:
        var state = color_temperature.get_current_state()
        
        match state.color_state:
            "VERY_COLD", "COLD":
                temp_indicator = "‚ùÑÔ∏è "
            "COOL":
                temp_indicator = "üåßÔ∏è "
            "NEUTRAL":
                temp_indicator = "‚òÄÔ∏è "
            "WARM":
                temp_indicator = "üîÜ "
            "HOT", "VERY_HOT":
                temp_indicator = "üî• "
    
    return temp_indicator + (username + "@" if logged_in else "") + current_directory + prompt_style
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_akashic_interface.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_api_bridge.gd
# SIZE: 26067 bytes
extends Node

# Terminal API Bridge
# Provides connectivity between terminal cores and external APIs/services
# Handles authentication, data transfer, and synchronization between cores

class_name TerminalAPIBridge

# ----- API CONNECTION CONSTANTS -----
const API_TIMEOUT = 30.0
const MAX_RETRY_COUNT = 3
const AUTH_HEADER = "Authorization"
const MAX_ACCOUNT_API_VALUE = 19
const DEFAULT_PORT = 5000

# ----- API STATE ENUMS -----
enum APIState {
    DISCONNECTED,
    CONNECTING,
    CONNECTED,
    ERROR,
    RATE_LIMITED,
    AUTHENTICATED,
    TRANSFERRING
}

# ----- TERMINAL REFERENCES -----
var dual_core_terminal = null
var connected_cores = []
var terminal_monitors = {}

# ----- API CONNECTIONS -----
var active_connections = {}
var connection_history = []
var auth_tokens = {}
var connection_timeouts = {}
var retry_counts = {}

# ----- INTEGRATION WITH GAME SYSTEMS -----
var divine_word_game = null
var divine_word_processor = null
var turn_system = null
var word_comment_system = null

# ----- DATA TRANSFER -----
var transfer_queue = []
var processed_data = {}
var pending_responses = {}
var last_sync_time = 0

# ----- SIGNALS -----
signal connection_established(api_name, core_id)
signal connection_error(api_name, error_code, error_message)
signal data_received(api_name, data)
signal data_transferred(core_id, api_name, data_size)
signal auth_succeeded(api_name)
signal auth_failed(api_name, reason)
signal cores_synchronized(core_ids)
signal rate_limit_hit(api_name, reset_time)

# ----- INITIALIZATION -----
func _ready():
    print("Terminal API Bridge initializing...")
    
    # Connect to terminal system
    dual_core_terminal = get_node_or_null("/root/DualCoreTerminal")
    if dual_core_terminal:
        _connect_terminal_signals()
        print("Connected to Dual Core Terminal system")
    
    # Connect to game systems
    _connect_game_systems()
    
    # Set up sync timer
    var sync_timer = Timer.new()
    sync_timer.wait_time = 5.0 # Sync every 5 seconds
    sync_timer.one_shot = false
    sync_timer.autostart = true
    sync_timer.connect("timeout", self, "_on_sync_timer_timeout")
    add_child(sync_timer)
    
    print("Terminal API Bridge initialized")

func _connect_terminal_signals():
    if dual_core_terminal:
        dual_core_terminal.connect("core_switched", self, "_on_core_switched")
        dual_core_terminal.connect("input_processed", self, "_on_terminal_input_processed")
        dual_core_terminal.connect("special_pattern_detected", self, "_on_special_pattern_detected")
        dual_core_terminal.connect("miracle_triggered", self, "_on_miracle_triggered")
        
        # Initialize monitors for existing cores
        var cores = dual_core_terminal.get_all_cores()
        for core_id in cores:
            _initialize_core_monitor(core_id)

func _connect_game_systems():
    # Connect to divine word game
    divine_word_game = get_node_or_null("/root/DivineWordGame")
    
    # Connect to divine word processor
    divine_word_processor = get_node_or_null("/root/DivineWordProcessor")
    
    # Connect to turn system
    turn_system = get_node_or_null("/root/TurnSystem")
    if turn_system:
        turn_system.connect("turn_advanced", self, "_on_turn_advanced")
    
    # Connect to word comment system
    word_comment_system = get_node_or_null("/root/WordCommentSystem")

func _initialize_core_monitor(core_id):
    # Create a monitor for this core
    terminal_monitors[core_id] = {
        "last_input": null,
        "last_output": null,
        "connection_status": {},
        "last_activity": OS.get_unix_time(),
        "data_stats": {
            "sent_bytes": 0,
            "received_bytes": 0,
            "last_transfer": 0
        }
    }

# ----- PROCESSING -----
func _process(delta):
    # Process pending connections
    _process_connections()
    
    # Process transfer queue
    _process_transfer_queue()
    
    # Check for connection timeouts
    _check_connection_timeouts()

func _process_connections():
    # Process each active connection
    for api_name in active_connections:
        var connection = active_connections[api_name]
        
        # If connection is in CONNECTING state, check if it has established
        if connection.state == APIState.CONNECTING:
            if connection.has("connection") and connection.connection:
                if connection.connection.get_status() == HTTPClient.STATUS_CONNECTED:
                    # Connection established
                    connection.state = APIState.CONNECTED
                    emit_signal("connection_established", api_name, connection.core_id)
                    
                    # If we have auth token, authenticate
                    if auth_tokens.has(api_name):
                        _authenticate(api_name)
                elif connection.connection.get_status() == HTTPClient.STATUS_BODY or connection.connection.get_status() == HTTPClient.STATUS_CONNECTED:
                    # Check for response
                    if connection.connection.has_response():
                        var headers = connection.connection.get_response_headers_as_dictionary()
                        var body = connection.connection.read_response_body_chunk()
                        
                        # Process response
                        _process_api_response(api_name, headers, body)
                elif connection.connection.get_status() == HTTPClient.STATUS_CANT_CONNECT:
                    # Connection failed
                    connection.state = APIState.ERROR
                    emit_signal("connection_error", api_name, HTTPClient.STATUS_CANT_CONNECT, "Cannot connect to API")
                    
                    # Increment retry count
                    if not retry_counts.has(api_name):
                        retry_counts[api_name] = 0
                    retry_counts[api_name] += 1
                    
                    if retry_counts[api_name] <= MAX_RETRY_COUNT:
                        # Retry connection
                        _connect_to_api(api_name, connection.host, connection.port, connection.core_id)
                    else:
                        # Too many retries, give up
                        emit_signal("connection_error", api_name, HTTPClient.STATUS_CANT_CONNECT, "Max retry count exceeded")

func _process_transfer_queue():
    # Process data transfer queue
    if transfer_queue.size() > 0:
        var transfer = transfer_queue[0]
        var api_name = transfer.api_name
        
        if active_connections.has(api_name):
            var connection = active_connections[api_name]
            
            if connection.state == APIState.AUTHENTICATED:
                # API is authenticated, can transfer data
                var core_id = transfer.core_id
                var data = transfer.data
                var endpoint = transfer.endpoint
                var method = transfer.method
                
                # Try to send the data
                var success = _send_to_api(api_name, endpoint, method, data)
                
                if success:
                    # Data sent, update state
                    connection.state = APIState.TRANSFERRING
                    
                    # Update stats for core monitor
                    if terminal_monitors.has(core_id):
                        var data_size = str(data).length()
                        terminal_monitors[core_id].data_stats.sent_bytes += data_size
                        terminal_monitors[core_id].data_stats.last_transfer = OS.get_unix_time()
                        
                        emit_signal("data_transferred", core_id, api_name, data_size)
                    
                    # Remove from queue
                    transfer_queue.pop_front()
                else:
                    # Failed to send, check if we should retry
                    transfer.retry_count += 1
                    
                    if transfer.retry_count > MAX_RETRY_COUNT:
                        # Too many retries, remove from queue and report error
                        transfer_queue.pop_front()
                        emit_signal("connection_error", api_name, 0, "Failed to send data after " + str(MAX_RETRY_COUNT) + " retries")
            elif connection.state == APIState.CONNECTED:
                # Need to authenticate first
                _authenticate(api_name)
            elif connection.state == APIState.RATE_LIMITED:
                # We're rate limited, stop processing for now
                # The timer will reset the state once the rate limit expires
                pass
            else:
                # Connection not in a state to transfer, remove from queue
                transfer_queue.pop_front()
        else:
            # API connection doesn't exist, remove from queue
            transfer_queue.pop_front()

func _check_connection_timeouts():
    # Check for connection timeouts
    var current_time = OS.get_unix_time()
    
    for api_name in connection_timeouts:
        var timeout_time = connection_timeouts[api_name]
        
        if current_time > timeout_time:
            # Connection has timed out
            if active_connections.has(api_name):
                var connection = active_connections[api_name]
                
                if connection.state == APIState.CONNECTING:
                    # Still trying to connect after timeout
                    connection.state = APIState.ERROR
                    emit_signal("connection_error", api_name, 0, "Connection timeout")
                    
                    # Close connection
                    if connection.has("connection") and connection.connection:
                        connection.connection.close()
                    
                    # Remove from active connections
                    active_connections.erase(api_name)
            
            # Remove timeout
            connection_timeouts.erase(api_name)

# ----- API CONNECTION MANAGEMENT -----
func connect_to_api(api_name, host, port=DEFAULT_PORT, core_id=null):
    # Use active core if none specified
    if core_id == null and dual_core_terminal:
        core_id = dual_core_terminal.get_current_core_id()
    
    # Add to connected cores if not already there
    if core_id != null and not connected_cores.has(core_id):
        connected_cores.append(core_id)
        
        # Initialize monitor if needed
        if not terminal_monitors.has(core_id):
            _initialize_core_monitor(core_id)
        
        # Update monitor with connection info
        terminal_monitors[core_id].connection_status[api_name] = APIState.CONNECTING
    
    return _connect_to_api(api_name, host, port, core_id)

func _connect_to_api(api_name, host, port, core_id):
    # Check if already connected
    if active_connections.has(api_name) and active_connections[api_name].state >= APIState.CONNECTED:
        return true
    
    # Create HTTPClient
    var http = HTTPClient.new()
    var err = http.connect_to_host(host, port)
    
    if err != OK:
        emit_signal("connection_error", api_name, err, "Failed to connect to host")
        return false
    
    # Store connection
    active_connections[api_name] = {
        "connection": http,
        "host": host,
        "port": port,
        "state": APIState.CONNECTING,
        "core_id": core_id
    }
    
    # Set timeout
    connection_timeouts[api_name] = OS.get_unix_time() + API_TIMEOUT
    
    # Reset retry count
    retry_counts[api_name] = 0
    
    print("Connecting to API: " + api_name + " at " + host + ":" + str(port))
    return true

func set_auth_token(api_name, token):
    auth_tokens[api_name] = token
    
    # If already connected, authenticate now
    if active_connections.has(api_name) and active_connections[api_name].state == APIState.CONNECTED:
        _authenticate(api_name)
    
    return true

func _authenticate(api_name):
    if not active_connections.has(api_name) or not auth_tokens.has(api_name):
        return false
    
    var connection = active_connections[api_name]
    
    # Create auth request
    var headers = [
        "Content-Type: application/json",
        AUTH_HEADER + ": " + auth_tokens[api_name]
    ]
    
    var data = JSON.print({"authenticate": true})
    
    # Send auth request
    var err = connection.connection.request("POST", "/auth", headers, data)
    
    if err != OK:
        emit_signal("connection_error", api_name, err, "Failed to send auth request")
        return false
    
    # Wait for response in process_connections
    return true

func _process_api_response(api_name, headers, body):
    if not active_connections.has(api_name):
        return
    
    var connection = active_connections[api_name]
    
    # Check for rate limiting headers
    if headers.has("X-RateLimit-Remaining") and int(headers["X-RateLimit-Remaining"]) == 0:
        connection.state = APIState.RATE_LIMITED
        
        var reset_time = int(headers["X-RateLimit-Reset"]) if headers.has("X-RateLimit-Reset") else 60
        emit_signal("rate_limit_hit", api_name, reset_time)
        
        # Set timer to reset rate limit
        var timer = Timer.new()
        timer.wait_time = reset_time
        timer.one_shot = true
        timer.autostart = true
        timer.connect("timeout", self, "_on_rate_limit_reset", [api_name])
        add_child(timer)
        
        return
    
    # Try to parse JSON body
    var json = JSON.parse(body.get_string_from_utf8())
    
    if json.error == OK:
        var response_data = json.result
        
        # Check response type
        if response_data.has("authenticated") and response_data.authenticated:
            # Authentication successful
            connection.state = APIState.AUTHENTICATED
            emit_signal("auth_succeeded", api_name)
        else:
            # Normal data response
            emit_signal("data_received", api_name, response_data)
            
            # Store in processed data
            processed_data[api_name] = response_data
            
            # Complete transfer
            if connection.state == APIState.TRANSFERRING:
                connection.state = APIState.AUTHENTICATED
            
            # Update core monitor stats if we have a core ID
            if connection.has("core_id") and terminal_monitors.has(connection.core_id):
                var data_size = body.size()
                terminal_monitors[connection.core_id].data_stats.received_bytes += data_size
                terminal_monitors[connection.core_id].data_stats.last_transfer = OS.get_unix_time()
            
            # Check for pending response handlers
            if pending_responses.has(api_name):
                var callback = pending_responses[api_name]
                if callback.has("target") and callback.has("method"):
                    if callback.target.has_method(callback.method):
                        callback.target.call(callback.method, response_data)
                pending_responses.erase(api_name)
    else:
        # Failed to parse JSON
        emit_signal("connection_error", api_name, json.error, "Failed to parse response")

func _send_to_api(api_name, endpoint, method, data):
    if not active_connections.has(api_name):
        return false
    
    var connection = active_connections[api_name]
    
    if not connection.connection:
        return false
    
    # Create request
    var headers = [
        "Content-Type: application/json",
        AUTH_HEADER + ": " + auth_tokens[api_name]
    ]
    
    var json_data = JSON.print(data)
    
    # Send request
    var err = connection.connection.request(method, endpoint, headers, json_data)
    
    if err != OK:
        emit_signal("connection_error", api_name, err, "Failed to send request")
        return false
    
    return true

func _on_rate_limit_reset(api_name):
    if active_connections.has(api_name) and active_connections[api_name].state == APIState.RATE_LIMITED:
        active_connections[api_name].state = APIState.AUTHENTICATED
        print("Rate limit reset for API: " + api_name)

# ----- DATA TRANSFER -----
func send_data(api_name, endpoint, data, method="POST", core_id=null):
    # Use active core if none specified
    if core_id == null and dual_core_terminal:
        core_id = dual_core_terminal.get_current_core_id()
    
    // Add to transfer queue
    transfer_queue.append({
        "api_name": api_name,
        "endpoint": endpoint,
        "data": data,
        "method": method,
        "core_id": core_id,
        "timestamp": OS.get_unix_time(),
        "retry_count": 0
    })
    
    // If connection doesn't exist yet, try to establish it
    if not active_connections.has(api_name):
        emit_signal("connection_error", api_name, 0, "No active connection")
        return false
    
    return true

func register_response_handler(api_name, target, method):
    pending_responses[api_name] = {
        "target": target,
        "method": method,
        "timestamp": OS.get_unix_time()
    }

func synchronize_cores(core_ids=null):
    // If no core IDs specified, sync all connected cores
    if core_ids == null:
        core_ids = connected_cores
    
    var sync_data = {}
    
    // Gather data from each core
    for core_id in core_ids:
        if dual_core_terminal and dual_core_terminal.cores.has(core_id):
            var core_info = dual_core_terminal.get_core_info(core_id)
            
            // Extract relevant data for sync
            sync_data[core_id] = {
                "name": core_info.name,
                "state": core_info.state,
                "bracket_style": core_info.bracket_style,
                "account_value": core_info.account_value,
                "miracle_count": core_info.miracle_count,
                "last_input": core_info.last_input,
                "time_state": dual_core_terminal.get_time_state()
            }
    
    // Record sync time
    last_sync_time = OS.get_unix_time()
    
    emit_signal("cores_synchronized", core_ids)
    return sync_data

func _on_sync_timer_timeout():
    // Auto-sync cores every 5 seconds
    synchronize_cores()

# ----- EVENT HANDLERS -----
func _on_core_switched(old_core_id, new_core_id):
    // Update active API connections for the new core
    for api_name in active_connections:
        var connection = active_connections[api_name]
        
        if connection.core_id == old_core_id:
            connection.core_id = new_core_id
            
            // Update monitor
            if terminal_monitors.has(new_core_id):
                terminal_monitors[new_core_id].connection_status[api_name] = connection.state

func _on_terminal_input_processed(core_id, input_text, result):
    // Update terminal monitor
    if terminal_monitors.has(core_id):
        terminal_monitors[core_id].last_input = input_text
        terminal_monitors[core_id].last_output = result
        terminal_monitors[core_id].last_activity = OS.get_unix_time()
        
        // If input contains API-related commands, process them
        if "#api" in input_text:
            _process_api_command(core_id, input_text)

func _process_api_command(core_id, input_text):
    // Parse API command from input text
    var parts = input_text.split("#api", true, 1)
    
    if parts.size() < 2:
        return
    
    var command_text = parts[1].strip_edges()
    var command_parts = command_text.split(" ", false)
    
    if command_parts.size() < 1:
        return
    
    var cmd = command_parts[0].to_lower()
    
    match cmd:
        "connect":
            // #api connect api_name host [port]
            if command_parts.size() >= 3:
                var api_name = command_parts[1]
                var host = command_parts[2]
                var port = DEFAULT_PORT
                
                if command_parts.size() >= 4 and command_parts[3].is_valid_integer():
                    port = int(command_parts[3])
                
                connect_to_api(api_name, host, port, core_id)
        
        "auth":
            // #api auth api_name token
            if command_parts.size() >= 3:
                var api_name = command_parts[1]
                var token = command_parts[2]
                
                set_auth_token(api_name, token)
        
        "send":
            // #api send api_name endpoint data
            if command_parts.size() >= 4:
                var api_name = command_parts[1]
                var endpoint = command_parts[2]
                var data_str = command_parts.slice(3, command_parts.size() - 1).join(" ")
                
                // Try to parse data as JSON
                var json = JSON.parse(data_str)
                var data = data_str
                
                if json.error == OK:
                    data = json.result
                
                send_data(api_name, endpoint, data, "POST", core_id)
        
        "disconnect":
            // #api disconnect api_name
            if command_parts.size() >= 2:
                var api_name = command_parts[1]
                
                if active_connections.has(api_name):
                    var connection = active_connections[api_name]
                    
                    if connection.has("connection") and connection.connection:
                        connection.connection.close()
                    
                    active_connections.erase(api_name)
                    
                    if core_id != null and terminal_monitors.has(core_id):
                        terminal_monitors[core_id].connection_status.erase(api_name)
                    
                    print("Disconnected from API: " + api_name)

func _on_special_pattern_detected(pattern, effect):
    // Special handling for API patterns
    if pattern == "<->" or pattern == "|/\\|":
        // These patterns indicate dimensional connections or gates
        // Could trigger API sync across dimensions
        for api_name in active_connections:
            var connection = active_connections[api_name]
            
            if connection.state >= APIState.CONNECTED:
                // Send special pattern data
                var data = {
                    "pattern": pattern,
                    "effect": effect,
                    "dimension": turn_system.current_dimension if turn_system else 0,
                    "timestamp": OS.get_unix_time()
                }
                
                send_data(api_name, "/pattern", data, "POST", connection.core_id)

func _on_miracle_triggered(core_id):
    // When a miracle is triggered, notify all connected APIs
    for api_name in active_connections:
        var connection = active_connections[api_name]
        
        if connection.state >= APIState.CONNECTED:
            // Send miracle notification
            var data = {
                "event": "miracle",
                "core_id": core_id,
                "dimension": turn_system.current_dimension if turn_system else 0,
                "timestamp": OS.get_unix_time()
            }
            
            send_data(api_name, "/event", data, "POST", connection.core_id)

func _on_turn_advanced(old_turn, new_turn):
    // When turn advances, update all connected APIs
    for api_name in active_connections:
        var connection = active_connections[api_name]
        
        if connection.state >= APIState.CONNECTED:
            // Send turn update
            var data = {
                "event": "turn_advanced",
                "old_turn": old_turn,
                "new_turn": new_turn,
                "timestamp": OS.get_unix_time()
            }
            
            send_data(api_name, "/event", data, "POST", connection.core_id)

# ----- PUBLIC API -----
func get_connection_status(api_name):
    if active_connections.has(api_name):
        return active_connections[api_name].state
    return APIState.DISCONNECTED

func get_core_monitor_data(core_id):
    if terminal_monitors.has(core_id):
        return terminal_monitors[core_id]
    return null

func get_all_monitors():
    return terminal_monitors

func get_active_connections():
    var connections = []
    for api_name in active_connections:
        connections.append({
            "name": api_name,
            "state": active_connections[api_name].state,
            "host": active_connections[api_name].host,
            "port": active_connections[api_name].port,
            "core_id": active_connections[api_name].core_id
        })
    return connections

func clear_transfer_queue():
    transfer_queue.clear()
    return true

func get_processed_data(api_name):
    if processed_data.has(api_name):
        return processed_data[api_name]
    return null

func get_last_sync_time():
    return last_sync_time

func set_account_api_value(core_id, value):
    if value < 0 or value > MAX_ACCOUNT_API_VALUE:
        return false
    
    if dual_core_terminal and dual_core_terminal.cores.has(core_id):
        dual_core_terminal.cores[core_id].account_value = value
        
        // If account value reached max, set special state
        if value == MAX_ACCOUNT_API_VALUE:
            dual_core_terminal.cores[core_id].state = dual_core_terminal.WindowState.MAX_ACCOUNT
            
            // Add comment about max account value reached
            if word_comment_system:
                word_comment_system.add_comment("account_" + str(core_id),
                    "Core " + str(core_id) + " reached MAX_ACCOUNT value (" + str(value) + ")!",
                    word_comment_system.CommentType.OBSERVATION, "API_Bridge")
        
        return true
    
    return false

func close_all_connections():
    for api_name in active_connections:
        var connection = active_connections[api_name]
        
        if connection.has("connection") and connection.connection:
            connection.connection.close()
    
    active_connections.clear()
    return true
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_api_bridge.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_bridge_connector.gd
# SIZE: 28390 bytes
class_name TerminalBridgeConnector
extends Node

# ----- TERMINAL CONNECTION CONSTANTS -----
const COLOR_PALETTES = {
    "UNIVERSE_389": {
        "CENTER_ORANGE": Color(1.0, 0.6, 0.0, 1.0),
        "DARK_RED": Color(0.5, 0.0, 0.0, 1.0),
        "BLACK": Color(0.0, 0.0, 0.0, 1.0),
        "DARK_GREY": Color(0.2, 0.2, 0.2, 1.0),
        "GREY": Color(0.5, 0.5, 0.5, 1.0),
        "LIGHT_GREY": Color(0.8, 0.8, 0.8, 1.0),
        "WHITE": Color(1.0, 1.0, 1.0, 1.0)
    },
    "LUMINOUS_OS": {
        "DARK_GRADIENT": [
            Color(0.1, 0.1, 0.1, 1.0),
            Color(0.2, 0.1, 0.05, 1.0),
            Color(0.3, 0.15, 0.1, 1.0),
            Color(0.4, 0.2, 0.1, 1.0),
            Color(0.5, 0.25, 0.15, 1.0)
        ],
        "SHINE_POINTS": [389, 333, 555, 777, 999]
    },
    "NEGATIVE_SPACE": {
        "BASE_INVERSION": {
            "source": Color(1.0, 0.6, 0.0, 1.0),
            "inverted": Color(0.0, 0.4, 1.0, 1.0)
        },
        "TEMPERATURE_SCALE": {
            "cold": -273,
            "neutral": 0,
            "warm": 37,
            "hot": 100
        }
    }
}

const ENERGY_SHAPES = {
    "TRANSPORT_VECTORS": [
        Vector3(1, 0, 0),    # Right/East
        Vector3(0, 1, 0),    # Up/North
        Vector3(0, 0, 1),    # Forward/Future
        Vector3(-1, 0, 0),   # Left/West
        Vector3(0, -1, 0),   # Down/South
        Vector3(0, 0, -1),   # Back/Past
        Vector3(0, 0, 0)     # Center/Present
    ],
    "PROJECTION_TYPES": [
        "stellar",           # Star-based projections
        "planetary",         # Planet-based projections
        "galactic",          # Galaxy-based projections
        "universal",         # Universe-based projections
        "dimensional",       # Cross-dimensional projections
        "ethereal",          # Ethereal-plane projections
        "terminal"           # Terminal-based projections
    ],
    "MICROPHONE_FREQUENCIES": {
        "low": [20, 250],
        "mid": [250, 4000],
        "high": [4000, 20000]
    }
}

const STAR_SYSTEM_389 = {
    "total_stars": 389,
    "core_stars": 89,
    "boundary_stars": 300,
    "galaxy_type": "claude",
    "center_color": "orange"
}

# ----- INTEGRATION POINTS -----
var akashic_system = null
var ethereal_bridge = null
var color_system = null
var terminal_ui = null
var records_system = null
var migration_system = null

# ----- CONNECTION STATE -----
var active_connections = {}
var temperature_state = 0
var color_gradient_index = 0
var projection_active = false
var user_view_mode = "terminal"
var energy_flow_direction = Vector3(0, 0, 0)
var connected_universes = []
var audio_input_active = false

# ----- SIGNALS -----
signal terminal_connected(details)
signal color_shift_detected(from_color, to_color, temperature)
signal universe_connection_established(universe_name, star_count)
signal energy_shape_transported(shape_type, from_point, to_point)
signal projection_changed(type, intensity)
signal audio_frequency_detected(frequency_range, intensity)
signal akashic_record_linked(record_type, cosmic_address)

# ----- INITIALIZATION -----
func _ready():
    _find_systems()
    _initialize_terminal_connection()
    _setup_color_gradients()
    _register_universal_connections()
    
    print("Terminal Bridge Connector initialized")

func _find_systems():
    # Find AkashicNumberSystem
    akashic_system = get_node_or_null("/root/AkashicNumberSystem")
    if not akashic_system:
        akashic_system = _find_node_by_class(get_tree().root, "AkashicNumberSystem")
    
    # Find EtherealMigrationBridge
    ethereal_bridge = get_node_or_null("/root/EtherealMigrationBridge")
    if not ethereal_bridge:
        ethereal_bridge = _find_node_by_class(get_tree().root, "EtherealMigrationBridge")
    
    # Find DimensionalColorSystem
    color_system = get_node_or_null("/root/DimensionalColorSystem")
    if not color_system:
        color_system = _find_node_by_class(get_tree().root, "DimensionalColorSystem")
    
    # Find Records System
    records_system = get_node_or_null("/root/JSH_records_system")
    if not records_system:
        records_system = _find_node_by_class(get_tree().root, "JSH_records_system")
    
    # Find Migration System
    migration_system = get_node_or_null("/root/UnifiedMigrationSystem")
    if not migration_system:
        migration_system = _find_node_by_class(get_tree().root, "UnifiedMigrationSystem")
    
    print("Systems found: Akashic=%s, Ethereal=%s, Color=%s, Records=%s, Migration=%s" % [
        "Yes" if akashic_system else "No",
        "Yes" if ethereal_bridge else "No",
        "Yes" if color_system else "No",
        "Yes" if records_system else "No",
        "Yes" if migration_system else "No"
    ])

func _find_node_by_class(node, class_name_str):
    if node.get_class() == class_name_str or (node.get_script() and node.get_script().get_path().find(class_name_str.to_lower()) >= 0):
        return node
    
    for child in node.get_children():
        var found = _find_node_by_class(child, class_name_str)
        if found:
            return found
    
    return null

func _initialize_terminal_connection():
    var terminal_details = {
        "type": "terminal_bridge",
        "connected_universes": STAR_SYSTEM_389.total_stars,
        "primary_color": COLOR_PALETTES.UNIVERSE_389.CENTER_ORANGE,
        "temperature": COLOR_PALETTES.NEGATIVE_SPACE.TEMPERATURE_SCALE.neutral,
        "energy_shape": ENERGY_SHAPES.PROJECTION_TYPES[6],  # terminal
        "timestamp": Time.get_unix_time_from_system()
    }
    
    # Register in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(STAR_SYSTEM_389.total_stars, "universe_389_stars")
        akashic_system.register_number(STAR_SYSTEM_389.core_stars, "universe_389_core")
        
        # Register unique timestamp
        akashic_system.register_number(terminal_details.timestamp, "terminal_connect_time")
    
    # Record in records system
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("terminal_connection", terminal_details)
    
    # Register with color system
    if color_system and color_system.has_method("register_color_palette"):
        color_system.register_color_palette("universe_389", COLOR_PALETTES.UNIVERSE_389)
        color_system.register_color_palette("luminous_os", COLOR_PALETTES.LUMINOUS_OS.DARK_GRADIENT)
    
    # Mark as active
    active_connections["terminal"] = true
    
    emit_signal("terminal_connected", terminal_details)

func _setup_color_gradients():
    # Initialize all color gradients
    _create_color_gradient("orange_to_black", 
        COLOR_PALETTES.UNIVERSE_389.CENTER_ORANGE,
        COLOR_PALETTES.UNIVERSE_389.BLACK,
        7)  # 7 steps gradient
    
    _create_color_gradient("grey_scale", 
        COLOR_PALETTES.UNIVERSE_389.BLACK,
        COLOR_PALETTES.UNIVERSE_389.WHITE,
        9)  # 9 steps gradient
    
    _create_color_gradient("luminous_shine", 
        COLOR_PALETTES.LUMINOUS_OS.DARK_GRADIENT[0],
        COLOR_PALETTES.LUMINOUS_OS.DARK_GRADIENT[4],
        5)  # 5 steps gradient
    
    # Set default gradient
    color_gradient_index = 0

func _create_color_gradient(name, from_color, to_color, steps):
    if not color_system or not color_system.has_method("create_gradient"):
        return
    
    color_system.create_gradient(name, from_color, to_color, steps)

func _register_universal_connections():
    # Register connections to universes
    connected_universes = [
        "luminous_os",
        "universe_389",
        "claude_galaxy",
        "ethereal_engine",
        "akashic_records",
        "dimensional_colors",
        "terminal_projection"
    ]
    
    # Track connections
    for universe in connected_universes:
        active_connections[universe] = true
        
        # Create cosmic address for each universe
        var cosmic_address = _generate_cosmic_address(universe)
        
        # Record in akashic system
        if akashic_system and akashic_system.has_method("register_number"):
            akashic_system.register_number(cosmic_address.hash(), "cosmic_address_" + universe)
        
        # Emit signal
        emit_signal("universe_connection_established", universe, _get_universe_star_count(universe))
        emit_signal("akashic_record_linked", "universe", cosmic_address)

# ----- TERMINAL CONNECTION FUNCTIONS -----
func connect_to_user_actions(user_id = "terminal_user"):
    # Create connection record
    var connection_record = {
        "user_id": user_id,
        "timestamp": Time.get_unix_time_from_system(),
        "terminal_type": "bridge_connector",
        "color_mode": _get_current_color_mode(),
        "temperature": temperature_state,
        "connected_universes": connected_universes
    }
    
    # Record the connection
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("user_terminal_connection", connection_record)
    
    # Set new mode
    user_view_mode = "user_interactive"
    
    # Return connection data
    return connection_record

func detect_user_action(action_type, action_data):
    # Process user action
    match action_type:
        "color_change":
            return _process_color_change(action_data)
        "temperature_adjust":
            return _process_temperature_adjustment(action_data)
        "projection_toggle":
            return _process_projection_toggle(action_data)
        "universe_connect":
            return _process_universe_connection(action_data)
        "energy_transport":
            return _process_energy_transport(action_data)
        "audio_input":
            return _process_audio_input(action_data)
        "akashic_sync":
            return _process_akashic_sync(action_data)
        _:
            return {
                "success": false,
                "error": "Unknown action type: " + action_type
            }

func _process_color_change(data):
    var from_color = _get_current_color()
    var to_color = null
    
    # Determine target color
    if data.has("color_name"):
        to_color = _get_color_by_name(data.color_name)
    elif data.has("color_value"):
        to_color = data.color_value
    elif data.has("gradient_step"):
        color_gradient_index = data.gradient_step
        to_color = _get_current_gradient_color()
    
    if not to_color:
        return {
            "success": false,
            "error": "Invalid color specification"
        }
    
    # Register color change
    if color_system and color_system.has_method("shift_color"):
        color_system.shift_color(from_color, to_color, temperature_state)
    
    # Record the change
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("color_shift", {
            "from": from_color.to_html(),
            "to": to_color.to_html(),
            "temperature": temperature_state,
            "timestamp": Time.get_unix_time_from_system()
        })
    
    # Emit signal
    emit_signal("color_shift_detected", from_color, to_color, temperature_state)
    
    return {
        "success": true,
        "from_color": from_color.to_html(),
        "to_color": to_color.to_html(),
        "temperature": temperature_state
    }

func _process_temperature_adjustment(data):
    var old_temp = temperature_state
    
    # Update temperature
    if data.has("value"):
        temperature_state = data.value
    elif data.has("delta"):
        temperature_state += data.delta
    
    # Register temperature change
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(temperature_state, "temperature_state")
    
    # Record the change
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("temperature_change", {
            "from": old_temp,
            "to": temperature_state,
            "timestamp": Time.get_unix_time_from_system()
        })
    
    return {
        "success": true,
        "old_temperature": old_temp,
        "new_temperature": temperature_state
    }

func _process_projection_toggle(data):
    projection_active = data.active if data.has("active") else !projection_active
    var projection_type = data.type if data.has("type") else "terminal"
    var intensity = data.intensity if data.has("intensity") else 1.0
    
    # Record the change
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("projection_toggle", {
            "active": projection_active,
            "type": projection_type,
            "intensity": intensity,
            "timestamp": Time.get_unix_time_from_system()
        })
    
    # Emit signal
    emit_signal("projection_changed", projection_type, intensity)
    
    return {
        "success": true,
        "projection_active": projection_active,
        "projection_type": projection_type,
        "intensity": intensity
    }

func _process_universe_connection(data):
    var universe_name = data.universe if data.has("universe") else "luminous_os"
    var connect_state = data.connect if data.has("connect") else true
    
    # Update connection state
    active_connections[universe_name] = connect_state
    
    if connect_state and !connected_universes.has(universe_name):
        connected_universes.append(universe_name)
    elif !connect_state and connected_universes.has(universe_name):
        connected_universes.erase(universe_name)
    
    # Create cosmic address
    var cosmic_address = _generate_cosmic_address(universe_name)
    
    # Register in akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        var star_count = _get_universe_star_count(universe_name)
        akashic_system.register_number(star_count, universe_name + "_stars")
    
    # Record the connection
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("universe_connection", {
            "universe": universe_name,
            "connected": connect_state,
            "cosmic_address": cosmic_address,
            "timestamp": Time.get_unix_time_from_system()
        })
    
    # Emit signal
    if connect_state:
        emit_signal("universe_connection_established", universe_name, _get_universe_star_count(universe_name))
        emit_signal("akashic_record_linked", "universe", cosmic_address)
    
    return {
        "success": true,
        "universe": universe_name,
        "connected": connect_state,
        "cosmic_address": cosmic_address
    }

func _process_energy_transport(data):
    var shape_type = data.shape if data.has("shape") else "terminal"
    var from_point = data.from if data.has("from") else Vector3(0, 0, 0)
    var to_point = data.to if data.has("to") else Vector3(0, 0, 1)
    
    # Update energy flow direction
    energy_flow_direction = to_point - from_point
    
    # Record the transport
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("energy_transport", {
            "shape": shape_type,
            "from": from_point,
            "to": to_point,
            "flow_direction": energy_flow_direction,
            "timestamp": Time.get_unix_time_from_system()
        })
    
    # Emit signal
    emit_signal("energy_shape_transported", shape_type, from_point, to_point)
    
    return {
        "success": true,
        "shape_type": shape_type,
        "from_point": from_point,
        "to_point": to_point,
        "flow_direction": energy_flow_direction
    }

func _process_audio_input(data):
    audio_input_active = data.active if data.has("active") else true
    var frequency_range = data.range if data.has("range") else "mid"
    var intensity = data.intensity if data.has("intensity") else 1.0
    
    # Get actual frequency values
    var freq_values = ENERGY_SHAPES.MICROPHONE_FREQUENCIES[frequency_range]
    
    # Record the audio input
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("audio_input", {
            "active": audio_input_active,
            "frequency_range": frequency_range,
            "frequency_values": freq_values,
            "intensity": intensity,
            "timestamp": Time.get_unix_time_from_system()
        })
    
    # Register with akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(freq_values[0], "audio_freq_low")
        akashic_system.register_number(freq_values[1], "audio_freq_high")
    
    # Emit signal
    emit_signal("audio_frequency_detected", frequency_range, intensity)
    
    return {
        "success": true,
        "audio_active": audio_input_active,
        "frequency_range": frequency_range,
        "frequency_values": freq_values,
        "intensity": intensity
    }

func _process_akashic_sync(data):
    var record_type = data.type if data.has("type") else "terminal"
    var sync_all = data.sync_all if data.has("sync_all") else false
    
    # Generate cosmic address
    var cosmic_address = _generate_cosmic_address(record_type)
    
    # Perform the sync
    if ethereal_bridge and ethereal_bridge.has_method("_record_node_migration"):
        ethereal_bridge._record_node_migration(record_type, "akashic_sync")
    
    # Sync with akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(cosmic_address.hash(), "akashic_sync_" + record_type)
    
    # Record the sync
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("akashic_sync", {
            "record_type": record_type,
            "cosmic_address": cosmic_address,
            "sync_all": sync_all,
            "timestamp": Time.get_unix_time_from_system()
        })
    
    # Emit signal
    emit_signal("akashic_record_linked", record_type, cosmic_address)
    
    return {
        "success": true,
        "record_type": record_type,
        "cosmic_address": cosmic_address,
        "sync_all": sync_all
    }

# ----- AKASHIC RECORD INTEGRATION -----
func link_akashic_records_to_ethereal():
    # Check if both systems are available
    if not akashic_system or not ethereal_bridge:
        return {
            "success": false,
            "error": "Required systems unavailable",
            "akashic_available": akashic_system != null,
            "ethereal_available": ethereal_bridge != null
        }
    
    # Create bridge records
    var bridge_records = []
    
    # 1. Link color systems
    if color_system:
        var color_record = {
            "type": "color_bridge",
            "palettes": COLOR_PALETTES.keys(),
            "gradients": 3,  # Number of gradients created
            "timestamp": Time.get_unix_time_from_system()
        }
        bridge_records.append(color_record)
        
        # Register key colors in akashic system
        akashic_system.register_number(COLOR_PALETTES.UNIVERSE_389.CENTER_ORANGE.to_rgba32(), "center_orange_rgba")
    
    # 2. Link energy transport
    var energy_record = {
        "type": "energy_bridge",
        "vectors": ENERGY_SHAPES.TRANSPORT_VECTORS.size(),
        "projection_types": ENERGY_SHAPES.PROJECTION_TYPES,
        "frequency_ranges": ENERGY_SHAPES.MICROPHONE_FREQUENCIES.keys(),
        "timestamp": Time.get_unix_time_from_system()
    }
    bridge_records.append(energy_record)
    
    # 3. Link universe connections
    var universe_record = {
        "type": "universe_bridge",
        "connected_universes": connected_universes,
        "total_stars": STAR_SYSTEM_389.total_stars,
        "timestamp": Time.get_unix_time_from_system()
    }
    bridge_records.append(universe_record)
    
    # 4. Create the core bridge record
    var core_bridge = {
        "type": "akashic_ethereal_bridge",
        "bridge_records": bridge_records,
        "temperature": temperature_state,
        "projection_active": projection_active,
        "color_gradient": _get_current_color_mode(),
        "timestamp": Time.get_unix_time_from_system()
    }
    
    # Record in ethereal bridge
    if ethereal_bridge.has_method("_record_record_set_migration"):
        ethereal_bridge._record_record_set_migration("akashic_ethereal_bridge")
    
    # Record in records system
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("akashic_ethereal_bridge", core_bridge)
    
    # Generate cosmic address
    var cosmic_address = _generate_cosmic_address("akashic_ethereal_bridge")
    
    # Register core bridge in akashic system
    akashic_system.register_number(cosmic_address.hash(), "akashic_ethereal_bridge_hash")
    akashic_system.register_number(bridge_records.size(), "bridge_records_count")
    akashic_system.register_number(core_bridge.timestamp, "bridge_timestamp")
    
    # Emit signals
    emit_signal("akashic_record_linked", "akashic_ethereal_bridge", cosmic_address)
    
    return {
        "success": true,
        "bridge_records": bridge_records.size(),
        "cosmic_address": cosmic_address,
        "bridge_timestamp": core_bridge.timestamp
    }

func sync_terminal_view_with_akashic():
    # Get current timestamp
    var sync_timestamp = Time.get_unix_time_from_system()
    
    # Create the sync record
    var sync_record = {
        "type": "terminal_view_sync",
        "user_view_mode": user_view_mode,
        "color_mode": _get_current_color_mode(),
        "temperature": temperature_state,
        "projection_active": projection_active,
        "connected_universes": connected_universes,
        "energy_flow": energy_flow_direction,
        "audio_input_active": audio_input_active,
        "timestamp": sync_timestamp
    }
    
    # Record in records system
    if records_system and records_system.has_method("create_memory_record"):
        records_system.create_memory_record("terminal_view_sync", sync_record)
    
    # Assign lucky numbers to akashic system
    if akashic_system and akashic_system.has_method("register_number"):
        akashic_system.register_number(sync_timestamp, "terminal_sync_time")
        akashic_system.register_number(connected_universes.size(), "connected_universe_count")
        akashic_system.register_number(color_gradient_index, "color_gradient_index")
        
        # Register special numbers from COLOR_PALETTES.LUMINOUS_OS.SHINE_POINTS
        for shine_point in COLOR_PALETTES.LUMINOUS_OS.SHINE_POINTS:
            akashic_system.register_number(shine_point, "shine_point_" + str(shine_point))
    
    return {
        "success": true,
        "sync_timestamp": sync_timestamp,
        "view_mode": user_view_mode,
        "color_mode": _get_current_color_mode(),
        "connected_universes": connected_universes.size()
    }

# ----- HELPER FUNCTIONS -----
func _generate_cosmic_address(base_name):
    var timestamp = Time.get_unix_time_from_system()
    var address_components = [
        base_name,
        str(timestamp),
        str(STAR_SYSTEM_389.total_stars),
        _get_current_color_mode(),
        str(temperature_state)
    ]
    
    return address_components.join(":")

func _get_universe_star_count(universe_name):
    match universe_name:
        "universe_389":
            return STAR_SYSTEM_389.total_stars
        "claude_galaxy":
            return 2025
        "luminous_os":
            return 333
        "ethereal_engine":
            return 555
        "akashic_records":
            return 777
        "dimensional_colors":
            return 999
        "terminal_projection":
            return 389
        _:
            return 89

func _get_color_by_name(color_name):
    # Check Universe 389 palette
    if COLOR_PALETTES.UNIVERSE_389.has(color_name.to_upper()):
        return COLOR_PALETTES.UNIVERSE_389[color_name.to_upper()]
    
    # Check Luminous OS gradient
    match color_name.to_lower():
        "luminous_dark":
            return COLOR_PALETTES.LUMINOUS_OS.DARK_GRADIENT[0]
        "luminous_medium":
            return COLOR_PALETTES.LUMINOUS_OS.DARK_GRADIENT[2]
        "luminous_light":
            return COLOR_PALETTES.LUMINOUS_OS.DARK_GRADIENT[4]
        _:
            return COLOR_PALETTES.UNIVERSE_389.CENTER_ORANGE

func _get_current_color():
    # Get color based on current mode and gradient index
    match _get_current_color_mode():
        "orange_to_black":
            var gradient_pos = float(color_gradient_index) / 6.0
            return COLOR_PALETTES.UNIVERSE_389.CENTER_ORANGE.lerp(
                COLOR_PALETTES.UNIVERSE_389.BLACK, 
                gradient_pos)
        "grey_scale":
            var gradient_pos = float(color_gradient_index) / 8.0
            return COLOR_PALETTES.UNIVERSE_389.BLACK.lerp(
                COLOR_PALETTES.UNIVERSE_389.WHITE, 
                gradient_pos)
        "luminous_shine":
            var idx = mini(color_gradient_index, COLOR_PALETTES.LUMINOUS_OS.DARK_GRADIENT.size() - 1)
            return COLOR_PALETTES.LUMINOUS_OS.DARK_GRADIENT[idx]
        _:
            return COLOR_PALETTES.UNIVERSE_389.CENTER_ORANGE

func _get_current_gradient_color():
    # Get the current color from the active gradient
    if color_system and color_system.has_method("get_gradient_color"):
        return color_system.get_gradient_color(_get_current_color_mode(), color_gradient_index)
    else:
        return _get_current_color()

func _get_current_color_mode():
    var modes = ["orange_to_black", "grey_scale", "luminous_shine"]
    var temperature_range = COLOR_PALETTES.NEGATIVE_SPACE.TEMPERATURE_SCALE
    
    # Select mode based on temperature
    if temperature_state <= temperature_range.cold:
        return "luminous_shine"
    elif temperature_state <= temperature_range.neutral:
        return "grey_scale"
    else:
        return "orange_to_black"

# ----- PUBLIC API -----
func connect_terminal_to_user():
    return connect_to_user_actions()

func process_user_color_change(color_name):
    return detect_user_action("color_change", {"color_name": color_name})

func adjust_temperature(delta):
    return detect_user_action("temperature_adjust", {"delta": delta})

func toggle_projection(active = true, type = "terminal"):
    return detect_user_action("projection_toggle", {"active": active, "type": type})

func connect_to_universe(universe_name, connect = true):
    return detect_user_action("universe_connect", {"universe": universe_name, "connect": connect})

func transport_energy_shape(shape_type, from_point, to_point):
    return detect_user_action("energy_transport", {
        "shape": shape_type,
        "from": from_point,
        "to": to_point
    })

func activate_audio_input(frequency_range = "mid", intensity = 1.0):
    return detect_user_action("audio_input", {
        "active": true,
        "range": frequency_range,
        "intensity": intensity
    })

func sync_akashic_record(record_type, sync_all = false):
    return detect_user_action("akashic_sync", {
        "type": record_type,
        "sync_all": sync_all
    })

func get_color_palette(palette_name):
    if COLOR_PALETTES.has(palette_name.to_upper()):
        return COLOR_PALETTES[palette_name.to_upper()]
    return null

func get_connected_universes():
    return connected_universes

func get_temperature_state():
    return temperature_state

func get_current_projection_state():
    return {
        "active": projection_active,
        "user_view_mode": user_view_mode,
        "energy_flow": energy_flow_direction
    }

func get_terminal_connection_stats():
    return {
        "connected_universes": connected_universes.size(),
        "active_color_mode": _get_current_color_mode(),
        "temperature": temperature_state,
        "projection_active": projection_active,
        "audio_active": audio_input_active,
        "total_stars": STAR_SYSTEM_389.total_stars
    }

func create_terminal_bridge_with_ethereal():
    var result = link_akashic_records_to_ethereal()
    sync_terminal_view_with_akashic()
    return result
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_bridge_connector.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_grid_creator.gd
# SIZE: 27817 bytes
extends Node

# Terminal Grid Creator
# Creates game elements (dungeons, ships, bases) using ASCII symbols
# Handles pattern detection and supports special effects

class_name TerminalGridCreator

# ----- GRID PROPERTIES -----
@export var grid_width: int = 80
@export var grid_height: int = 24
@export var cell_size: Vector2 = Vector2(16, 16)
@export var default_symbol: String = "."

# ----- SPECIAL SYMBOL PATTERNS -----
const SPECIAL_PATTERNS = {
    "#$%$#@@": "miracle_portal",
    "####": "solid_wall",
    "~~~~": "water_area",
    "^^^^": "lava_pit",
    "...+...": "door_corridor",
    "@@@": "entity_spawn",
    "$$$": "treasure_room",
    "###\n#+#\n###": "enclosed_room",
    "[@]": "player_start",
    "<->": "teleporter",
    "/*\\": "time_rune",
    "|/\\|": "dimension_gate"
}

# ----- GRID CELLS -----
var grid_cells = []
var grid_elements = []
var recent_patterns = []
var saved_grids = {}

# ----- SHAPE CATEGORIES -----
enum ShapeCategory {
    ROOM,
    CORRIDOR,
    SHIP,
    BASE,
    ENTITY,
    SPECIAL
}

# ----- TIME STATES -----
enum TimeState {
    PAST,
    PRESENT,
    FUTURE,
    TIMELESS
}

# ----- GAME SYSTEMS -----
var dual_core_terminal = null
var divine_word_game = null
var turn_system = null

# ----- SIGNALS -----
signal grid_created(grid_id, width, height)
signal grid_element_added(element_id, category, pattern)
signal grid_element_removed(element_id)
signal special_pattern_detected(pattern, effect)
signal miracle_portal_created(x, y)
signal grid_saved(grid_id, name)
signal grid_loaded(grid_id, name)
signal time_effect_applied(grid_id, time_state)

# ----- INITIALIZATION -----
func _ready():
    print("Terminal Grid Creator initializing...")
    
    # Initialize empty grid
    _initialize_grid()
    
    # Connect to game systems
    _connect_to_game_systems()
    
    print("Terminal Grid Creator initialized")
    print("Grid size: " + str(grid_width) + "x" + str(grid_height))

func _initialize_grid():
    grid_cells = []
    
    # Create empty grid with default symbols
    for y in range(grid_height):
        var row = []
        for x in range(grid_width):
            row.append({
                "symbol": default_symbol,
                "element_id": -1,  # No element
                "color": Color(1, 1, 1),
                "properties": {}
            })
        grid_cells.append(row)

func _connect_to_game_systems():
    # Connect to dual core terminal
    dual_core_terminal = get_node_or_null("/root/DualCoreTerminal")
    if dual_core_terminal:
        dual_core_terminal.connect("special_pattern_detected", self, "_on_special_pattern_detected")
        dual_core_terminal.connect("time_state_changed", self, "_on_time_state_changed")
    
    # Connect to divine word game
    divine_word_game = get_node_or_null("/root/DivineWordGame")
    
    # Connect to turn system
    turn_system = get_node_or_null("/root/TurnSystem")
    if turn_system:
        turn_system.connect("dimension_changed", self, "_on_dimension_changed")

# ----- GRID MANAGEMENT -----
func create_grid(width, height, default_sym = "."):
    # Store current grid if it has elements
    if grid_elements.size() > 0:
        saved_grids["previous_grid"] = {
            "cells": grid_cells.duplicate(true),
            "elements": grid_elements.duplicate(true),
            "width": grid_width,
            "height": grid_height
        }
    
    # Update grid properties
    grid_width = width
    grid_height = height
    default_symbol = default_sym
    
    # Create new grid
    _initialize_grid()
    grid_elements = []
    
    # Generate grid ID
    var grid_id = "grid_" + str(OS.get_unix_time())
    
    emit_signal("grid_created", grid_id, width, height)
    return grid_id

func place_symbol(x, y, symbol, element_id = -1, properties = {}):
    # Check bounds
    if x < 0 or x >= grid_width or y < 0 or y >= grid_height:
        return false
    
    # Update cell
    grid_cells[y][x].symbol = symbol
    grid_cells[y][x].element_id = element_id
    
    # Add properties
    for key in properties:
        grid_cells[y][x].properties[key] = properties[key]
    
    # Check for special pattern at this location
    _check_patterns_at(x, y)
    
    return true

func place_pattern(x, y, pattern, category, properties = {}):
    var lines = pattern.split("\n")
    var height = lines.size()
    var width = 0
    
    # Find max width
    for line in lines:
        width = max(width, line.length())
    
    # Create element entry
    var element_id = grid_elements.size()
    var element = {
        "id": element_id,
        "category": category,
        "pattern": pattern,
        "x": x,
        "y": y,
        "width": width,
        "height": height,
        "properties": properties.duplicate(),
        "cells": []
    }
    
    # Place each symbol
    for dy in range(height):
        if y + dy >= grid_height:
            continue
        
        var line = lines[dy]
        for dx in range(line.length()):
            if x + dx >= grid_width:
                continue
            
            var symbol = line[dx]
            place_symbol(x + dx, y + dy, symbol, element_id, properties)
            
            # Track cells in element
            element.cells.append({"x": x + dx, "y": y + dy})
    
    # Add element
    grid_elements.append(element)
    
    # Check for special pattern
    _check_pattern_string(pattern, x, y)
    
    emit_signal("grid_element_added", element_id, category, pattern)
    return element_id

func remove_element(element_id):
    if element_id < 0 or element_id >= grid_elements.size():
        return false
    
    var element = grid_elements[element_id]
    
    # Clear all cells used by this element
    for cell in element.cells:
        var x = cell.x
        var y = cell.y
        
        if x >= 0 and x < grid_width and y >= 0 and y < grid_height:
            grid_cells[y][x].symbol = default_symbol
            grid_cells[y][x].element_id = -1
            grid_cells[y][x].properties = {}
    
    # Remove element
    grid_elements[element_id] = null  # Keep array indices intact
    
    emit_signal("grid_element_removed", element_id)
    return true

func save_grid(name):
    var grid_data = {
        "cells": grid_cells.duplicate(true),
        "elements": grid_elements.duplicate(true),
        "width": grid_width,
        "height": grid_height,
        "default_symbol": default_symbol,
        "saved_time": OS.get_unix_time()
    }
    
    saved_grids[name] = grid_data
    
    emit_signal("grid_saved", "grid_" + str(OS.get_unix_time()), name)
    return true

func load_grid(name):
    if not saved_grids.has(name):
        return false
    
    var grid_data = saved_grids[name]
    
    # Load grid properties
    grid_width = grid_data.width
    grid_height = grid_data.height
    default_symbol = grid_data.default_symbol
    
    # Load cells and elements
    grid_cells = grid_data.cells.duplicate(true)
    grid_elements = grid_data.elements.duplicate(true)
    
    emit_signal("grid_loaded", "grid_" + str(OS.get_unix_time()), name)
    return true

# ----- PATTERN DETECTION -----
func _check_patterns_at(x, y):
    # Check for horizontal patterns
    _check_horizontal_pattern(x, y)
    
    # Check for vertical patterns
    _check_vertical_pattern(x, y)
    
    # Check for rectangular patterns
    _check_rectangular_pattern(x, y)

func _check_horizontal_pattern(x, y):
    if x + 10 > grid_width:
        return
    
    # Build horizontal string
    var h_string = ""
    for dx in range(10):
        h_string += grid_cells[y][x + dx].symbol
    
    # Check against special patterns
    for pattern in SPECIAL_PATTERNS:
        if h_string.find(pattern) >= 0:
            _on_pattern_detected(pattern, SPECIAL_PATTERNS[pattern], x, y)

func _check_vertical_pattern(x, y):
    if y + 10 > grid_height:
        return
    
    # Build vertical string
    var v_string = ""
    for dy in range(10):
        v_string += grid_cells[y + dy][x].symbol
    
    # Check against special patterns
    for pattern in SPECIAL_PATTERNS:
        if v_string.find(pattern) >= 0:
            _on_pattern_detected(pattern, SPECIAL_PATTERNS[pattern], x, y)

func _check_rectangular_pattern(x, y):
    # Check for small rectangular patterns (up to 5x5)
    if x + 5 > grid_width or y + 5 > grid_height:
        return
    
    # Build rectangular string
    var rect_string = ""
    for dy in range(5):
        for dx in range(5):
            rect_string += grid_cells[y + dy][x + dx].symbol
        rect_string += "\n"
    
    # Check against special patterns that contain newlines
    for pattern in SPECIAL_PATTERNS:
        if "\n" in pattern and rect_string.find(pattern) >= 0:
            _on_pattern_detected(pattern, SPECIAL_PATTERNS[pattern], x, y)

func _check_pattern_string(pattern, x, y):
    # Check the pattern string directly for special patterns
    for special in SPECIAL_PATTERNS:
        if pattern.find(special) >= 0:
            _on_pattern_detected(special, SPECIAL_PATTERNS[special], x, y)

func _on_pattern_detected(pattern, effect, x, y):
    # Add to recent patterns
    recent_patterns.append({
        "pattern": pattern,
        "effect": effect,
        "x": x,
        "y": y,
        "timestamp": OS.get_unix_time()
    })
    
    # Emit signal
    emit_signal("special_pattern_detected", pattern, effect)
    
    # Handle special effects
    match effect:
        "miracle_portal":
            _create_miracle_portal(x, y)
        "teleporter":
            _create_teleporter(x, y)
        "time_rune":
            _create_time_rune(x, y)
        "dimension_gate":
            _create_dimension_gate(x, y)

func _create_miracle_portal(x, y):
    # Create special visual effect for miracle portal
    var portal_properties = {
        "type": "miracle_portal",
        "active": true,
        "created_at": OS.get_unix_time(),
        "color": Color(1, 0.5, 1)  # Purple glow
    }
    
    # Create portal pattern
    var portal_pattern = "#$%$#@@\n@#$%$#@\n@$#%$#@"
    place_pattern(x, y, portal_pattern, ShapeCategory.SPECIAL, portal_properties)
    
    emit_signal("miracle_portal_created", x, y)
    
    # Notify divine word game if available
    if divine_word_game:
        divine_word_game.process_word("miracle_portal")

func _create_teleporter(x, y):
    # Create teleporter effect
    var teleporter_properties = {
        "type": "teleporter",
        "active": true,
        "created_at": OS.get_unix_time(),
        "destination_x": randi() % grid_width,
        "destination_y": randi() % grid_height
    }
    
    place_pattern(x, y, "<->", ShapeCategory.SPECIAL, teleporter_properties)

func _create_time_rune(x, y):
    # Create time rune effect
    var time_rune_properties = {
        "type": "time_rune",
        "active": true,
        "created_at": OS.get_unix_time(),
        "time_state": TimeState.PRESENT
    }
    
    place_pattern(x, y, "/*\\", ShapeCategory.SPECIAL, time_rune_properties)

func _create_dimension_gate(x, y):
    # Create dimension gate effect
    var dimension_gate_properties = {
        "type": "dimension_gate",
        "active": true,
        "created_at": OS.get_unix_time(),
        "current_dimension": turn_system.current_dimension if turn_system else 3,
        "target_dimension": (turn_system.current_dimension + 1) % (turn_system.max_turns + 1) if turn_system else 4
    }
    
    place_pattern(x, y, "|/\\|", ShapeCategory.SPECIAL, dimension_gate_properties)

# ----- TIME EFFECTS -----
func apply_time_effect(time_state):
    var current_grid_id = "grid_" + str(OS.get_unix_time())
    
    # Apply different effects based on time state
    match time_state:
        TimeState.PAST:
            # Show older versions of elements
            if saved_grids.has("previous_grid"):
                # Temporarily load past version
                var current = {
                    "cells": grid_cells.duplicate(true),
                    "elements": grid_elements.duplicate(true),
                    "width": grid_width,
                    "height": grid_height
                }
                
                # Load previous grid
                grid_cells = saved_grids.previous_grid.cells.duplicate(true)
                grid_elements = saved_grids.previous_grid.elements.duplicate(true)
                
                # Apply faded effect
                for y in range(grid_height):
                    for x in range(grid_width):
                        if grid_cells[y][x].has("color"):
                            grid_cells[y][x].color = grid_cells[y][x].color.darkened(0.3)
                
                # Save current as temp for later restoration
                saved_grids["temp_current"] = current
        
        TimeState.FUTURE:
            # Show potential future elements
            # Generate some new elements based on existing ones
            var future_elements = []
            
            for element in grid_elements:
                if element == null:
                    continue
                
                # Create evolved version of the element
                var evolved = element.duplicate(true)
                evolved.id = grid_elements.size() + future_elements.size()
                
                # Shift position slightly
                evolved.x += randi() % 5 - 2
                evolved.y += randi() % 3 - 1
                
                # Ensure within bounds
                evolved.x = clamp(evolved.x, 0, grid_width - evolved.width)
                evolved.y = clamp(evolved.y, 0, grid_height - evolved.height)
                
                future_elements.append(evolved)
            
            # Save current as temp
            saved_grids["temp_current"] = {
                "cells": grid_cells.duplicate(true),
                "elements": grid_elements.duplicate(true),
                "width": grid_width,
                "height": grid_height
            }
            
            # Add future elements
            for element in future_elements:
                # Parse pattern
                var lines = element.pattern.split("\n")
                
                # Place each symbol
                for dy in range(element.height):
                    if element.y + dy >= grid_height:
                        continue
                    
                    var line = lines[dy] if dy < lines.size() else ""
                    for dx in range(element.width):
                        if element.x + dx >= grid_width or dx >= line.length():
                            continue
                        
                        var symbol = line[dx]
                        grid_cells[element.y + dy][element.x + dx].symbol = symbol
                        grid_cells[element.y + dy][element.x + dx].element_id = element.id
                        grid_cells[element.y + dy][element.x + dx].color = Color(0.8, 0.8, 1.0)  # Bluish tint
        
        TimeState.TIMELESS:
            # Show all time states overlapping
            # Save current first
            saved_grids["temp_current"] = {
                "cells": grid_cells.duplicate(true),
                "elements": grid_elements.duplicate(true),
                "width": grid_width,
                "height": grid_height
            }
            
            # Blend past and future if available
            if saved_grids.has("previous_grid"):
                for y in range(min(grid_height, saved_grids.previous_grid.height)):
                    for x in range(min(grid_width, saved_grids.previous_grid.width)):
                        # 50% chance to use past symbol
                        if randf() < 0.5:
                            grid_cells[y][x].symbol = saved_grids.previous_grid.cells[y][x].symbol
                            grid_cells[y][x].color = Color(1, 0.7, 1)  # Purple tint
        
        TimeState.PRESENT:
            # Restore from temp if it exists
            if saved_grids.has("temp_current"):
                grid_cells = saved_grids.temp_current.cells.duplicate(true)
                grid_elements = saved_grids.temp_current.elements.duplicate(true)
                saved_grids.erase("temp_current")
    
    emit_signal("time_effect_applied", current_grid_id, time_state)
    return current_grid_id

# ----- EVENT HANDLERS -----
func _on_special_pattern_detected(pattern, effect):
    # Called when DualCoreTerminal detects a pattern
    # Add to recent patterns
    recent_patterns.append({
        "pattern": pattern,
        "effect": effect,
        "x": -1,  # Unknown location
        "y": -1,
        "source": "terminal",
        "timestamp": OS.get_unix_time()
    })
    
    # If it's a grid-related pattern, try to place it somewhere
    if SPECIAL_PATTERNS.has(pattern):
        # Find a suitable location
        var x = randi() % (grid_width - 10)
        var y = randi() % (grid_height - 5)
        
        place_pattern(x, y, pattern, ShapeCategory.SPECIAL, {
            "source": "terminal_pattern",
            "effect": effect
        })

func _on_time_state_changed(old_state, new_state):
    # Apply time effect to the grid
    apply_time_effect(new_state)

func _on_dimension_changed(new_dimension, old_dimension):
    # Handle dimension change
    # Save current grid
    save_grid("dimension_" + str(old_dimension))
    
    # If we have a saved grid for the new dimension, load it
    if saved_grids.has("dimension_" + str(new_dimension)):
        load_grid("dimension_" + str(new_dimension))
    else:
        # Create a new grid for this dimension
        create_grid(grid_width, grid_height, default_symbol)
        
        # Add dimension-specific elements
        _add_dimension_elements(new_dimension)

func _add_dimension_elements(dimension):
    # Add dimension-specific elements to a new grid
    match dimension:
        1: # Linear elements (1D)
            place_pattern(10, grid_height / 2, "----------------", ShapeCategory.CORRIDOR, {
                "dimension": 1,
                "description": "Linear path"
            })
        
        2: # Planar elements (2D)
            var square = "+----+\n|    |\n|    |\n+----+"
            place_pattern(grid_width / 2 - 3, grid_height / 2 - 2, square, ShapeCategory.ROOM, {
                "dimension": 2,
                "description": "Square room"
            })
        
        3: # Spatial elements (3D)
            var cube = "/-----\\\n|     |\n|     |\n|     |\n\\-----/"
            place_pattern(grid_width / 2 - 3, grid_height / 2 - 2, cube, ShapeCategory.ROOM, {
                "dimension": 3,
                "description": "Cube room"
            })
        
        4: # Temporal elements (4D)
            place_pattern(grid_width / 2 - 3, grid_height / 2 - 1, "/*\\", ShapeCategory.SPECIAL, {
                "dimension": 4,
                "description": "Time rune",
                "type": "time_rune"
            })
        
        5: # Probability elements (5D)
            var pattern = "~~~?\n?~~~\n~~~?\n?~~~"
            place_pattern(grid_width / 2 - 2, grid_height / 2 - 2, pattern, ShapeCategory.SPECIAL, {
                "dimension": 5,
                "description": "Probability waves"
            })
        
        7: # Dream elements (7D)
            var pattern = "*   *\n * * \n  *  \n * * \n*   *"
            place_pattern(grid_width / 2 - 2, grid_height / 2 - 2, pattern, ShapeCategory.SPECIAL, {
                "dimension": 7,
                "description": "Dream fragment"
            })
        
        9: # Judgment elements (9D)
            var pattern = "=====\n  |\n  |\n  O  "
            place_pattern(grid_width / 2 - 2, grid_height / 2 - 2, pattern, ShapeCategory.SPECIAL, {
                "dimension": 9,
                "description": "Scales of judgment"
            })
        
        12: # Divine elements (12D)
            place_pattern(grid_width / 2 - 3, grid_height / 2 - 1, "#$%$#@@", ShapeCategory.SPECIAL, {
                "dimension": 12,
                "description": "Miracle portal",
                "type": "miracle_portal"
            })

# ----- PUBLIC API -----
func get_grid_size():
    return Vector2(grid_width, grid_height)

func get_cell(x, y):
    if x < 0 or x >= grid_width or y < 0 or y >= grid_height:
        return null
    
    return grid_cells[y][x]

func get_grid_as_string():
    var result = ""
    
    for y in range(grid_height):
        var row = ""
        for x in range(grid_width):
            row += grid_cells[y][x].symbol
        result += row + "\n"
    
    return result

func get_element(element_id):
    if element_id < 0 or element_id >= grid_elements.size():
        return null
    
    return grid_elements[element_id]

func get_elements_by_category(category):
    var result = []
    
    for element in grid_elements:
        if element != null and element.category == category:
            result.append(element)
    
    return result

func get_saved_grid_names():
    return saved_grids.keys()

func clear_grid():
    _initialize_grid()
    grid_elements = []
    return true

func get_recent_patterns(limit=5):
    if recent_patterns.size() <= limit:
        return recent_patterns
    
    return recent_patterns.slice(recent_patterns.size() - limit, recent_patterns.size() - 1)

func add_room(x, y, width, height, door_positions=[]):
    # Create a room with optional doors
    var room = ""
    
    # Generate room ASCII art
    for dy in range(height):
        var row = ""
        for dx in range(width):
            var is_door = false
            
            # Check if this position has a door
            for door in door_positions:
                if door.x == dx and door.y == dy:
                    is_door = true
                    break
            
            # Border chars
            if dy == 0 and dx == 0:
                row += "+"  # Top-left corner
            elif dy == 0 and dx == width - 1:
                row += "+"  # Top-right corner
            elif dy == height - 1 and dx == 0:
                row += "+"  # Bottom-left corner
            elif dy == height - 1 and dx == width - 1:
                row += "+"  # Bottom-right corner
            elif dy == 0 or dy == height - 1:
                row += "-"  # Horizontal walls
            elif dx == 0 or dx == width - 1:
                row += "|"  # Vertical walls
            else:
                row += " "  # Interior
            
            # Replace with door if needed
            if is_door:
                row[row.length() - 1] = "+"
        
        room += row
        if dy < height - 1:
            room += "\n"
    
    return place_pattern(x, y, room, ShapeCategory.ROOM, {
        "type": "room",
        "has_doors": door_positions.size() > 0
    })

func add_corridor(start_x, start_y, end_x, end_y):
    # Create a corridor between two points
    var pattern = ""
    var min_x = min(start_x, end_x)
    var max_x = max(start_x, end_x)
    var min_y = min(start_y, end_y)
    var max_y = max(start_y, end_y)
    
    # Determine if horizontal or vertical
    if abs(end_x - start_x) > abs(end_y - start_y):
        # Horizontal corridor
        pattern = "#" + "-".repeat(max_x - min_x - 1) + "#"
        return place_pattern(min_x, start_y, pattern, ShapeCategory.CORRIDOR, {
            "type": "corridor",
            "direction": "horizontal"
        })
    else:
        # Vertical corridor
        for dy in range(max_y - min_y + 1):
            pattern += "#\n"
        return place_pattern(start_x, min_y, pattern, ShapeCategory.CORRIDOR, {
            "type": "corridor",
            "direction": "vertical"
        })

func add_ship(x, y, ship_type="small"):
    var pattern = ""
    
    match ship_type:
        "small":
            pattern = " /\\\n<==>\n \\/"
        "medium":
            pattern = "  /\\\n /  \\\n<====>\n \\  /\n  \\/"
        "large":
            pattern = "   /\\\n  /  \\\n /    \\\n<======>\n \\    /\n  \\  /\n   \\/"
        "alien":
            pattern = " _._\n/ O \\\n<-X->\n\\_^_/"
    
    return place_pattern(x, y, pattern, ShapeCategory.SHIP, {
        "type": "ship",
        "ship_type": ship_type
    })

func add_base(x, y, base_type="outpost"):
    var pattern = ""
    
    match base_type:
        "outpost":
            pattern = "+---+\n|[o]|\n+---+"
        "fortress":
            pattern = "+-----+\n|  ^  |\n| [ ] |\n|< X >|\n+-----+"
        "spaceport":
            pattern = "  /\\  \n /  \\ \n/====\\\n|    |\n|====|"
    
    return place_pattern(x, y, pattern, ShapeCategory.BASE, {
        "type": "base",
        "base_type": base_type
    })

func add_entity(x, y, entity_type="player"):
    var symbol = "@"
    
    match entity_type:
        "player":
            symbol = "@"
        "enemy":
            symbol = "E"
        "npc":
            symbol = "N"
        "treasure":
            symbol = "$"
        "boss":
            symbol = "B"
    
    return place_symbol(x, y, symbol, grid_elements.size(), {
        "type": "entity",
        "entity_type": entity_type
    })

func generate_dungeon(rooms=5, corridor_chance=0.7):
    # Clear grid
    clear_grid()
    
    # Generate rooms
    var room_positions = []
    for i in range(rooms):
        var width = 5 + randi() % 5
        var height = 3 + randi() % 3
        var x = randi() % (grid_width - width - 2) + 1
        var y = randi() % (grid_height - height - 2) + 1
        
        var room_id = add_room(x, y, width, height)
        room_positions.append({
            "id": room_id,
            "x": x,
            "y": y,
            "width": width,
            "height": height,
            "center_x": x + width / 2,
            "center_y": y + height / 2
        })
    
    # Generate corridors between rooms
    for i in range(room_positions.size()):
        var room1 = room_positions[i]
        
        # Connect to a random other room
        var room2_idx = (i + 1 + randi() % (room_positions.size() - 1)) % room_positions.size()
        var room2 = room_positions[room2_idx]
        
        if randf() < corridor_chance:
            add_corridor(room1.center_x, room1.center_y, room2.center_x, room2.center_y)
    
    # Add some entities
    var player_room = room_positions[randi() % room_positions.size()]
    add_entity(player_room.center_x, player_room.center_y, "player")
    
    # Add some treasures and enemies
    for i in range(1, room_positions.size()):
        var room = room_positions[i]
        var entity_type = "enemy" if randf() < 0.7 else "treasure"
        
        add_entity(room.center_x, room.center_y, entity_type)
    
    return "dungeon_" + str(OS.get_unix_time())

func generate_space_map(ships=3, bases=2):
    # Clear grid
    clear_grid()
    
    # Fill with stars
    for i in range(grid_width * grid_height / 50):
        var x = randi() % grid_width
        var y = randi() % grid_height
        place_symbol(x, y, ".", -1, {"type": "star"})
    
    # Add ships
    var ship_types = ["small", "medium", "large", "alien"]
    for i in range(ships):
        var x = randi() % (grid_width - 10) + 5
        var y = randi() % (grid_height - 10) + 5
        var ship_type = ship_types[randi() % ship_types.size()]
        
        add_ship(x, y, ship_type)
    
    # Add bases
    var base_types = ["outpost", "fortress", "spaceport"]
    for i in range(bases):
        var x = randi() % (grid_width - 10) + 5
        var y = randi() % (grid_height - 10) + 5
        var base_type = base_types[randi() % base_types.size()]
        
        add_base(x, y, base_type)
    
    # Add player ship
    var player_x = grid_width / 2
    var player_y = grid_height - 5
    add_ship(player_x, player_y, "small")
    
    return "space_map_" + str(OS.get_unix_time())
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_grid_creator.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_memory_system.gd
# SIZE: 13733 bytes
extends Control

# Terminal Memory System with Concurrent Processing Capabilities
# Integrates with TDIC (Temporal Dictionary) and supports executing 2-3 functions simultaneously

# Memory storage systems
var memory_buffer = []
var offline_data = {}
var tdic_entries = {
	"past": [],
	"present": [],
	"future": []
}

# Terminal display properties
var terminal_width = 80
var terminal_colors = {
	"default": Color(0.9, 0.9, 0.9),
	"past": Color(0.6, 0.6, 0.9),    # Soft blue for past
	"present": Color(0.9, 0.9, 0.9), # White for present
	"future": Color(0.9, 0.6, 0.6),  # Soft red for future
	"sad": Color(0.5, 0.5, 0.7)      # Sad colors as requested
}

# UI elements
var terminal
var input_field

# Concurrent processor
var processor

func _ready():
	# Initialize the concurrent processor
	processor = ConcurrentProcessor.new()
	add_child(processor)
	processor.connect("task_completed", self, "_on_task_completed")
	processor.connect("all_tasks_completed", self, "_on_all_tasks_completed")
	
	# Load saved memories
	processor.schedule_task("load_data", self, "load_offline_memories")
	
	# Setup terminal display
	setup_terminal_display()
	
	# Initialize with welcome message
	add_memory_text("Terminal Memory System initialized with concurrent processing.", "system")
	add_memory_text("Using TDIC protocol for temporal organization of data.", "system")
	add_memory_text("Type '#help' for available commands.", "system")

# Setup the terminal display elements
func setup_terminal_display():
	# This would create the actual UI elements
	terminal = RichTextLabel.new()
	terminal.bbcode_enabled = true
	terminal.rect_min_size = Vector2(600, 400)
	terminal.scroll_following = true
	add_child(terminal)
	
	input_field = LineEdit.new()
	input_field.rect_min_size = Vector2(600, 30)
	input_field.connect("text_entered", self, "_on_text_entered")
	add_child(input_field)
	
	# Set layout (would be replaced by proper UI in real implementation)
	terminal.rect_position = Vector2(10, 10)
	input_field.rect_position = Vector2(10, 420)

# Process input with command parsing
func _on_text_entered(text):
	input_field.text = ""
	
	if text.empty():
		return
		
	# Process commands
	if text.begins_with("#"):
		process_command(text)
	else:
		# Add as regular memory entry
		processor.schedule_task("add_memory", self, "add_memory_text", [text])
		
		# Also process as TDIC entry if it has temporal markers
		if text.begins_with("[past]") or text.begins_with("[present]") or text.begins_with("[future]"):
			processor.schedule_task("process_tdic", self, "process_tdic_entry", [text])

# Process special commands with # prefix
func process_command(command):
	var cmd_parts = command.split(" ", true, 1)
	var cmd = cmd_parts[0].to_lower()
	var args = cmd_parts[1] if cmd_parts.size() > 1 else ""
	
	match cmd:
		"#help":
			display_help()
		"#save":
			processor.schedule_task("save_data", self, "save_offline_memories", [], ConcurrentProcessor.Priority.HIGH)
		"#load":
			processor.schedule_task("load_data", self, "load_offline_memories", [], ConcurrentProcessor.Priority.HIGH)
		"#clear":
			processor.schedule_task("clear_display", self, "clear_terminal")
		"#show":
			var timeframe = args if args in ["past", "present", "future", "all"] else "all"
			processor.schedule_task("display_memories", self, "display_memories", [timeframe])
		"#run":
			run_parallel_functions(args)
		"#chain":
			run_chained_functions(args)
		"##":
			# Double hash commands for more advanced operations
			process_advanced_command(args)
		"###":
			# Triple hash commands for system-level operations
			process_system_command(args)
		_:
			add_memory_text("Unknown command: " + cmd, "error")

# Auto Text Wrap for Terminal Output
func add_memory_text(text, category="general"):
	var wrapped_text = auto_wrap_text(text, terminal_width)
	
	# Add to memory buffer
	memory_buffer.append({
		"text": wrapped_text,
		"timestamp": OS.get_unix_time(),
		"category": category,
		"offline": true
	})
	
	# Update terminal display
	update_terminal_display()
	
	return true  # For task completion

# TDIC (Temporal Dictionary) Implementation
func process_tdic_entry(text):
	# Extract timeframe markers
	var timeframe = "present"
	if text.begins_with("[past]"):
		timeframe = "past"
		text = text.substr(6).strip_edges()
	elif text.begins_with("[future]"):
		timeframe = "future"
		text = text.substr(8).strip_edges()
	elif text.begins_with("[present]"):
		text = text.substr(9).strip_edges()
		
	# Store in temporal dictionary
	tdic_entries[timeframe].append({
		"content": text,
		"timestamp": OS.get_unix_time()
	})
	
	add_memory_text("Entry added to " + timeframe + " TDIC registry.", "system")
	return true  # For task completion

# Offline Data Storage & Retrieval
func save_offline_memories():
	var file = File.new()
	file.open("user://offline_memories.dat", File.WRITE)
	file.store_var({
		"memory_buffer": memory_buffer,
		"tdic_entries": tdic_entries
	})
	file.close()
	
	add_memory_text("Memories saved to offline storage.", "system")
	return true  # For task completion

func load_offline_memories():
	var file = File.new()
	if file.file_exists("user://offline_memories.dat"):
		file.open("user://offline_memories.dat", File.READ)
		var data = file.get_var()
		memory_buffer = data.memory_buffer
		tdic_entries = data.tdic_entries
		file.close()
		
		add_memory_text("Memories loaded from offline storage.", "system")
	else:
		add_memory_text("No offline memory file found.", "system")
	
	return true  # For task completion

# Terminal Display with Temporal Awareness
func display_memories(timeframe="all"):
	terminal.clear()
	
	add_memory_text("Displaying " + timeframe + " memories...", "system")
	
	for memory in memory_buffer:
		var memory_timeframe = get_memory_timeframe(memory)
		if timeframe == "all" or memory_timeframe == timeframe:
			var color = terminal_colors.default
			
			if memory_timeframe in terminal_colors:
				color = terminal_colors[memory_timeframe]
				
			if memory.category == "sad":
				color = terminal_colors.sad
				
			terminal.append_bbcode("[color=#" + color.to_html() + "]" + memory.text + "[/color]\n")
	
	return true  # For task completion

# Helper function to get memory timeframe
func get_memory_timeframe(memory):
	var text = memory.text
	
	if text.begins_with("[past]"):
		return "past"
	elif text.begins_with("[future]"):
		return "future"
	elif text.begins_with("[present]"):
		return "present"
		
	# Default to present if no explicit timeframe
	return "present"

# Clear the terminal display
func clear_terminal():
	terminal.clear()
	add_memory_text("Terminal display cleared.", "system")
	return true  # For task completion

# Auto-wrap text to fit terminal width
func auto_wrap_text(text, width):
	var wrapped = ""
	var line = ""
	var words = text.split(" ")
	
	for word in words:
		if line.length() + word.length() + 1 <= width:
			if line.empty():
				line = word
			else:
				line += " " + word
		else:
			wrapped += line + "\n"
			line = word
	
	if not line.empty():
		wrapped += line
		
	return wrapped

# Update the terminal display with current buffer
func update_terminal_display():
	# Get the last few entries to display
	var display_count = min(10, memory_buffer.size())
	var start_index = max(0, memory_buffer.size() - display_count)
	
	for i in range(start_index, memory_buffer.size()):
		var memory = memory_buffer[i]
		var color = terminal_colors.default
		
		var timeframe = get_memory_timeframe(memory)
		if timeframe in terminal_colors:
			color = terminal_colors[timeframe]
			
		if memory.category == "sad":
			color = terminal_colors.sad
			
		terminal.append_bbcode("[color=#" + color.to_html() + "]" + memory.text + "[/color]\n")

# Display help information
func display_help():
	add_memory_text("Terminal Memory System Commands:", "system")
	add_memory_text("  #help - Display this help message", "system")
	add_memory_text("  #save - Save all memories to offline storage", "system")
	add_memory_text("  #load - Load memories from offline storage", "system")
	add_memory_text("  #clear - Clear terminal display", "system")
	add_memory_text("  #show [past|present|future|all] - Display memories for timeframe", "system")
	add_memory_text("  #run [func1,func2,func3] - Run multiple functions in parallel", "system")
	add_memory_text("  #chain [func1,func2,func3] - Run functions in sequence", "system")
	add_memory_text("  ## [command] - Execute advanced command", "system")
	add_memory_text("  ### [command] - Execute system-level command", "system")
	add_memory_text("", "system")
	add_memory_text("TDIC Temporal Markers:", "system")
	add_memory_text("  [past] Text... - Mark entry as past memory", "system")
	add_memory_text("  [present] Text... - Mark entry as present memory", "system")
	add_memory_text("  [future] Text... - Mark entry as future memory", "system")

# Process advanced commands (##)
func process_advanced_command(args):
	var parts = args.split(" ", true, 1)
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"color":
			set_color_theme(subargs)
		"export":
			export_memories(subargs)
		"search":
			search_memories(subargs)
		_:
			add_memory_text("Unknown advanced command: " + subcmd, "error")

# Process system commands (###)
func process_system_command(args):
	var parts = args.split(" ", true, 1)
	var subcmd = parts[0].to_lower()
	var subargs = parts[1] if parts.size() > 1 else ""
	
	match subcmd:
		"reset":
			reset_system()
		"optimize":
			optimize_memory()
		"concurrent":
			set_concurrency(subargs)
		_:
			add_memory_text("Unknown system command: " + subcmd, "error")

# Set color theme
func set_color_theme(theme):
	match theme:
		"default":
			terminal_colors.default = Color(0.9, 0.9, 0.9)
			terminal_colors.past = Color(0.6, 0.6, 0.9)
			terminal_colors.present = Color(0.9, 0.9, 0.9)
			terminal_colors.future = Color(0.9, 0.6, 0.6)
		"sad":
			# Sad colors palette
			terminal_colors.default = Color(0.5, 0.5, 0.7)
			terminal_colors.past = Color(0.4, 0.4, 0.6)
			terminal_colors.present = Color(0.5, 0.5, 0.7)
			terminal_colors.future = Color(0.6, 0.4, 0.5)
		_:
			add_memory_text("Unknown color theme: " + theme, "error")
			return
			
	add_memory_text("Color theme changed to: " + theme, "system")
	update_terminal_display()

# Export memories to file
func export_memories(format):
	add_memory_text("Exporting memories in " + format + " format...", "system")
	# Implementation would vary based on format

# Search through memories
func search_memories(query):
	add_memory_text("Searching for: " + query, "system")
	var results = []
	
	for memory in memory_buffer:
		if memory.text.to_lower().find(query.to_lower()) >= 0:
			results.append(memory)
	
	add_memory_text("Found " + str(results.size()) + " results:", "system")
	for result in results:
		add_memory_text(result.text, "search_result")

# Reset the entire system
func reset_system():
	add_memory_text("WARNING: Resetting entire memory system...", "system")
	memory_buffer.clear()
	tdic_entries.clear()
	tdic_entries = {
		"past": [],
		"present": [],
		"future": []
	}
	save_offline_memories()
	add_memory_text("Memory system reset complete.", "system")

# Optimize memory storage
func optimize_memory():
	add_memory_text("Optimizing memory storage...", "system")
	# Implementation would compress and optimize storage

# Set concurrency level
func set_concurrency(level):
	var value = int(level)
	if value >= 1 and value <= 5:
		processor.set_max_concurrent_tasks(value)
		add_memory_text("Concurrency level set to: " + str(value), "system")
	else:
		add_memory_text("Invalid concurrency level. Use 1-5.", "error")

# Run multiple functions in parallel
func run_parallel_functions(function_list):
	var functions = function_list.split(",")
	if functions.size() > 0:
		add_memory_text("Running " + str(functions.size()) + " functions in parallel...", "system")
		
		var function_map = {
			"save": "save_offline_memories",
			"load": "load_offline_memories",
			"clear": "clear_terminal",
			"display": "display_memories",
			"search": "search_memories",
			"optimize": "optimize_memory"
		}
		
		var valid_functions = []
		var args_list = []
		
		for func_name in functions:
			func_name = func_name.strip_edges()
			if func_name in function_map:
				valid_functions.append(function_map[func_name])
				args_list.append([])
			else:
				add_memory_text("Unknown function: " + func_name, "error")
		
		if valid_functions.size() > 0:
			processor.create_parallel_tasks("parallel_run", self, valid_functions, args_list)
	else:
		add_memory_text("No functions specified.", "error")

# Run functions in sequence
func run_chained_functions(function_list):
	var functions = function_list.split(",")
	if functions.size() > 0:
		add_memory_text("Running " + str(functions.size()) + " functions in sequence...", "system")
		
		var function_map = {
			"save": "save_offline_memories",
			"load": "load_offline_memories",
			"clear": "clear_terminal",
			"display": "display_memories",
			"search": "search_memories",
			"optimize": "optimize_memory"
		}
		
		var valid_functions = []
		var args_list = []
		
		for func_name in functions:
			func_name = func_name.strip_edges()
			if func_name in function_map:
				valid_functions.append(function_map[func_name])
				args_list.append([])
			else:
				add_memory_text("Unknown function: " + func_name, "error")
		
		if valid_functions.size() > 0:
			processor.create_task_chain("chain_run", self, valid_functions, args_list)
	else:
		add_memory_text("No functions specified.", "error")

# Signal handlers
func _on_task_completed(task_id, result):
	add_memory_text("Task completed: " + task_id, "system")

func _on_all_tasks_completed():
	add_memory_text("All scheduled tasks completed.", "system")
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_memory_system.gd

# FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_overlay.gd
# SIZE: 21521 bytes
extends Control

class_name TerminalOverlay

# Terminal overlay with dynamic color shifting and EVE integration

# Color constants
const COLOR_LIGHT_BLUE = Color(0.5, 0.7, 0.9, 0.9)
const COLOR_EVE_BLUE = Color(0.4, 0.6, 0.9, 0.8)
const COLOR_SHIFT_BLUE = Color(0.3, 0.5, 0.8, 0.7)
const COLOR_DEEP_BLUE = Color(0.2, 0.4, 0.7, 0.9)
const COLOR_ETHEREAL_BLUE = Color(0.6, 0.8, 0.95, 0.8)

# EVE shift markers
const EVE_SHIFT_SYMBOLS = ["#", "##", "###", "####", "#####"]

# Terminal properties
export var terminal_font_size = 14
export var terminal_opacity = 0.8
export var terminal_color = COLOR_LIGHT_BLUE
export var terminal_border_size = 2
export var terminal_text_color = Color(1, 1, 1, 0.9)
export var terminal_size = Vector2(800, 600)
export var terminal_position = Vector2(20, 20)

# Terminal state
var is_visible = true
var is_shifting = false
var current_mode = "default"
var terminal_title = "Terminal Overlay # EVE SHIFT"
var terminal_content = []
var terminal_commands = []
var command_history = []
var current_command = ""
var cursor_position = 0
var cursor_visible = true
var cursor_blink_timer = 0
var eve_shift_enabled = false
var current_shift_phase = 0
var shift_colors = []
var terminal_border_color = Color(1, 1, 1, 0.5)

# Terminal animation
var animation_time = 0
var wave_amplitude = 3.0
var wave_frequency = 2.0
var pulse_intensity = 0.2
var glow_intensity = 0.5
var shift_progress = 0.0
var color_transition_duration = 1.2
var color_from = COLOR_LIGHT_BLUE
var color_to = COLOR_LIGHT_BLUE
var symbol_rotation = 0.0

# Memory system connection
var memory_system = null

# Signals
signal command_entered(command)
signal color_changed(color)
signal overlay_toggled(visible)
signal eve_shift_toggled(enabled)

func _ready():
    # Set initial properties
    rect_size = terminal_size
    rect_position = terminal_position
    
    # Setup cursor blink timer
    var timer = Timer.new()
    timer.wait_time = 0.5
    timer.connect("timeout", self, "_on_cursor_blink")
    add_child(timer)
    timer.start()
    
    # Initialize colors
    _initialize_shift_colors()
    
    # Connect to memory system if available
    connect_to_memory_system()
    
    # Set initial content
    add_text("Terminal Overlay Initialized")
    add_text("Color: Light Blue")
    add_text("EVE Shift: Disabled")
    add_text("Type 'help' for commands")
    add_text("# Type 'eve' to activate EVE shift")

func _initialize_shift_colors():
    # Define color shift sequence
    shift_colors = [
        COLOR_LIGHT_BLUE,
        COLOR_EVE_BLUE,
        COLOR_SHIFT_BLUE,
        COLOR_DEEP_BLUE,
        COLOR_ETHEREAL_BLUE
    ]

func connect_to_memory_system():
    # Find memory system node
    if has_node("/root/ProjectMemorySystem") or get_node_or_null("/root/ProjectMemorySystem"):
        memory_system = get_node("/root/ProjectMemorySystem")
        memory_system.connect("color_shifted", self, "_on_memory_color_shifted")
        memory_system.connect("overlay_updated", self, "_on_overlay_updated")
        print("Connected to ProjectMemorySystem")
        return true
    
    # Try SmartAccountSystem path
    if has_node("/root/SmartAccountSystem/ProjectMemorySystem") or get_node_or_null("/root/SmartAccountSystem/ProjectMemorySystem"):
        memory_system = get_node("/root/SmartAccountSystem/ProjectMemorySystem")
        memory_system.connect("color_shifted", self, "_on_memory_color_shifted")
        memory_system.connect("overlay_updated", self, "_on_overlay_updated")
        print("Connected to ProjectMemorySystem under SmartAccountSystem")
        return true
    
    return false

func _process(delta):
    # Update animation time
    animation_time += delta
    
    # Update color transition if shifting
    if is_shifting:
        shift_progress += delta / color_transition_duration
        if shift_progress >= 1.0:
            shift_progress = 1.0
            is_shifting = false
        
        # Interpolate color
        terminal_color = color_from.linear_interpolate(color_to, shift_progress)
        
        # Apply pulse effect during shift
        var pulse = sin(animation_time * 5.0) * pulse_intensity
        terminal_color = terminal_color.lightened(pulse)
    
    # Update symbol rotation for EVE shift
    if eve_shift_enabled:
        symbol_rotation += delta * 0.5
        current_shift_phase = int(animation_time / 3.0) % 5
    
    # Request redraw
    update()

func _draw():
    # Draw terminal background with color
    var background_rect = Rect2(Vector2.ZERO, rect_size)
    draw_rect(background_rect, terminal_color, true)
    
    # Draw terminal border
    var border_rect = Rect2(Vector2.ZERO, rect_size)
    draw_rect(border_rect, terminal_border_color, false, terminal_border_size)
    
    # Draw title bar
    var title_bar_rect = Rect2(Vector2.ZERO, Vector2(rect_size.x, 30))
    draw_rect(title_bar_rect, terminal_color.darkened(0.2), true)
    
    # Draw title
    var title_text = terminal_title
    if eve_shift_enabled:
        # Add EVE shift marker
        title_text += " " + EVE_SHIFT_SYMBOLS[current_shift_phase]
    
    draw_string(get_font("", ""), Vector2(10, 20), title_text, terminal_text_color)
    
    # Draw content
    var content_y = 40
    for line in terminal_content:
        draw_string(get_font("", ""), Vector2(10, content_y), line, terminal_text_color)
        content_y += terminal_font_size + 5
    
    # Draw command line
    var command_prompt = ">> "
    var full_command = command_prompt + current_command
    
    draw_string(get_font("", ""), Vector2(10, content_y), full_command, terminal_text_color)
    
    # Draw cursor if visible
    if cursor_visible:
        var cursor_x = 10 + get_font("", "").get_string_size(command_prompt + current_command.substr(0, cursor_position)).x
        draw_rect(Rect2(Vector2(cursor_x, content_y - terminal_font_size), Vector2(2, terminal_font_size)), terminal_text_color, true)
    
    # Draw EVE shift effects if enabled
    if eve_shift_enabled:
        draw_eve_shift_effects()

func draw_eve_shift_effects():
    # Draw EVE shift symbol in corner
    var symbol = EVE_SHIFT_SYMBOLS[current_shift_phase]
    var symbol_pos = Vector2(rect_size.x - 30, 20)
    
    # Add rotation effect to symbol
    var font = get_font("", "")
    var symbol_size = font.get_string_size(symbol)
    var symbol_center = symbol_pos + symbol_size / 2
    
    # Draw rotated symbol
    draw_set_transform(symbol_center, symbol_rotation, Vector2(1, 1))
    draw_string(font, symbol_pos - symbol_center, symbol, terminal_text_color.lightened(0.3))
    draw_set_transform(Vector2.ZERO, 0, Vector2(1, 1))
    
    # Draw bottom wave effect
    var wave_points = PoolVector2Array()
    var wave_y = rect_size.y - 20
    
    for x in range(0, int(rect_size.x), 5):
        var wave_offset = sin((x / rect_size.x * 5 + animation_time) * wave_frequency) * wave_amplitude
        wave_points.append(Vector2(x, wave_y + wave_offset))
    
    # Draw wave line
    if wave_points.size() >= 2:
        for i in range(wave_points.size() - 1):
            draw_line(wave_points[i], wave_points[i+1], terminal_text_color.lightened(0.2), 2.0)

func _input(event):
    # Handle keyboard input
    if event is InputEventKey and event.pressed:
        match event.scancode:
            KEY_BACKSPACE:
                if cursor_position > 0:
                    current_command = current_command.substr(0, cursor_position - 1) + current_command.substr(cursor_position)
                    cursor_position -= 1
            KEY_DELETE:
                if cursor_position < current_command.length():
                    current_command = current_command.substr(0, cursor_position) + current_command.substr(cursor_position + 1)
            KEY_LEFT:
                cursor_position = max(0, cursor_position - 1)
            KEY_RIGHT:
                cursor_position = min(current_command.length(), cursor_position + 1)
            KEY_HOME:
                cursor_position = 0
            KEY_END:
                cursor_position = current_command.length()
            KEY_UP:
                # Navigate command history (up)
                if command_history.size() > 0:
                    current_command = command_history[command_history.size() - 1]
                    cursor_position = current_command.length()
            KEY_DOWN:
                # Navigate command history (down)
                current_command = ""
                cursor_position = 0
            KEY_RETURN, KEY_ENTER:
                # Process command
                if current_command.strip_edges() != "":
                    process_command(current_command)
                    command_history.append(current_command)
                    if command_history.size() > 50:
                        command_history.pop_front()
                    current_command = ""
                    cursor_position = 0
            _:
                # Add character to command
                if event.unicode > 0:
                    var char = char(event.unicode)
                    current_command = current_command.substr(0, cursor_position) + char + current_command.substr(cursor_position)
                    cursor_position += 1
        
        # Reset cursor blink
        cursor_visible = true
        
        # Ensure redraw
        update()

func _on_cursor_blink():
    cursor_visible = !cursor_visible
    update()

func _on_memory_color_shifted(from_color, to_color):
    # Start color transition
    start_color_transition(from_color, to_color)

func _on_overlay_updated(settings):
    # Update from memory system settings
    if "color" in settings:
        terminal_color = settings["color"]
    
    if "opacity" in settings:
        terminal_opacity = settings["opacity"]
    
    if "dimensions" in settings:
        rect_size = settings["dimensions"]
    
    if "position" in settings:
        rect_position = settings["position"]
    
    if "border" in settings and "size" in settings["border"]:
        terminal_border_size = settings["border"]["size"]
        
    if "border" in settings and "color" in settings["border"]:
        terminal_border_color = settings["border"]["color"]
    
    if "text" in settings and "color" in settings["text"]:
        terminal_text_color = settings["text"]["color"]
        
    if "text" in settings and "size" in settings["text"]:
        terminal_font_size = settings["text"]["size"]
    
    if "title" in settings:
        terminal_title = settings["title"]
    
    if "visible" in settings:
        is_visible = settings["visible"]
        visible = is_visible
    
    # Request redraw
    update()

func add_text(text):
    # Add text to terminal content
    terminal_content.append(text)
    
    # Limit content size
    if terminal_content.size() > 100:
        terminal_content.pop_front()
    
    # Request redraw
    update()

func clear_terminal():
    # Clear terminal content
    terminal_content.clear()
    
    # Request redraw
    update()

func process_command(command):
    # Add command to terminal
    add_text(">> " + command)
    
    # Process command
    var cmd_parts = command.split(" ")
    var cmd_name = cmd_parts[0].to_lower()
    
    match cmd_name:
        "help":
            add_text("Available commands:")
            add_text("  help - Show this help")
            add_text("  clear - Clear terminal")
            add_text("  color - Change terminal color")
            add_text("  shift - Trigger color shift")
            add_text("  eve - Toggle EVE shift mode")
            add_text("  opacity - Set terminal opacity (0.1-1.0)")
            add_text("  memory - Access memory system")
            add_text("  wave - Adjust wave animation")
            add_text("  hide - Hide terminal overlay")
            add_text("  show - Show terminal overlay")
            add_text("  exit - Close terminal")
        
        "clear":
            clear_terminal()
        
        "color":
            if cmd_parts.size() > 1:
                var color_name = cmd_parts[1].to_lower()
                set_color_by_name(color_name)
            else:
                add_text("Current color: " + get_current_color_name())
                add_text("Usage: color [light_blue|eve_blue|shift_blue|deep_blue|ethereal_blue]")
        
        "shift":
            if memory_system:
                var result = memory_system.shift_colors()
                if result:
                    add_text("Shifted colors: " + result["from"] + " -> " + result["to"])
                else:
                    add_text("Color shift in progress, please wait...")
            else:
                trigger_color_shift()
        
        "eve":
            toggle_eve_shift()
        
        "opacity":
            if cmd_parts.size() > 1:
                var opacity = float(cmd_parts[1])
                set_opacity(opacity)
            else:
                add_text("Current opacity: " + str(terminal_opacity))
                add_text("Usage: opacity [0.1-1.0]")
        
        "memory":
            if cmd_parts.size() > 1:
                process_memory_command(cmd_parts)
            else:
                add_text("Memory system commands:")
                add_text("  memory add [content] [category] - Add memory")
                add_text("  memory recall [id] - Recall memory")
                add_text("  memory forget [id] - Forget memory")
                add_text("  memory list - List all memories")
                add_text("  memory stats - Show memory statistics")
        
        "wave":
            if cmd_parts.size() > 2:
                var param = cmd_parts[1].to_lower()
                var value = float(cmd_parts[2])
                set_wave_parameter(param, value)
            else:
                add_text("Wave parameters:")
                add_text("  wave amplitude [value] - Set wave height")
                add_text("  wave frequency [value] - Set wave speed")
                add_text("  wave pulse [value] - Set pulse intensity")
        
        "hide":
            hide_terminal()
        
        "show":
            show_terminal()
        
        "exit":
            hide_terminal()
        
        _:
            add_text("Unknown command: " + cmd_name)
            add_text("Type 'help' for commands")
    
    # Emit signal for command
    emit_signal("command_entered", command)

func process_memory_command(cmd_parts):
    if not memory_system:
        add_text("Memory system not available")
        return
    
    var action = cmd_parts[1].to_lower()
    
    match action:
        "add":
            if cmd_parts.size() >= 4:
                var content = cmd_parts[2]
                var category = cmd_parts[3]
                var memory_id = memory_system.add_memory(content, category)
                if memory_id:
                    add_text("Memory added: " + memory_id)
                else:
                    add_text("Failed to add memory")
            else:
                add_text("Usage: memory add [content] [category]")
        
        "recall":
            if cmd_parts.size() >= 3:
                var memory_id = cmd_parts[2]
                var memory = memory_system.recall_memory(memory_id)
                if memory:
                    add_text("Memory recalled: " + memory["content"])
                else:
                    add_text("Memory not found")
            else:
                add_text("Usage: memory recall [id]")
        
        "forget":
            if cmd_parts.size() >= 3:
                var memory_id = cmd_parts[2]
                var result = memory_system.forget_memory(memory_id)
                if result:
                    add_text("Memory forgotten: " + memory_id)
                else:
                    add_text("Memory not found")
            else:
                add_text("Usage: memory forget [id]")
        
        "list":
            var category = "project_structure"
            if cmd_parts.size() >= 3:
                category = cmd_parts[2]
            
            var memories = memory_system.get_memories_by_category(category)
            add_text("Memories in category " + category + ":")
            
            for memory in memories:
                add_text("  " + memory["id"] + ": " + memory["content"])
            
            if memories.size() == 0:
                add_text("  No memories found")
        
        "stats":
            add_text("Memory system statistics:")
            
            var total_memories = 0
            for category in memory_system.memory_banks:
                var count = memory_system.memory_banks[category]["memories"].size()
                total_memories += count
                add_text("  " + category + ": " + str(count) + " memories")
            
            add_text("Total memories: " + str(total_memories))
            add_text("Forgotten memories: " + str(memory_system.forgotten_memories.size()))
            
            if memory_system.current_memory_focus:
                add_text("Current focus: " + memory_system.current_memory_focus)
            
            if memory_system.project_eve_shift_active:
                add_text("EVE Shift: Active (Phase " + str(memory_system.current_shift_phase) + ")")
            else:
                add_text("EVE Shift: Inactive")
        
        _:
            add_text("Unknown memory command: " + action)
            add_text("Type 'memory' for help")

func set_color_by_name(color_name):
    var color = null
    
    match color_name:
        "light_blue":
            color = COLOR_LIGHT_BLUE
        "eve_blue":
            color = COLOR_EVE_BLUE
        "shift_blue":
            color = COLOR_SHIFT_BLUE
        "deep_blue":
            color = COLOR_DEEP_BLUE
        "ethereal_blue":
            color = COLOR_ETHEREAL_BLUE
        _:
            add_text("Unknown color: " + color_name)
            return
    
    # Set color
    start_color_transition(terminal_color, color)
    
    # Update memory system if connected
    if memory_system:
        memory_system.set_overlay_color(color)
    
    add_text("Color set to: " + color_name)
    emit_signal("color_changed", color)

func get_current_color_name():
    if terminal_color.is_equal_approx(COLOR_LIGHT_BLUE):
        return "light_blue"
    elif terminal_color.is_equal_approx(COLOR_EVE_BLUE):
        return "eve_blue"
    elif terminal_color.is_equal_approx(COLOR_SHIFT_BLUE):
        return "shift_blue"
    elif terminal_color.is_equal_approx(COLOR_DEEP_BLUE):
        return "deep_blue"
    elif terminal_color.is_equal_approx(COLOR_ETHEREAL_BLUE):
        return "ethereal_blue"
    else:
        return "custom"

func start_color_transition(from, to):
    # Start color transition animation
    color_from = from
    color_to = to
    shift_progress = 0.0
    is_shifting = true

func trigger_color_shift():
    # Find next color in shift sequence
    var current_index = shift_colors.find(terminal_color)
    if current_index < 0:
        current_index = 0
    
    var next_index = (current_index + 1) % shift_colors.size()
    var next_color = shift_colors[next_index]
    
    # Start transition
    start_color_transition(terminal_color, next_color)
    
    # Update text
    add_text("Shifting color: " + get_current_color_name() + " -> " + 
             (["light_blue", "eve_blue", "shift_blue", "deep_blue", "ethereal_blue"][next_index]))

func toggle_eve_shift():
    eve_shift_enabled = !eve_shift_enabled
    
    if eve_shift_enabled:
        add_text("EVE Shift activated")
        
        # Set color to EVE blue
        start_color_transition(terminal_color, COLOR_EVE_BLUE)
        
        # Update memory system if connected
        if memory_system:
            memory_system.start_eve_shift()
    else:
        add_text("EVE Shift deactivated")
        
        # Set color back to light blue
        start_color_transition(terminal_color, COLOR_LIGHT_BLUE)
        
        # Update memory system if connected
        if memory_system:
            memory_system.stop_eve_shift()
    
    emit_signal("eve_shift_toggled", eve_shift_enabled)

func set_opacity(opacity):
    # Set terminal opacity
    terminal_opacity = clamp(opacity, 0.1, 1.0)
    modulate.a = terminal_opacity
    
    # Update memory system if connected
    if memory_system:
        memory_system.set_overlay_opacity(terminal_opacity)
    
    add_text("Opacity set to: " + str(terminal_opacity))

func set_wave_parameter(param, value):
    match param:
        "amplitude":
            wave_amplitude = clamp(value, 0.0, 10.0)
            add_text("Wave amplitude set to: " + str(wave_amplitude))
        "frequency":
            wave_frequency = clamp(value, 0.1, 5.0)
            add_text("Wave frequency set to: " + str(wave_frequency))
        "pulse":
            pulse_intensity = clamp(value, 0.0, 0.5)
            add_text("Pulse intensity set to: " + str(pulse_intensity))
        _:
            add_text("Unknown wave parameter: " + param)

func hide_terminal():
    # Hide terminal
    is_visible = false
    visible = false
    
    # Update memory system if connected
    if memory_system:
        memory_system.toggle_overlay_visibility()
    
    emit_signal("overlay_toggled", false)

func show_terminal():
    # Show terminal
    is_visible = true
    visible = true
    
    # Update memory system if connected
    if memory_system:
        memory_system.toggle_overlay_visibility()
    
    emit_signal("overlay_toggled", true)
# END FILE: /mnt/c/Users/Percision 15/12_turns_system/terminal_overlay.gd

