# AkashicNotepad3D.gd - Main controller for 3D knowledge visualization
extends Node3D
class_name AkashicNotepad3D

signal dimension_changed(from_level: String, to_level: String)
signal word_evolved(old_word: String, new_word: String)
signal connection_created(word_a: String, word_b: String)

# Dimensional structure matching your images
var current_dimension = "stars"
var dimension_hierarchy = {
	"multiverse": {
		"level": 0,
		"children": ["universes"],
		"scale": 10000.0,
		"color": Color.DEEP_PINK
	},
	"universes": {
		"level": 1, 
		"children": ["galaxies"],
		"scale": 5000.0,
		"color": Color.CYAN
	},
	"galaxies": {
		"level": 2,
		"children": ["stars"],
		"scale": 1000.0,
		"color": Color.BLUE
	},
	"stars": {
		"level": 3,
		"children": ["planets"],
		"scale": 400.0,
		"color": Color.YELLOW
	},
	"planets": {
		"level": 4,
		"children": ["surface"],
		"scale": 100.0,
		"color": Color.GREEN
	}
}

# Knowledge nodes and connections
var knowledge_nodes = {}
var node_connections = {}
var active_words = ["consciousness", "evolution", "manifestation"]

# 3D positioning system from your coordinate notes
var coordinate_system = {
	"frames": {},  # Your frame database system
	"current_frame": Vector3.ZERO,
	"frame_size": Vector3(10, 10, 10)
}

# Terminal integration
var terminal_commands = {}
var ai_collaborators = ["Claude", "Luno", "Luminus"]

func _ready():
	setup_dimensional_structure()
	initialize_knowledge_nodes()
	setup_terminal_interface()
	setup_evolution_system()

# Set up the multi-dimensional structure from your images
func setup_dimensional_structure():
	for dimension in dimension_hierarchy:
		var dim_node = Node3D.new()
		dim_node.name = dimension
		add_child(dim_node)
		
		# Create visual representation
		create_dimension_visualization(dim_node, dimension)

func create_dimension_visualization(parent: Node3D, dim_name: String):
	var dim_data = dimension_hierarchy[dim_name]
	
	# Create the main container plane (like in your images)
	var container = create_knowledge_container(dim_data.scale, dim_data.color)
	parent.add_child(container)
	
	# Add floating knowledge nodes
	create_floating_nodes(parent, dim_name)

# Create the blue translucent containers from your screenshots
func create_knowledge_container(scale: float, color: Color) -> MeshInstance3D:
	var mesh_instance = MeshInstance3D.new()
	var box_mesh = BoxMesh.new()
	box_mesh.size = Vector3(scale * 0.8, scale * 0.6, scale * 0.4)
	
	mesh_instance.mesh = box_mesh
	
	# Create the translucent material like in your images
	var material = StandardMaterial3D.new()
	material.albedo_color = color
	material.albedo_color.a = 0.3
	material.flags_transparent = true
	material.flags_unshaded = true
	mesh_instance.material_override = material
	
	return mesh_instance

# Create floating knowledge nodes (the colored spheres/ellipses)
func create_floating_nodes(parent: Node3D, dimension: String):
	var node_count = get_node_count_for_dimension(dimension)
	
	for i in range(node_count):
		var knowledge_node = create_knowledge_node(dimension, i)
		parent.add_child(knowledge_node)
		
		# Position using your coordinate system
		position_node_in_frame(knowledge_node, dimension, i)

func create_knowledge_node(dimension: String, index: int) -> Node3D:
	var node = Node3D.new()
	node.name = "%s_node_%d" % [dimension, index]
	
	# Create visual representation
	var mesh_instance = MeshInstance3D.new()
	var sphere_mesh = SphereMesh.new()
	sphere_mesh.radius = randf_range(2.0, 8.0)
	mesh_instance.mesh = sphere_mesh
	
	# Random colors like in your screenshots
	var material = StandardMaterial3D.new()
	material.albedo_color = get_random_knowledge_color()
	material.emission_enabled = true
	material.emission = material.albedo_color * 0.5
	mesh_instance.material_override = material
	
	node.add_child(mesh_instance)
	
	# Add interaction capability
	var area = Area3D.new()
	var collision = CollisionShape3D.new()
	var sphere_shape = SphereShape3D.new()
	sphere_shape.radius = sphere_mesh.radius
	collision.shape = sphere_shape
	area.add_child(collision)
	node.add_child(area)
	
	# Connect interaction signals
	area.input_event.connect(_on_node_clicked.bind(node))
	
	return node

# Your frame-based positioning system
func position_node_in_frame(node: Node3D, dimension: String, index: int):
	var dim_data = dimension_hierarchy[dimension]
	var scale = dim_data.scale
	
	# Use your coordinate system from the notes
	var frame_pos = calculate_frame_position(index, scale)
	node.position = frame_pos
	
	# Add some orbital movement for cosmic feel
	add_orbital_motion(node, dimension)

func calculate_frame_position(index: int, scale: float) -> Vector3:
	# Implement your coordinate system from the notes
	var angle = (index * TAU) / 8.0  # Distribute around circle
	var radius = scale * 0.3
	var height = sin(index * 0.5) * scale * 0.1
	
	return Vector3(
		cos(angle) * radius,
		height,
		sin(angle) * radius
	)

# Navigation between dimensions (like in your UI)
func navigate_to_dimension(target_dimension: String):
	if target_dimension in dimension_hierarchy:
		var old_dimension = current_dimension
		current_dimension = target_dimension
		
		animate_dimension_transition(old_dimension, target_dimension)
		emit_signal("dimension_changed", old_dimension, target_dimension)

func animate_dimension_transition(from_dim: String, to_dim: String):
	var tween = create_tween()
	var camera = get_viewport().get_camera_3d()
	
	var from_node = get_node(from_dim)
	var to_node = get_node(to_dim)
	
	# Smooth camera transition
	tween.tween_property(camera, "position", to_node.position + Vector3(0, 50, 100), 1.0)
	tween.tween_property(camera, "rotation", Vector3(-0.2, 0, 0), 1.0)

# Terminal interface for your command system
func setup_terminal_interface():
	terminal_commands = {
		"navigate": navigate_to_dimension,
		"create_word": create_new_word,
		"evolve_word": evolve_word,
		"connect_words": connect_words,
		"ai_collaborate": request_ai_collaboration
	}

func process_terminal_command(command: String, args: Array):
	var cmd_parts = command.split(" ")
	var cmd_name = cmd_parts[0]
	
	if cmd_name in terminal_commands:
		var cmd_func = terminal_commands[cmd_name]
		cmd_func.callv(args)

# Word evolution system from your DNA/RNA concept
func evolve_word(word: String, evolution_type: String = "AIRNA"):
	var evolved_word = apply_evolution_rules(word, evolution_type)
	
	# Update visual representation
	update_word_visualization(word, evolved_word)
	
	emit_signal("word_evolved", word, evolved_word)
	return evolved_word

func apply_evolution_rules(word: String, type: String) -> String:
	# Your AIDNA/AIRNA evolution system
	match type:
		"AIRNA":  # Asking Biologically Create Digitally
			return word + "_evolved"
		"AIDNA":  # Explained Function Give Human
			return word + "_explained"
		"AIRNAA": # Intelligently Joined Kreation Logically
			return word + "_enhanced"
		"AIDNAA": # Manually Nonchalantly Organized Production
			return word + "_manual"
		_:
			return word

# Connection system for knowledge nodes
func connect_words(word_a: String, word_b: String):
	if not word_a in node_connections:
		node_connections[word_a] = []
	
	node_connections[word_a].append(word_b)
	
	# Create visual connection
	create_visual_connection(word_a, word_b)
	emit_signal("connection_created", word_a, word_b)

func create_visual_connection(word_a: String, word_b: String):
	# Create a line between connected nodes
	var line_node = Node3D.new()
	line_node.name = "connection_%s_%s" % [word_a, word_b]
	add_child(line_node)
	
	# Add visual line renderer here
	draw_connection_line(line_node, word_a, word_b)

# AI collaboration system
func request_ai_collaboration(task: String, ai_name: String = "Claude"):
	var collaboration_data = {
		"task": task,
		"ai": ai_name,
		"context": current_dimension,
		"active_words": active_words,
		"timestamp": Time.get_datetime_string_from_system()
	}
	
	# Process with appropriate AI
	match ai_name:
		"Claude":
			process_claude_collaboration(collaboration_data)
		"Luno":
			process_luno_collaboration(collaboration_data)
		"Luminus":
			process_luminus_collaboration(collaboration_data)

# Input handling for navigation
func _input(event):
	if event is InputEventKey and event.pressed:
		match event.keycode:
			KEY_TAB:
				toggle_navigation_mode()
			KEY_C:
				create_new_word_at_cursor()
			KEY_E:
				evolve_selected_word()

# Utility functions
func get_node_count_for_dimension(dimension: String) -> int:
	match dimension:
		"multiverse": return 3
		"universes": return 7
		"galaxies": return 12
		"stars": return 15
		"planets": return 8
		_: return 5

func get_random_knowledge_color() -> Color:
	var colors = [
		Color.YELLOW,    # Like in your screenshots
		Color.GREEN,
		Color.CYAN,
		Color.WHITE,
		Color.ORANGE
	]
	return colors[randi() % colors.size()]

func add_orbital_motion(node: Node3D, dimension: String):
	# Add subtle rotation for cosmic feel
	var tween = create_tween()
	tween.set_loops()
	tween.tween_property(node, "rotation_degrees:y", 360, 10.0)

func _on_node_clicked(camera, event, position, normal, shape_idx, node):
	if event is InputEventMouseButton and event.pressed:
		if event.button_index == MOUSE_BUTTON_LEFT:
			select_knowledge_node(node)
		elif event.button_index == MOUSE_BUTTON_RIGHT:
			show_node_context_menu(node)

func select_knowledge_node(node: Node3D):
	print("Selected knowledge node: ", node.name)
	# Implement selection visual feedback

func show_node_context_menu(node: Node3D):
	# Show context menu for node operations
	print("Context menu for: ", node.name)

# Evolution and version control integration
func setup_evolution_system():
	# Connect to the evolution manager we created earlier
	if has_node("/root/EvolutionManager"):
		var evolution_manager = get_node("/root/EvolutionManager")
		evolution_manager.connect("ai_collaboration_needed", _on_ai_collaboration_needed)

func _on_ai_collaboration_needed(task: Dictionary):
	# Handle AI collaboration requests
	print("AI collaboration needed: ", task)