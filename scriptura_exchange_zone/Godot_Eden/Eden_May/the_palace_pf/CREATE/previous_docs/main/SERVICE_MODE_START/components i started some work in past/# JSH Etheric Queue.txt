#
# JSH Etheric Queue
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┓     •   ┏┓        
#       888  `"Y8888o.   888ooooo888     ┣ ╋┏┓┏┓┓┏  ┃┃┓┏┏┓┓┏┏┓
#       888      `"Y88b  888     888     ┗┛┗┗ ┛ ┗┗  ┗┻┗┻┗ ┗┻┗ 
#       888 oo     .d8P  888     888         
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Etheric Queue
#

func three_stages_of_creation(data_set_name):
	
	print(" delta message start 00")
	if array_mutex_process.try_lock():
		print(" delta message start 0E")
	else:
		print(" delta message start 0F")
	array_mutex_process.lock()
	for current_sets_to_create in list_of_sets_to_create:
		if current_sets_to_create[0] == data_set_name:
			array_mutex_process.unlock()
			return
	array_mutex_process.unlock()
	print(" delta message start 01")
	var current_stage_of_creation : int = 0
	var first_stage_bool : int = 0
	var second_stage_bool : int = 0
	var third_stage_bool : int = 0
	var fourth_stage_bool : int = 0
	var fifth_stage_bool : int = 0
	var sixth_stage_bool : int = 0
	var seventh_stage_bool : int = 0
	var eight_stage_bool : int = 0
	var nineth_stage_bool : int = 0
	
	array_mutex_process.lock()
	print(" delta message start 02")
	#print(" delta message start we start three stage sof creation inside some mutex lock ")
	
	list_of_sets_to_create.append([data_set_name, current_stage_of_creation, first_stage_bool, second_stage_bool, third_stage_bool, fourth_stage_bool, fifth_stage_bool, sixth_stage_bool, seventh_stage_bool, eight_stage_bool, nineth_stage_bool])
	array_mutex_process.unlock()
	print(" delta message start 03")






func check_currently_being_created_sets():
	print(" delta message start hmm we check if we can push further  ")
	print(" we check em again, are they stuck?")

	array_mutex_process.lock()
	mutex_for_container_state.lock()

	for set_to_create in list_of_sets_to_create:
		print(" we have that for example : ", set_to_create)
		print(" it can even be seen as [0] ", set_to_create[0])
		var name_of_set = set_to_create[0]
		var counter_now : int = -1
		
		var dumb_counter_0 : int = 0
		var dumb_counter_1 : int = 0
		
		
		if current_containers_state.has(name_of_set):
			print(" it has something 0 ", counter_now)
			counter_now = 0

		if current_containers_state.has(name_of_set + "_"):
			print(" it has something 1")
			if counter_now == -1:
				name_of_set = name_of_set + "_"
				counter_now = -2
		
		# is it atelaset container, not containter or whatever i tried to write
		if current_containers_state.has(name_of_set + "container"):
			print(" it has something 2")
			if counter_now == -2:
				name_of_set = name_of_set + "container"
				
				
		
		for singular_info in set_to_create:
			if singular_info is int:
				print(" singular_info ", singular_info)
				if dumb_counter_0 == 0:
					dumb_counter_0 +=1
				else:
					dumb_counter_0 +=1
					if singular_info != 0:
						dumb_counter_1 +=1
		
		
		
		print(" checky chicky : " , name_of_set , " and that counter : " , counter_now , " , " , dumb_counter_0 , " , " , dumb_counter_1)
		

		load_queue_mutex.lock()

		if load_queue.has(name_of_set):
			print(" we have it already in load queue")
			if load_queue[name_of_set].has("metadata"):
				print(" it already had it ")
			else:
				load_queue[name_of_set]["metadata"] = {}
				#load_queue[name_of_set]["metadata"]["status"]
		
		if dumb_counter_1 >= 1:
			print(" we are somewhere, here something started the creation ")
			load_queue[name_of_set]["metadata"]["status"] = int(1)
		else:
			print(" that thing have not started its creation ")
			load_queue[name_of_set]["metadata"]["status"] = int(0)

		print(" cheecku chicku : load_queue : " , load_queue)
		load_queue_mutex.unlock()

	array_mutex_process.unlock()
	mutex_for_container_state.unlock()





func process_stages():
	
	array_mutex_process.lock()
	
	for sets_to_create in list_of_sets_to_create:
		var dataset = sets_to_create[0]
		var dataset_name = sets_to_create[0]
		var current_stage = sets_to_create[1]
		match current_stage:
			0:
				if sets_to_create[1] == 0 and curent_queue[0][0] == 0 and sets_to_create[2] == 0:
					curent_queue[0][0] += 1
					sets_to_create[2] += 1
					print(" creation 00 ", dataset_name)
					first_stage_of_creation_(dataset_name, sets_to_create)
			1:
				if sets_to_create[1] == 1 and curent_queue[1][0] == 0 and sets_to_create[3] == 0:
					sets_to_create[3] += 1
					curent_queue[0][0] -= 1
					curent_queue[1][0] += 1
					print(" creation 01 ", dataset_name)
					second_stage_of_creation_(dataset_name, sets_to_create)
			2:
				if sets_to_create[1] == 2 and curent_queue[2][0] == 0 and sets_to_create[4] == 0:
					curent_queue[1][0] -= 1 
					curent_queue[2][0] += 1
					sets_to_create[4] += 1
					print(" creation 02 ", dataset_name)
					third_stage_of_creation_(dataset_name, sets_to_create)
			3:
				if sets_to_create[1] == 3 and curent_queue[3][0] == 0 and sets_to_create[5] == 0:
					sets_to_create[5] += 1
					curent_queue[2][0] -= 1
					curent_queue[3][0] += 1
					fourth_impact_of_creation_(dataset_name, sets_to_create)
			4:
				if sets_to_create[1] == 4 and curent_queue[4][0] == 0 and sets_to_create[6] == 0:
					sets_to_create[6] += 1
					curent_queue[3][0] -= 1
					curent_queue[4][0] += 1
					fifth_impact_of_creation_(dataset_name, sets_to_create)
			5:
				if sets_to_create[1] == 5 and curent_queue[5][0] == 0 and sets_to_create[7] == 0:
					sets_to_create[7] += 1
					curent_queue[4][0] -= 1
					list_of_sets_to_create.erase(sets_to_create)
					if list_of_sets_to_create.size() == 0:
						curent_queue = [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]] 
			6:
				curent_queue[4][0] -= 1
				
				list_of_sets_to_create.erase(sets_to_create)
				
				if list_of_sets_to_create.size() == 0:
					curent_queue = [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]] 
			7:
				curent_queue[4][0] -= 1
				list_of_sets_to_create.erase(sets_to_create)
				if list_of_sets_to_create.size() == 0:
					curent_queue = [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]] 
					the_menace_checker = 0
	array_mutex_process.unlock()


# here we made a task, so we first get the data, into several vars, not just one array
func the_finisher_for_nodes(data_to_be_parsed):
	var path_of_node_jsh = data_to_be_parsed[0][0]
	var node_name_jsh_checker = data_to_be_parsed[0][1]
	var node_to_be_checker = data_to_be_parsed[0][2]
	jsh_tree_get_node_status_changer(path_of_node_jsh, node_name_jsh_checker, node_to_be_checker)

# and here we process that data
func jsh_tree_get_node_status_changer(node_path_jsh_tree_status: String, node_name: String, node_to_check: Node):
	var path_parts_jsh_status_node = node_path_jsh_tree_status.split("/")
	
	tree_mutex.lock()
	var current = scene_tree_jsh["main_root"]["branches"]
	tree_mutex.unlock()
	
	var name_of_container = path_parts_jsh_status_node[0]
	var name_of_current_thing = path_parts_jsh_status_node[path_parts_jsh_status_node.size() - 1]
	
	tree_mutex.lock()
	array_counting_mutex.lock()
	
	for part in path_parts_jsh_status_node:
		if current.has(part):
			current = current[part]
			if path_parts_jsh_status_node[-1] == part:
				if node_to_check:
					current["status"] = "active"
					current["node"] = node_to_check
					
					if array_for_counting_finish.has(name_of_container):
						if array_for_counting_finish[name_of_container].has(name_of_current_thing):
							array_for_counting_finish[name_of_container][name_of_current_thing]["node"] = node_to_check
						array_for_counting_finish[path_parts_jsh_status_node[0]]["metadata"]["counter_after"] +=1
						if array_for_counting_finish[name_of_container]["metadata"]["datapoint_name"] == name_of_current_thing:
							array_for_counting_finish[name_of_container]["metadata"]["datapoint_node"] = node_to_check
						if array_for_counting_finish[name_of_container]["metadata"]["container_path"] == name_of_current_thing:
							array_for_counting_finish[name_of_container]["metadata"]["container_node"] = node_to_check
						# here we get all the nodes, so we can send further, dictionary with all them nodes
						if array_for_counting_finish[name_of_container]["metadata"]["counter_before"] == array_for_counting_finish[name_of_container]["metadata"]["counter_after"]:
							create_new_task("newer_even_function_for_dictionary", name_of_container)
					else:
						print(" dilemafiasco i guess it could like, not find somehow that container? how ?")
				else: # here i guess, the node doest exist? which should not be possible in current sceneario, where we get it on main thread, and task is made after that?
					print(" dilemafiasco new way to check node from proces we are but we didnt get node? on if:")
			else: # we didnt find it yet, so we dig further
				current = current["children"]
		else:
			print(" dilemafiasco the new one? ")
	tree_mutex.unlock()
	array_counting_mutex.unlock()


# functions that worked, kinda, but i turned them off now, i want new, better and smarter way to check stuff
func start_timer_of_finito(data_timero):
	await get_tree().create_timer(1.0).timeout
	print(data_timero)
	var container_timero
	var the_path_of_thing
	array_counting_mutex.lock()
	if array_for_counting_finish.has(container_timero):
		print(" i guess after 1s it still has that ")
		array_counting_mutex.unlock()
	else:
		print(" it was probably send already")
		array_counting_mutex.unlock()


func recreate_missing_nodes(array_of_recreation):
	var container_name = array_of_recreation[0]
	var path_of_missing_node = array_of_recreation[1]
	var splitted_path_for_main_thingy = path_of_missing_node.split("/")
	var node_we_look_for_now : String
	var set_name_we_look_for : String
	if splitted_path_for_main_thingy.size() > 1:
		node_we_look_for_now = splitted_path_for_main_thingy[1]
		print(" that thingy is bigger than 1, so it is not container ? " , node_we_look_for_now)
	
	active_r_s_mut.lock()
	for current_activ_rec in active_record_sets:
		for current_avail_rec in active_record_sets[current_activ_rec][current_activ_rec + "records"]["header"]:
			print("current_avail_rec " , current_avail_rec)
			if node_we_look_for_now == current_avail_rec:
				print(" we found that thing " )
				if scene_tree_jsh["main_root"]["branches"].has(container_name):
					if scene_tree_jsh["main_root"]["branches"][container_name]["children"].has(node_we_look_for_now):
						print_tree_pretty()
						print(" the tree has that branch?")
						print_tree_structure(scene_tree_jsh["main_root"]["branches"][container_name]["children"][node_we_look_for_now], 0)
						disable_all_branches_reset_counters(scene_tree_jsh["main_root"]["branches"][container_name]["children"][node_we_look_for_now], container_name)
						print_tree_structure(scene_tree_jsh["main_root"]["branches"][container_name]["children"][node_we_look_for_now], 0)
						var path_for_node_to_unload = container_name + "/" + node_we_look_for_now
						array_counting_mutex.lock()
						if array_for_counting_finish[container_name].has(node_we_look_for_now):
							array_for_counting_finish[container_name][node_we_look_for_now]["node"] = []
						array_counting_mutex.unlock()
						for singular_thingies in active_record_sets[current_activ_rec][current_activ_rec + "records"]["content"]:
							print(" singular_thingies : " , singular_thingies[0][0][0])
							if singular_thingies[0][0][0] == node_we_look_for_now:
								print(" we found active records part : " , singular_thingies)
								unload_node_branch(path_for_node_to_unload, singular_thingies)
								return
				return
	active_r_s_mut.unlock()


func recreator_of_singular_thing(data_set):
	var cached_data_new = data_set.duplicate(true) 
	var thing_name
	var coords_to_place
	var direction_to_place
	var thing_type_file
	var shape_name
	var root_name
	var pathway_dna
	var group_number
	var first_line : Array = []
	var lines_parsed : Array = []
	for lines in cached_data_new:
		if lines == cached_data_new[0]:
			first_line = cached_data_new[0]
		else:
			lines_parsed.append(lines)
	thing_name = first_line[0][0]
	coords_to_place = first_line[1][0]
	direction_to_place = first_line[2][0]
	thing_type_file = first_line[3][0]
	shape_name = first_line[4][0]
	root_name = first_line[5][0]
	pathway_dna = first_line[6][0]
	group_number = first_line[7][0]
	#print(" the thingy dingy  : " , thing_name, thing_type_file, first_line, lines_parsed[0], group_number, shape_name, lines_parsed)
	analise_data(thing_name, thing_type_file, first_line, lines_parsed[0], group_number, shape_name, lines_parsed)
	first_line.clear()
	lines_parsed.clear()

func unload_node_branch(path_for_node_to_unload, recreation_of_node_data):
	var node_to_unload_now = jsh_tree_get_node(path_for_node_to_unload)
	if node_to_unload_now:
		print(" node_to_unload_now : " , node_to_unload_now)
		node_to_unload_now.queue_free()
	print_tree_pretty()
	recreator_of_singular_thing(recreation_of_node_data)

func disable_all_branches_reset_counters(branch_to_disable, container_name_for_array):
	var all_containers : Array = []
	var all_nodes : Array = []
	var branches_to_process : Array = []
	var just_container : Array = []

	var process_branch = func traverse_branch(branch: Dictionary):
		if branch["metadata"].has("full_path") and branch["metadata"]["full_path"] != null:
			
			all_containers.append(branch["name"])
			if branch["status"] == "active":
				
				array_counting_mutex.lock()
				array_for_counting_finish[container_name_for_array]["metadata"]["counter_after"] -=1
				array_counting_mutex.unlock()
				
			branch["status"] = "disabled"
		
		if branch.has("children"):
			for child_name in branch["children"]:
				branches_to_process.append(branch["children"][child_name])
				
				if branch["children"][child_name]["status"] == "active":
					
					array_counting_mutex.lock()
					array_for_counting_finish[container_name_for_array]["metadata"]["counter_after"] -=1
					array_counting_mutex.unlock()
					
				branch["children"][child_name]["status"] = "disabled"

	# Children finder
	var process_children = func traverse_branch(branch: Dictionary):
		if branch.has("metadata"):# we must complete the evaluation evolution and ovulation of this game
			all_nodes.append(branch["metadata"]["full_path"])

		if branch.has("children"):
			for child_name in branch["children"]:
				branches_to_process.append(branch["children"][child_name])
				
				if branch["children"][child_name]["status"] == "active":
					
					array_counting_mutex.lock()
					array_for_counting_finish[container_name_for_array]["metadata"]["counter_after"] -=1
					array_counting_mutex.unlock()
				
				branch["children"][child_name]["status"] = "disabled"

	process_branch.call(branch_to_disable)

	var current_branches = branches_to_process.duplicate(false)

	# Process branches until none left
	while branches_to_process.size() > 0:
		var current_branch = branches_to_process[0]  # Get first branch
		process_branch.call(current_branch)        # Process it
		branches_to_process.remove_at(0)            # Remove it and array shifts automatically





# the steps of creation, functions to send data further
func first_stage_of_creation_(data_set_name_0, sets_to_create_0):
	create_new_task("initialize_menu", sets_to_create_0[0])




func second_stage_of_creation_(data_set_name_1, sets_to_create_1):
	create_new_task("second_impact_for_real", sets_to_create_1[0])

func second_impact_for_real(set_to_do_thingy):
	var records_set_name_0 = set_to_do_thingy + "_"
	var container_name_for_array = container_finder(records_set_name_0)
	
	array_counting_mutex.lock()
	if !array_for_counting_finish.has(container_name_for_array):
		array_for_counting_finish[container_name_for_array] = {}
	array_counting_mutex.unlock()
		
	active_r_s_mut.lock()
	var safe_activ_record_set = active_record_sets
	active_r_s_mut.unlock()
	
	process_active_records_for_tree(safe_activ_record_set, records_set_name_0, container_name_for_array)

	array_mutex_process.lock()
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == set_to_do_thingy:
			number_thingy[1] +=1
	array_mutex_process.unlock()
	
	



func third_stage_of_creation_(data_set_name_2, sets_to_create_2):
	create_new_task("third_impact_right_now", sets_to_create_2[0])

func third_impact_right_now(data_set_thingiess):
	var records_set_name_1 = data_set_thingiess + "_"
	load_cached_data(records_set_name_1)
	
	array_mutex_process.lock()
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == data_set_thingiess:
			number_thingy[1] +=1
	array_mutex_process.unlock()




func fourth_impact_of_creation_(data_set_name_3, sets_to_create_3):
	create_new_task("fourth_impact_right_now", data_set_name_3)

func fourth_impact_right_now(data_set_nameeee):
	var records_set_name_1 = data_set_nameeee + "_"
	load_cached_data_second_impact(records_set_name_1)
	
	array_mutex_process.lock()
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == data_set_nameeee:
			number_thingy[1] +=1
	array_mutex_process.unlock()


func fifth_impact_of_creation_(data_set_name_4, sets_to_create_4):
	create_new_task("fifth_impact_right_now", data_set_name_4)

func fifth_impact_right_now(data_set_nameeeeee):
#	var records_set_name_2 = data_set_nameeeeee + "_"

	array_mutex_process.lock()
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == data_set_nameeeeee:
			print(" fifth imnpact list of sets to create we plus one " , data_set_nameeeeee)
			number_thingy[1] +=1
	array_mutex_process.unlock()



# here we get datapoint, and send that data further
func newer_even_function_for_dictionary(name_of_container):

	array_counting_mutex.lock()
	var datapoint_node_newest = array_for_counting_finish[name_of_container]["metadata"]["datapoint_node"]#.duplicate(true)
	var deep_state_copy_of_apples = array_for_counting_finish[name_of_container].duplicate(true)
	array_counting_mutex.unlock()
	#print(" i guess somehow, we get the node, and now, we got some kind of trouble? ", datapoint_node_newest)
	datapoint_node_newest.new_datapoint_layer_system(deep_state_copy_of_apples)
	
	#array_counting_mutex.lock()
	#array_for_counting_finish.erase(name_of_container) 
	#array_counting_mutex.unlock()