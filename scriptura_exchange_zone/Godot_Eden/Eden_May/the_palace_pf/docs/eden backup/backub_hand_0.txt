# main, main node, main_root, main.gd, scripts/main.gd

#
# JSH Ethereal Engine
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┓ ┓         ┓  ┏┓    •      ┏┓        
#       888  `"Y8888o.   888ooooo888     ┣ ╋┣┓┏┓┏┓┏┓┏┓┃  ┣ ┏┓┏┓┓┏┓┏┓  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┗┛┗┛┗┗ ┛ ┗ ┗┻┗  ┗┛┛┗┗┫┗┛┗┗   ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                          ┛          ┛      
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Ethereal Engine
#

# so me, others me from dreams, and whoever i hear i guess, we work together, through space and time, to make that vidya ive been day dreaming for past 20 years
# cmon
extends Node3D



var first_start_check : String = "pending"
# the last hope to figure out, why a task failed, was started, but didnt quite get anywhere?
var int_of_stuff_started : int = 0
var int_of_stuff_finished : int = 0


# a new jewish hope, for new process frame intel
#signal frame_processed
#var frame_signal_connected := false

# the files, directiories, folders, spaces, places, data
var path = "D:/Eden"
var file_path
var files_content
var folders_content
var directory_existence = false
var folders_existence = false
var files_existence = false

# the scripts, that we apply to datapoints, containers, line for clicky
const DataPointScript = preload("res://scripts/data_point.gd")
const ContainterScript = preload("res://scripts/containter.gd")
const LineScript = preload("res://scripts/line.gd")

# the ready stuff, first container, akashic_records and ray thingy stuff screen, mouse lol
var ray_distance_set = 20.0
var viewport
var mouse_pos
var camera

# the delta idea of turns and moves, so we always have it easy as we spread the tasks
var turn_number_process : int = 0
var delta_turn_0 : int = 0

# the active and cached data, for creation, recreation etc
var active_record_sets: Dictionary = {}
var active_r_s_mut = Mutex.new()



var cached_record_sets: Dictionary = {}
var cached_r_s_mutex = Mutex.new()



# current state of set, being created, its name as string
var list_of_sets_to_create : Array = []
var array_mutex_process = Mutex.new()

# data to be put for my eyes
var max_nodes_added_per_cycle : int = 369
var nodes_to_be_added_int : int = 0
var nodes_to_be_added : Array = []
var mutex_nodes_to_be_added = Mutex.new()

# second impact of creation data
var max_data_send_per_cycle : int = 369
var data_to_be_send : Array = []
var mutex_data_to_send = Mutex.new()




# moving and rotating things
var max_movements_per_cycle : int = 369
var things_to_be_moved : Array = []
var movmentes_mutex = Mutex.new()





# the unloading stuff
var max_nodes_to_unload_per_cycle : int = 369
var nodes_to_be_unloaded : Array = []
var mutex_for_unloading_nodes = Mutex.new()




# the function caller from main thread
var max_functions_called_per_cycle : int = 369
var functions_to_be_called : Array = []
var mutex_function_call = Mutex.new()





# the godot tree, didnt respect my needs, made my own, even signed it
var scene_tree_jsh : Dictionary = {}
var tree_mutex = Mutex.new()




var cached_jsh_tree_branches : Dictionary = {}
var cached_tree_mutex = Mutex.new()









var status_symbol = {
	"active": "●",
	"pending": "○", 
	"disabled": "×"
}

var cache_timestamps: Dictionary = {}
var max_cache_size_mb: int = 8 #50

# like C and D on windows, so drives, maybe some /home or whatever others use
var available_directiories : Array = []

@onready var thread_pool = get_node("/root/thread_pool_autoload")

var curent_queue : Array = [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]] 

var the_menace_checker : int = 0
var menace_mutex = Mutex.new()






var array_for_counting_finish : Dictionary = {}
var array_counting_mutex = Mutex.new()



# the godly messengers with data, getting them download, and even uploading information
var download_received : Dictionary = {}
var upload_to_send : Dictionary = {}


var current_containers_state : Dictionary = {}
var mutex_for_container_state = Mutex.new()




var menace_tricker_checker : int = -2
var mutex_for_trickery = Mutex.new()



var unload_queue : Dictionary = {}
var unload_queue_mutex = Mutex.new()



var load_queue : Dictionary = {}
var load_queue_mutex = Mutex.new()


# list of containers, group of containers too maybe? lets use both, for shish and giggle

#

var mutex_containers = Mutex.new() # Mutex kurwa, not Metex Mutex Mutex Mutex
var list_of_containers : Dictionary = {}







var mutex_singular_l_u = Mutex.new()


var array_with_no_mutex : Array = []

var dictionary_of_mistakes : Dictionary = {}
var dictionary_of_mistakes_mutex = Mutex.new()

# tree_mutex


var task_timeouts = {}
var max_task_duration = 50000 # 50 seconds


# Should be expanded to:
var task_timestamps = {}
var task_status = {}


#
# JSH Ethereal Engine Start up
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┓         ┓     ┏┓    •      
#       888  `"Y8888o.   888ooooo888     ┗┓╋┏┓┏┓╋  ╋┣┓┏┓  ┣ ┏┓┏┓┓┏┓┏┓  
#       888      `"Y88b  888     888     ┗┛┗┗┻┛ ┗  ┗┛┗┗   ┗┛┛┗┗┫┗┛┗┗   
#       888 oo     .d8P  888     888                           ┛         
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Ethereal Engine Start up
#

var message_of_delta_start

var array_of_startup_check : Array = []


func _init():
	print(" ready on each script ? 1")
	prepare_akashic_records()

func _ready():
	
	message_of_delta_start = breaks_and_handles_check()
	print(" delta message start ", message_of_delta_start)
	
	
	thread_pool.connect("task_discarded", func(task): 
		print(" thread pool connect task discarded")
		queue_pusher_adder(task)
		int_of_stuff_finished +=1
	)
	
	thread_pool.connect("task_started", func(task):
		print("task_started", task)
		int_of_stuff_started +=1
		)
	#connect("frame_processed", Callable(self, "_on_frame_processed"))
	#frame_signal_connected = true
	#thread_pool.connect("task_discarded", Callable(self, "_on_task_discarded"))
	print("_ready : Project Eden, ver : new dictionaries of data sendin and cachin")
	print(" prepare_basic operation before creation ")
	#prepare_akashic_records()
	check_settings_file()
	mouse_pos = get_viewport().get_mouse_position()
	camera = get_viewport().get_camera_3d()
	viewport = get_viewport()
	start_up_scene_tree()
	print(" delta message start we start three stage sof creation ")
	create_new_task("three_stages_of_creation", "base")
	create_new_task("three_stages_of_creation", "menu")
	print(" delta message start we start three stage sof creation well, both went theirs ways ")
	

###########################
## the Claude Repair Attempt
#####################

#var task_timeouts = {}
#var max_task_duration = 50000 # 50 seconds
#
#
## Should be expanded to:
#var task_timestamps = {}
#var task_status = {}

func track_task_status(task_id):
	task_status[task_id] = {
		"start_time": Time.get_ticks_msec(),
		"status": "pending",
		"retries": 0,
		"error_count": 0
	}


func track_task_completion(task_id):
	task_timeouts[task_id] = {
		"start_time": Time.get_ticks_msec(),
		"status": "pending"
	}
	
	# Check after max duration
	await get_tree().create_timer(max_task_duration / 1000.0).timeout
	if task_timeouts.has(task_id) and task_timeouts[task_id]["status"] == "pending":
		# Task timed out - attempt recovery
		handle_task_timeout(task_id)

func handle_task_timeout(task_id):
	var task_data = task_status[task_id]
	
	# Reset stuck mutexes
	var mutexes_to_check = [
		active_r_s_mut,
		cached_r_s_mutex,
		tree_mutex,
		mutex_for_container_state
	]
	
	for mutex in mutexes_to_check:
		if !mutex.try_lock():
			# Force unlock if stuck
			mutex.unlock()
			log_error_state("mutex_stuck", {
				"task_id": task_id,
				"mutex": mutex
			})
	
	# Clear queue if needed
	if task_data["retries"] > 3:
		clear_task_queues()

func clear_task_queues():
	array_mutex_process.lock()
	list_of_sets_to_create.clear()
	array_mutex_process.unlock()
	
	mutex_nodes_to_be_added.lock() 
	nodes_to_be_added.clear()
	mutex_nodes_to_be_added.unlock()
	
	# Reset container states
	mutex_for_container_state.lock()
	for container in current_containers_state.keys():
		current_containers_state[container]["status"] = -1
	mutex_for_container_state.unlock()


func validate_container_state(container_name):
	var required_nodes = ["datapoint", "container"]
	var missing_nodes = []
	
	tree_mutex.lock()
	if scene_tree_jsh["main_root"]["branches"].has(container_name):
		var container = scene_tree_jsh["main_root"]["branches"][container_name]
		
		for node_type in required_nodes:
			if !container.has(node_type) or !is_instance_valid(container[node_type]["node"]):
				missing_nodes.append(node_type)
	tree_mutex.unlock()
	
	if missing_nodes.size() > 0:
		attempt_container_repair(container_name, missing_nodes)
		
func attempt_container_repair(container_name, missing_nodes):
	active_r_s_mut.lock()
	var records_set_name = container_name.split("_")[0] + "_"
	
	if active_record_sets.has(records_set_name):
		var records = active_record_sets[records_set_name]
		# Attempt to recreate missing nodes from records
		for node_type in missing_nodes:
			recreate_node_from_records(container_name, node_type, records) 
	active_r_s_mut.unlock()
	
	

func log_error_state(error_type, details):
	dictionary_of_mistakes_mutex.lock()
	
	if !dictionary_of_mistakes.has(error_type):
		dictionary_of_mistakes[error_type] = {
			"first_seen": Time.get_ticks_msec(),
			"count": 0,
			"instances": []
		}
	
	dictionary_of_mistakes[error_type]["count"] += 1
	dictionary_of_mistakes[error_type]["instances"].append({
		"time": Time.get_ticks_msec(),
		"details": details
	})
	
	# If error occurs frequently, trigger deep repair
	if dictionary_of_mistakes[error_type]["count"] > 5:
		trigger_deep_repair(error_type)
		
	dictionary_of_mistakes_mutex.unlock()

func start_health_checks():
	while true:
		await get_tree().create_timer(5.0).timeout
		check_system_health()

func check_system_health():
	# Check thread pool state
	if int_of_stuff_started > int_of_stuff_finished + 10:
		log_error_state("thread_pool_backlog", {
			"started": int_of_stuff_started,
			"finished": int_of_stuff_finished
		})
	
	# Check container states
	mutex_for_container_state.lock()
	for container in current_containers_state:
		if current_containers_state[container]["status"] == -1:
			validate_container_state(container)
	mutex_for_container_state.unlock()


###################################
## main functions i guess are needed
####################################

func prepare_akashic_records():
	print(" first we need a screen, and light state : ", first_start_check)
	first_start_check = "started"
	print(" state now : ", first_start_check)
	var main_sets_names = BanksCombiner.dataSetLimits
	array_of_startup_check.append(first_start_check)
	array_of_startup_check.append([["akashic_records"],["base"],["menu"]])
	
	array_of_startup_check.append(main_sets_names)
	# the basic_pack_of_records
	print(" stuff to do : " , array_of_startup_check)
	

func zippy_unzipper_data_center():
	print(" the load and unload of zip file is needed ")
	print(" lets do it three letters system of words ")
	print(" the gateway of repeats ")
	print(" one big zip file ")


func handle_random_errors(): # array_with_no_mutex
	print(" elquadromadro trying to figure out random problems ")
	for current_error in array_with_no_mutex:
		print(" elquadromadro error to stick to something " , current_error)
		var name_of_error = current_error[0]
		var type_of_error = current_error[1]
		print(" elquadromadro error to stick to something " , name_of_error , " and " , type_of_error)
		dictionary_of_mistakes_mutex.lock()
		
		if dictionary_of_mistakes.has(name_of_error):
			# that one appeared before
			
			print(" elquadromadro we had issues with that one before ")
			if dictionary_of_mistakes[name_of_error].has(name_of_error):
				# we had this type of error before
				#dictionary_of_mistakes[name_of_error][name_of_error].has("status"):
					#print(" it does have status tho")
				
				print(" elquadromadro the same error as we had previously ")
				if dictionary_of_mistakes[name_of_error][name_of_error].has(type_of_error):
					print(" elquadromadro the same type of the same error hmm ")
					# this same stage of error as before
					
				
		else:
			print(" elquadromadro that is a new trouble maker, why could it not work already ? ")
			dictionary_of_mistakes[name_of_error] = {}
			dictionary_of_mistakes[name_of_error]["status"] = "pending"
			dictionary_of_mistakes[name_of_error]["counter"] = int(1)
			
			dictionary_of_mistakes[name_of_error][name_of_error] = {}
			dictionary_of_mistakes[name_of_error][name_of_error]["status"] = "pending"
			dictionary_of_mistakes[name_of_error][name_of_error]["counter"] = int(1)
			
			dictionary_of_mistakes[name_of_error][name_of_error][type_of_error] = {}
			dictionary_of_mistakes[name_of_error][name_of_error][type_of_error]["status"] = "pending"
			dictionary_of_mistakes[name_of_error][name_of_error][type_of_error]["counter"] = int(1)
		
		
		print(" elquadromadro dictionary_of_mistakes_mutex : " , dictionary_of_mistakes_mutex)
		dictionary_of_mistakes_mutex.unlock()



#######################
## Claude continuation
#######################

func recreate_node_from_records(container_name: String, node_type: String, records: Dictionary):
	print("Attempting to recreate %s for container %s" % [node_type, container_name])
	
	var records_set_name = container_name + "records"
	var node_data = null
	
	# Find the original node data in records
	if records.has(records_set_name):
		for record in records[records_set_name]["content"]:
			if record[0][3][0] == node_type:  # Check node type
				node_data = record[0]
				break
	
	if node_data:
		match node_type:
			"datapoint":
				var data_point = Node3D.new()
				data_point.set_script(DataPointScript)
				data_point.setup_main_reference(self)
				
				# Recreate with original parameters
				var version = node_data[4][0]  # Version from records
				var setup_data = node_data[5]  # Setup data from records
				data_point.power_up_data_point(node_data[0][0], int(version), setup_data)
				
				# Add to scene tree
				var node_path = node_data[6][0]
				tasked_children(data_point, node_path)
				
				# Update tree data
				tree_mutex.lock()
				scene_tree_jsh["main_root"]["branches"][container_name]["datapoint"] = {
					"datapoint_name": node_data[0][0],
					"datapoint_path": node_path,
					"node": data_point
				}
				tree_mutex.unlock()
				
			"container":
				var container = Node3D.new()
				container.set_script(ContainterScript)
				container.name = node_data[0][0]
				
				if container.has_method("container_initialize"):
					container.container_initialize(node_data[5])
				
				var node_path = node_data[6][0]
				tasked_children(container, node_path)
				
				tree_mutex.lock()
				scene_tree_jsh["main_root"]["branches"][container_name]["node"] = container
				scene_tree_jsh["main_root"]["branches"][container_name]["status"] = "active"
				tree_mutex.unlock()
			
			_:
				print("Unknown node type for recreation: ", node_type)
		
		# Log recovery attempt
		log_error_state("node_recreation", {
			"container": container_name,
			"node_type": node_type,
			"success": true
		})
	else:
		print("Failed to find data for node recreation")
		log_error_state("node_recreation_failed", {
			"container": container_name,
			"node_type": node_type,
			"reason": "no_data_found"
		})

func trigger_deep_repair(error_type: String):
	print("Initiating deep repair for error type: ", error_type)
	
	dictionary_of_mistakes_mutex.lock()
	var error_data = dictionary_of_mistakes[error_type]
	dictionary_of_mistakes_mutex.unlock()
	
	match error_type:
		"thread_pool_backlog":
			# Reset thread counters and clear stuck tasks
			int_of_stuff_started = 0
			int_of_stuff_finished = 0
			
			# Recheck all container states
			mutex_for_container_state.lock()
			for container in current_containers_state.keys():
				current_containers_state[container]["status"] = -1  # Force recheck
			mutex_for_container_state.unlock()
			
			# Trigger container state checker
			mutex_for_trickery.lock()
			menace_tricker_checker = 1
			mutex_for_trickery.unlock()
		
		"node_missing":
			# Scan all containers for missing nodes
			tree_mutex.lock()
			for branch_name in scene_tree_jsh["main_root"]["branches"].keys():
				var branch = scene_tree_jsh["main_root"]["branches"][branch_name]
				
				# Check required nodes
				var missing = []
				if !branch.has("datapoint") or !branch["datapoint"].has("node"):
					missing.append("datapoint")
				if !branch.has("node") or !is_instance_valid(branch["node"]):
					missing.append("container")
				
				if missing.size() > 0:
					# Get records for reconstruction
					active_r_s_mut.lock()
					var records_set = branch_name.split("_")[0] + "_"
					if active_record_sets.has(records_set):
						var records = active_record_sets[records_set]
						for node_type in missing:
							recreate_node_from_records(branch_name, node_type, records)
					active_r_s_mut.unlock()
			tree_mutex.unlock()
		
		"container_state_mismatch":
			# Reset all container states and force revalidation
			mutex_for_container_state.lock()
			current_containers_state.clear()
			mutex_for_container_state.unlock()
			
			mutex_containers.lock()
			list_of_containers.clear()
			mutex_containers.unlock()
			
			# Force recheck of all active records
			active_r_s_mut.lock()
			for records_set in active_record_sets.keys():
				if active_record_sets[records_set].has("metadata"):
					active_record_sets[records_set]["metadata"]["container_count"] = 0
			active_r_s_mut.unlock()
			
			# Trigger full recheck
			containers_states_checker()
			containers_list_creator()
		
		_:
			print("Unknown error type for deep repair: ", error_type)
	
	# Clear error history after repair attempt
	dictionary_of_mistakes_mutex.lock()
	dictionary_of_mistakes[error_type]["count"] = 0
	dictionary_of_mistakes[error_type]["instances"].clear()
	dictionary_of_mistakes_mutex.unlock()






func breaks_and_handles_check():
	#print()
	
	var current_state_mutexes : Array = []
	var negative_counter : int = -1
	var positive_counter : int = -1
	
#####################################################
		## active_r_s_mut
	var mutex_check_0 = null
	if active_r_s_mut.try_lock():
		mutex_check_0 = active_r_s_mut.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_0 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_0)
#####################################################
	
#####################################################
		## cached_r_s_mutex
	var mutex_check_1 = null
	if cached_r_s_mutex.try_lock():
		mutex_check_1 = cached_r_s_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_1 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_1)
#####################################################
	
#####################################################
		## tree_mutex
	var mutex_check_2 = null
	if tree_mutex.try_lock():
		mutex_check_2 = tree_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_2 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_2)
#####################################################
	
	
#####################################################
		## cached_tree_mutex
	var mutex_check_3 = null
	if cached_tree_mutex.try_lock():
		mutex_check_3 = cached_tree_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_3 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_3)
#####################################################
	
	
#####################################################
		## mutex_nodes_to_be_added
	var mutex_check_4 = null
	if mutex_nodes_to_be_added.try_lock():
		mutex_check_4 = mutex_nodes_to_be_added.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_4 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_4)
#####################################################
	
#####################################################
		## movmentes_mutex
	var mutex_check_5 = null
	if movmentes_mutex.try_lock():
		mutex_check_5 = movmentes_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_5 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_5)
#####################################################
	
#####################################################
		## mutex_data_to_send
	var mutex_check_6 = null
	if mutex_data_to_send.try_lock():
		mutex_check_6 = mutex_data_to_send.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_6 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_6)
#####################################################
	
#####################################################
		## mutex_function_call
	var mutex_check_7 = null
	if mutex_function_call.try_lock():
		mutex_check_7 = mutex_function_call.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_7 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_7)
#####################################################
	
#####################################################
		## mutex_for_unloading_nodes
	var mutex_check_8 = null
	if mutex_for_unloading_nodes.try_lock():
		mutex_check_8 = mutex_for_unloading_nodes.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_8 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_8)
#####################################################

#####################################################
		## array_mutex_process
	var mutex_check_9 = null
	if array_mutex_process.try_lock():
		mutex_check_9 = array_mutex_process.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_9 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_9)
#####################################################



############################################################

# the cardinal sin of creation beyond number 9

#############################################################


#####################################################
		## menace_mutex
	var mutex_check_00 = null
	if menace_mutex.try_lock():
		mutex_check_00 = menace_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_00 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_00)
#####################################################

#####################################################
	# array_counting_mutex
	var mutex_check_01 = null
	if array_counting_mutex.try_lock():
		mutex_check_01 = array_counting_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_01 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_01)
#####################################################

#####################################################
	# mutex_for_container_state
	var mutex_check_02 = null
	if mutex_for_container_state.try_lock():
		mutex_check_02 = mutex_for_container_state.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_02 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_02)
#####################################################

#####################################################
	# mutex_for_trickery
	var mutex_check_03 = null
	if mutex_for_trickery.try_lock():
		mutex_check_03 = mutex_for_trickery.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_03 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_03)
#####################################################

#####################################################
	# unload_queue_mutex
	var mutex_check_04 = null
	if unload_queue_mutex.try_lock():
		mutex_check_04 = unload_queue_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_04 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_04)
#####################################################

#####################################################
	# mutex_containers
	var mutex_check_05 = null
	if mutex_containers.try_lock():
		mutex_check_05 = mutex_containers.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_05 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_05)
#####################################################

#####################################################
	# mutex_singular_l_u
	var mutex_check_06 = null
	if mutex_singular_l_u.try_lock():
		mutex_check_06 = mutex_singular_l_u.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_06 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_06)
#####################################################



#####################################################
	# unload_queue_mutex
	var mutex_check_07 = null
	if unload_queue_mutex.try_lock():
		mutex_check_07 = unload_queue_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_07 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_07)
#####################################################


#####################################################
	# load_queue_mutex
	var mutex_check_08 = null
	if load_queue_mutex.try_lock():
		mutex_check_08 = load_queue_mutex.try_lock()
		#############################################
		positive_counter +=1
	else:
		mutex_check_08 = false
		negative_counter +=1
		#############################################
	current_state_mutexes.append(mutex_check_08)
#####################################################
	
	

	return current_state_mutexes
	#print(" we check a thing ? " , current_state_mutexes)




# 









#func _on_task_discarded(task):
	#print("Task was discarded:", task.tag, " Result:", task.result)
#func _on_frame_processed():
	# Signal received
#	pass

var blimp_of_time : Array = []

func before_time_blimp(how_many_finished, how_many_shall_been_finished):
	# how much time after delta?
	# i dunno, we would need to check it and store it
	# like clockwork
	# the warp of space and time
	# first make one here :
	
	var before_blimp_time = Time.get_ticks_msec()
	
	print("before_blimp_time : " , before_blimp_time)
	print(" past_deltas_memories : ", past_deltas_memories)
	print(" stored_delta_memory : ", stored_delta_memory)
	print(" these two should be normalized too i guess ")
	print()
	print(" check basic if we allign with prophecies of wisest spirits, do we unlock before it is too late ")
	print(" how_many_shall_been_finished : ", how_many_shall_been_finished)
	print(" how_many_finished : " ,how_many_finished)
	print()
	if how_many_finished != how_many_shall_been_finished:
		print(" something does not add upp " , how_many_finished , " is maybe probably bigger, maybe smaller, hmm numbers < < > > which way != == ? ", how_many_shall_been_finished)
		print(" how_many_shall_been_finished - how_many_shall_been_finished ", how_many_finished - how_many_shall_been_finished)
		print(" in reverse maybe ? ", how_many_shall_been_finished - how_many_finished)
		print(" it is not the first tine  i guess : [0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0 ")
		print(" hmm 0220 0220 0220, like an sos or something ?")
		
		# [0]
		blimp_of_time.append(how_many_finished)
		
		# [1]
		blimp_of_time.append(how_many_shall_been_finished)
		
		# [2]
		# int_of_stuff_started
		blimp_of_time.append(int_of_stuff_started)
		
		# [3]
		# int_of_stuff_finished
		blimp_of_time.append(int_of_stuff_finished)
		
		# has it happened before ?
		if blimp_of_time.size() > 3:
			print(" hald to tell otherwise, some array size is bigger than 3 ", blimp_of_time)
		# is it a new thing ?
		
		# biggest differences
		
		# biggest difference ever
		
		# time limits, 1 second
		
		# 10 seconds # how many times
		
		# 30 seconds
		
		# 1 minute
		
	#pass
	# time os thing? of when we started ready function, when we finished it, the blimp of mutexes, first needed sets to even see a single rain drop fall on her ass check
	
	#



func queue_pusher_adder(task):
	#print("taskkk tag : ",task.tag, " taskkk target instance :  ", task.target_instance, " taskkk result : ", task.result, " taskkk target method : ", task.target_method, " target argument : " , task.target_argument)
	mutex_singular_l_u.lock()
	var method_task = task.target_method
	
	var completion_time = Time.get_ticks_msec()
	var task_id = str(task.tag)
	var target_argument = task.target_argument

	if task_status.has(task_id):
		var duration = completion_time - task_status[task_id]["start_time"]
		if duration > 1000: # 1 second timeout
			handle_task_timeout(task_id)
	
	print(" taskkkkk : ", method_task)
	
	# Process task
	match method_task:
		"three_stages_of_creation":
			handle_creation_task(target_argument)
			mutex_for_trickery.lock()
			menace_tricker_checker = 1
			mutex_for_trickery.unlock()
		"unload_container":
			handle_unload_task(target_argument)
			mutex_for_trickery.lock()
			menace_tricker_checker = 1
			mutex_for_trickery.unlock()
		"the_finisher_for_nodes":
			print(" this means, the node is being finished to be whip out baby ")
	#if method_task == "the_finisher_for_nodes":
		#


func handle_creation_task(target_argument):
	var type_of_state : int = 1
	print(" handle_creation_task : ", target_argument)
	
	# Check if we can proceed with creation
	load_queue_mutex.lock()
	var can_proceed = true
	if load_queue.has(target_argument):
		if load_queue[target_argument].has("metadata"):
			if load_queue[target_argument]["metadata"].has("status"):
				if load_queue[target_argument]["metadata"]["status"] != 0:
					can_proceed = false
	load_queue_mutex.unlock()
	
	if can_proceed:
		# Update tree state
		the_current_state_of_tree(target_argument, type_of_state)
		
		# Trigger recheck
		mutex_for_trickery.lock()
		menace_tricker_checker = 1
		mutex_for_trickery.unlock()
	else:
		# Log creation attempt for retry
		dictionary_of_mistakes_mutex.lock()
		if !dictionary_of_mistakes.has(target_argument):
			dictionary_of_mistakes[target_argument] = {
				"status": "pending",
				"counter": int(1),
				"last_attempt": Time.get_ticks_msec()
			}
		dictionary_of_mistakes_mutex.unlock()

func handle_unload_task(target_argument):
	var type_of_state : int = -1
	var the_shorter_set = target_argument.substr(0, str(target_argument).length() - 10)
	print(" handle_unload_task : ", target_argument, " shortened to: ", the_shorter_set)
	
	# Check unload queue state
	unload_queue_mutex.lock()
	if !unload_queue.has(target_argument):
		unload_queue[target_argument] = {
			"metadata": {
				"status": "pending",
				"tries": 0,
				"last_attempt": Time.get_ticks_msec()
			}
		}
	else:
		unload_queue[target_argument]["metadata"]["tries"] += 1
		unload_queue[target_argument]["metadata"]["last_attempt"] = Time.get_ticks_msec()
	unload_queue_mutex.unlock()
	
	# Update tree state for unloading
	the_current_state_of_tree(the_shorter_set, type_of_state)
	
	# Trigger recheck
	mutex_for_trickery.lock()
	menace_tricker_checker = 1
	mutex_for_trickery.unlock()
	
	# Monitor unload progress
	if unload_queue[target_argument]["metadata"]["tries"] > 3:
		# Log potential stuck unload
		dictionary_of_mistakes_mutex.lock()
		if !dictionary_of_mistakes.has(target_argument):
			dictionary_of_mistakes[target_argument] = {
				"status": "stuck_unload",
				"counter": int(1),
				"last_attempt": Time.get_ticks_msec()
			}
		dictionary_of_mistakes_mutex.unlock()

	#if method_task == "three_stages_of_creation":
		#var target_argument = task.target_argument
		#var type_of_state : int = 1
		#print(" taskkk three stages of creation  : " , target_argument , " amd " , method_task)
		#the_current_state_of_tree(target_argument, type_of_state)
		#
		#print(" menace checker after task done ? hmm ")
		#mutex_for_trickery.lock()
		#menace_tricker_checker = 1
		#mutex_for_trickery.unlock()
		#print(" menace checker after task done ? hmm  2")
	#
	#if method_task == "unload_container":
		#var target_argument = task.target_argument
		#var type_of_state : int = -1
		#var the_shorter_set = target_argument.substr(0, str(target_argument).length() - 10)
		#print(" taskkk unload container : " , target_argument, " method_task " , method_task)
		#the_current_state_of_tree(the_shorter_set, type_of_state)
		
		#unload_queue_mutex.lock()
		#
		#if !unload_queue.has(target_argument):
			#print(" it is freshly added for unloading")
			#var int_for_counting_tries : int = 0
			#unload_queue[target_argument] = {
				#"status" = "pending",
				#"tries" = int_for_counting_tries
			#}
		#else:
			#unload_queue[target_argument]["tries"] +=1
		#
		#unload_queue_mutex.unlock()
		
		
		
	mutex_singular_l_u.unlock()
	# the stuff, that could interrupt, is making the tree, pending
	
	# three_stages_of_creation , not really, we could hit limit of active sets, already unloaded?
	
	# next one kinda the same
	
	# initialize_menu
	
	
	

	# this means, that we have a set to pull out on the scene
	
	# second_impact_for_real
	
	# the same as above
	
	# third_impact_right_now
	
	# fourth_impact_right_now
	
	# fifth_impact_right_now
	
	# this means, that we updated scene tree
	
	# the_finisher_for_nodes
	
	# task_to_send_data_to_datapoint
	
	

	
	
	
	
	# the ones that unload stuff ?



# the set first contact with existnce

func the_current_state_of_tree(set_name_now, the_state):
	
	mutex_for_container_state.lock()
	if current_containers_state.has(set_name_now):
		current_containers_state[set_name_now]["status"] = the_state
		print("taskkkkl it has it already ", set_name_now, " its status : " , the_state)
	else:
		print("taskkkkl does not have ", set_name_now, " its status : " , the_state)
		current_containers_state[set_name_now] = {
			"status" = the_state
		}
	mutex_for_container_state.unlock()



	if the_state == 1:
		print(" to be loaded ")
		
		load_queue_mutex.lock()
		
		if load_queue.has(set_name_now):
			
			print(" we had it before, to be loaded : ", set_name_now)
		else:
			load_queue[set_name_now] = {}
			print(" we have not loaded it before : ", set_name_now)
		
		load_queue_mutex.unlock()
		



	if the_state == -1:
		print(" to be unloaded ")
		
		unload_queue_mutex.lock()
		
		if unload_queue.has(set_name_now):
			print(" we had it before, to be unloaded : ", set_name_now)
		else:
			unload_queue[set_name_now] = {}
			print(" we have not unloaded it before")
		
		unload_queue_mutex.unlock()
		















# containers



func check_if_first_time(set_name_first, the_current_of_energy):
	
	#mutex_for_container_state.lock()
	
	#if current_containers_state[set_name_first].has("three_i"):
		#var three_ii = current_containers_state[set_name_first]["three_i"]
		#print(" three_ii : ", three_ii)
	
	#mutex_for_container_state.unlock()
	
	mutex_containers.lock()
	
	print(" set_name_first  : " , set_name_first , " the_current_of_energy ", the_current_of_energy , " list_of_containers " , list_of_containers)
	
	if list_of_containers.has(set_name_first):
		print(" it have it already")
	else:
		list_of_containers[set_name_first] = {}
		list_of_containers[set_name_first]["status"] = the_current_of_energy
	
	list_of_containers
	
	mutex_containers.unlock()

# check every container found in a set list


func connect_containers(container_name_0, container_name_1):
	print(" two containers to connect " , container_name_0 , " and : " , container_name_0)

	var container_data_0
	var container_data_1

	mutex_containers.lock()
	
	
	if list_of_containers.has(container_name_0):
		# it has that container
		if list_of_containers[container_name_0].has("connected_containers"):
			
			
			
			container_data_0 = list_of_containers[container_name_0]
		else:
			# it needs connected containers, connection
			list_of_containers[container_name_0]["connected_containers"] = {}
			list_of_containers[container_name_0]["connected_containers"][container_name_1] = {}
		
	if list_of_containers.has(container_name_1):
		
		if list_of_containers[container_name_1].has("connected_containers"):
			
			
			
			container_data_1 = list_of_containers[container_name_1]
		else:
			list_of_containers[container_name_1]["connected_containers"] = {}
			list_of_containers[container_name_1]["connected_containers"][container_name_0] = {}
	
	
	
	mutex_containers.unlock()












func containers_list_creator():
	# check if we have any containers
	mutex_for_container_state.lock()
	
	if current_containers_state.size() > 0:
		print(" fatal kurwa error : ", current_containers_state)
		print("checkerrr bigger list than 0 ")
		# lets add also there, new status, of what be done before
		
		# later if it is already in active state, and its own status, is the same, we dont need to check
		
		
		
		for data_sets_to_check in current_containers_state: 
			#print(" alkaida is calling fbi xd  :  ", data_sets_to_check , ", " , current_containers_state[data_sets_to_check]["status"], " but also we got three ints lol ", current_containers_state[data_sets_to_check]["three_i"])
			
			
			var three_iii : Vector3i
			var current_state_0 : int = -1
			var current_state_1 : int = -1
			var current_state_2 : int = -1
			three_iii.x = current_state_0
			three_iii.y = current_state_1
			three_iii.z = current_state_2
			
			var new_information_0 = null
			
			
			
			print(" first we check basics")
			
			var three_ii
			if current_containers_state[data_sets_to_check].has("three_i"):
				three_ii = current_containers_state[data_sets_to_check]["three_i"]
				three_iii.x = 0
			else:
				three_ii = null
				three_iii.x = -2
			
			
			
			var current_status
			if current_containers_state[data_sets_to_check].has("status"):
				print(" allah akbar, three_ii ", three_ii, current_containers_state[data_sets_to_check]["status"])
				current_status = current_containers_state[data_sets_to_check]["status"]
				three_iii.x = 1
			else:
				current_status = null
				three_iii.x = -2
				
			# container of set information exist :
			
			var current_container_to_check
			if current_containers_state[data_sets_to_check].has("container_name"):
				current_container_to_check = current_containers_state[data_sets_to_check]["container_name"]
				three_iii.x = 2
				
			else:
				current_container_to_check = null
				three_iii.x = -2
				
				
			# check if tree has that container
			if current_container_to_check != null:
				if current_status != null:
					check_if_first_time(current_container_to_check, current_status)
					three_iii.x = -3
					
			
			
			print(" fatal kurwa error 0 : ", current_container_to_check , ", 1 : " , current_status , ", 2 : " , three_ii)
			if current_container_to_check == null:
				if current_status == null:
					if three_ii == null:
						print(" FATAL KURWA ERROR WE MUST DO SOMETHING")
						three_iii.x -4
			
			mutex_containers.lock()
			#
			if list_of_containers.has(current_container_to_check):
				print("three_ii tree check 011 normal human first check, if it is, not if it isnt ")
				three_iii.y = 0
				# so that container exist, so we can check more things
				
				# if status exist there? we can check if it is to load, or to unload
				
				
				if list_of_containers[current_container_to_check].has("status"):
					print(" three_ii tree check 013 status? : ", list_of_containers[current_container_to_check]["status"])
					three_iii.y = 1
					
				
				
				# we can check previous three_i check
				
				
				if list_of_containers[current_container_to_check].has("three_i"):
					print(" three_ii tree check 014 ")
					list_of_containers[current_container_to_check]["three_i"] = three_iii
					three_iii.y = 2
				else:
					print(" three_ii tree check 015 we dont have it there, yet, lets add something to it")
					list_of_containers[current_container_to_check]["three_i"] = three_iii
					
					
			else:
				print("three_ii tree check 0112 three_ii what i maybe trully need more?")
				#check_if_first_time()
				three_iii.y = -2
			#
			#
			mutex_containers.unlock()
			
			
			tree_mutex.lock()
			

			
			if scene_tree_jsh.has("main_root"):
				print(" three_ii tree check 00 ")
				three_iii.z = 0
				
				if scene_tree_jsh["main_root"].has("branches"):
					print(" three_ii tree check 01")
					if scene_tree_jsh["main_root"]["branches"].has(current_container_to_check):
						three_iii.z = 1
						
						print(" three_ii tree check 02")
					else:
						print(" three_ii tree check 00, we didnt find that container in tree, maybe it will appear, lets add new list of add to queue")
						new_information_0 = container_finder(data_sets_to_check)
						three_iii.z = -2
						print(" new_information_0  : " , new_information_0, " and previous info : " , current_container_to_check)
						if current_container_to_check != new_information_0:
							print(" new_information_0 they are not the same how lol ")
							
							check_if_first_time(new_information_0, current_status)
							three_iii.z = -3
							
							

						# maybe record name and container names are different
						
						# lets recheck container name? by base name
						
			
			tree_mutex.unlock()
			
			mutex_containers.lock()
			
			

			
			#
			for container_to_check in list_of_containers:
				print(" three_ii :" , container_to_check)
				print()
				print(list_of_containers[container_to_check])
				print()
				if new_information_0 != null:
					if list_of_containers[container_to_check].has("connected_containers"):
						# IF NOT HAVE THAT CONTAINER CONNECTED TO THAT CONTAINER, CONNECT THEM
						if !list_of_containers[container_to_check]["connected_containers"].has(new_information_0):
							connect_containers(container_to_check, new_information_0)
					# IF IT DOES NOT HAVE ANY CONNECTED CONTAINERS AT ALL 
					else:
						connect_containers(current_container_to_check, new_information_0)
				
				
			
			mutex_containers.unlock()
			
			
			print(" three_ii ",scene_tree_jsh)
			print(" what we even wanted with these three ? three_ii : " , three_ii , " , ", current_status , " , " , current_container_to_check)
			
			# container name can be broken, unfortunately
			
				#mutex_containers.lock()
				#
				#
				#
				## if it is new container
				#
				#
				#
				#if !list_of_containers.has(current_container_to_check):
					##print(" fatal kurwa error : 0 ", list_of_containers[current_container_to_check])
					#list_of_containers[current_container_to_check] = {
						#"record_sets" = {},
						#"status" = current_containers_state[data_sets_to_check]["status"],
						#"datapoint_node" = "",
						#
					#}
					##print(" allah akbar, yes ", current_container_to_check)
					#print(" fatal kurwa error : 0 ", list_of_containers[current_container_to_check])
					##list_of_containers[current_container_to_check]["record_sets"].append(current_containers_state[data_sets_to_check]["three_i"])
					#
					#if !list_of_containers[current_container_to_check]["record_sets"].has(data_sets_to_check):
						##print(" allah akbar, 0 it new set to add, to that container sets list ", data_sets_to_check , " in container : " , current_container_to_check)
						#
						## checks if that container has currently checked record set
						#
						## creates entry of that record set in container list
						#list_of_containers[current_container_to_check]["record_sets"][data_sets_to_check] = current_containers_state[data_sets_to_check]["three_i"]
						#list_of_containers[current_container_to_check]["status"] = current_containers_state[data_sets_to_check]["status"]
					##else:
					##	print(" allah akbar,  0 it is new set to add?")
					#
					#
				#else:
					#print(" fatal kurwa error : 1 ", list_of_containers[current_container_to_check])
					#
					## maybe here i check again if sometihing updated?
				#
				#
				#
				#
				#
					## that container exist already, lets update its current status? if it has container ?
				#
				#
				#
				#
				#
				#
					#if !list_of_containers[current_container_to_check]["record_sets"].has(data_sets_to_check):
						#print(" allah akbar,  1 it new set to add, to that container sets list ", data_sets_to_check , " in container : " , current_container_to_check)
						#
						#
						#
						## container to add
						#list_of_containers[current_container_to_check]["record_sets"][data_sets_to_check] = current_containers_state[data_sets_to_check]["three_i"]
						#list_of_containers[current_container_to_check]["status"] = current_containers_state[data_sets_to_check]["status"]
					#else:
						#print(" allah akbar, it was like that at creation? : " , list_of_containers[current_container_to_check]["record_sets"][data_sets_to_check])
						#print(" allah akbar,  1 lets update it ", current_containers_state[data_sets_to_check]["three_i"])
						#
						#
						## update container status
						#list_of_containers[current_container_to_check]["record_sets"][data_sets_to_check] = current_containers_state[data_sets_to_check]["three_i"]
						#list_of_containers[current_container_to_check]["status"] = current_containers_state[data_sets_to_check]["status"]
					#
					#
					#
				#mutex_containers.unlock()
			#
			#else:
				#print(" allah akbar, something went wrong ")
				#
				#
			#
			#
			

			
			# here we can check if the scene tree is created?
			
			
			
			if current_containers_state[data_sets_to_check]["status"] == 1:
				print(" taskkkkl should load = 1 ")
				if three_ii.x == -1:
					print(" allah akbar, run again? 0 ")
					
					
					mutex_for_trickery.lock()
					menace_tricker_checker = 1
					mutex_for_trickery.unlock()
					
					#containers_states_checker()
				else:
					print(" it has container? ")
					
					
				if three_ii.y == -1:
					print(" allah akbar, run again? 1 ")
					
					mutex_for_trickery.lock()
					menace_tricker_checker = 1
					mutex_for_trickery.unlock()
					
					
				if three_ii.z == -1:
					print(" allah akbar, run again 2")
					#containers_states_checker()
					mutex_for_trickery.lock()
					menace_tricker_checker = 1
					mutex_for_trickery.unlock()
					
				if three_ii.z == 0:
					# hmm it meant it has anything, and it was container node too?
					print(" allah akbar, run again 3")
					#containers_states_checker()
					mutex_for_trickery.lock()
					menace_tricker_checker = 1
					mutex_for_trickery.unlock()
					
				if three_ii.z == 1:
					# hmm, that meant we have also datapoint node
					print(" allah akbar, run again 4")
					#containers_states_checker()
					mutex_for_trickery.lock()
					menace_tricker_checker = 1
					mutex_for_trickery.unlock()
					
					
				if three_ii.z == 2:
					continue
					# and this one means we also send the dictionary of things here too
					#print(" we can get container and datapoint node " , current_containers_state[data_sets_to_check]["status"])
					# current_container_to_check
					#if current_containers_state[data_sets_to_check]["status"] == 1:
					## current datapoint to check
						#if !scene_tree_jsh["main_root"]["branches"].has(current_container_to_check):
							#print(" it is error")
							#mutex_for_trickery.lock()
							#menace_tricker_checker = 1
							#mutex_for_trickery.unlock()
							#current_containers_state[data_sets_to_check]["status"] = -2 # probably to be unloaded
							#
						#if current_containers_state[data_sets_to_check].has("three_i"):
							#var three_i_update = current_containers_state[data_sets_to_check]["three_i"]
							#three_i_update.x = -1
							#three_i_update.y = -1
							#three_i_update.z = -1
							#
							#
							#return
					#
						#var current_datapoint_path_for_node = scene_tree_jsh["main_root"]["branches"][current_container_to_check]["datapoint"]["datapoint_path"]
						#var current_datapoint_node_now = get_node_or_null(current_datapoint_path_for_node)
						#if current_datapoint_node_now:
							#scene_tree_jsh["main_root"]["branches"][current_container_to_check]["datapoint"]["node"] = current_datapoint_node_now
							#
						#
						#mutex_containers.lock()
						#
						#if list_of_containers.has(current_container_to_check):
							#print(" we have that container, in container list, lets check if it has container)node")
							#if !list_of_containers[current_container_to_check].has("container_node"):
								#list_of_containers[current_container_to_check]["container_node"] = scene_tree_jsh["main_root"]["branches"][current_container_to_check]["node"]
								#print("it has that")
							#if !list_of_containers[current_container_to_check].has("datapoint_node"):
								#list_of_containers[current_container_to_check]["datapoint_node"] = scene_tree_jsh["main_root"]["branches"][current_container_to_check]["datapoint"]["node"]
								#
						#mutex_containers.unlock()
			else:
				print(" taskkkkl means unload ?")
				var three_i_update = current_containers_state[data_sets_to_check]["three_i"]
				three_i_update.x = -1
				three_i_update.y = -1
				three_i_update.z = -1
				
					
				
	print(" allah akbar, end : list_of_containers ", list_of_containers)
	mutex_for_container_state.unlock()


















# check every set in list


# records sets lists

func containers_states_checker():
	print()
	
	
	# check if we have any containers
	mutex_for_container_state.lock()
	if current_containers_state.size() > 0:
		print("checkerrr bigger list than 0 ")
		# lets add also there, new status, of what be done before
		
		# later if it is already in active state, and its own status, is the same, we dont need to check
		
		for data_sets_to_check in current_containers_state:
			print(" alkaida is calling fbi xd :  ", data_sets_to_check , ", " , current_containers_state[data_sets_to_check]["status"])
			#print(" its own status : ",current_containers_state[data_sets_to_check]["status"])
			
			var state_of_check_0 : int = -1
			var state_of_check_1 : int = -1
			var state_of_check_2 : int = -1
			
			var vector_now : Vector3i
			
			vector_now.x = state_of_check_0
			vector_now.y = state_of_check_1
			vector_now.z = state_of_check_2
			
			if !current_containers_state[data_sets_to_check].has("status_tree"):
				current_containers_state[data_sets_to_check]["status_tree"] = "pending"
				current_containers_state[data_sets_to_check]["three_i"] = vector_now
				
			if current_containers_state[data_sets_to_check]["status"] == -1:
				print(" we must reset the xyz thingy")
				current_containers_state[data_sets_to_check]["three_i"] = vector_now
			#var state_of_check_0 : int = -1
			#var state_of_check_1 : int = -1
			#var state_of_check_2 : int = -1
			var set_name_plus = data_sets_to_check + "_"
			var container_name_from_data_set : String = ""
			var datapoint_node_now : Node
			var container_node_now : Node
			var data_array_now : Array = []
			var dictionary_size_now : int
			# first check if it exist in active record sets
			active_r_s_mut.lock()
			if active_record_sets.has(set_name_plus):
				#print("checkerrr 0 active records set has it")
				var plus_records = set_name_plus + "records"
				
				current_containers_state[data_sets_to_check]["status_tree"] = "started_0"
				
				if active_record_sets[set_name_plus].has(plus_records):
					#print(" we got records in it ", active_record_sets[set_name_plus][plus_records]["content"][0][0][3][0])
					
					# we got active records set in that name
					current_containers_state[data_sets_to_check]["status_tree"] = "started_1"
					
					if active_record_sets[set_name_plus][plus_records].has("content"):
					
						if active_record_sets[set_name_plus][plus_records]["content"] is Array:
							print(" hmm " , active_record_sets[set_name_plus][plus_records]["content"])
							
							if active_record_sets[set_name_plus][plus_records]["content"] != []:
							
								if active_record_sets[set_name_plus][plus_records]["content"][0][0][3][0] is String:
									if active_record_sets[set_name_plus][plus_records]["content"][0][0][3][0] != "container":
										#print(" it is not container ", active_record_sets[set_name_plus][plus_records]["content"][0][0][5][0])
										container_name_from_data_set = active_record_sets[set_name_plus][plus_records]["content"][0][0][5][0]
										
										current_containers_state[data_sets_to_check]["status_tree"] = "started_2"
										
									else:
										#print(" it is container " , active_record_sets[set_name_plus][plus_records]["content"][0][0][6][0])
										container_name_from_data_set = active_record_sets[set_name_plus][plus_records]["content"][0][0][6][0]
										
										current_containers_state[data_sets_to_check]["status_tree"] = "started_3"
								else:
									print(" FATAL KURWA ERROR, 1")
							else:
								print(" FATAL KURWA ERROR, 2",  active_record_sets[set_name_plus][plus_records]["content"])
						else:
							print(" FATAL KURWA ERROR, 3")
						
					else:
						print(" FATAL KURWA ERROR, VERY IMPORTANT, DUNNO WHY IT HAPPENED, OH MY ")
					#else:
						#print(" FATAL KURWA ERROR, 1")
				else:
					print(" FATAL KURWA ERROR, 0")
				
				
				state_of_check_0 = 1
				current_containers_state[data_sets_to_check]["three_i"].x = state_of_check_0
				
				active_r_s_mut.unlock()
			else:
				active_r_s_mut.unlock()
				#print("checkerrr 0 active records set DONT it")
				# if it should be not active, check if it has its cached version
				cached_r_s_mutex.lock()
				if cached_record_sets.has(set_name_plus):
					#print("checkerrr 0  cached has it ")
					var plus_records = set_name_plus + "records"
					
					current_containers_state[data_sets_to_check]["status_tree"] = "cached_0"
					
					if cached_record_sets[set_name_plus].has(plus_records):
						#print(" we got records in it ", cached_record_sets[set_name_plus][plus_records]["content"][0][0][3][0])
						
						current_containers_state[data_sets_to_check]["status_tree"] = "cached_1"
						
						if cached_record_sets[set_name_plus][plus_records]["content"][0][0][3][0] != "container":
							#print(" it is not container ", cached_record_sets[set_name_plus][plus_records]["content"][0][0][5][0])
							container_name_from_data_set = cached_record_sets[set_name_plus][plus_records]["content"][0][0][5][0]
							
							current_containers_state[data_sets_to_check]["status_tree"] = "cached_2"
							
						else:
							#print(" it is container " , cached_record_sets[set_name_plus][plus_records]["content"][0][0][6][0])
							container_name_from_data_set = cached_record_sets[set_name_plus][plus_records]["content"][0][0][6][0]
							
							current_containers_state[data_sets_to_check]["status_tree"] = "cached_3"
							
					state_of_check_0 = 0
					current_containers_state[data_sets_to_check]["three_i"].x = state_of_check_0
					
					
					cached_r_s_mutex.unlock()
				else:
					#print("checkerrr 0  cached DONT have it")
					cached_r_s_mutex.unlock()
			# now we have state of set having data of creation : 
			# state_of_check_0
			# 1 = active
			# 0 = cached
			if state_of_check_0 != -1:
				#print(" checkerrr 1 we can probably check more things")
				var container_name
				if container_name_from_data_set != "":
					#print(" checkerrr we have container name ")
					container_name = container_name_from_data_set
				else:
					container_name = data_sets_to_check + "_container"
					# then check if it has entry in tree
				current_containers_state[data_sets_to_check]["container_name"] = container_name
				
				
					# check if the cached tree has entry
				tree_mutex.lock()
				if scene_tree_jsh.has("main_root"):
					if scene_tree_jsh["main_root"]["branches"].has(container_name):
						#print(" checkerrr 2 it has that thingy")
						
						current_containers_state[data_sets_to_check]["status_tree"] = "started_4"
						
						if scene_tree_jsh["main_root"]["branches"][container_name].has("node"):
							print(" it has node, do we unload there ? nah it can go both ways")
							if is_instance_valid(scene_tree_jsh["main_root"]["branches"][container_name]["node"]):
								container_node_now = scene_tree_jsh["main_root"]["branches"][container_name]["node"]
							else:
								container_node_now = null
						else:
							container_node_now = null
							state_of_check_2 = -1
						
						
						
						if container_node_now:
							state_of_check_2 = 0
							current_containers_state[data_sets_to_check]["three_i"].z = state_of_check_2
							var container_name_for_trick = scene_tree_jsh["main_root"]["branches"][container_name]["name"]
							
							
							
							
							# we got container node first time for 
							
							
							#mutex_containers.lock()
							#
							#if !list_of_containers.has(container_name_for_trick):
								#print("maybe not 0 we dont have that container yet in our list?", container_name_for_trick)
							#else:
								#print("maybe not 0 we already kinda have that container in list", container_name_for_trick)
							#
							#mutex_containers.unlock()
							


							# if we dont have container thingy rn, we must try again
							#mutex_for_trickery.lock()
							#menace_tricker_checker = 1
							#mutex_for_trickery.unlock()


							
							
							current_containers_state[data_sets_to_check]["status_tree"] = "started_5"
							
							#print(" container node found : " , container_node_now)
							var datapoint_path_now = scene_tree_jsh["main_root"]["branches"][container_name]["datapoint"]["datapoint_path"]
							datapoint_node_now = get_node(datapoint_path_now)
							if datapoint_node_now:
								
								
								# we got datapoint node for containers status first time?
								
								
								
								current_containers_state[data_sets_to_check]["status_tree"] = "started_6"
								
								#print(" datapoint node found = ", datapoint_node_now)
								state_of_check_2 = 1
								current_containers_state[data_sets_to_check]["three_i"].z = state_of_check_2
								if datapoint_node_now.has_method("check_state_of_dictionary_and_three_ints_of_doom"):
									var data_array_now_ = datapoint_node_now.check_state_of_dictionary_and_three_ints_of_doom()
									
									
									
									
									
									
									
									current_containers_state[data_sets_to_check]["status_tree"] = "started_7"
									
									if data_array_now_ != null:
										data_array_now = data_array_now_
										#print("  kkkdexd it is not null " , data_array_now[0]["metadata"])
										if data_array_now[0] is Dictionary:
											#print(" kkkdexd  it is dictionary")
											
											current_containers_state[data_sets_to_check]["status_tree"] = "started_8"
											state_of_check_2 = 2
											current_containers_state[data_sets_to_check]["three_i"].z = state_of_check_2
											
									#	else:
									#		print("  kkkdexd  it isnt dictionary ")
									#else:
									#	print(" kkkdexd it is null ???")
									#data_array_now.append(data_array_now_)
									# [0] = the dictionary
									# [1] = three ints in vec3i xyz ?
									#if data_array_now[0].has("metadata"):
									#	print(" the data array [0] has metadata")
						state_of_check_1 = 1
						current_containers_state[data_sets_to_check]["three_i"].y = state_of_check_1
						
	# check if container node is there
	
	# check if datapoint node is there
	
	# there should be datapoint and container
	
	# var datapoint_node_now : Node
	
	# container_node_now : Node
	
						tree_mutex.unlock()
					else:
						#print(" checkerrr 2 we didnt find the tree branch " , container_name)
						tree_mutex.unlock()
						# didnt find it on main tree, lets check cached tree
						
						
						cached_tree_mutex.lock()
						if cached_jsh_tree_branches.has(container_name):
							#print(" checkerrr 2 we found it on cached ")
							
							
							current_containers_state[data_sets_to_check]["status_tree"] = "cached_4"
							
							state_of_check_1 = 0
							current_containers_state[data_sets_to_check]["three_i"].y = state_of_check_1
							
							cached_tree_mutex.unlock()
						#else:
							#print()
							
							
							
							
							
							
	# check if container node is there
	
	# check if datapoint node is there
	
	# it should be null
						else:
							#print(" checkerrr 2 cached does not have it ")
							
							mutex_for_trickery.lock()
							menace_tricker_checker = 1
							mutex_for_trickery.unlock()
							
							
							cached_tree_mutex.unlock()
							
						
				else:
					#print(" checkerrr 2 the tree does not have main_root")
					
					current_containers_state[data_sets_to_check]["status_tree"] = "fatal_kurwa_error"
					
					tree_mutex.unlock()
			if state_of_check_1 != -1:
				#print(" checkerrr 3 we can again continue")
				if state_of_check_2 != -1:
					print(" we even got nodes to tinker with")
			print(" alkaida is calling fbi xd :  ", data_sets_to_check , ", " , current_containers_state[data_sets_to_check]["three_i"])
	mutex_for_container_state.unlock()
	
	mutex_for_trickery.lock()
	if menace_tricker_checker == 2:
		print(" check is finished and we didnt get interupted while doing so kurwa ")
		menace_tricker_checker = 3
	mutex_for_trickery.unlock()
	

	
	
	
	# check if container node is there
	
	# check if datapoint node is there
	
	
	
	# check datapoint dictionary of things with metadata
	
	# if we dont have it here, lets try to find it in datapoint
	
	# if the datapoint node is there
	
	# lets also check three ints of truth
	
	# probably the mutexes are needed for that in datapoint
	
	# check_state_of_dictionary_and_three_ints_of_doom()
	# return dictionary, vec3i(0, 0, 0)

#
# JSH Ethereal Engine THE ETHERIC DOWNLOAD SYSTEM
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┓     •   ┳┓       ┓     ┓   ┏┓         
#       888  `"Y8888o.   888ooooo888     ┣ ╋┏┓┏┓┓┏  ┃┃┏┓┓┏┏┏┓┃┏┓┏┓┏┫┏  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┗┛┗┗ ┛ ┗┗  ┻┛┗┛┗┻┛┛┗┗┗┛┗┻┗┻┛  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                                      ┛     
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Etheric Download System
#

# var download_received : Dictionary = {}
# var upload_to_send : Dictionary = {}

#func downloads_of_information():
	#print
	# here we receive downloads from containers and datapoints
	# we create keys for the didctionary, with name to where to send it, and what to send there

#func upload_data():
	#print
	# here we will be sending data to specific nodes, containers, datapoints
	# we could add some kind of counter, of how many times we tried to send something, and cache that message? then we can try to send that message again, less often, and check if that node exist,
	# also that cached message can have metadata and time? like if a player died, and cannot receive a message, we delete that message and informations about that player too, to save ram
	# as messengers of god, shall also have fun, instead of running boring quests, we can hit the dungeons and build mechas with our minds


#
# JSH Ethereal Engine THE ETHERIC QUEUE
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┓     •   ┏┓        
#       888  `"Y8888o.   888ooooo888     ┣ ╋┏┓┏┓┓┏  ┃┃┓┏┏┓┓┏┏┓
#       888      `"Y88b  888     888     ┗┛┗┗ ┛ ┗┗  ┗┻┗┻┗ ┗┻┗ 
#       888 oo     .d8P  888     888         
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Etheric Queue
#

func three_stages_of_creation(data_set_name):
	
	print(" delta message start 00")
	array_mutex_process.lock()
	for current_sets_to_create in list_of_sets_to_create:
		if current_sets_to_create[0] == data_set_name:
			array_mutex_process.unlock()
			return
	array_mutex_process.unlock()
	print(" delta message start 01")
	var current_stage_of_creation : int = 0
	var first_stage_bool : int = 0
	var second_stage_bool : int = 0
	var third_stage_bool : int = 0
	var fourth_stage_bool : int = 0
	var fifth_stage_bool : int = 0
	var sixth_stage_bool : int = 0
	var seventh_stage_bool : int = 0
	var eight_stage_bool : int = 0
	var nineth_stage_bool : int = 0
	
	array_mutex_process.lock()
	print(" delta message start 02")
	#print(" delta message start we start three stage sof creation inside some mutex lock ")
	
	list_of_sets_to_create.append([data_set_name, current_stage_of_creation, first_stage_bool, second_stage_bool, third_stage_bool, fourth_stage_bool, fifth_stage_bool, sixth_stage_bool, seventh_stage_bool, eight_stage_bool, nineth_stage_bool])
	array_mutex_process.unlock()
	print(" delta message start 03")






func check_currently_being_created_sets():
	print(" delta message start hmm we check if we can push further  ")
	print(" we check em again, are they stuck?")

	array_mutex_process.lock()
	mutex_for_container_state.lock()

	for set_to_create in list_of_sets_to_create:
		print(" we have that for example : ", set_to_create)
		print(" it can even be seen as [0] ", set_to_create[0])
		var name_of_set = set_to_create[0]
		var counter_now : int = -1
		
		var dumb_counter_0 : int = 0
		var dumb_counter_1 : int = 0
		
		
		if current_containers_state.has(name_of_set):
			print(" it has something 0 ", counter_now)
			counter_now = 0

		if current_containers_state.has(name_of_set + "_"):
			print(" it has something 1")
			if counter_now == -1:
				name_of_set = name_of_set + "_"
				counter_now = -2
		
		# is it atelaset container, not containter or whatever i tried to write
		if current_containers_state.has(name_of_set + "container"):
			print(" it has something 2")
			if counter_now == -2:
				name_of_set = name_of_set + "container"
				
				
		
		for singular_info in set_to_create:
			if singular_info is int:
				print(" singular_info ", singular_info)
				if dumb_counter_0 == 0:
					dumb_counter_0 +=1
				else:
					dumb_counter_0 +=1
					if singular_info != 0:
						dumb_counter_1 +=1
		
		
		
		print(" checky chicky : " , name_of_set , " and that counter : " , counter_now , " , " , dumb_counter_0 , " , " , dumb_counter_1)
		

		load_queue_mutex.lock()

		if load_queue.has(name_of_set):
			print(" we have it already in load queue")
			if load_queue[name_of_set].has("metadata"):
				print(" it already had it ")
			else:
				load_queue[name_of_set]["metadata"] = {}
				#load_queue[name_of_set]["metadata"]["status"]
		
		if dumb_counter_1 >= 1:
			print(" we are somewhere, here something started the creation ")
			load_queue[name_of_set]["metadata"]["status"] = int(1)
		else:
			print(" that thing have not started its creation ")
			load_queue[name_of_set]["metadata"]["status"] = int(0)

		print(" cheecku chicku : load_queue : " , load_queue)
		load_queue_mutex.unlock()

	array_mutex_process.unlock()
	mutex_for_container_state.unlock()





func process_stages():
	
	array_mutex_process.lock()
	
	for sets_to_create in list_of_sets_to_create:
		var dataset = sets_to_create[0]
		var dataset_name = sets_to_create[0]
		var current_stage = sets_to_create[1]
		match current_stage:
			0:
				if sets_to_create[1] == 0 and curent_queue[0][0] == 0 and sets_to_create[2] == 0:
					curent_queue[0][0] += 1
					sets_to_create[2] += 1
					print(" creation 00 ", dataset_name)
					first_stage_of_creation_(dataset_name, sets_to_create)
			1:
				if sets_to_create[1] == 1 and curent_queue[1][0] == 0 and sets_to_create[3] == 0:
					sets_to_create[3] += 1
					curent_queue[0][0] -= 1
					curent_queue[1][0] += 1
					print(" creation 01 ", dataset_name)
					second_stage_of_creation_(dataset_name, sets_to_create)
			2:
				if sets_to_create[1] == 2 and curent_queue[2][0] == 0 and sets_to_create[4] == 0:
					curent_queue[1][0] -= 1 
					curent_queue[2][0] += 1
					sets_to_create[4] += 1
					print(" creation 02 ", dataset_name)
					third_stage_of_creation_(dataset_name, sets_to_create)
			3:
				if sets_to_create[1] == 3 and curent_queue[3][0] == 0 and sets_to_create[5] == 0:
					sets_to_create[5] += 1
					curent_queue[2][0] -= 1
					curent_queue[3][0] += 1
					fourth_impact_of_creation_(dataset_name, sets_to_create)
			4:
				if sets_to_create[1] == 4 and curent_queue[4][0] == 0 and sets_to_create[6] == 0:
					sets_to_create[6] += 1
					curent_queue[3][0] -= 1
					curent_queue[4][0] += 1
					fifth_impact_of_creation_(dataset_name, sets_to_create)
			5:
				if sets_to_create[1] == 5 and curent_queue[5][0] == 0 and sets_to_create[7] == 0:
					sets_to_create[7] += 1
					curent_queue[4][0] -= 1
					list_of_sets_to_create.erase(sets_to_create)
					if list_of_sets_to_create.size() == 0:
						curent_queue = [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]] 
			6:
				curent_queue[4][0] -= 1
				
				list_of_sets_to_create.erase(sets_to_create)
				
				if list_of_sets_to_create.size() == 0:
					curent_queue = [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]] 
			7:
				curent_queue[4][0] -= 1
				list_of_sets_to_create.erase(sets_to_create)
				if list_of_sets_to_create.size() == 0:
					curent_queue = [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]] 
					the_menace_checker = 0
	array_mutex_process.unlock()


# here we made a task, so we first get the data, into several vars, not just one array
func the_finisher_for_nodes(data_to_be_parsed):
	var path_of_node_jsh = data_to_be_parsed[0][0]
	var node_name_jsh_checker = data_to_be_parsed[0][1]
	var node_to_be_checker = data_to_be_parsed[0][2]
	jsh_tree_get_node_status_changer(path_of_node_jsh, node_name_jsh_checker, node_to_be_checker)

# and here we process that data
func jsh_tree_get_node_status_changer(node_path_jsh_tree_status: String, node_name: String, node_to_check: Node):
	var path_parts_jsh_status_node = node_path_jsh_tree_status.split("/")
	
	tree_mutex.lock()
	var current = scene_tree_jsh["main_root"]["branches"]
	tree_mutex.unlock()
	
	var name_of_container = path_parts_jsh_status_node[0]
	var name_of_current_thing = path_parts_jsh_status_node[path_parts_jsh_status_node.size() - 1]
	
	tree_mutex.lock()
	array_counting_mutex.lock()
	
	for part in path_parts_jsh_status_node:
		if current.has(part):
			current = current[part]
			if path_parts_jsh_status_node[-1] == part:
				if node_to_check:
					current["status"] = "active"
					current["node"] = node_to_check
					
					if array_for_counting_finish.has(name_of_container):
						if array_for_counting_finish[name_of_container].has(name_of_current_thing):
							array_for_counting_finish[name_of_container][name_of_current_thing]["node"] = node_to_check
						array_for_counting_finish[path_parts_jsh_status_node[0]]["metadata"]["counter_after"] +=1
						if array_for_counting_finish[name_of_container]["metadata"]["datapoint_name"] == name_of_current_thing:
							array_for_counting_finish[name_of_container]["metadata"]["datapoint_node"] = node_to_check
						if array_for_counting_finish[name_of_container]["metadata"]["container_path"] == name_of_current_thing:
							array_for_counting_finish[name_of_container]["metadata"]["container_node"] = node_to_check
						# here we get all the nodes, so we can send further, dictionary with all them nodes
						if array_for_counting_finish[name_of_container]["metadata"]["counter_before"] == array_for_counting_finish[name_of_container]["metadata"]["counter_after"]:
							create_new_task("newer_even_function_for_dictionary", name_of_container)
					else:
						print(" dilemafiasco i guess it could like, not find somehow that container? how ?")
				else: # here i guess, the node doest exist? which should not be possible in current sceneario, where we get it on main thread, and task is made after that?
					print(" dilemafiasco new way to check node from proces we are but we didnt get node? on if:")
			else: # we didnt find it yet, so we dig further
				current = current["children"]
		else:
			print(" dilemafiasco the new one? ")
	tree_mutex.unlock()
	array_counting_mutex.unlock()


# functions that worked, kinda, but i turned them off now, i want new, better and smarter way to check stuff
func start_timer_of_finito(data_timero):
	await get_tree().create_timer(1.0).timeout
	print(data_timero)
	var container_timero
	var the_path_of_thing
	array_counting_mutex.lock()
	if array_for_counting_finish.has(container_timero):
		print(" i guess after 1s it still has that ")
		array_counting_mutex.unlock()
	else:
		print(" it was probably send already")
		array_counting_mutex.unlock()


func recreate_missing_nodes(array_of_recreation):
	var container_name = array_of_recreation[0]
	var path_of_missing_node = array_of_recreation[1]
	var splitted_path_for_main_thingy = path_of_missing_node.split("/")
	var node_we_look_for_now : String
	var set_name_we_look_for : String
	if splitted_path_for_main_thingy.size() > 1:
		node_we_look_for_now = splitted_path_for_main_thingy[1]
		print(" that thingy is bigger than 1, so it is not container ? " , node_we_look_for_now)
	
	active_r_s_mut.lock()
	for current_activ_rec in active_record_sets:
		for current_avail_rec in active_record_sets[current_activ_rec][current_activ_rec + "records"]["header"]:
			print("current_avail_rec " , current_avail_rec)
			if node_we_look_for_now == current_avail_rec:
				print(" we found that thing " )
				if scene_tree_jsh["main_root"]["branches"].has(container_name):
					if scene_tree_jsh["main_root"]["branches"][container_name]["children"].has(node_we_look_for_now):
						print_tree_pretty()
						print(" the tree has that branch?")
						print_tree_structure(scene_tree_jsh["main_root"]["branches"][container_name]["children"][node_we_look_for_now], 0)
						disable_all_branches_reset_counters(scene_tree_jsh["main_root"]["branches"][container_name]["children"][node_we_look_for_now], container_name)
						print_tree_structure(scene_tree_jsh["main_root"]["branches"][container_name]["children"][node_we_look_for_now], 0)
						var path_for_node_to_unload = container_name + "/" + node_we_look_for_now
						array_counting_mutex.lock()
						if array_for_counting_finish[container_name].has(node_we_look_for_now):
							array_for_counting_finish[container_name][node_we_look_for_now]["node"] = []
						array_counting_mutex.unlock()
						for singular_thingies in active_record_sets[current_activ_rec][current_activ_rec + "records"]["content"]:
							print(" singular_thingies : " , singular_thingies[0][0][0])
							if singular_thingies[0][0][0] == node_we_look_for_now:
								print(" we found active records part : " , singular_thingies)
								unload_node_branch(path_for_node_to_unload, singular_thingies)
								return
				return
	active_r_s_mut.unlock()


func recreator_of_singular_thing(data_set):
	var cached_data_new = data_set.duplicate(true) 
	var thing_name
	var coords_to_place
	var direction_to_place
	var thing_type_file
	var shape_name
	var root_name
	var pathway_dna
	var group_number
	var first_line : Array = []
	var lines_parsed : Array = []
	for lines in cached_data_new:
		if lines == cached_data_new[0]:
			first_line = cached_data_new[0]
		else:
			lines_parsed.append(lines)
	thing_name = first_line[0][0]
	coords_to_place = first_line[1][0]
	direction_to_place = first_line[2][0]
	thing_type_file = first_line[3][0]
	shape_name = first_line[4][0]
	root_name = first_line[5][0]
	pathway_dna = first_line[6][0]
	group_number = first_line[7][0]
	#print(" the thingy dingy  : " , thing_name, thing_type_file, first_line, lines_parsed[0], group_number, shape_name, lines_parsed)
	analise_data(thing_name, thing_type_file, first_line, lines_parsed[0], group_number, shape_name, lines_parsed)
	first_line.clear()
	lines_parsed.clear()

func unload_node_branch(path_for_node_to_unload, recreation_of_node_data):
	var node_to_unload_now = jsh_tree_get_node(path_for_node_to_unload)
	if node_to_unload_now:
		print(" node_to_unload_now : " , node_to_unload_now)
		node_to_unload_now.queue_free()
	print_tree_pretty()
	recreator_of_singular_thing(recreation_of_node_data)

func disable_all_branches_reset_counters(branch_to_disable, container_name_for_array):
	var all_containers : Array = []
	var all_nodes : Array = []
	var branches_to_process : Array = []
	var just_container : Array = []

	var process_branch = func traverse_branch(branch: Dictionary):
		if branch["metadata"].has("full_path") and branch["metadata"]["full_path"] != null:
			
			all_containers.append(branch["name"])
			if branch["status"] == "active":
				
				array_counting_mutex.lock()
				array_for_counting_finish[container_name_for_array]["metadata"]["counter_after"] -=1
				array_counting_mutex.unlock()
				
			branch["status"] = "disabled"
		
		if branch.has("children"):
			for child_name in branch["children"]:
				branches_to_process.append(branch["children"][child_name])
				
				if branch["children"][child_name]["status"] == "active":
					
					array_counting_mutex.lock()
					array_for_counting_finish[container_name_for_array]["metadata"]["counter_after"] -=1
					array_counting_mutex.unlock()
					
				branch["children"][child_name]["status"] = "disabled"

	# Children finder
	var process_children = func traverse_branch(branch: Dictionary):
		if branch.has("metadata"):# we must complete the evaluation evolution and ovulation of this game
			all_nodes.append(branch["metadata"]["full_path"])

		if branch.has("children"):
			for child_name in branch["children"]:
				branches_to_process.append(branch["children"][child_name])
				
				if branch["children"][child_name]["status"] == "active":
					
					array_counting_mutex.lock()
					array_for_counting_finish[container_name_for_array]["metadata"]["counter_after"] -=1
					array_counting_mutex.unlock()
				
				branch["children"][child_name]["status"] = "disabled"

	process_branch.call(branch_to_disable)

	var current_branches = branches_to_process.duplicate(false)

	# Process branches until none left
	while branches_to_process.size() > 0:
		var current_branch = branches_to_process[0]  # Get first branch
		process_branch.call(current_branch)        # Process it
		branches_to_process.remove_at(0)            # Remove it and array shifts automatically





# the steps of creation, functions to send data further
func first_stage_of_creation_(data_set_name_0, sets_to_create_0):
	create_new_task("initialize_menu", sets_to_create_0[0])




func second_stage_of_creation_(data_set_name_1, sets_to_create_1):
	create_new_task("second_impact_for_real", sets_to_create_1[0])

func second_impact_for_real(set_to_do_thingy):
	var records_set_name_0 = set_to_do_thingy + "_"
	var container_name_for_array = container_finder(records_set_name_0)
	
	array_counting_mutex.lock()
	if !array_for_counting_finish.has(container_name_for_array):
		array_for_counting_finish[container_name_for_array] = {}
	array_counting_mutex.unlock()
		
	active_r_s_mut.lock()
	var safe_activ_record_set = active_record_sets
	active_r_s_mut.unlock()
	
	process_active_records_for_tree(safe_activ_record_set, records_set_name_0, container_name_for_array)

	array_mutex_process.lock()
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == set_to_do_thingy:
			number_thingy[1] +=1
	array_mutex_process.unlock()
	
	



func third_stage_of_creation_(data_set_name_2, sets_to_create_2):
	create_new_task("third_impact_right_now", sets_to_create_2[0])

func third_impact_right_now(data_set_thingiess):
	var records_set_name_1 = data_set_thingiess + "_"
	load_cached_data(records_set_name_1)
	
	array_mutex_process.lock()
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == data_set_thingiess:
			number_thingy[1] +=1
	array_mutex_process.unlock()




func fourth_impact_of_creation_(data_set_name_3, sets_to_create_3):
	create_new_task("fourth_impact_right_now", data_set_name_3)

func fourth_impact_right_now(data_set_nameeee):
	var records_set_name_1 = data_set_nameeee + "_"
	load_cached_data_second_impact(records_set_name_1)
	
	array_mutex_process.lock()
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == data_set_nameeee:
			number_thingy[1] +=1
	array_mutex_process.unlock()


func fifth_impact_of_creation_(data_set_name_4, sets_to_create_4):
	create_new_task("fifth_impact_right_now", data_set_name_4)

func fifth_impact_right_now(data_set_nameeeeee):
#	var records_set_name_2 = data_set_nameeeeee + "_"

	array_mutex_process.lock()
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == data_set_nameeeeee:
			print(" fifth imnpact list of sets to create we plus one " , data_set_nameeeeee)
			number_thingy[1] +=1
	array_mutex_process.unlock()



# here we get datapoint, and send that data further
func newer_even_function_for_dictionary(name_of_container):

	array_counting_mutex.lock()
	var datapoint_node_newest = array_for_counting_finish[name_of_container]["metadata"]["datapoint_node"]#.duplicate(true)
	var deep_state_copy_of_apples = array_for_counting_finish[name_of_container].duplicate(true)
	array_counting_mutex.unlock()
	#print(" i guess somehow, we get the node, and now, we got some kind of trouble? ", datapoint_node_newest)
	datapoint_node_newest.new_datapoint_layer_system(deep_state_copy_of_apples)
	
	#array_counting_mutex.lock()
	#array_for_counting_finish.erase(name_of_container) 
	#array_counting_mutex.unlock()


#
# JSH Records System
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┳┓        ┓   ┏┓         
#       888  `"Y8888o.   888ooooo888     ┣┫┏┓┏┏┓┏┓┏┫┏  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┛┗┗ ┗┗┛┛ ┗┻┛  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                      ┛       
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Records System
#

func container_finder(set_name):
	
	#var set_name_check = set_name.find("_")
	#print(" new_information_0 : ", set_name_check)
	
	
	var wordly_word = set_name + BanksCombiner.data_names_0[0]
	
	active_r_s_mut.lock()
	
	
	var container_name_now = "akashic_records"
	
	
	
	
	if active_record_sets.has(set_name):
	
		if active_record_sets[set_name][wordly_word].has("content") and active_record_sets[set_name][wordly_word]["content"] != []:
		# it is content = [] so it is still empty
			active_record_sets[set_name][wordly_word]
			container_name_now = active_record_sets[set_name][wordly_word]["content"][0][0][6][0]#.duplicate(true)
		
		
	active_r_s_mut.unlock()
	
	var container_splitter = container_name_now.split("/")
	if container_splitter.size() > 1:
		container_name_now = container_splitter[0]
	return container_name_now



func tasked_children(node_to_be_added, node_to_be_added_path):
	var splitted_path = node_to_be_added_path.split("/")
	var container_name = splitted_path[0]
	var node_to_be_added_name = splitted_path[-1]
	var parent_path = "/".join(splitted_path.slice(0, -1)) 

	if splitted_path.size() == 1:
		var node_type : int = 0
		
		mutex_nodes_to_be_added.lock()
		nodes_to_be_added.append([node_type, node_to_be_added_name, node_to_be_added])
		mutex_nodes_to_be_added.unlock()
		
	elif splitted_path.size() == 2:
		var node_type : int = 1
		
		mutex_nodes_to_be_added.lock()
		nodes_to_be_added.append([node_type, parent_path, node_to_be_added_name, node_to_be_added])
		mutex_nodes_to_be_added.unlock()
		
	else:
		var parent_name = splitted_path[1]
		var node_type : int = 2
		
		mutex_nodes_to_be_added.lock()
		nodes_to_be_added.append([node_type, parent_path, node_to_be_added_name, node_to_be_added, container_name])
		mutex_nodes_to_be_added.unlock()


func task_to_send_data_to_datapoint(data_for_sending):
	#await_for_signal()
	var current_datatype = data_for_sending[0][0]
	var first_line_t = data_for_sending[0][1]
	var parsed_lines_t = data_for_sending[0][2]
	var data_point_node_t = data_for_sending[0][3]
	
	match current_datatype:
		"instructions_analiser":
			var container_node_t = data_for_sending[0][4]
			instructions_analiser(first_line_t, parsed_lines_t[0], parsed_lines_t[1], data_point_node_t, container_node_t)
		"scene_frame_upload":
			var container_node_t = data_for_sending[0][4]
			scene_frames_upload_to_datapoint(first_line_t, parsed_lines_t, data_point_node_t, container_node_t)
		"interactions_upload":
			interactions_upload_to_datapoint(first_line_t, parsed_lines_t, data_point_node_t)

#
# JSH Scene Tree
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┓         ┏┳┓        ┏┓        
#       888  `"Y8888o.   888ooooo888     ┗┓┏┏┓┏┓┏┓   ┃ ┏┓┏┓┏┓  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┗┛┗┗ ┛┗┗    ┻ ┛ ┗ ┗   ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                              ┛      
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Scene Tree
#

# container_path
func disable_all_branches(branch_to_disable):
	var all_containers : Array = []
	var all_nodes : Array = []
	var branches_to_process : Array = []
	var just_container : Array = []

	var process_branch = func traverse_branch(branch: Dictionary):
		tree_mutex.lock()
		if branch["metadata"].has("full_path") and branch["metadata"]["full_path"] != null:

			all_containers.append(branch["name"])
			branch["status"] = "disabled"
			branch["node"] = null

		if branch.has("children"):
			for child_name in branch["children"]:
				branches_to_process.append(branch["children"][child_name])
				branch["children"][child_name]["status"] = "disabled"
				branch["children"][child_name]["node"] = null 
		tree_mutex.unlock()

	process_branch.call(branch_to_disable)
	
	var current_branches = branches_to_process.duplicate(false)

	# Process branches until none left
	while branches_to_process.size() > 0:
		
		tree_mutex.lock()
		var current_branch = branches_to_process[0]  # Get first branch
		tree_mutex.unlock()
		
		process_branch.call(current_branch)        # Process it
		
		tree_mutex.lock()
		branches_to_process.remove_at(0)            # Remove it and array shifts automatically
		tree_mutex.unlock()


func find_branch_to_unload(thing_path):
	var new_path_splitter = str(thing_path).split("/")
	tree_mutex.lock()
	if scene_tree_jsh["main_root"]["branches"][new_path_splitter[0]]["children"].has(new_path_splitter[1]):
		var branch_part_to_cache = scene_tree_jsh["main_root"]["branches"][new_path_splitter[0]]["children"][new_path_splitter[1]].duplicate(true)
		var branch_name_to_cache = new_path_splitter[0]
		var child_name_to_cache = new_path_splitter[1]
		tree_mutex.unlock()
		cache_branch(branch_name_to_cache, child_name_to_cache, branch_part_to_cache)
		
		tree_mutex.lock()
		scene_tree_jsh["main_root"]["branches"][new_path_splitter[0]]["children"].erase(new_path_splitter[1])
		tree_mutex.unlock()
	else:
		tree_mutex.unlock()
		
		
	array_counting_mutex.lock()
	
	# if has branch name
	if array_for_counting_finish.has(new_path_splitter[0]):
		if array_for_counting_finish[new_path_splitter[0]].has(new_path_splitter[1]):
			print(" cache branch we can unload that node ", new_path_splitter[1])
			array_for_counting_finish[new_path_splitter[0]].erase(new_path_splitter[1])
		else:
			print(" cache branch that node does not exist in that container", new_path_splitter[0])
	else:
		print(" cache branch that container does not exist")
		# if has child_name
	
	array_counting_mutex.unlock()


func cache_tree_branch_fully(container_to_unload):
	
	cached_tree_mutex.lock()
	
	print(" new function to cache tree branch fully ", container_to_unload)
	if !cached_jsh_tree_branches.has(container_to_unload):
		print(" new function, it doesnt have that branch ", container_to_unload)
		
		tree_mutex.lock()
		if scene_tree_jsh["main_root"]["branches"].has(container_to_unload):
			print(" the main scene tree thingy got that container in it rn ")
			tree_mutex.unlock()
			
			disable_all_branches(scene_tree_jsh["main_root"]["branches"][container_to_unload])
			
			tree_mutex.lock()
			cached_jsh_tree_branches[container_to_unload] = scene_tree_jsh["main_root"]["branches"][container_to_unload]
			scene_tree_jsh["main_root"]["branches"].erase(container_to_unload)
			tree_mutex.unlock()
		else:
			tree_mutex.unlock()
	
	cached_tree_mutex.unlock()



func cache_branch(branch_name, child_name, branch_part):
	
	print(" cache branch : ", branch_name, child_name)
	
	cached_tree_mutex.lock()
	
	if !cached_jsh_tree_branches.has(branch_name):
		
		tree_mutex.lock()
		cached_jsh_tree_branches[branch_name] = {
			"name" = scene_tree_jsh["main_root"]["branches"][branch_name]["name"],
			"type" = scene_tree_jsh["main_root"]["branches"][branch_name]["type"],
			"jsh_type" = scene_tree_jsh["main_root"]["branches"][branch_name]["jsh_type"],
			"parent" = scene_tree_jsh["main_root"]["branches"][branch_name]["parent"],
			"status" = "disabled",
			"node" = null,
			"metadata" = scene_tree_jsh["main_root"]["branches"][branch_name]["metadata"],
			"children" = {}
		}
		tree_mutex.unlock()
		
		

		
		
	if cached_jsh_tree_branches.has(branch_name):
		if !cached_jsh_tree_branches[branch_name]["children"].has(child_name):
			disable_all_branches(branch_part)
			
			tree_mutex.lock()
			cached_jsh_tree_branches[branch_name]["children"][child_name] = branch_part
			tree_mutex.unlock()
	
	cached_tree_mutex.unlock()

# scene tree start up, creating the main root node info there
func start_up_scene_tree():
	
	tree_mutex.lock()
	scene_tree_jsh = TreeBlueprints.SCENE_TREE_BLUEPRINT.duplicate(true)
	var name_to_add = self.name
	scene_tree_jsh["main_root"]["name"] = name_to_add
	scene_tree_jsh["main_root"]["type"] = self.get_class()
	scene_tree_jsh["main_root"]["metadata"]["creation_time"] = Time.get_ticks_msec()
	scene_tree_jsh["main_root"]["node"] = self
	scene_tree_jsh["main_root"]["status"] = "active"
	tree_mutex.unlock()


func the_pretender_printer(node_name: String, node_path_jsh_tree: String, godot_node_type, node_type: String = "Node3D"):

	tree_mutex.lock()
	if !scene_tree_jsh.has("main_root"):
		scene_tree_jsh = TreeBlueprints.SCENE_TREE_BLUEPRINT.duplicate(true)
		scene_tree_jsh["main_root"]["name"] = "main"
		scene_tree_jsh["main_root"]["type"] = "Node3D"
		scene_tree_jsh["main_root"]["status"] = "active"
		scene_tree_jsh["main_root"]["node"] = self

	var path_parts = node_path_jsh_tree.split("/")
	var current_branch = scene_tree_jsh["main_root"]["branches"]
	cached_tree_mutex.lock()
	var cached_current_branch = cached_jsh_tree_branches
	cached_tree_mutex.unlock()
	# Track the full path as we build it
	var current_full_path = ""
	
	# Handle path traversal
	for i in range(path_parts.size()):
		var part = path_parts[i]
		current_full_path = current_full_path + "/" + part if current_full_path else part
		if !current_branch.has(part):
			if cached_current_branch.has(part):
				print(" the cached branch has that one ")
				current_branch[part] = cached_current_branch[part]
				cached_current_branch.erase(part)
			else:
				var new_branch = TreeBlueprints.BRANCH_BLUEPRINT.duplicate(true)
				new_branch["name"] = part
				new_branch["type"] = godot_node_type
				new_branch["jsh_type"] = node_type
				new_branch["status"] = "pending"
				new_branch["node"] = null
				new_branch["metadata"] = {
					"creation_time": Time.get_ticks_msec(),
					"full_path": current_full_path,
					"parent_path": current_full_path.get_base_dir(),
					"has_collision": false,
					"has_area": false
				}
				if node_type == "datapoint":
					scene_tree_jsh["main_root"]["branches"][path_parts[0]]["datapoint"] = {
						"datapoint_name" = new_branch["name"],
						"datapoint_path" = new_branch["metadata"]["full_path"]
					}
				current_branch[part] = new_branch

		if i < path_parts.size() - 1:
			if !current_branch[part].has("children"):
				current_branch[part]["children"] = {}
			current_branch = current_branch[part]["children"]
			
			if cached_current_branch.has(part):
				if cached_current_branch[part].has("children"):
					print(" the cached branch had them children")
					cached_current_branch = cached_current_branch[part]["children"]
	tree_mutex.unlock()


# Modified print_tree_structure function
func print_tree_structure(branch: Dictionary, indent: int = 0):
	tree_mutex.lock()
	var indent_str = "  ".repeat(indent)
	var status = branch.get("status", "pending")  # Default to pending if no status
	print("%s%s (%s) %s" % [
		indent_str, 
		branch["name"], 
		branch["type"],
		status_symbol[status]
	])
	
	if branch.has("metadata"):
		var metadata = branch["metadata"]
		if metadata.get("has_collision", false):
			print("%s  └─ Has Collision" % indent_str)
		if metadata.get("has_area", false):
			print("%s  └─ Has Area" % indent_str)
	
	if branch.has("branches"):
		for child in branch["branches"].values():
			tree_mutex.unlock()
			print_tree_structure(child, indent + 1)
	elif branch.has("children"):
		for child in branch["children"].values():
			tree_mutex.unlock()
			print_tree_structure(child, indent + 1)
	tree_mutex.unlock()

func jsh_tree_get_node(node_path_get_node: String) -> Node:
	var path_parts = node_path_get_node.split("/")
	tree_mutex.lock()
	var current = scene_tree_jsh["main_root"]["branches"]
	for part in path_parts:
		if current.has(part):
			current = current[part]
			if path_parts[-1] == part:
				#print(" current : " , current["node"])
				tree_mutex.unlock()
				return current["node"]
			else:
				current = current["children"]
	tree_mutex.unlock()
	return null


# claude idea of how to change it, i guess for me them mutexes unlocking after we call function, makes sense, maybe it is broken, will figure it out, when i have problem with it, may it be there
#func print_tree_structure(branch: Dictionary, indent: int = 0):
	#tree_mutex.lock()
	#var indent_str = "  ".repeat(indent)
	#var status = branch.get("status", "pending")
	#var children_to_process = []
	#
	## Get all needed data while locked
	#print("%s%s (%s) %s" % [
		#indent_str, 
		#branch["name"], 
		#branch["type"],
		#status_symbol[status]
	#])
	#
	#if branch.has("branches"):
		#children_to_process = branch["branches"].values()
	#elif branch.has("children"):
		#children_to_process = branch["children"].values()
	#tree_mutex.unlock()
#
	## Process children after unlock
	#for child in children_to_process:
		#print_tree_structure(child, indent + 1)



#func jsh_scene_tree_get_children(node_path_get_childs: String) -> Array:
	#var path_parts = node_path_get_childs.split("/")
	##tree_mutex.lock()
	#var current_branch = scene_tree_jsh["main_root"]["branches"]
	##tree_mutex.unlock()
	## Navigate to the requested node
	#for part in path_parts:
		#if current_branch.has(part):
			#if path_parts[-1] == part:
				## We found our node, return its children
				#return current_branch[part].get("children", {}).keys()
			#else:
				## Keep navigating
				#current_branch = current_branch[part]["children"]
	#
	#return []


#
# JSH Multi Threads
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┳┳┓  ┓ •  ┏┳┓┓        ┓   ┏┓         
#       888  `"Y8888o.   888ooooo888     ┃┃┃┓┏┃╋┓   ┃ ┣┓┏┓┏┓┏┓┏┫┏  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┛ ┗┗┻┗┗┗   ┻ ┛┗┛ ┗ ┗┻┗┻┛  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                                  ┛       
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Multi Threads
#

# creating new tasks, also punishing mortals 
func create_new_task(function_name: String, data):
	var new_data_way = str(data)
	var task_tag = function_name + "|" + new_data_way + "|" + str(Time.get_ticks_msec())
	
	## Declare the variable first
	#var completion_handler
	#
	## Then assign the function to it
	#completion_handler = func(completed_tag):
		#if completed_tag == task_tag:
			#thread_pool.disconnect("task_finished", completion_handler)
	thread_pool.submit_task(self, function_name, data, task_tag)

#
# JSH Files Management
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┓•┓     ┳┳┓                    ┏┓         
#       888  `"Y8888o.   888ooooo888     ┣ ┓┃┏┓┏  ┃┃┃┏┓┏┓┏┓┏┓┏┓┏┳┓┏┓┏┓╋  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┻ ┗┗┗ ┛  ┛ ┗┗┻┛┗┗┻┗┫┗ ┛┗┗┗ ┛┗┗  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                        ┛               ┛       
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Files Management
#


# file creation, here we have functions from second, maybe third chicken
# now we have nice eggs
func create_file(array_with_data: Array, lines_amount: int, name_for_file: String):

	var file = FileAccess.open(path + "/" + name_for_file + ".txt", FileAccess.WRITE)
	if file:
		# We'll loop from 0 to lines_amount-1 to write each line
		for line in range(lines_amount):
			file.store_line(array_with_data[line][0]) 
		file_path = path + "/" + name_for_file + ".txt"
	
	
# finding files in lists of files, missing files thingy? or was it integrity stuff
func file_finder(file_name, path_to_file, list_of_files, type_of_data):
	var counter_liste = list_of_files.size()
	var counter_times : int = 0
	
	for file in list_of_files:
		if file == file_name:
			file_path = path_to_file + "/" + file


#checks if it is a first run, checks for an akashic_records.txt file
func check_folder(folder_path):
	var space_existence = DirAccess.open(folder_path)
	if space_existence:
		check_folder_content(space_existence)
		directory_existence = true
	else:
		pass

# checking folder content
func check_folder_content(directory):  # Take DirAccess as parameter
	files_content = directory.get_files()      # Get array of files
	folders_content = directory.get_directories()  # Get array of folders
	
	# Check if we have any files
	if files_content.size() > 0:
		files_existence = true
	else:
		files_existence = false
		
	# Check if we have any folders
	if folders_content.size() > 0:
		folders_existence = true
	else:
		folders_existence = false


# here we check existence of settings file and also sending it to class file
func check_settings_file():
	var settings_exists = FileAccess.file_exists("user://settings.txt")
	
	if settings_exists:
		# File exists, we can try to open it
		var file = FileAccess.open("user://settings.txt", FileAccess.READ)
		if file:
			#print("Successfully opened settings file")
			SettingsBank.load_settings_file("user://settings.txt")
			return true
		else:
#			print("File exists but couldn't open it")
			return false
	else:
		#print("No settings file found in user://")
		var file_data_of_settings = SettingsBank.settings_file_blue_print_0
		var data_of_settings_cleaned : Array = []
		for entry in file_data_of_settings[0]:
			var cleansed = entry[0].split("|")
			data_of_settings_cleaned.append(cleansed)
			
		# here we are after cleaning settings thingy, the D eden is : data_of_settings_cleaned[0][1] = lets see now : D:/Eden so here we got string! just string :(
		var path_for_directory = data_of_settings_cleaned[0][1]
		var path_for_user_data = "user://" # + data_of_settings_cleaned[1][1]
		var path_for_database = data_of_settings_cleaned[1][1]
		var settings_file_name = data_of_settings_cleaned[2][1]
		var default_directory = DirAccess.dir_exists_absolute(path_for_directory)
		# Check if directory exists first

		if default_directory == true:
			print("the directory exist, we can send there file, hmm, damn, i wanted to do it different way, like use res? but lets just do it my way, it even finds")
		else:
			scan_available_storage()
		scan_available_storage()
		if available_directiories[0]:
			data_of_settings_cleaned.append(["available_directiory" , available_directiories[0]])
		#return false
		if !DirAccess.dir_exists_absolute(path_for_user_data + path_for_database):
		#	# Create directory
			DirAccess.make_dir_recursive_absolute(path_for_user_data + path_for_database)
		if !FileAccess.file_exists(path_for_user_data + settings_file_name):
			var file = FileAccess.open(path_for_user_data + settings_file_name, FileAccess.WRITE)
			if file:
				for line in data_of_settings_cleaned:
					file.store_line(line[0] + " : " + line[1])
			SettingsBank.load_settings_file(path_for_user_data + settings_file_name)
	

# creating file, what to put in, where,name
func file_creation(file_content,  path_for_file, name_for_file):
	var file = FileAccess.open( path_for_file + "/" + name_for_file + ".txt", FileAccess.WRITE)
	if file:
		for line in file_content:
			file.store_line(line)  # [0] because each line is in its own array


#
# hmm i think i didnt use these, we done it different way
#
func setup_settings():
	# 1. Check for directory
	var eden_path = find_or_create_eden_directory()
	
	# 2. Check/Create akashic_records folder
	var akashic_path = eden_path + "/akashic_records"
	if !DirAccess.dir_exists_absolute(akashic_path):
		DirAccess.make_dir_recursive_absolute(akashic_path)
	
	# 3. Check/Create settings file
	var settings_file_path = akashic_path + "/settings.txt"
	if !FileAccess.file_exists(settings_file_path):
		create_default_settings(settings_file_path)
	
	# 4. Load settings into SettingsBank
	SettingsBank.load_settings_file(settings_file_path)


# so this one
func find_or_create_eden_directory():
	var available_dirs = scan_available_storage()
	
	# Try to find existing Eden folder
	for dir in available_dirs:
		if DirAccess.dir_exists_absolute(dir + "/Eden"):
			return dir + "/Eden"
	
	# If not found, create in first available directory
	var target_dir = available_dirs[0] + "/Eden"
	DirAccess.make_dir_recursive_absolute(target_dir)
	return target_dir

# and this
func create_default_settings(file_path_c_d_s):
	var settings_data = []
	for entry in SettingsBank.settings_file_blue_print_0[0]:
		settings_data.append(entry)
	
	create_file(settings_data, settings_data.size(), "settings")


# 
func scan_available_storage():
	#print("Scanning available storage...")
	
	# For Windows: Check drives A-Z
	if OS.get_name() == "Windows":
		for ascii in range(65, 91):  # A-Z in ASCII
			var drive = char(ascii) + ":/"
			var dir = DirAccess.open(drive)
			if dir != null:
				#print("Found drive: ", drive)
				available_directiories.append(drive)
				#print(" available_directiories : " , available_directiories)
	
	# For Android: Check common storage paths
	elif OS.get_name() == "Android":
		var common_paths = [
			"/storage/emulated/0/",  # Internal storage
			"/sdcard/",              # Common symlink to internal storage
			"/storage/"              # Parent directory for all storage
		]
		
		for path_s_a_s in common_paths:
			var dir = DirAccess.open(path)
			if dir != null:
				#print("Found storage: ", path)
				# List all storage devices in /storage/
				if path_s_a_s == "/storage/":
					var contents = dir.get_directories()
					for storage in contents:
						print("Storage device found: /storage/" + storage)


#
# Memories Management
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┳┳┓         •     ┳┳┓                   ┏┓         
#       888  `"Y8888o.   888ooooo888     ┃┃┃┏┓┏┳┓┏┓┏┓┓┏┓┏  ┃┃┃┏┓┏┓┏┓┏┓┏┓┏┳┓┏┓┏┓╋ ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┛ ┗┗ ┛┗┗┗┛┛ ┗┗ ┛  ┛ ┗┗┻┛┗┗┻┗┫┗ ┛┗┗┗ ┛┗┗ ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                                 ┛              ┛       
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# Memories Management
#

 		#var first_stage_of_creation : String = "abort_creation"
		#var stage_of_creation : String = "first"
		
func new_function_for_creation_recovery(record_type_now, first_stage_of_creation_now, stage_of_creation_now):
	print(" fatal kurwa error 000 ", record_type_now , " , " , first_stage_of_creation_now, " , " , stage_of_creation_now)
	if load_queue_mutex.try_lock():
		print(" fatal kurwa error 00 load_queue_mutex ",)
	else:
		print(" fatal kurwa error 001 load_queue_mutex ",)
		
	array_with_no_mutex.append([record_type_now, first_stage_of_creation_now, stage_of_creation_now])
	
	#load_queue_mutex.lock()
	#print(" fatal kurwa error 00666 load_queue_mutex ",)
	#load_queue_mutex.unlock()


func initialize_menu(record_type: String):
	
	var type_of_data : int
	print(" initalize memories ! 0 : " , record_type)
	
	var records_set_name = record_type + "_"
	var use_cache = false
	var already_exists = false
   



	print(" initalize memories ! 0L0 : " , record_type)
	if active_r_s_mut.try_lock():
		print(" initalize memories ! 0L1 : " , record_type)
		if cached_r_s_mutex.try_lock():
			print(" initalize memories ! 0L2 : " , record_type)
		else:
			print(" initalize memories ! 0L3 : " , record_type)
	else:
		print(" initalize memories ! 0L4 : " , record_type)
		print(" active records set, is actually being used ")
		
		
		
		
		var first_stage_of_creation : String = "abort_creation"
		var stage_of_creation : String = "first"
		
		new_function_for_creation_recovery(record_type, first_stage_of_creation, stage_of_creation)
		
		
		
		if cached_r_s_mutex.try_lock():
			print(" initalize memories ! 0L5 : " , record_type)
		else:
			print(" initalize memories ! 0L6 : " , record_type)
			
			
			var first_stage_of_creation_0 : String = "abort_creation"
			var stage_of_creation_0 : String = "first"
			
			new_function_for_creation_recovery(record_type, first_stage_of_creation_0, stage_of_creation_0)
			
			
			
			if array_mutex_process.try_lock():
				print(" initalize memories ! 0L7 : " , record_type)
			else:
				print(" initalize memories ! 0L8 : " , record_type)
				
				var first_stage_of_creation_1 : String = "abort_creation"
				var stage_of_creation_1 : String = "first"
				
				new_function_for_creation_recovery(record_type, first_stage_of_creation_1, stage_of_creation_1)
				
				
				#array_mutex_process.lock()
				#
				#for number_thingy in list_of_sets_to_create:
					#if number_thingy[0] == record_type:
						#print(" initialize menu, finish i guess we found the second gate ?")
						#number_thingy[1] +=6
						#
				#array_mutex_process.unlock()
			
			
			
			
		





	active_r_s_mut.lock()
	print(" initalize memories ! 0000 : " , record_type)
	cached_r_s_mutex.lock()
	print(" initalize memories ! 00000 : " , record_type)
	
	# check if it is in active
	if active_record_sets.has(records_set_name):
		print(" initalize memories ! 0A : " , record_type)
		already_exists = true
		if active_record_sets[records_set_name].has("metadata"):
			print(" initalize memories ! 0B : " , record_type)
			if active_record_sets[records_set_name]["metadata"]["container_count"] == BanksCombiner.dataSetLimits[records_set_name]:
				print(" initalize memories ! 0C : " , record_type)
				
				
				
				array_mutex_process.lock()
				for number_thingy in list_of_sets_to_create:
					if number_thingy[0] == record_type:
						print(" initialize menu, finish i guess we found the second gate ?")
						number_thingy[1] +=6
				array_mutex_process.unlock()
				
				
				
				active_r_s_mut.unlock()
				cached_r_s_mutex.unlock()
				
				
				
				return
				
				
			
			
			
			if active_record_sets[records_set_name]["metadata"]["container_count"] == 1:
				
				
				var number_of_set = active_record_sets[records_set_name]["metadata"]["container_count"]
				var additional_set_name = record_type + str(number_of_set)
				var additional_set_name_ = additional_set_name + "_"
				
				
				if !active_record_sets.has(additional_set_name_):
					
					
					if cached_record_sets.has(records_set_name):
						print(" initalize memories ! :  but cached had copy of that one? ")
						active_record_sets[additional_set_name_] = cached_record_sets[additional_set_name_]
						cached_record_sets.erase(additional_set_name_)
					# missing logic
					
					# if cached has it, take it, if not, then do as it was before
					
					
					else:
						var new_data = recreator(number_of_set, active_record_sets[records_set_name], record_type, additional_set_name_)
						active_record_sets[additional_set_name_] = new_data.duplicate(true)
					
					
					
					# up to that line ?
					
					# maybe i didnt have to, dunno ghosts demanded it
					
					
					
					
					
					array_mutex_process.lock()
					for number_thingy in list_of_sets_to_create:
						if number_thingy[0] == record_type:
							print(" initialize menu, finish i guess we found the third gate ? ")
							number_thingy[1] +=1
							number_thingy[0] = additional_set_name
					array_mutex_process.unlock()
					
					active_record_sets[records_set_name]["metadata"]["container_count"] +=1
					
					
					
					active_r_s_mut.unlock()
					cached_r_s_mutex.unlock()
					
					
					
					
					return 
# here we will also need to check if "number_of_set" > max countainer count in
				# IF WE ALREADY HAD ONE ADDDITIONAL SET MADE BEFORE!!!!
			if active_record_sets[records_set_name]["metadata"]["container_count"] > 1:
				#print(" active records set fiasco ? 5")
				var number_of_set = active_record_sets[records_set_name]["metadata"]["container_count"]
				var previous_additional_set_name = record_type + str(number_of_set -1)
				var previous_additional_set_name_underscore = previous_additional_set_name + "_"
				
				var additional_set_name = record_type + str(number_of_set)
				var additional_set_name_ = additional_set_name + "_"
				
				if !active_record_sets.has(additional_set_name_):
					var new_data = recreator(number_of_set, active_record_sets[previous_additional_set_name_underscore], previous_additional_set_name, additional_set_name_)
					active_record_sets[additional_set_name_] = new_data.duplicate(true)
					
					active_record_sets[records_set_name]["metadata"]["container_count"] +=1
					
					
					
					
					array_mutex_process.lock()
					
					for number_thingy in list_of_sets_to_create:
						if number_thingy[0] == record_type:
							print(" initialize menu, finish i guess we found the fourth gate ?")
							number_thingy[1] +=1
							number_thingy[0] = additional_set_name
							
					array_mutex_process.unlock()
					
					
					
					active_r_s_mut.unlock()
					cached_r_s_mutex.unlock()
					
					
					
					return
				else:
					#print(" active records set fiasco ? 7")
					active_record_sets[records_set_name]["metadata"]["container_count"] +=1
					
					# my mind is telling me, we have that already in active and it is additional set? so maybe? we hit the limit number of that additional record set ???
					
					# errror
					
					
					# attention
					
					
					
					array_mutex_process.lock()
					
					for number_thingy in list_of_sets_to_create:
						if number_thingy[0] == record_type:
							print(" initialize menu, finish i guess we found the fifth gate ?")
							number_thingy[1] +=1
							number_thingy[0] = additional_set_name
							
					array_mutex_process.unlock()
					
					
					
					active_r_s_mut.unlock()
					cached_r_s_mutex.unlock()
					
					# almost kurwa there
					
					
					
					
					
				return

		if active_record_sets[records_set_name].is_empty():
			print(" initalize memories ! 0D : " , record_type)
			#print(" active records set fiasco ? 8")
			if cached_record_sets.has(records_set_name):
				#print(" active records set fiasco ? 9")
				if !cached_record_sets[records_set_name].is_empty():
					#print(" active records set fiasco ? 10")
					active_record_sets[records_set_name] = cached_record_sets[records_set_name].duplicate(true)
					active_record_sets[records_set_name]["metadata"]["container_count"] +=1
					cached_record_sets.erase(records_set_name)

					array_mutex_process.lock()
					
					for number_thingy in list_of_sets_to_create:
						if number_thingy[0] == record_type:
							print(" initialize menu, finish i guess we found the sixth gate ?")
							number_thingy[1] +=1
							
					array_mutex_process.unlock()
					
					
					
					active_r_s_mut.unlock()
					cached_r_s_mutex.unlock()
					
					
					
					return

	active_r_s_mut.unlock()
	cached_r_s_mutex.unlock()

	print("initalize memories ! 01 we went further ")
	
	var datapoint_node
	var records : Dictionary
	var current_data_pack_loaded
	var records_part : String
	var records_name : String
#	print(" initialize menu lets check that records_part :  ", records_part)
	records_part = ""
#	print(" initialize menu now i tried cleaning it records_part : ", records_part)
	
	match record_type:
		"base":
			current_data_pack_loaded = BanksCombiner.combination_0
			records_part = "base_"
		"menu":
			current_data_pack_loaded = BanksCombiner.combination_1
			records_part = "menu_"
		"settings":
			current_data_pack_loaded = BanksCombiner.combination_2
			records_part = "settings_"
		"keyboard":
			current_data_pack_loaded = BanksCombiner.combination_3
			records_part = "keyboard_"
		"keyboard_left":
			current_data_pack_loaded = BanksCombiner.combination_4
			records_part = "keyboard_left_"
		"keyboard_right":
			current_data_pack_loaded = BanksCombiner.combination_5
			records_part = "keyboard_right_"
		# Add more record sets as needed
		"things_creation":
			current_data_pack_loaded = BanksCombiner.combination_6
			records_part = "things_creation_"
		"singular_lines":
			current_data_pack_loaded = BanksCombiner.combination_7
			records_part = "singular_lines_"
		_:
			#print("Unknown record set to find in banks combiner : ", record_type)
			return {}
	
	
	for data_types in current_data_pack_loaded:
		#print("data_types : ", data_types[0])
		type_of_data = data_types[0]
		# get records by its type :)
		match type_of_data:
			0:
				#print(" zero ?")
				records = find_record_set(record_type)
				
				records_name = records_part + "records" # 0 = "records" , 1 = "instructions" 2 = "scenes"  3 = "interactions"
			1:
				#print(" one ? ")
				records = find_instructions_set(record_type)
				
				records_name = records_part + "instructions"
			2: 
				#print(" two ? ")
				records = find_scene_frames(record_type)
				
				records_name = records_part + "scenes"
			3:
				#print(" three ? ")
				records = find_interactions_list(record_type)
				
				records_name = records_part + "interactions"
		
		load_record_set(records_part, records_name, type_of_data, records)




## the outcome from creation

	print(" initialize menu, finish ")
	
	
	
	array_mutex_process.lock()
	
	
	
	for number_thingy in list_of_sets_to_create:
		if number_thingy[0] == record_type:
			print(" initialize menu, finish i guess we found the first gate ?")
			number_thingy[1] +=1
			
			
			
	array_mutex_process.unlock()



# finding records sets by memory name
func find_record_set(record_type: String) -> Dictionary:
#	print(" check_possible_interactions check_possible_interactions find rec")
	match record_type:
		"base":
			return RecordsBank.records_map_0
		"menu":
			return RecordsBank.records_map_2
		"settings":
			return RecordsBank.records_map_3
		"keyboard":
			return RecordsBank.records_map_4
		"keyboard_left":
			return RecordsBank.records_map_5
		"keyboard_right":
			return RecordsBank.records_map_6
		"things_creation":
			return RecordsBank.records_map_7
		"singular_lines":
			return RecordsBank.records_map_8
		# Add more record sets as needed
		_:
			#print("Unknown record set: ", record_type)
			return {}

# the same but for instruction by memory name
func find_instructions_set(record_type: String) -> Dictionary:
	match record_type:
		"base":
			return InstructionsBank.instructions_set_0
		"menu":
			return InstructionsBank.instructions_set_1
		"settings":
			return InstructionsBank.instructions_set_2
		"keyboard":
			return InstructionsBank.instructions_set_3
		"keyboard_left":
			return InstructionsBank.instructions_set_4
		"keyboard_right":
			return InstructionsBank.instructions_set_5
		"things_creation":
			return InstructionsBank.instructions_set_6
		"singular_lines":
			return InstructionsBank.instructions_set_7
		# Add more record sets as needed
		_:
			#print("Unknown record set: ", record_type)
			return {}
			

# the same as before, but for frames, scenes, memory
func find_scene_frames(record_type: String) -> Dictionary:
	match record_type:
		"base":
			return ScenesBank.scenes_frames_0
		"menu":
			return ScenesBank.scenes_frames_1
		"settings":
			return ScenesBank.scenes_frames_2
		"keyboard":
			return ScenesBank.scenes_frames_3
		"keyboard_left":
			return ScenesBank.scenes_frames_4
		"keyboard_right":
			return ScenesBank.scenes_frames_5
		"things_creation":
			return ScenesBank.scenes_frames_6
		"singular_lines":
			return ScenesBank.scenes_frames_7
		# Add more record sets as needed
		_:
			#print("Unknown record set: ", record_type)
			return {}
			

# here are interactions! to punish mortals
func find_interactions_list(record_type: String) -> Dictionary:
	#print(" so are we there?")
	match record_type:
		"base":
			#print(" maybe we somehow go to the base drop?")
			return InteractionsBank.interactions_list_0
		"menu":
			#print(" so efforts were made, we are supposed to load interactions list 1 : ", InteractionsBank.interactions_list_1)
			return InteractionsBank.interactions_list_1
		"settings":
			return InteractionsBank.interactions_list_2
		"keyboard":
			return InteractionsBank.interactions_list_3
		"keyboard_left":
			return InteractionsBank.interactions_list_4
		"keyboard_right":
			return InteractionsBank.interactions_list_5
		"things_creation":
			return InteractionsBank.interactions_list_6
		"singular_lines":
			return InteractionsBank.interactions_list_7
		# Add more record sets as needed
		_:
			#print("Unknown record set: ", record_type)
			return {}

#
# JSH Memories Transcription
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┳┳┓         •     ┏┳┓          •   •      ┏┓         
#       888  `"Y8888o.   888ooooo888     ┃┃┃┏┓┏┳┓┏┓┏┓┓┏┓┏   ┃ ┏┓┏┓┏┓┏┏┏┓┓┏┓╋┓┏┓┏┓  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┛ ┗┗ ┛┗┗┗┛┛ ┗┗ ┛   ┻ ┛ ┗┻┛┗┛┗┛ ┗┣┛┗┗┗┛┛┗  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                                     ┛            ┛       
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Memories Transcription
#

func recreator(number_to_add, data_to_process, data_set_name, new_name_for_set):
	
	var initial_number_to_add : int = int(number_to_add)
	print(" recreator whats wrong")
	print(" new_name_for_set : " , new_name_for_set)
	var processed_data : Dictionary
	var data_to_work_on = data_to_process.duplicate(true)
	var container_path = data_set_name + "_container/thing_"
	var patterns = ["thing_" , container_path ]
	var number_we_wanna_add : int
	var container_name_to_free
	var data_type_name_combined_first = data_set_name + "_" + BanksCombiner.data_names_0[0]
	var tasks_to_be_done : int = 0
	var datapoint_name
	var datapoint_container_name
	
	for container_to_find in data_to_work_on[data_type_name_combined_first]["content"]:
		if container_to_find[0][3][0] == "container":
			container_name_to_free = container_to_find[0][0][0]
			container_to_find.clear()
			break
	
	data_to_work_on[data_type_name_combined_first]["content"].erase([])

	for data_types in BanksCombiner.data_names_0:
		var data_type_name_combined = data_set_name + "_" + data_types
		

		
		
		print(data_set_name + "_" + data_types)
		for data_to_be_parsed_1 in data_to_work_on[data_type_name_combined]: 
			if data_to_be_parsed_1 == "header":
				if BanksCombiner.data_names_0[0] == data_types:
					number_we_wanna_add = data_to_work_on[data_type_name_combined][data_to_be_parsed_1].size()
					var counter_for_header_strings : int = 0
					for container_name_to_find in data_to_work_on[data_type_name_combined][data_to_be_parsed_1]:
						if container_name_to_find == container_name_to_free:
							container_name_to_find = ""
							data_to_work_on[data_type_name_combined][data_to_be_parsed_1][counter_for_header_strings] = ""
							data_to_work_on[data_type_name_combined][data_to_be_parsed_1].erase("")
							counter_for_header_strings +=1
							break
			var counter_new_0 : int = 0
			for data_to_be_parsed_2 in data_to_work_on[data_type_name_combined][data_to_be_parsed_1]:
				if data_to_be_parsed_2 is String:
					
					

					
					for pattern in patterns:
						if data_to_be_parsed_2.begins_with(pattern):
							var string_to_change = data_to_be_parsed_2.split("_")
							var size_of_array = string_to_change.size() -1
							string_to_change[size_of_array] = str(int(string_to_change[size_of_array]) + number_we_wanna_add)
							string_to_change = "_".join(string_to_change)
							data_to_work_on[data_type_name_combined][data_to_be_parsed_1][counter_new_0] = string_to_change
				if data_to_be_parsed_2 is Array:
					print(" recreator data_types : " , data_types)
					
					
					if data_types == "instructions":
						print(" recreator_check : 0 : ", data_to_be_parsed_2[0][1][0])
						print(" recreator_check : 0 : ", data_to_be_parsed_2[2][0][0])
						if data_to_be_parsed_2[0][1][0] == "set_the_scene":
							print(" recreator_check : 0 :  we found that set the scene " , number_to_add , " for   " , new_name_for_set)
							data_to_be_parsed_2[2][0][0][0] = str(number_to_add)
							#break
					
					if initial_number_to_add == 1:
						if data_types == "scenes":
							print(" recreator_check : 10 : ", data_to_be_parsed_2[0][0], " and number_to_add : " , number_to_add)
							print(" recreator_check : 11 : ", data_to_be_parsed_2)
							var scene_number = data_to_be_parsed_2[0][0][0].substr(6, data_to_be_parsed_2[0][0][0].length()) #scene)
							print(" recreator_check : 12 : ", scene_number)
							number_to_add = scene_number
							print(" recreator_check : 14 number_to_add " , number_to_add)
						if data_types == "interactions":
							number_to_add = initial_number_to_add
							print(" recreator_check : 15 number_to_add " , number_to_add)
					else:
						break
							
						#break
						

						
					
					print(" recreator data_types : continuation : " , data_types)
					
					if data_to_be_parsed_2.size() > 1:
						var counter_new_1 : int = 0
						var counter_helper : int = 0
						for data_to_be_parsed_3 in data_to_be_parsed_2:
							if data_to_be_parsed_3 is String:
								
								
								#if data_types == "instructions":
									#print(" recreator_check : 0 1 instructions part , ", number_to_add)
								
								
								
									
									
									#print(" recreator_check : 0  2 : " , data_to_work_on[data_type_name_combined]["content"][0])
								
								
								
								for pattern in patterns:
									if data_to_be_parsed_3.begins_with(pattern):
										var string_to_change = data_to_be_parsed_3.split("_")
										var size_of_array = string_to_change.size() -1
										string_to_change[size_of_array] = str(int(string_to_change[size_of_array]) + number_we_wanna_add)
										string_to_change = "_".join(string_to_change)
										data_to_be_parsed_3 = string_to_change
										counter_helper +=1
							if data_to_be_parsed_3 is Array:
								

								
								if data_to_be_parsed_3.size() > 1:
									var counter_new_2 : int = 0
									for data_to_be_parsed_4 in data_to_be_parsed_3:
										if data_to_be_parsed_4[0] is String:
											for pattern in patterns:
												if data_to_be_parsed_4[0].begins_with(pattern):
													var string_to_change = data_to_be_parsed_4[0].split("_")
													var size_of_array = string_to_change.size() -1
													string_to_change[size_of_array] = str(int(string_to_change[size_of_array]) + number_we_wanna_add)
													string_to_change = "_".join(string_to_change)
													data_to_be_parsed_4[0] = string_to_change
										counter_new_2 +=1
							counter_new_1 +=1
				counter_new_0 +=1


	for container_to_find in data_to_work_on[data_type_name_combined_first]["content"]:
		if container_to_find[0][3][0] == "datapoint":
			datapoint_name = container_to_find[0][0][0] # datapoint_name datapoint_container_name
			datapoint_container_name = container_to_find[0][5][0]
			break

# 
	for data_types in BanksCombiner.data_names_0:
		var data_type_name_combined = data_set_name + "_" + data_types
		var data_type_name_combined_new = new_name_for_set + data_types
		print(data_set_name + "_" + data_types)
		for data_to_be_parsed_1 in data_to_work_on[data_type_name_combined]: 
			processed_data[data_type_name_combined_new] = data_to_work_on[data_type_name_combined].duplicate(true)
	
	processed_data["metadata"] = {
				"timestamp": Time.get_ticks_msec(),
				"datapoint_name": datapoint_name,
				"datapoint_container_name": datapoint_container_name
			} # # datapoint_name datapoint_container_name
	
	print(" recreator : ", processed_data)
	return processed_data





# the functions of the past, that works, and i can use it if! i would need them :)
# finding highest number, in an array of ints
func find_highest_in_array(numbers: Array) -> int:
	return numbers.max()



func load_record_set(records_part: String, record_type: String, type_of_data : int, records : Dictionary) -> void:
	print(" load records set")
	# dataSetLimits and data_sets_names in BanksCombiner
	var max_nunmber_of_thingy = BanksCombiner.dataSetLimits[records_part]
	
	var current_record_type = record_type.split("_")
	var current_r_t_l = current_record_type.size() - 1
	var current_r_t_f = current_record_type[current_r_t_l]
	
	var amounts_of_that_record
	var current_int_number : int = -1
	
	if BanksCombiner.data_names_2_numbers.has(current_r_t_f):
		#print(" the number of record type : in int : ", BanksCombiner.data_names_2_numbers[current_r_t_f])
		#current_int_number
		current_int_number = BanksCombiner.data_names_2_numbers[current_r_t_f]
		
		#current_int_number +=6
		#print(" the number of record type : in int : " , current_int_number)
	
	var current_number_of_that_set : int = 0
	
	active_r_s_mut.lock()
	if !active_record_sets.has(records_part): # added that ! xD
		current_number_of_that_set = 1
	active_r_s_mut.unlock()
	
	var list_of_reliquaries : Array = [] # list of sacred relics—each one unique
	var codices : Array = [] # Ancient manuscripts that hold wisdom
	var current_record_line : Array = []
	
	
	for current_record_to_process in records:
		print(" do we even get there 02 ", current_record_to_process, " is that : ", current_r_t_f )#, " current_record_to_process :" ,records[current_record_to_process] )

		
		
		var another_array_damn : Array = []
		var string_splitter
		for current_part in records[current_record_to_process]:
			string_splitter = current_part[0].split("|")
			var string_to_be_splitted
			var tomes_of_knowledge : Array = []
			for stringy_string in string_splitter:
				string_to_be_splitted = stringy_string.split(",")
				tomes_of_knowledge.append(string_to_be_splitted)
			current_record_line.append(string_splitter[0])
			another_array_damn.append(tomes_of_knowledge)
		
		match current_int_number:
			0:
				#print(" the numbers thingy dilema records ", list_of_reliquaries.size())
				continue
				
			1:
				if max_nunmber_of_thingy > 1:
					print(" dubi dabi kurwa")
				#print(" instructions ")
				#print(" do we even get there 03 instructions ", another_array_damn," and that thingy : " , current_record_line)
				#print(" do we even get there 04 ", another_array_damn[0][1][0])
				#if another_array_damn[0][1][0] is String:
					#print(" do we even get there 05 it is a string")
					#match another_array_damn[0][1][0]:
						#"set_the_scene":
							#print(" do we even get there 06 set the scene ", another_array_damn[2][0][0])
							#
							#active_r_s_mut.lock()
							#if active_record_sets.has(records_part):
								#if active_record_sets[records_part].has("metadata"):
									#print(" do we even get there 06")
									## all turns well somehow, we got it
									#if active_record_sets[records_part]["metadata"].has("record_data"):
										#active_record_sets[records_part]["metadata"]["record_data"] = {
											#"scene_to_set" = another_array_damn[2][0][0]
											#
										#}
									#
									#
								#else:
									#print(" do we even get there 07 we got problem 1")
									## does not have metadata yet
							#else:
								#print(" do we even get there 08 we got problem 0")
								## does not have that record set yet
							#
							#
				continue
			2:
				#print(" do we even get there 03 scnes ", another_array_damn, current_record_line)
				#print()
				#print(" do we even get there 04 ")
				# i wanna whip out scene number main
				continue
			3:
				#print(" interactions ")
				continue
		
		
		
		codices.append(another_array_damn)
		list_of_reliquaries.append(current_record_line[0])
		current_record_line.clear()
		
	var string_header : String = "header"
	var string_content : String = "content"
	var string_informational : String = ""
	var records_processed : Dictionary = {} #{list_of_reliquaries, codices}
	records_processed[string_header] =  list_of_reliquaries
	records_processed[string_content] = codices
	
	
	active_r_s_mut.lock()
	
	match current_int_number:
		0:
			print(" the numbers thingy dilema records ", list_of_reliquaries.size())
			if active_record_sets.has(records_part):
				if active_record_sets[records_part].has("metadata"):
					if active_record_sets[records_part]["metadata"].has("record_data"):
						active_record_sets[records_part]["metadata"]["record_data"]
						print()
			pass
	
	if active_record_sets.has(records_part):# and active_record_sets.has(record_type):
		if active_record_sets[records_part].has(record_type):
			active_r_s_mut.unlock()
			print(" do we even get there 0 ")
			return
	active_r_s_mut.unlock()
	
	
	active_r_s_mut.lock()
	#if active_record_sets[records_part].has("metadata"):
	#	print(" do we even get there 06")
	
	
	if not active_record_sets.has(records_part):
		active_record_sets[records_part] = {
			"metadata": {
				"timestamp": Time.get_ticks_msec(),
				"container_count": current_number_of_that_set,
				"max_containers": max_nunmber_of_thingy
			}
		}
		print(" do we even get there 01 ", active_record_sets[records_part]["metadata"])
	active_r_s_mut.unlock()
	
	
	active_r_s_mut.lock()
	if records.size() > 0:
		active_record_sets[records_part][record_type] = records_processed
		#current_record_set = record_type
	active_r_s_mut.unlock()


# the splitter function? just an easy way, to like, do something, between created memory dictionary, and where we analise what we have and what we wanna do with it
# now it just do json copy without really doing too much
func read_records_data(record_set : Dictionary, records_set_name):
	print(" active records set fiasco ? read records data")


func process_active_records_for_tree(active_records: Dictionary, set_name_to_process : String, container_name_here : String):
	var records_set_name = set_name_to_process + "records"
	
	active_r_s_mut.lock()
	for record in active_records[set_name_to_process][records_set_name]["content"]:
		
		var node_data = record[0]
		var node_name = node_data[0][0]
		var node_path_p_a_r_f_t = node_data[6][0]
		var node_type = node_data[3][0]
		var godot_type = match_node_type(node_type)
		
		if node_type != "container" and node_type != "datapoint":
			array_counting_mutex.lock()
			if !array_for_counting_finish[container_name_here].has("metadata"):
				var counter_before : int = 0
				var counter_after : int = 0
				var inty_bolean : int = 0
				
				array_for_counting_finish[container_name_here]["metadata"] = {
					"counter_before" = counter_before,
					"counter_after" = counter_after,
					"process_to_send" = inty_bolean
				}
				array_counting_mutex.unlock()
				
			else:
				array_counting_mutex.unlock()
				
				
			array_counting_mutex.lock()
			if !array_for_counting_finish[container_name_here].has(node_name):
				
				array_for_counting_finish[container_name_here][node_name] = {
					"node" = [],
					"type" = node_type,
					"g_type" = godot_type
				}
				array_counting_mutex.unlock()
				
			else:
				array_counting_mutex.unlock()

		array_counting_mutex.lock()
		if !array_for_counting_finish[container_name_here].has("metadata"):
			
			var counter_before : int = 0
			var counter_after : int = 0
			var inty_bolean : int = 0
			
			array_for_counting_finish[container_name_here]["metadata"] = {
				"counter_before" = counter_before,
				"counter_after" = counter_after,
				"process_to_send" = inty_bolean
			}
			array_counting_mutex.unlock()
		else:
			array_counting_mutex.unlock()
			
			
		if node_type == "datapoint":
			
			array_counting_mutex.lock()
			array_for_counting_finish[container_name_here]["metadata"]["datapoint_path"] = node_path_p_a_r_f_t
			array_for_counting_finish[container_name_here]["metadata"]["datapoint_name"] = node_name
			array_counting_mutex.unlock()
			
		if node_type == "container":
			
			array_counting_mutex.lock()
			array_for_counting_finish[container_name_here]["metadata"]["container_path"] = node_path_p_a_r_f_t
			array_for_counting_finish[container_name_here]["metadata"]["container_name"] = node_name
			array_counting_mutex.unlock()
			
		var new_type_thingy = godot_type + "|" + node_type
		the_pretender_printer(node_name, node_path_p_a_r_f_t, new_type_thingy, node_type)
		
		array_counting_mutex.lock()
		array_for_counting_finish[container_name_here]["metadata"]["counter_before"] +=1
		array_counting_mutex.unlock()
		
				# Add collision nodes based on type
		if node_type in ["flat_shape", "model", "cursor", "screen", "circle"]:
			
			array_counting_mutex.lock()
			array_for_counting_finish[container_name_here]["metadata"]["counter_before"] +=4
			array_counting_mutex.unlock()
			
			# Static body and shape
			var static_body_name = "collision_" + node_name
			var static_body_path = node_path_p_a_r_f_t + "/" + static_body_name
			the_pretender_printer(static_body_name, static_body_path, "StaticBody3D", "collision")
			
			var shape_name = "shape_" + node_name
			var shape_path = static_body_path + "/" + shape_name
			the_pretender_printer(shape_name, shape_path, "CollisionShape3D", "collision")

			# Area and its shape
			var area_name = "aura_" + node_name
			var area_path = node_path_p_a_r_f_t + "/" + area_name
			the_pretender_printer(area_name, area_path, "Area3D", "area")

			var area_shape_name = "collision_aura_" + node_name
			var area_shape_path = area_path + "/" + area_shape_name
			the_pretender_printer(area_shape_name, area_shape_path, "CollisionShape3D", "collision")

		# Special handling for buttons
		elif node_type == "button":
			
			array_counting_mutex.lock()
			array_for_counting_finish[container_name_here]["metadata"]["counter_before"] +=6
			array_counting_mutex.unlock()
			
			var text_name = "text_" + node_name
			var text_path = node_path_p_a_r_f_t + "/" + text_name
			the_pretender_printer(text_name, text_path, "Label3D", "text")
			
			var shape_name = "shape_" + node_name
			var shape_path = node_path_p_a_r_f_t + "/" + shape_name
			the_pretender_printer(shape_name, shape_path, "MeshInstance3D", "button")

			# Collision for shape
			var collision_shape_name = "collision_" + shape_name
			var collision_shape_path = shape_path + "/" + collision_shape_name
			the_pretender_printer(collision_shape_name, collision_shape_path, "StaticBody3D", "collision")

			var shape_collision_name = "shape_" + shape_name
			var shape_collision_path = collision_shape_path + "/" + shape_collision_name
			the_pretender_printer(shape_collision_name, shape_collision_path, "CollisionShape3D", "collision")

			# Area for shape
			var area_name = "aura_" + shape_name
			var area_path = shape_path + "/" + area_name
			the_pretender_printer(area_name, area_path, "Area3D", "area")

			var area_collision_name = "collision_aura_" + shape_name
			var area_collision_path = area_path + "/" + area_collision_name
			the_pretender_printer(area_collision_name, area_collision_path, "CollisionShape3D", "collision")
	#print(" process active record for tree dilema finish")
	active_r_s_mut.unlock()

func match_node_type(type: String) -> String:
	match type:
		"flat_shape", "model", "cursor", "screen", "circle":
			return "MeshInstance3D"
		"text":
			return "Label3D"
		"button":
			return "Node3D" 
		"connection":
			return "MeshInstance3D"
		"text_mesh":
			return "MeshInstance3D"
		"datapoint":
			return "Node3D"
		"container":
			return "Node3D"
		_:
			return "Node3D"

# here we make deep copy dictionary of json
func deep_copy_dictionary(original: Dictionary) -> Dictionary:
	# First, convert to JSON string (this breaks all references)
	var json_string = JSON.stringify(original)
	# Then parse back to dictionary (creates entirely new data structure)
	var parsed = JSON.parse_string(json_string)
	return parsed


# here we are unloading sets to cache, adding stamp of time so 4d is here already
# we also check the size, check if we can even cache it or we need to clean previous data
# current limit is like 50 mb
func unload_record_set(records_sets_name : String, record_type: String) -> void:
	records_sets_name = records_sets_name + "_"
	
	active_r_s_mut.lock()
	if active_record_sets.has(records_sets_name):
		if active_record_sets[records_sets_name].has(record_type):
			var data = active_record_sets[records_sets_name][record_type]
			var meta_data = active_record_sets[records_sets_name]["metadata"]
			active_r_s_mut.unlock()
			
			cache_data(records_sets_name, record_type, data, meta_data)
			
			active_r_s_mut.lock()
			active_record_sets[records_sets_name].erase(record_type)
			active_r_s_mut.unlock()
			
		else:
			active_r_s_mut.unlock()
	else:
		active_r_s_mut.unlock()


# here we actually cache that data
func cache_data(records_sets_name: String, record_type: String, data, meta_data) -> void:
	var current_cache_size = get_cache_total_size()
	var new_data_size = get_dictionary_memory_size(data)
	var max_size_bytes = max_cache_size_mb * 1024 * 1024
	if current_cache_size + new_data_size > max_size_bytes:
		clean_oldest_dataset()
	current_cache_size = get_cache_total_size()
	
	
	cached_r_s_mutex.lock()
	if current_cache_size + new_data_size <= max_size_bytes:
		if !cached_record_sets.has(records_sets_name):
			
			active_r_s_mut.lock()
			cached_record_sets[records_sets_name] = { # current_cache_size
				"metadata": active_record_sets[records_sets_name]["metadata"].duplicate(true)
			}
			active_r_s_mut.unlock()
			
		cached_record_sets[records_sets_name][record_type] = data.duplicate(true)
		cached_record_sets[records_sets_name]["metadata"][str(record_type)] = {
			"size": new_data_size,
			"time_of_cache" : Time.get_ticks_msec()
		}
		cache_timestamps[records_sets_name + record_type] = Time.get_ticks_msec()

	else:
		print("Cache limit reached, cannot store new data")
	cached_r_s_mutex.unlock()
	
# here we are cleaning cache from oldest file
func clean_oldest_dataset() -> void:
	var oldest_time = Time.get_ticks_msec()
	var oldest_set = ""
	
	for timestamp_key in cache_timestamps:
		if cache_timestamps[timestamp_key] < oldest_time:
			oldest_time = cache_timestamps[timestamp_key]
			oldest_set = timestamp_key.split("_")[0]
	
	if oldest_set != "":
		#print("Removing oldest dataset: ", oldest_set)
		cached_r_s_mutex.lock()
		cached_record_sets.erase(oldest_set + "_")
		cached_r_s_mutex.unlock()
		
		# Clean related timestamps
		var to_remove = []
		for timestamp_key in cache_timestamps:
			if timestamp_key.begins_with(oldest_set):
				to_remove.append(timestamp_key)
		
		for key in to_remove:
			cache_timestamps.erase(key)


# here the size of dictionary is being checked
func get_dictionary_memory_size(dict: Dictionary) -> int:
	var serialized = var_to_bytes(dict)
	return serialized.size()


# total size of cached memory ram whatever
func get_cache_total_size() -> int:
	var total_size: int = 0
	
	
	cached_r_s_mutex.lock()
	for records_set in cached_record_sets:
		for record_type in cached_record_sets[records_set]:
			var data = cached_record_sets[records_set][record_type]
			total_size += get_dictionary_memory_size(data)
	
	#print("Total cache size in bytes: ", total_size)
	#print("Total cache size in MB: ", total_size / (1024.0 * 1024.0))
	cached_r_s_mutex.unlock()
	return total_size

# never really used, but it is still kinda there i guess, maybe one day i will, like use it for something, right now? threads
func get_record_type_id(record_type: String) -> int:
	match record_type:
		"base":
			return 0
		"menu":
			return 1
		_:
			return -1


#
# JSH Hidden Veil
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┓┏• ┓ ┓      ┓┏  •┓  ┏┓         
#       888  `"Y8888o.   888ooooo888     ┣┫┓┏┫┏┫┏┓┏┓  ┃┃┏┓┓┃  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┛┗┗┗┻┗┻┗ ┛┗  ┗┛┗ ┗┗  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                             ┛       
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Hidden Veil
#

#var signal_int : int = 0
#var signal_changed = false

#func await_for_signal():
	#var current_signal_int = signal_int
	#while current_signal_int == signal_int:
		#pass
	#print("signal changed, lets move on")
	
	
func the_fourth_dimensional_magic(type_of_operation : String, node : Node, data_of_movement):
	var data_for_movement : Array = []
	data_for_movement.append(type_of_operation)
	data_for_movement.append(node)
	data_for_movement.append(data_of_movement)
	movmentes_mutex.lock()
	things_to_be_moved.append(data_for_movement)
	movmentes_mutex.unlock()
	
func fifth_dimensional_magic(type_of_unloading : String, node_path_for_unload : String):
	#print(" main script, we got data for unloading , " , node_path_for_unload)
	var data_for_unloading : Array = []
	data_for_unloading.append(type_of_unloading)
	data_for_unloading.append(node_path_for_unload)
	mutex_for_unloading_nodes.lock()
	nodes_to_be_unloaded.append(data_for_unloading)
	mutex_for_unloading_nodes.unlock()

func sixth_dimensional_magic(type_of_function, node_to_call, function_name : String, additional_data = null):
	var data_for_function_call : Array = []
	data_for_function_call.append(type_of_function)
	data_for_function_call.append(node_to_call)
	data_for_function_call.append(function_name)
	if additional_data != null:
		data_for_function_call.append(additional_data)
	mutex_function_call.lock()
	functions_to_be_called.append(data_for_function_call)
	mutex_function_call.unlock()



func call_some_thingy():
	print()
	var data_pooint_node_now = get_node("keyboard_right_container/thing_53")
	data_pooint_node_now.process_delta_fake()
	

var past_deltas_memories : Array = []

var stored_delta_memory : Array = []

#var turn_delta_time_0 : 

func each_blimp_of_delta():
	var each_blimp_time = Time.get_ticks_msec()
	stored_delta_memory.append(each_blimp_time)
	print(" this is blimp of each tick : ", each_blimp_time)
	print(" time of each turn delta ")
	

func _process(delta):
	
	# handle camera before any turn takes place
	camera.process(delta)
	camera.process_roll(delta)
	
	# check mutex state before each turn now? or not each turn?
	# var message_of_delta = breaks_and_handles_check()
	# print(" message_of_delta : " , message_of_delta)
	
	each_blimp_of_delta()
	##############################################
	## do we take time blimp here to? with delta time for each of 0 to 9 turns so 10 in total ?
	 
	
	match turn_number_process:
		0:
			turn_number_process += 1
			array_mutex_process.lock()
			if list_of_sets_to_create.size() > 0:
				process_stages()
				array_mutex_process.unlock()
			else:
				array_mutex_process.unlock()

			delta_turn_0 = delta
			#call_some_thingy()
			#print_tree_pretty()
			#print_tree_structure(scene_tree_jsh["main_root"]["branches"]["keyboard_right_container"], 0)
			#print(array_for_counting_finish)
			
			pass
		1:
			turn_number_process += 1
			
			mutex_nodes_to_be_added.lock()
			if nodes_to_be_added.size() > 0:
				for i in range(min(max_nodes_added_per_cycle, nodes_to_be_added.size())):
					var data_to_process = nodes_to_be_added.pop_front()
					var data_type = data_to_process[0]
					match data_type:
						0:
							var container_to_add = data_to_process[2]
							var container_name = data_to_process[1]
							
							add_child(container_to_add)
							
							var just_added_node = get_node(container_name)
							if just_added_node:
								#print(" just adde dnode 0 : ", just_added_node)
								var data_to_be_checked : Array = []
								data_to_be_checked.append([container_name, container_name, just_added_node])
								create_new_task("the_finisher_for_nodes", data_to_be_checked)
							else:
								nodes_to_be_added.append(data_to_process)
								print(" ERROR container was not found ")
						1:
							
							var parent_path = data_to_process[1]
							var node_name = data_to_process[2]
							var main_node_to_add = data_to_process[3]
							var combined_path = parent_path + "/" + node_name
							
							
							var container = get_node(parent_path)
							if container:
								container.add_child(main_node_to_add)
								var just_added_node = get_node(combined_path)
								if just_added_node:
									#print(" just adde dnode 1 : ", just_added_node)
									var data_to_be_checked : Array = []
									data_to_be_checked.append([combined_path, node_name, just_added_node])
									create_new_task("the_finisher_for_nodes", data_to_be_checked)
								else:
									print("ERROR main node not found")
									nodes_to_be_added.append(data_to_process)
								
							else:
								print("ERROR container for main node not found")
								nodes_to_be_added.append(data_to_process)
						2:
							var parent_path = data_to_process[1]
							var node_name = data_to_process[2]
							var main_node_to_add = data_to_process[3]
							var container_name = data_to_process[4]
							var combined_path = parent_path + "/" + node_name
							
							var container = get_node(parent_path)
							if container:
								container.add_child(main_node_to_add)
								var just_added_node = get_node(combined_path)
								if just_added_node:
									#print(" just adde dnode 2 : ", just_added_node)
									var data_to_be_checked : Array = []
									data_to_be_checked.append([combined_path, node_name, just_added_node])
									create_new_task("the_finisher_for_nodes", data_to_be_checked)
								else:
									print(" ERROR sub node not found ")
									nodes_to_be_added.append(data_to_process)
								
							else:
								print(" ERROR main node for sub node not found ")
								nodes_to_be_added.append(data_to_process)
							
			
			mutex_nodes_to_be_added.unlock()
			pass
		2:
			turn_number_process += 1
			mutex_data_to_send.lock()
			
			if data_to_be_send.size() > 0:
				for i in range(min(max_data_send_per_cycle, data_to_be_send.size())):
					var data_to_be_send_rn = data_to_be_send.pop_front()
					var current_type_of_data = data_to_be_send_rn[0]
					var datapoint_path_cur = data_to_be_send_rn[1]
					match current_type_of_data:
						"instructions_analiser":
							var container_path_rn = data_to_be_send_rn[2]
							var container_node_rn = get_node(container_path_rn)
							if container_node_rn:
								var datapoint_node_rn = get_node(datapoint_path_cur)
								if datapoint_node_rn:
									var array_of_data_for_threes : Array = []
									array_of_data_for_threes.append([current_type_of_data, data_to_be_send_rn[3].duplicate(true), data_to_be_send_rn[4].duplicate(true), datapoint_node_rn, container_node_rn])
									create_new_task("task_to_send_data_to_datapoint", array_of_data_for_threes)
								else:
									print(" we didnt find the datapoint we must append stuff ")
									data_to_be_send.append(data_to_be_send_rn)
							else:
								print(" we didnt get container, we must append ")
								data_to_be_send.append(data_to_be_send_rn)
						"scene_frame_upload":
							var container_path_rn = data_to_be_send_rn[2]
							var container_node_rn = get_node(container_path_rn)
							if container_node_rn:
								var datapoint_node_rn = get_node(datapoint_path_cur)
								if datapoint_node_rn:
									var array_of_data_for_threes : Array = []
									array_of_data_for_threes.append([current_type_of_data, data_to_be_send_rn[3].duplicate(true), data_to_be_send_rn[4].duplicate(true), datapoint_node_rn, container_node_rn])
									create_new_task("task_to_send_data_to_datapoint", array_of_data_for_threes)
								else:
									print(" we didnt find the datapoint we must append stuff ")
									data_to_be_send.append(data_to_be_send_rn)
							else:
								print(" we didnt get container, we must append ")
								data_to_be_send.append(data_to_be_send_rn)
						"interactions_upload":
							var datapoint_node_rn = get_node(datapoint_path_cur)
							if datapoint_node_rn:
								var array_of_data_for_threes : Array = []
								array_of_data_for_threes.append([current_type_of_data, data_to_be_send_rn[3].duplicate(true), data_to_be_send_rn[4].duplicate(true), datapoint_node_rn])
								create_new_task("task_to_send_data_to_datapoint", array_of_data_for_threes)
							else:
								print(" we didnt got that datapoint, we gotta apend")
			mutex_data_to_send.unlock()
			pass
		3:
			turn_number_process += 1
			
			movmentes_mutex.lock()
			if things_to_be_moved.size() > 0:
				for i in range(min(max_movements_per_cycle, things_to_be_moved.size())):
					#print()
					var data_to_process = things_to_be_moved.pop_front()
					var data_type = data_to_process[0]
					var node_to_operate = data_to_process[1]
					var data_for_operation = data_to_process[2]
					match data_type:
						"move":
							#print(" we would move stuff ", node_to_operate)
							node_to_operate.position = data_for_operation
						"rotate":
							#print(" we would rotate stuff ", node_to_operate)
							node_to_operate.rotation.x -= deg_to_rad(data_for_operation)
						"write":
							#print(" here we would change text i guess ")
							for child in node_to_operate.get_children():
								if child is Label3D:
									child.text = data_for_operation
			movmentes_mutex.unlock()

			pass
		4:
			turn_number_process += 1
			
			mutex_for_unloading_nodes.lock()
			if nodes_to_be_unloaded.size() > 0:
				for i in range(min(max_nodes_to_unload_per_cycle, nodes_to_be_unloaded.size())):
					var data_to_process = nodes_to_be_unloaded.pop_front()
					var data_type = data_to_process[0]
					var path_of_the_node = data_to_process[1]
					match data_type:
						"container":
							print(" we would unload container")
							var container_to_unload = get_node_or_null(path_of_the_node)
							if container_to_unload:
								#print(" the container exist")
								var sub_path_of_the_node = path_of_the_node.substr(0, path_of_the_node.length() -10)
								print("taskkkk sub_path_of_the_node ", sub_path_of_the_node)
								container_to_unload.queue_free()
								create_new_task("unload_container", path_of_the_node)
							else:
								print(" we didnt find that container")
						"just_node":
							#print(" we would unload just a node")
							var node_to_unload = get_node_or_null(path_of_the_node)
							if node_to_unload:
								node_to_unload.queue_free()
								create_new_task("find_branch_to_unload", path_of_the_node)
							else:
								print(" i guess we didnt get node unfortunatelly ?")
			mutex_for_unloading_nodes.unlock()
			pass
		5:
			
			turn_number_process += 1
			
			mutex_function_call.lock()
			if functions_to_be_called.size() > 0:
				for i in range(min(max_functions_called_per_cycle, functions_to_be_called.size())):
					var data_to_process = functions_to_be_called.pop_front()
					var type_of_functi = data_to_process[0]
					var node_to_call = data_to_process[1]
					var function_name = data_to_process[2]
					match type_of_functi:
						"single_function":
							if node_to_call and node_to_call.has_method(function_name):
								node_to_call.call(function_name)
						"call_function_get_node":
							var function_data = data_to_process[3]
							var node_to_call_now = get_node_or_null(node_to_call)
							#print(" can i atleast print that thing? ", data_to_process)
							if node_to_call_now and node_to_call_now.has_method(function_name):
								#print(" well we did get a node?")
								node_to_call_now.call(function_name, function_data)
						"call_function_single_get_node":
							#print()
							var node_to_call_now = get_node_or_null(node_to_call)
							if node_to_call_now and node_to_call_now.has_method(function_name):
								node_to_call_now.call(function_name)
						"get_nodes_call_function":
							#print()
							if data_to_process.size() > 3:
								var function_data = data_to_process[3]
								for nodes in node_to_call:
									var current_node_to_call = get_node_or_null(nodes)
									if current_node_to_call and current_node_to_call.has_method(function_name):
										#print( " we got that node, and it has that function, ", function_data)
										current_node_to_call.call(function_name, function_data)
							else:
								print(" parallel reality somehow it is small size?")
								
							#node_to_call_now.call(function_name, function_data)
							
			mutex_function_call.unlock()
			
			pass
		6:
			turn_number_process += 1
			var start_finished_counting : int = int_of_stuff_finished
			var start_now_counting : int = int_of_stuff_started
			before_time_blimp(start_finished_counting, start_now_counting)
			# check states of containers, and created data already
			var shall_execute : int = 0
			mutex_for_trickery.lock()
			if menace_tricker_checker == 1:
				shall_execute = 1
				menace_tricker_checker = 2
			mutex_for_trickery.unlock()
			print(shall_execute)
			
			
			
			# FATAL ERROR MODE
			if shall_execute == 3:
				containers_states_checker()
				containers_list_creator()
				var message_now_mutex = breaks_and_handles_check()
				check_currently_being_created_sets()
				handle_random_errors() # array_with_no_mutex
				
				mutex_for_container_state.lock()
				mutex_containers.lock()
				print(" process delta ")
				print(" process delta outcome : list_of_containers " , list_of_containers)
				print(" process delta ")
				print(" process delta outcome : current_containers_state : ", current_containers_state)
				print("  process delta ")
				print(" process delta mutex chck : ", message_now_mutex)
				print(" process delta array with no protection : " , array_with_no_mutex)
				mutex_containers.unlock()
				mutex_for_container_state.unlock()
				
				# The pattern shows tasks starting but not finishing (2 started, 0 finished)
			if start_now_counting > start_finished_counting:
				print(" Task completion check - Started: ", start_now_counting, " Finished: ", start_finished_counting)
				
				# Check container states
				containers_states_checker()
				containers_list_creator()
				
				# Check mutexes
				var mutex_states = breaks_and_handles_check()
				
				# Check creation progress
				check_currently_being_created_sets()
				
				# Handle any errors
				handle_random_errors()
				
				check_thread_status()
				
				# Debug output
				mutex_for_container_state.lock()
				mutex_containers.lock()
				print(" Process state check:")
				print(" - Containers: ", list_of_containers)
				print(" - Container states: ", current_containers_state)
				print(" - Mutex states: ", mutex_states)
				print(" - Unhandled errors: ", array_with_no_mutex)
				mutex_containers.unlock()
				mutex_for_container_state.unlock()
				
					# Check memory state periodically
				var current_time = Time.get_ticks_msec()
				if current_time - memory_metadata["last_cleanup"] > memory_metadata["cleanup_thresholds"]["time_between_cleanups"]:
					var memory_state = check_memory_state()
					memory_metadata["last_cleanup"] = current_time
				
			pass
		7:
			turn_number_process += 1
			pass
		8:
			turn_number_process += 1
			pass
		9:
			turn_number_process = 0
			pass
	# Check if any mouse buttons are currently held down
	if Input.is_mouse_button_pressed(MOUSE_BUTTON_LEFT):
		pass
		#print("Left mouse button is held")
	if Input.is_mouse_button_pressed(MOUSE_BUTTON_RIGHT):
		pass
		#print("Right mouse button is held")


# Add properties to track main script memory
var memory_metadata = {
	"arrays": {
		"blimp_of_time": [],
		"stored_delta_memory": [],
		"past_deltas_memories": [],
		"array_with_no_mutex": [],
		"list_of_sets_to_create": []
	},
	"dictionaries": {
		"active_record_sets": {},
		"cached_record_sets": {},
		"scene_tree_jsh": {},
		"current_containers_state": {},
		"dictionary_of_mistakes": {}
	},
	"last_cleanup": Time.get_ticks_msec(),
	"cleanup_thresholds": {
		"array_max": 1000,  # Max array entries
		"dict_max_mb": 50,  # Max dictionary size in MB
		"time_between_cleanups": 30000  # 30 seconds
	}
}


func get_data_structure_size(data) -> int:
	# Early return for null data
	if data == null:
		return 0
		
	match typeof(data):
		TYPE_DICTIONARY:
			var total_size = 0
			for key in data:
				# Add key size
				total_size += var_to_bytes(key).size()
				# Add value size recursively
				if data[key] != null:
					total_size += get_data_structure_size(data[key])
			return total_size
			
		TYPE_ARRAY:
			var total_size = 0
			for item in data:
				if item != null:
					total_size += get_data_structure_size(item)
			return total_size
			
		TYPE_OBJECT:
			# Handle special cases like Nodes
			if data is Node:
				return 8  # Base pointer size
			return var_to_bytes(data).size()
			
		TYPE_STRING:
			return data.length() * 2  # Approximate UTF-16 size
			
		TYPE_INT:
			return 4
			
		TYPE_FLOAT:
			return 8
			
		TYPE_VECTOR2, TYPE_VECTOR2I:
			return 8
			
		TYPE_VECTOR3, TYPE_VECTOR3I:
			return 12
			
		_:
			# Default fallback using var_to_bytes
			return var_to_bytes(data).size()

# Helper function to safely get property
func get_jsh(property_name: String):
	if property_name in self:
		return self[property_name]
	return null

func check_memory_state():
	var current_time = Time.get_ticks_msec()
	var sizes = {}
	
	# Check arrays
	for array_name in memory_metadata["arrays"].keys():
		if get_jsh(array_name) != null:
			var array_size = get_data_structure_size(get_jsh(array_name))
			sizes[array_name] = array_size
			
			if array_size > memory_metadata["cleanup_thresholds"]["array_max"]:
				clean_array(array_name)
	
	# Check dictionaries
	for dict_name in memory_metadata["dictionaries"].keys():
		if get_jsh(dict_name) != null:
			var dict_size = get_data_structure_size(get_jsh(dict_name))
			sizes[dict_name] = dict_size
			
			# Convert to MB
			var size_mb = dict_size / (1024 * 1024)
			if size_mb > memory_metadata["cleanup_thresholds"]["dict_max_mb"]:
				clean_dictionary(dict_name)
	
	print("\nMemory State:")
	for name in sizes:
		print("%s: %s bytes" % [name, sizes[name]])
		
	return sizes

func clean_array(array_name: String):
	match array_name:
		"stored_delta_memory":
			# Keep only last 100 entries
			if stored_delta_memory.size() > 100:
				stored_delta_memory = stored_delta_memory.slice(-100)
				
		"blimp_of_time":
			if blimp_of_time.size() > 50:
				blimp_of_time = blimp_of_time.slice(-50)
		
		"array_with_no_mutex":
			# Clean old errors
			var current_time = Time.get_ticks_msec()
			array_with_no_mutex = array_with_no_mutex.filter(
				func(error): return current_time - error.time < 300000 # 5 minutes
			)

func clean_dictionary(dict_name: String):
	match dict_name:
		"cached_record_sets":
			# Clean old cached records
			var current_time = Time.get_ticks_msec()
			for key in cached_record_sets.keys():
				if current_time - cached_record_sets[key].get("timestamp", 0) > 3600000: # 1 hour
					cached_record_sets.erase(key)
					
		"dictionary_of_mistakes":
			# Clean resolved errors
			for key in dictionary_of_mistakes.keys():
				if dictionary_of_mistakes[key].get("status") == "resolved":
					dictionary_of_mistakes.erase(key)

func check_thread_status():
	var thread_stats = thread_pool.get_thread_stats()
	var total_threads = OS.get_processor_count()
	var executing_threads = 0
	var stuck_threads = 0
	
	print("\nThread Pool Status:")
	for thread_id in thread_stats:
		var state = thread_stats[thread_id]
		
		if state["status"] == "executing":
			executing_threads += 1
		if state["is_stuck"]:
			stuck_threads += 1
			
		print("Thread %s:" % thread_id)
		print("  Status: %s (for %dms)" % [
			state["status"],
			state["time_in_state_ms"]
		])
		print("  Tasks Completed: %d" % state["tasks_completed"])
		
		if state["current_task"]:
			print("  Current Task: %s" % state["current_task"].target_method)
			print("  Task Args: %s" % str(state["current_task"].target_argument))
	
	print("\nSummary:")
	print("Total Threads: %d" % total_threads)
	print("Executing: %d" % executing_threads)
	print("Stuck: %d" % stuck_threads)

#func before_time_blimp():
	#print(" check basic if we allign with prophecies of wisest spirits, do we unlock before it is too late ")
	# 
# calculate time function, took from other of my projects, here we also have some funsy easings to make stuff blink or whatever
# a lot of it is turned off, have leftover from shader projects, had fun
func calculate_time(delta_current, time, hour, minute, second):
	#print("delta_current : ", delta_current, " time : ", time, " hour : ", hour, " minute : ", minute, " second : ", second)
	#time_passed += delta_current
	
	# time, plus two differenly calculated?
	time = Time.get_ticks_msec()
	var time_0 = time / 1000.0#(Time.get_ticks_msec() / 1000.0)
	#var time_1 = time / 10000.0#(Time.get_ticks_msec() / 10000.0)
	#var time_2 = time / 100000.0
	
	var all_seconds : int = time / 1000
	var minutes : int = all_seconds / 60
	var remaining_seconds : int = all_seconds % 60
	print("Time: ", minutes, " minutes and ", remaining_seconds, " seconds")
	#var timer_reset = int(time_0)
	#var timer_reset2 = int(time_1)
	
	#var timer_new = time_0 - timer_reset
	#var timer_new2 = time_1 - timer_reset2
	
	#var oscillation = abs(1 - (timer_new * 2))
	#var oscillation2 = abs(1 - (timer_new2 * 2))	
	
	#var information =  0.5 * timer_new
	#var information2 = 0.5 * oscillation
	
	#var information3 = 0.5 + information2
	#var information4 = 2 + (2.0 * oscillation2)
	
	#var passed_seconds
	#var passed_minutes
	#var passed_hour
	
	# Convert milliseconds to seconds
	#if passed_seconds >= 60:
	#	passed_seconds -= 60
	#	passed_minutes += 1
		
		# Convert seconds to minutes
	#	if passed_minutes >= 60:
	#		passed_minutes -= 60
	#		passed_hour += 1
	#		

	#print("Time: ", minutes_passed, "m:", seconds_passed, "s:", milliseconds_passed, "ms")
	
	
	#second = time_0
	#minute = time_0 
	#print(" time calculated, 4 new main variables ")
	#print(" time : ", time, " time_0 : ", time_0, " time_1 : ", time_1, " time_2 : ", time_2)
	#print("past data, for shaders, from 1 to 0, from 0 to 1, simple easing? hmm")
	#print(" 2 new timers : ", timer_new, "timer_new2", timer_new2)
	#print(" oscilation? 2 : ", oscillation, " 2 ", oscillation2)
	#print("some information data ")
	#print("information : ", information, " , information2 : ", information2, " , information3 : ", information3, " , information4 : ", information4)



#
# JSH Projections System
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┓    •    •       ┏┓         
#       888  `"Y8888o.   888ooooo888     ┃┃┏┓┏┓┓┏┓┏╋┓┏┓┏┓┏  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┣┛┛ ┗┛┃┗ ┗┗┗┗┛┛┗┛  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888           ┛               ┛      
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Projections System
#

# input, so far on laptop i just use mouse to interact, click, release, drag, left, right, middle one for camera
func _input(event: InputEvent):
	if event is InputEventMouseButton:
		if event.button_index == MOUSE_BUTTON_LEFT:
			if event.pressed:
				print("_input : Left mouse clicked at: ", event.position)
				var current_ray_points = get_ray_points(event.position)
			else:
				print("_input : Left mouse released at: ", event.position)
		
		if event.button_index == MOUSE_BUTTON_RIGHT:
			if event.pressed:
				pass
				#print("_input : Right mouse clicked at: ", event.position)
			else:
				#print("_input : Right mouse released at: ", event.position)
				pass
	# Handle mouse motion
	if event is InputEventMouseMotion:
		#print("_input : Mouse moved to: ", event.position)
		# For relative movement:
		#print("_input : Mouse movement delta: ", event.relative)
		pass
		
	camera.input(event)


# ray points for mouse, with that we click things, change scenes, interact
func get_ray_points(mouse_position: Vector2):
	# Get the ray from the camera
	var from = camera.project_ray_origin(mouse_position)
	var ray_normal = camera.project_ray_normal(mouse_position)
	var to = from + ray_normal * ray_distance_set
	
	#print(get_world_3d())
	var space_state = get_world_3d().direct_space_state
	var query = PhysicsRayQueryParameters3D.create(from, to)
	var result = space_state.intersect_ray(query)
	
	var data : Array = []
	data.append(result)
	data.append(to)
	data.append(from)
	print(" to : " , to , " result : " , result , " from : " , from)
	create_new_task("ray_cast_data_preparer", data) #

func ray_cast_data_preparer(data_ray_cast):
	var results = data_ray_cast[0]
	var tos = data_ray_cast[1]
	var froms = data_ray_cast[2]
	multi_threaded_ray_cast(results, tos, froms)

func multi_threaded_ray_cast(result, to, from):
	print(" are we even at begining?")
	if result:
		to = result.position
		var collider = result.collider
		# Get the parent "thing" node
		var parent = collider.get_parent()
		var containter = parent.get_parent()
		var get_container = func(node: Node, method_name: String):
			while node:
				if node.has_method(method_name):
					return node
				node = node.get_parent()
			return null
		#print(" maytbe there?")
		var container = get_container.call(containter, "get_datapoint")
		
#		print("containter : ", container)
		var datapoint = container.get_datapoint()
		var current_node = collider
		#print("current_node : " , current_node)
		#await self.get_tree().process_frame
		while current_node != null and not current_node.name.begins_with("thing_"):
			current_node = current_node.get_parent()
		
		if current_node:
			#var array_of_things_that_shall_remain = 
			if datapoint:
				datapoint.thing_interaction(current_node)
			else:
				print(" somehow we didnt get that datapoint, but we got different kinds of data :) " , container.name)
				var stringy_container = str(container.name)
				tree_mutex.lock()
				var datapoint_path_ray_cast = scene_tree_jsh["main_root"]["branches"][stringy_container]["datapoint"]["datapoint_path"]
				#print(scene_tree_jsh["main_root"]["branches"][stringy_container]["datapoint"]["datapoint_path"])
				tree_mutex.unlock()
				datapoint = jsh_tree_get_node(datapoint_path_ray_cast)
				if datapoint:
					datapoint.thing_interaction(current_node)
				else:
					print(" i guess it didn work out ?")
			#if array_of_things_that_shall_remain != null:
				#var array_size = array_of_things_that_shall_remain[1].size()
				#if array_size > 0:
					#secondary_interaction_after_rc(array_of_things_that_shall_remain[1])
				#unload_nodes(array_of_things_that_shall_remain[0][0])
	
	#print(" do we ray cast? ")
	var line_node_now = jsh_tree_get_node("akashic_records/thing_3")
	if line_node_now:
		var start_end_points : Array = [from, to]
		#print(line_node_now.get_script())
		#print(line_node_now.has_method("change_points_of_line"))
		line_node_now.change_points_of_line(start_end_points)
		return [from, to]

# the secondary interaction after first one, right now, we used it only for unloading containers, per specific scenes, where we can pull out more than one scene, so anywhere, can also have 
# more interaction of any kind, so far i only needed that one, rest is prepared
func secondary_interaction_after_rc(array_of_data):
	var size_of_array : int = array_of_data.size()
	var counter_to_know_which : int = 0
	for interactions_to_do in array_of_data :
		var array_to_have_fun_with =  array_of_data[counter_to_know_which]
		counter_to_know_which +=1
		var counter_inter : int = 0
		for inter in InteractionsBank.type_of_interactions_0:
			if array_of_data[0][0] == inter:
				match counter_inter: # "change_scene", "add_scene", "change_text", "call_function", "unload_container"
					0: # change_scene
						counter_inter = -1
					1: # add_scene
						counter_inter = -1
					2: # change_text
						counter_inter = -1
					3: # call_function
						counter_inter = -1
					4: # unload_container
						unload_container(array_to_have_fun_with[1])
						counter_inter = -1
					5: # dunno, we dont have one yet hehe
						counter_inter = -1
			counter_inter +=1




# get node or null mate, this shit is fantastic, get something or nothing and say your prayers or something
# here we were unloading containers
func unload_container(container_to_unload):
	print(" container_to_unload : " , container_to_unload)
	cache_tree_branch_fully(container_to_unload)
	process_to_unload_records(container_to_unload)
	
	array_counting_mutex.lock()
	
	# if has branch name
	if array_for_counting_finish.has(container_to_unload):
		print(" cache branch entire contionaeir now lololo")
		array_for_counting_finish.erase(container_to_unload)
		#if array_for_counting_finish[new_path_splitter[0]].has(new_path_splitter[1]):
		#	print(" cache branch we can unload that node ", new_path_splitter[1])
		##	array_for_counting_finish[new_path_splitter[0]].erase(new_path_splitter[1])
		#else:
		#	print(" cache branch that node does not exist in that container", new_path_splitter[0])
	else:
		print(" cache branch that container does not exist")
		# if has child_name
	
	array_counting_mutex.unlock()
	
	#unload_container_from_dictionary_of_nodes(container_to_unload)

# hmm here we are unloading containers, after going from raypoint, to datapoint to check what possibilities were there
# it is faster my way
func process_to_unload_records(container_name_to_unload):
	var parts = container_name_to_unload.split("_")
	if parts.size() < 2:
		return
	var records_sets_name
	if parts.size() > 2:
		records_sets_name = parts[0] + "_" + parts[1]
	else:
		records_sets_name = parts[0]
	var counter_for_rec_ty : int = 0
	
	active_r_s_mut.lock()
	if active_record_sets[records_sets_name + "_" ].has("metadata"):
		active_record_sets[records_sets_name + "_" ]["metadata"]["container_count"] = 0
		active_r_s_mut.unlock()
		
		for records_types in BanksCombiner.combination_0:
			var record_to_unloadin = records_sets_name + "_" + BanksCombiner.data_names_0[counter_for_rec_ty]
			counter_for_rec_ty +=1
			
			unload_record_set(records_sets_name , record_to_unloadin)
			
		active_r_s_mut.lock()
		active_record_sets[records_sets_name + "_" ].erase("metadata")
		active_r_s_mut.unlock()
		
	else:
		active_r_s_mut.unlock()



#
# JSH Memories Storage
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┳┳┓         •     ┏┓             ┏┓        
#       888  `"Y8888o.   888ooooo888     ┃┃┃┏┓┏┳┓┏┓┏┓┓┏┓┏  ┗┓╋┏┓┏┓┏┓┏┓┏┓  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┛ ┗┗ ┛┗┗┗┛┛ ┗┗ ┛  ┗┛┗┗┛┛ ┗┻┗┫┗   ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                                 ┛       ┛      
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Memories Storage
#


# node unloading, we also talk with datapoint, to tell it, if and what is there? what is missing?
# datapoint is smart
# yeah it is
func unload_nodes(array_of_thingiess_that_shall_remain):
	var counter_1 : int = 0
	var counter_2 : int = 0
	var data_point_node = array_of_thingiess_that_shall_remain[1][0]
	var data_point
	var children_finder = array_of_thingiess_that_shall_remain[0][0].get_children()
	for children in children_finder:
		var thing_to_something : int = 0
		thing_to_something = 0
		for nodes_to_remain in array_of_thingiess_that_shall_remain:
			if str(children.name) == str(nodes_to_remain[0]):
				thing_to_something = 1
				break
		match thing_to_something:
			0:
				counter_1 +=1
				print("this thing shall be unloaded :)")
				print(" children  ", children)
				find_branch_to_unload(children.get_path())
				children.queue_free()
			1:
				counter_2 +=1
				if data_point_node == str(children.name):
					data_point = children
	if counter_1 <=1:
		pass
	#else:
	#	data_point.update_layer_0_after_freeing()


#
# JSH Memories Processed
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┳┳┓         •     ┏┓            ┓  ┏┓         
#       888  `"Y8888o.   888ooooo888     ┃┃┃┏┓┏┳┓┏┓┏┓┓┏┓┏  ┃┃┏┓┏┓┏┏┓┏┏┏┓┏┫  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888     ┛ ┗┗ ┛┗┗┗┛┛ ┗┗ ┛  ┣┛┛ ┗┛┗┗ ┛┛┗ ┗┻  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888                                           ┛      
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Memories Processed
#

# loading cached data! the newest chicken we have! maybe it is egg already?! as we just need name of data set, that is in active record sets
func load_cached_data(data_set: String):
	var type_of_data : int
	var records_set_name = data_set
	
	active_r_s_mut.lock()
	var cached_data_new = active_record_sets[records_set_name].duplicate(true)
	active_r_s_mut.unlock()
	
	var thing_name
	var coords_to_place
	var direction_to_place
	var thing_type_file
	var shape_name
	var root_name
	var pathway_dna
	var group_number
	var counter_to_know : int = 0
	var first_line : Array = []
	var lines_parsed : Array = []
	for data_type in BanksCombiner.combination_new_gen_0:
		counter_to_know = 0
		type_of_data = int(data_type[0])
		var type_num = data_type[0]
		var data_name = records_set_name + BanksCombiner.data_names_0[type_num]
		var file_data = cached_data_new[data_name]["content"]
		var size_of_data = file_data.size()
	
		for record in file_data:
			counter_to_know +=1
			for lines in record:
				if lines == record[0]:
					first_line = record[0]
				else:
					lines_parsed.append(lines)
			match type_of_data:
				0:
					# First
					thing_name = first_line[0][0]
					# Second
					coords_to_place = first_line[1][0]
					# Third
					direction_to_place = first_line[2][0]
					# Fourth
					thing_type_file = first_line[3][0]
					# Fifth
					shape_name = first_line[4][0]
					# Sixth
					root_name = first_line[5][0]
					# Seventh
					pathway_dna = first_line[6][0]
					# Eight
					group_number = first_line[7][0]
				1:
					pass
					#print("file loading? 1")
				2:
					pass
					#print("file loading? 2 ")
				3:
					pass
					#print("file loading? 3 " )

			match type_of_data:
				0:
					#print( "  thing_name : " , thing_name, " thing_type_file :" , thing_type_file, " metadata_parts : " , first_line, " second_line :" , lines_parsed[0],  " group_number : " , group_number, " shape_name : " , shape_name, "information_lines : " , lines_parsed)
					analise_data(thing_name, thing_type_file, first_line, lines_parsed[0], group_number, shape_name, lines_parsed)
				1:
					print("instruction stuff:")
				2: 
					print(" scenes and frames analise : ")
				3: 
					print("so we will need to add them to datapoint")
					if counter_to_know - 666 == size_of_data:
						var container_node_path = first_line[1][0]
						var container_node = get_node(container_node_path)
						var datapoint_node = container_node.get_datapoint()
						var scene_number: int = 0
						datapoint_node.move_things_around(scene_number)
			first_line.clear()
			lines_parsed.clear()


func load_cached_data_second_impact(data_set: String):
	print(" load cached data start : " , data_set)
	var type_of_data : int
	var records_set_name = data_set
	
	active_r_s_mut.lock()
	var cached_data_new = active_record_sets[records_set_name].duplicate(true)
	active_r_s_mut.unlock()
	
	var thing_name
	var coords_to_place
	var direction_to_place
	var thing_type_file
	var shape_name
	var root_name
	var pathway_dna
	var group_number

	var first_line : Array = []
	var lines_parsed : Array = []
	for data_type in BanksCombiner.combination_new_gen_1:
		type_of_data = int(data_type[0])
		var type_num = data_type[0]
		var data_name = records_set_name + BanksCombiner.data_names_0[type_num]
		var file_data = cached_data_new[data_name]["content"]
		var size_of_data = file_data.size()
		for record in file_data:
			for lines in record:
				if lines == record[0]:
					first_line = record[0]
				else:
					lines_parsed.append(lines)
			match type_of_data:
				0:
					print("newly_made_dictio here we act re se ")
				1:
#					print("instruction stuff:")
					var thingies_to_make_path = lines_parsed[0]
					var datapoint_path_l_c_d_s_i =  thingies_to_make_path[0][0] + "/" + thingies_to_make_path[1][0]
					var data_type_s_i : String = "instructions_analiser"
					
					mutex_data_to_send.lock()
					data_to_be_send.append([data_type_s_i, datapoint_path_l_c_d_s_i, thingies_to_make_path[0][0], first_line.duplicate(true), lines_parsed.duplicate(true)])
					mutex_data_to_send.unlock()

				2: 
#					print(" scenes and frames analise : ")
					var thingies_to_make_path = lines_parsed[0]
					var datapoint_path_l_c_d_s_i0 =  first_line[1][0] + "/" + first_line[2][0]
					var data_type_s_i0 : String = "scene_frame_upload"
					
					mutex_data_to_send.lock()
					data_to_be_send.append([data_type_s_i0, datapoint_path_l_c_d_s_i0, first_line[1][0], first_line.duplicate(true), lines_parsed.duplicate(true)])
					mutex_data_to_send.unlock()
					
				3: #interactions
					var datapoint_path_l_c_d_s_i1 =  first_line[1][0] + "/" + first_line[2][0]
					var data_type_s_i1 : String = "interactions_upload"

					mutex_data_to_send.lock()
					data_to_be_send.append([data_type_s_i1, datapoint_path_l_c_d_s_i1, first_line[1][0], first_line.duplicate(true), lines_parsed.duplicate(true)])
					mutex_data_to_send.unlock()

			first_line.clear()
			lines_parsed.clear()
func interactions_upload_to_datapoint(header_line, information_lines, datapoint):
	var array_of_interactions : Array = []
	var number_of_interactions = header_line.size() - 5
	var num_counter : int = 5
	for num_in in number_of_interactions:
		array_of_interactions.append(header_line[num_counter])
		num_counter +=1
	datapoint.upload_interactions(header_line[3], information_lines, array_of_interactions, number_of_interactions)


# uploading scenes to datapoint
# we first must have container and datapoint for it
func scene_frames_upload_to_datapoint(header_line, information_lines, datapointi, containeri):
	var datapoint_path = header_line[1][0] + "/" + header_line[2][0]
	var datapoint_selector = datapointi
	var new_way1 = header_line
	var new_way2 = information_lines
	datapoint_selector.upload_scenes_frames(header_line, information_lines)

func instructions_analiser(metadata_parts, second_line, third_line, datapoint, container):
	
	var type = metadata_parts[1][0]
	var counter = -1
	for i in InstructionsBank.type_of_instruction_0:
		counter +=1
		if type == i:
			break
	match counter:
		0: # 0 = "assign_priority_to_datapoint"
			datapoint.datapoint_assign_priority(third_line[0][0])
		1: # 1 = "assign_things_to_datapoint"
			datapoint.add_thing_to_datapoint(third_line)
		2: # 2 = "set_max_things_number", 
			datapoint.datapoint_max_things_number_setter(third_line[0][0])
		3: # 3 = "connect_containter_datapoint"
			container.containter_start_up(0, datapoint)
		4: # 4 = "add_things_to_container", 
			print("analise instruction 4, we didnt use it yet, probably putting containers inside containers, so we have like, easy way to use scenes system :)")
		5: # 5 = "set_the_scene", 
			var scene_setter_number = int(third_line[0][0])
			datapoint.scene_to_set_number_later(scene_setter_number)
		6: # 6 = "rotate_container", 
			#container.rotation.x -= deg_to_rad(int(third_line[1][0]))
			var type_of_stuff : String = "rotate"
			the_fourth_dimensional_magic(type_of_stuff, container, int(third_line[1][0]))
			
		7: # 7 = "setup_text_bracet"
			var action_function_type : String = "single_function"
			var name_of_function : String = "setup_text_handling"
			sixth_dimensional_magic(action_function_type, datapoint, name_of_function)
			#datapoint.setup_text_handling() # = get_node(database_node_path)
		8: #
			#print(" interaction single multi mode or whatever" , third_line[0][0] , third_line[1][0])
			datapoint.set_maximum_interaction_number(third_line[0][0], int(third_line[1][0]))
			
		9: #move_container
			print(" move container " , third_line)
			var x = float(third_line[1][0])  # "0.0"
			var y = float(third_line[1][1])  # "-4.5"
			var z = float(third_line[1][2])  # "0.41"
			var new_position = Vector3(x, y, z)
			var type_of_stuff : String = "move"
			the_fourth_dimensional_magic(type_of_stuff, container, new_position)
			#container.position = Vector3(x, y, z)
		10:
			print(" load_file ")
			datapoint.initialize_loading_file(third_line)
			

# here we instead just called datapoint we pulled out, if we wanna add additional things, i guess we can just add stuff here and call it
func assign_things_to_datapoint():
	pass


#
# JSH Things Creation
#
#      oooo  .oooooo..o ooooo   ooooo 
#      `888 d8P'    `Y8 `888'   `888' 
#       888 Y88bo.       888     888     ┏┳┓┓ •       ┏┓       •      ┏┓        
#       888  `"Y8888o.   888ooooo888      ┃ ┣┓┓┏┓┏┓┏  ┃ ┏┓┏┓┏┓╋┓┏┓┏┓  ┗┓┓┏┏╋┏┓┏┳┓
#       888      `"Y88b  888     888      ┻ ┛┗┗┛┗┗┫┛  ┗┛┛ ┗ ┗┻┗┗┗┛┛┗  ┗┛┗┫┛┗┗ ┛┗┗
#       888 oo     .d8P  888     888              ┛                      ┛       
#   .o. 88P 8""88888P'  o888o   o888o 
#   `Y888P                            
#
# JSH Things Creation
#

#analise_data(thing_name, thing_type, metadata_parts, second_line)
# analise loaded and parsed data, for things creation!
#manifesting visual periphelia
func analise_data(thing_name_, type, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed):
	var counter = -1
	for i in RecordsBank.type_of_thing_0:
		counter +=1
		
		if type == i:
			break
		else:
			continue

	match counter:
		0:
			create_flat_shape(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		1:
			create_text_label(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		2:
			create_array_mesh(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed) 
		3:
			create_button(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		4:
			create_cursor(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		5:
			create_connection(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		6:
			create_screen(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		7:
			create_datapoint(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		8:
			create_circle_shape(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		9:
			create_container(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		10:
			create_textmesh(thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed)
		_:  
			print("hmmm didnt find the type of thing?")

# creating circle

# Example usage:
# here we are generating points in circular shape, for flat shape thingy
func create_circle_shape(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var coords = first_line[1]
	var to_rotate = first_line[2]
	var radius = data_to_write[0]
	var num_points = data_to_write[1]
	var points = generate_circle_points(int(radius[0]), int(num_points[0]))
	# Create the shape using your existing create_flat_shape function
	create_flat_shape(node_name, first_line, points, group_name, version_of_thing, information_lines_parsed)

# i mean here, before we mostly take data, and send it here and to flat shape later
func generate_circle_points(radius: float, num_points: int) -> Array:
	# Ensure minimum 3 points and maximum 33 points
	num_points = clamp(num_points, 3, 33)
	var points_to_clean
	var points = []
	var points_array = []
	var angle_step = TAU / num_points  # TAU is 2*PI, for a full circle
	
	for i in range(num_points):
		var angle = i * angle_step
		# Calculate point position using sin/cos
		var x : float = radius * cos(angle)
		var y : float = radius * sin(angle)
		var z : float
		# Format the point as a string like your other shape points
		points_to_clean = "%0.1f,%0.1f,0.0" % [x, y]
		points_to_clean = points_to_clean.split(",")
		points.append(points_to_clean)
	return points


# here we make flat shape, an center point, is main, 0 vertice
# thing_name_, data_to_analyze, second_part, group_number, verion_of_thing, information_lines_parsed
func create_flat_shape(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_f_s = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]
	var color_to_change = float(information_lines_parsed[1][0][0])
	var opacity_to_change = float(information_lines_parsed[1][1][0])
	var material = StandardMaterial3D.new()
	var color_to_add_op = get_spectrum_color(color_to_change)
	color_to_add_op.a = opacity_to_change
	material.albedo_color = color_to_add_op
	material.transparency = BaseMaterial3D.TRANSPARENCY_ALPHA_SCISSOR
	#mesh_instance.material_override = material
	var vertices = PackedVector3Array()
	var indices = PackedInt32Array()
	
	# Add center as first vertex
	vertices.push_back(Vector3.ZERO)  # Index 0 is center
	# Convert data points to Vector3s
	var vector_points = []
	for point in data_to_write:
		var point_vector = Vector3(float(point[0]), float(point[1]), float(point[2]))
		vector_points.append(point_vector)
		vertices.push_back(point_vector)
	for i in range(vector_points.size()):
		var next_i = (i + 1) % vector_points.size()
		indices.append(0)              # Center point
		indices.append(i + 1)          # Current vertex (add 1 because center is at 0)
		indices.append(next_i + 1)     # Next vertex (add 1 because center is at 0)
	
	# Create mesh
	var arr_mesh = ArrayMesh.new()
	var arrays = []
	arrays.resize(Mesh.ARRAY_MAX)
	arrays[Mesh.ARRAY_VERTEX] = vertices
	arrays[Mesh.ARRAY_INDEX] = indices
	
	arr_mesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, arrays)
	
	# Create mesh instance
	var mesh_instance = MeshInstance3D.new()
	mesh_instance.mesh = arr_mesh
	
	material.cull_mode = BaseMaterial3D.CULL_DISABLED # Visible from both sides
	var node_type = "flat_shape"
	
	mesh_instance.material_override = material
	node_creation(node_name, mesh_instance, coords, to_rotate, group_name, node_type, node_path_c_f_s)
#endregion

# normal text label, with normal font
# Create Label3D with text
#region create_text_label
func create_text_label(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_t_l = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]
	# Create Label3D node
	var text_label = Label3D.new()
	
	# Set the text from data (first element of first array)
	text_label.text = data_to_write[0][0]  # This will get "Akashic_Records"
	
	# Optional: Set font size (from second element of second array)
	text_label.font_size = int(data_to_write[1][0])  # This will get "33"
	text_label.no_depth_test = true  # Ensures text is always visible
	text_label.modulate = Color(1, 1, 1)  # White color
	
	# Now send the configured Label3D to node_creation
	var node_type = "text"
	node_creation(node_name, text_label, coords, to_rotate, group_name, node_type, node_path_c_t_l)


# here we make array mesh, i call it models, i guess it is similar to flat shape? with a difference that it does not have center point 
func create_array_mesh(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_a_m = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]

	var color_to_change = float(information_lines_parsed[1][0][0])
	var opacity_to_change = float(information_lines_parsed[1][1][0])
	
	var vertices = PackedVector3Array()
	var vector_points = []
	for point in data_to_write:
		vector_points.append(Vector3(float(point[0]), float(point[1]), float(point[2])))
	
	# Create triangles
	vertices.append(vector_points[0])
	vertices.append(vector_points[2])
	vertices.append(vector_points[1])
	
	vertices.append(vector_points[0])
	vertices.append(vector_points[3])
	vertices.append(vector_points[2])

	var arr_mesh = ArrayMesh.new()
	var arrays = []
	arrays.resize(Mesh.ARRAY_MAX)
	arrays[Mesh.ARRAY_VERTEX] = vertices
	
	arr_mesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, arrays)
	
	# Create mesh instance and set properties
	var mesh_instance = MeshInstance3D.new()
	mesh_instance.mesh = arr_mesh
	
	var material = StandardMaterial3D.new()
	var color_to_add_op = get_spectrum_color(color_to_change)
	color_to_add_op.a = opacity_to_change
	material.albedo_color = color_to_add_op
	material.transparency = BaseMaterial3D.TRANSPARENCY_ALPHA_SCISSOR
	mesh_instance.material_override = material
	var node_type = "model"
	node_creation(node_name, mesh_instance, coords, to_rotate, group_name, node_type, node_path_c_a_m)

# the fantastic thingy! like the gmod error thingy xD
func create_textmesh(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_tm = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]

	var text_for_label = information_lines_parsed[1][0][0]
	var size_for_label = int(information_lines_parsed[1][1][0])
	var depth = float(information_lines_parsed[1][2][0])
	var pixel_size = float(information_lines_parsed[1][3][0])

	var color_to_change = float(information_lines_parsed[1][4][0])
	var opacity_to_change = float(information_lines_parsed[1][5][0])

	var material = StandardMaterial3D.new()
	var color_to_add_op = get_spectrum_color(color_to_change)
	color_to_add_op.a = opacity_to_change
	material.albedo_color = color_to_add_op
	material.transparency = BaseMaterial3D.TRANSPARENCY_ALPHA_DEPTH_PRE_PASS

	
#	var material = StandardMaterial3D.new()
	var mesh_instance = MeshInstance3D.new()
	var text_mesh = TextMesh.new()
	text_mesh.text = text_for_label
	text_mesh.font_size = size_for_label
	text_mesh.depth = depth
	text_mesh.pixel_size = pixel_size
	text_mesh.horizontal_alignment = 1
	text_mesh.vertical_alignment = 1
	
	mesh_instance.mesh = text_mesh
	mesh_instance.name = node_name
	material.cull_mode = BaseMaterial3D.CULL_DISABLED
	
	if text_for_label == "JSH":
		material.metallic = 1.0
		material.metallic_specular = 0.52
		material.roughness = 0.33
	
	mesh_instance.material_override = material
	
	var node_type = "textmesh"
	node_creation(node_name, mesh_instance, coords, to_rotate, group_name, node_type, node_path_c_tm)


# here we are making buttons! just normal shape, a model, and a label, in one node :) it also has collision shape on model
func create_button(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_b = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]
	
	var mesh_name = "shape_" + node_name 
	var text_label_name = "text_" + node_name

	var color_to_change = float(information_lines_parsed[1][2][0])
	var opacity_to_change = float(information_lines_parsed[1][3][0])

	var material = StandardMaterial3D.new()
	var color_to_add_op = get_spectrum_color(color_to_change)
	color_to_add_op.a = opacity_to_change
	material.albedo_color = color_to_add_op
	material.transparency = BaseMaterial3D.TRANSPARENCY_ALPHA_SCISSOR
	var text_for_label = information_lines_parsed[1][0][0]
	var size_for_label = int(information_lines_parsed[1][1][0])
	
	var button_node = Node3D.new()
	button_node.name = node_name
	tasked_children(button_node, node_path_c_b)
	# Create the flat shape (background)
	var vertices = PackedVector3Array()
	var indices = PackedInt32Array()
	
	# Convert shape data points to Vector3s
	var vector_points = []
	for point in data_to_write:  # First array contains shape points
		var point_vector = Vector3(float(point[0]), float(point[1]), float(point[2]))
		vector_points.append(point_vector)
		vertices.push_back(point_vector)
	
	# Create triangles for the flat shape
	indices.append(0)  # First triangle
	indices.append(1)
	indices.append(2)
	
	indices.append(0)  # Second triangle
	indices.append(2)
	indices.append(3)
	
	# Create mesh for the shape
	var arr_mesh = ArrayMesh.new()
	var arrays = []
	arrays.resize(Mesh.ARRAY_MAX)
	arrays[Mesh.ARRAY_VERTEX] = vertices
	arrays[Mesh.ARRAY_INDEX] = indices
	
	arr_mesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, arrays)
	
	# Create mesh instance for the shape
	var mesh_instance = MeshInstance3D.new()
	mesh_instance.mesh = arr_mesh
	mesh_instance.name = mesh_name
	
	material.cull_mode = BaseMaterial3D.CULL_DISABLED
	mesh_instance.material_override = material
	
	# Create Label3D for the text
	var text_label = Label3D.new()
	text_label.name = text_label_name
	text_label.text = text_for_label
	text_label.font_size = size_for_label
	text_label.no_depth_test = true
	text_label.modulate = Color(1, 1, 1)  # White text
	text_label.position.z += 0.01  # Slight offset to prevent z-fighting
	
	var mesh_path = node_path_c_b + "/" + mesh_name
	var label_path = node_path_c_b + "/" + text_label_name
	tasked_children(text_label, label_path)
	# Use existing node creation for final setup
	var node_type = "button"
	node_creation(mesh_name, mesh_instance, coords, to_rotate, group_name, node_type, mesh_path)


# just normal three vertices triangle :)
# i wanna make mouse and moouse curson in vr and use hand tracking because!
# i can do it!
func create_cursor(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_c_0 = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]

	var color_to_change = float(information_lines_parsed[1][0][0])
	var opacity_to_change = float(information_lines_parsed[1][1][0])

	var material = StandardMaterial3D.new()
	var color_to_add_op = get_spectrum_color(color_to_change)
	color_to_add_op.a = opacity_to_change
	material.albedo_color = color_to_add_op
	material.transparency = BaseMaterial3D.TRANSPARENCY_ALPHA_SCISSOR
	
	var vertices = PackedVector3Array()
	var triangle_data = [data_to_write[0], data_to_write[1], data_to_write[2]]
	var triangle_scale = data_to_write[3]#cursor_thingy[3] 
	
	var triangle_scale_vec3 : Vector3 = Vector3(float(triangle_scale[0]), float(triangle_scale[1]), float(triangle_scale[2]))
	var vector_points = []
	for point in triangle_data:
		vector_points.append(Vector3(float(point[0]), float(point[1]), float(point[2])))
	
	# Create triangles
	vertices.append(vector_points[0])
	vertices.append(vector_points[1])
	vertices.append(vector_points[2])
	
	var arr_mesh = ArrayMesh.new()
	var arrays = []
	arrays.resize(Mesh.ARRAY_MAX)
	arrays[Mesh.ARRAY_VERTEX] = vertices
	
	arr_mesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, arrays)
	
	# Create mesh instance and set properties
	var mesh_instance = MeshInstance3D.new()
	mesh_instance.mesh = arr_mesh
	mesh_instance.scale = triangle_scale_vec3
	
	material.cull_mode = StandardMaterial3D.CULL_DISABLED  # This makes it visible from both sides
	material.shading_mode = BaseMaterial3D.SHADING_MODE_UNSHADED  # Optional: makes it look flat

	
	mesh_instance.material_override = material
	var node_type = "cursor"
	node_creation(node_name, mesh_instance, coords, to_rotate, group_name, node_type, node_path_c_c_0)


# here we are making lines! we need two points between something, to make the lines
func create_connection(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_cc_c = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]
	var cords_for_line = [data_to_write[0], data_to_write[1]]
	var color_for_line = data_to_write[2][0]
	
	# Convert the line endpoints from data_to_write
	var point1 = Vector3(
		float(cords_for_line[0][0]),
		float(cords_for_line[0][1]),
		float(cords_for_line[0][2])
	)
	
	var point2 = Vector3(
		float(cords_for_line[1][0]),
		float(cords_for_line[1][1]),
		float(cords_for_line[1][2])
	)

	var center = point1 + point2 / 2
	# Create the lines
	var mesh_instance = MeshInstance3D.new()
	var immediate_mesh = ImmediateMesh.new()
	mesh_instance.mesh = immediate_mesh
	mesh_instance.name = node_name
	
	# Set up material
	var material = StandardMaterial3D.new()
	material.shading_mode = StandardMaterial3D.SHADING_MODE_UNSHADED
	var color_line = float(data_to_write[2][0])
	material.albedo_color = get_spectrum_color(color_line)
	mesh_instance.material_override = material
	
	# Draw the lines
	immediate_mesh.surface_begin(Mesh.PRIMITIVE_LINES)
	
	# Line from point1 to center
	immediate_mesh.surface_add_vertex(point1 + center)
	immediate_mesh.surface_add_vertex(center)
	
	# Line from center to point2
	immediate_mesh.surface_add_vertex(center)
	immediate_mesh.surface_add_vertex(point2 + center)
	
	immediate_mesh.surface_end()
	
	mesh_instance.set_script(LineScript)
	var node_type = "connection"
	node_creation(node_name, mesh_instance, coords, to_rotate, group_name, node_type, node_path_cc_c)


# creating screen, it is just an 4 vertices point thingy
func create_screen(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_s = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]

	var color_to_change = float(information_lines_parsed[1][0][0])
	var opacity_to_change = float(information_lines_parsed[1][1][0])
	
	var material = StandardMaterial3D.new()
	var color_to_add_op = get_spectrum_color(color_to_change)
	color_to_add_op.a = opacity_to_change
	material.albedo_color = color_to_add_op
	material.transparency = BaseMaterial3D.TRANSPARENCY_ALPHA_DEPTH_PRE_PASS

	var vertices = PackedVector3Array()

	var vector_points = []
	for point in data_to_write:
		vector_points.append(Vector3(float(point[0]), float(point[1]), float(point[2])))
	
	# Create triangles
	vertices.append(vector_points[0])
	vertices.append(vector_points[2])
	vertices.append(vector_points[1])
	
	vertices.append(vector_points[0])
	vertices.append(vector_points[3])
	vertices.append(vector_points[2])

	var arr_mesh = ArrayMesh.new()
	var arrays = []
	arrays.resize(Mesh.ARRAY_MAX)
	arrays[Mesh.ARRAY_VERTEX] = vertices
	
	arr_mesh.add_surface_from_arrays(Mesh.PRIMITIVE_TRIANGLES, arrays)
	
	# Create mesh instance and set properties
	var mesh_instance = MeshInstance3D.new()
	mesh_instance.mesh = arr_mesh
	mesh_instance.material_override = material
	var node_type =  "screen"
	node_creation(node_name, mesh_instance, coords, to_rotate, group_name, node_type, node_path_c_s)


# datapoint creation! one of the nodes i really like :)
func create_datapoint(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_dp = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]
	var data_point = Node3D.new()
	data_point.set_script(DataPointScript)
	data_point.setup_main_reference(self)
	
	var message_tester 
	message_tester = data_point.power_up_data_point(node_name, int(version_of_thing), data_to_write)
	var node_type = "datapoint"
	node_creation(node_name, data_point, coords, to_rotate, group_name, node_type, node_path_c_dp)


# the container thingy
func create_container(node_name: String, first_line : Array, data_to_write : Array, group_name : String, version_of_thing : String, information_lines_parsed : Array):
	var node_path_c_con = first_line[6][0]
	var coords = first_line[1]
	var to_rotate = first_line[2]
	var container 
	container = Node3D.new()
	
	container.name = data_to_write[0][0]
	container.set_script(ContainterScript)
		# Add initialization with data_to_write if needed
	if container.has_method("container_initialize"):
		container.container_initialize(data_to_write)

	var node_type = "container"
	node_creation(data_to_write[0][0], container, coords, to_rotate, group_name, node_type, node_path_c_con)


# this is one of my ideas of how to make nice color slider, black to white to black to colors, so we got all colors kinda, like stars too, and at beginning we just have black to white hole stuff :)
func get_spectrum_color(value: float) -> Color:
	# Ensure value is between 0 and 1
	value = clamp(value, 0.0, 1.0)
	
	# Map 0-1 to our 9 color points
	var color_index = value * 10  # 10 segments for 11 colors
	
	# Define our color points
	var colors = [
		Color(0.0, 0.0, 0.0),      # 1. Black
		Color(1.0, 1.0, 1.0),      # 2. White
		Color(0.0, 0.0, 0.0),      # 3. Black
		Color(0.45, 0.25, 0.0),    # 4. Brown
		Color(1.0, 0.0, 0.0),      # 5. Red
		Color(1.0, 0.5, 0.0),      # 6. Orange
		Color(1.0, 1.0, 0.0),      # 7. Yellow
		Color(1.0, 1.0, 1.0),      # 8. White
		Color(0.0, 1.0, 0.0),      # 9. Green
		Color(0.0, 0.0, 1.0),      # 10. Blue
		Color(0.5, 0.0, 0.5)       # 11. Purple
	]
	
	# Find the two colors to interpolate between
	var lower_index = floor(color_index)
	var upper_index = ceil(color_index)
	
	# Get interpolation factor between these two colors
	var t = color_index - lower_index
	return colors[lower_index].lerp(colors[min(upper_index, 8)], t)

#
# JSH Scene Tree Add Nodes, Physical and Astral Bodies
#
#      oooo  .oooooo..o ooooo   ooooo      ┏┓         ┏┳┓        ┏┓ ┓ ┓  ┳┓   ┓     
#      `888 d8P'    `Y8 `888'   `888'      ┗┓┏┏┓┏┓┏┓   ┃ ┏┓┏┓┏┓  ┣┫┏┫┏┫  ┃┃┏┓┏┫┏┓┏   
#       888 Y88bo.       888     888       ┗┛┗┗ ┛┗┗    ┻ ┛ ┗ ┗   ┛┗┗┻┗┻  ┛┗┗┛┗┻┗ ┛   
#       888  `"Y8888o.   888ooooo888      ┏┓┓    •   ┓       ┓  ┏┓      ┓  ┳┓   ┓•  
#       888      `"Y88b  888     888      ┃┃┣┓┓┏┏┓┏┏┓┃  ┏┓┏┓┏┫  ┣┫┏╋┏┓┏┓┃  ┣┫┏┓┏┫┓┏┓┏
#       888 oo     .d8P  888     888      ┣┛┛┗┗┫┛┗┗┗┻┗  ┗┻┛┗┗┻  ┛┗┛┗┛ ┗┻┗  ┻┛┗┛┗┻┗┗ ┛
#   .o. 88P 8""88888P'  o888o   o888o          ┛                        
#   `Y888P                            
#
# JSH Scene Tree Add Nodes, Physical and Astral Bodies, also Sprit bodies ;)
#

# the node creation part! here we are putting nodes, wait a minute, we done it in buttons too? are we retarded or somethin?
func node_creation(node_name, crafted_data, coords, to_rotate, group_number, node_type, path_of_thing):
	crafted_data.add_to_group(group_number)
	var pos_parts = coords
	var position_ = Vector3(float(pos_parts[0]), float(pos_parts[1]), float(pos_parts[2]))
	crafted_data.position = position_
	
	# Set rotation
	var rot_parts = to_rotate
	var rotation_euler = Vector3(float(rot_parts[0]), float(rot_parts[1]), float(rot_parts[2]))
	crafted_data.rotation_degrees = rotation_euler
	# Set name if provided
	if node_name != "":
		crafted_data.name = node_name
		
	tasked_children(crafted_data, path_of_thing)
	
	match node_type:
		"flat_shape", "model", "cursor", "screen", "circle", "button" :
			add_collision_to_thing(crafted_data, node_type, path_of_thing, node_name)
		_:
			pass
	
	return crafted_data


# here we add collision shapes to things
func add_collision_to_thing(thing_node, node_type, path_of_thingy, name_of_thingy):
	# First add the regular flat collision
	
	# static_body
	var static_body_name = "collision_" + name_of_thingy 
	var static_body_path = path_of_thingy + "/" + static_body_name
	
	var static_body = StaticBody3D.new()
	static_body.name = static_body_name
	
	# collision_shape
	var shape_name = "shape_" + name_of_thingy 
	var collision_shape_path = static_body_path + "/"  + shape_name
	
	var collision_shape = CollisionShape3D.new()
	collision_shape.name = shape_name
	
	# area
	var area_name = "aura_" + name_of_thingy 
	var area_node_path = path_of_thingy + "/" + area_name
	
	var area = Area3D.new()
	area.name = area_name
	
	# area_collision_shape it trully is aura!
	var collision_area = "collision_aura_" + name_of_thingy
	var collision_area_path = area_node_path + "/" + collision_area
	
	var area_collision_shape = CollisionShape3D.new()
	area_collision_shape.name = collision_area

	# Get mesh data to determine shape size
	var mesh_instance = thing_node as MeshInstance3D
	if mesh_instance and mesh_instance.mesh:
		var aabb = mesh_instance.mesh.get_aabb()
		
		match node_type:
			"flat_shape", "model", "button", "cursor", "screen", "circle":
				# Create flat collision shape for StaticBody
				var flat_shape = ConvexPolygonShape3D.new()
				var vertices = mesh_instance.mesh.get_faces()
				flat_shape.points = vertices
				collision_shape.shape = flat_shape
				
				# Create larger shape for Area3D
				var area_shape = ConvexPolygonShape3D.new()
				var expanded_vertices = PackedVector3Array()
				
				# Create expanded version of vertices for area
				var expansion_distance = 0.2  # Distance to expand in all directions
				# Expand in all directions by adding vertices offset in +/- x, y, z
				for vert in vertices:
					# Positive directions
					expanded_vertices.push_back(vert + Vector3(expansion_distance, expansion_distance, expansion_distance))
					expanded_vertices.push_back(vert + Vector3(expansion_distance, expansion_distance, -expansion_distance))
					expanded_vertices.push_back(vert + Vector3(expansion_distance, -expansion_distance, expansion_distance))
					expanded_vertices.push_back(vert + Vector3(-expansion_distance, expansion_distance, expansion_distance))
					# Negative directions
					expanded_vertices.push_back(vert + Vector3(-expansion_distance, -expansion_distance, -expansion_distance))
					expanded_vertices.push_back(vert + Vector3(-expansion_distance, -expansion_distance, expansion_distance))
					expanded_vertices.push_back(vert + Vector3(-expansion_distance, expansion_distance, -expansion_distance))
					expanded_vertices.push_back(vert + Vector3(expansion_distance, -expansion_distance, -expansion_distance))
				
				area_shape.points = expanded_vertices
				area_collision_shape.shape = area_shape
				
			"heightmap":
				# Create flat collision shape for StaticBody
				var flat_shape = ConvexPolygonShape3D.new()
				var vertices = mesh_instance.mesh.get_faces()
				flat_shape.points = vertices
				collision_shape.shape = flat_shape
				
				# Create larger shape for Area3D
				var area_shape = ConvexPolygonShape3D.new()
				var expanded_vertices = PackedVector3Array()
				
				# Create expanded version of vertices for area
				var expansion_distance = 0.2  # Distance above and below the surface
				for vert in vertices:
					expanded_vertices.push_back(vert + Vector3(0, expansion_distance, 0))
				for vert in vertices:
					expanded_vertices.push_back(vert - Vector3(0, expansion_distance, 0))
				
				area_shape.points = expanded_vertices
				area_collision_shape.shape = area_shape
			_: # Default fallback
				return
	
	# Configure collision properties
	static_body.collision_layer = 1
	static_body.collision_mask = 1
	
	area.collision_layer = 2  # Using different layer for area detection
	area.collision_mask = 2   # Adjust these values based on your needs

	tasked_children(static_body, static_body_path)
	tasked_children(collision_shape, collision_shape_path)
	tasked_children(area, area_node_path)
	tasked_children(area_collision_shape, collision_area_path)
